file;linedbasedConf
/home/taes/taes/projects/jodd/revisions/rev_fec02fa_d3a363b/rev_fec02fa-d3a363b/jodd-petite/src/main/java/jodd/petite/PetiteContainer.java;<<<<<<< MINE
 * <ul>
 * <li>PetiteContainer - top layer that provides business usage</li>
 * <li>{@link PetiteRegistry}</li>
 * <li>{@link PetiteBeans}</li>
 * </ul>
=======
 * <ul>
 * <li>PetiteContainer - top layer that provides business usage methods
 * <li>{@link PetiteRegistry} - beans storage methods
 * <li>{@link PetiteBeans} - base layer for storing beans in scopes
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_fec02fa_d3a363b/rev_fec02fa-d3a363b/jodd-petite/src/main/java/jodd/petite/PetiteBeans.java;<<<<<<< MINE
	 * <ul>
	 * <li>if name is missing, it will be resolved from the class (name or annotation)</li>
	 * <li>if wiring mode is missing, it will be resolved from the class (annotation or default one)</li>
	 * <li>if scope type is missing, it will be resolved from the class (annotation or default one)</li>
	 * </ul>
=======
	 * <ul>
	 * <li>if name is missing, it will be resolved from the class (name or annotation)
	 * <li>if wiring mode is missing, it will be resolved from the class (annotation or default one)
	 * <li>if scope type is missing, it will be resolved from the class (annotation or default one)
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_fc5104c_379a202/rev_fc5104c-379a202/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/gadget/portlet/BaseGadgetPortlet.java;<<<<<<< MINE
=======
import com.liferay.portal.model.ResourceConstants;
import com.liferay.portal.model.Role;
import com.liferay.portal.model.RoleConstants;
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_fc5104c_379a202/rev_fc5104c-379a202/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/gadget/portlet/BaseGadgetPortlet.java;<<<<<<< MINE
=======
import com.liferay.portal.security.permission.ActionKeys;
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_fc5104c_379a202/rev_fc5104c-379a202/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/gadget/portlet/BaseGadgetPortlet.java;<<<<<<< MINE
=======
import com.liferay.portal.service.ResourcePermissionLocalServiceUtil;
import com.liferay.portal.service.RoleLocalServiceUtil;
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_fc5104c_379a202/rev_fc5104c-379a202/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/gadget/portlet/BaseGadgetPortlet.java;<<<<<<< MINE
=======
import com.liferay.portlet.expando.model.ExpandoColumn;
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_fc5104c_379a202/rev_fc5104c-379a202/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/gadget/portlet/BaseGadgetPortlet.java;<<<<<<< MINE
			ExpandoColumnLocalServiceUtil.addColumn(
				expandoTable.getTableId(), columnName,
				ExpandoColumnConstants.STRING);
=======
			ExpandoColumn expandoColumn =
				ExpandoColumnLocalServiceUtil.addColumn(
					expandoTable.getTableId(), columnName,
					ExpandoColumnConstants.STRING);

			Role role = RoleLocalServiceUtil.getRole(
				expandoColumn.getCompanyId(), RoleConstants.USER);

			ResourcePermissionLocalServiceUtil.setResourcePermissions(
				expandoColumn.getCompanyId(), ExpandoColumn.class.getName(),
				ResourceConstants.SCOPE_INDIVIDUAL,
				String.valueOf(expandoColumn.getColumnId()), role.getRoleId(),
				new String[] {ActionKeys.UPDATE, ActionKeys.VIEW});
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_f1160f3_1e333eb/rev_f1160f3-1e333eb/ribbon-core/src/main/java/com/netflix/loadbalancer/BaseLoadBalancer.java;<<<<<<< MINE
import com.netflix.niws.client.ClientFactory;
import com.netflix.niws.client.NIWSClientException;
=======
import com.netflix.niws.client.NiwsClientConfig;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_f1160f3_1e333eb/rev_f1160f3-1e333eb/ribbon-core/src/main/java/com/netflix/loadbalancer/BaseLoadBalancer.java;<<<<<<< MINE
import com.netflix.niws.client.NiwsClientConfig.NiwsClientConfigKey;
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_f1160f3_1e333eb/rev_f1160f3-1e333eb/ribbon-core/src/main/java/com/netflix/loadbalancer/AbstractLoadBalancer.java;<<<<<<< MINE
import com.netflix.niws.client.IClientConfigAware;

=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_f1160f3_1e333eb/rev_f1160f3-1e333eb/ribbon-core/src/main/java/com/netflix/niws/client/AbstractLoadBalancerAwareClient.java;<<<<<<< MINE
import com.netflix.niws.client.NiwsClientConfig.NiwsClientConfigKey;
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_f1160f3_1e333eb/rev_f1160f3-1e333eb/ribbon-core/src/main/java/com/netflix/niws/client/NiwsClientConfig.java;<<<<<<< MINE
=======
/*
*
* Copyright 2013 Netflix, Inc.
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
* http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*
*/
package com.netflix.niws.client;

import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.TimeUnit;

import org.apache.commons.configuration.AbstractConfiguration;
import org.apache.commons.configuration.Configuration;
import org.apache.commons.lang.StringUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.base.Strings;
import com.netflix.config.AbstractDynamicPropertyListener;
import com.netflix.config.ConfigurationManager;
import com.netflix.config.DynamicPropertyFactory;
import com.netflix.config.DynamicStringProperty;
import com.netflix.config.ExpandedConfigurationListenerAdapter;
import com.netflix.config.util.HttpVerbUriRegexPropertyValue;
import com.netflix.loadbalancer.DummyPing;
import com.netflix.niws.VipAddressResolver;

/**
 * Class that holds the NIWS Client Configuration to be used for <code>{@link RestClient}</code>)
 * @author Sudhir Tonse <stonse@netflix.com>
 *
 */
public class NiwsClientConfig implements IClientConfig {

    public static final Boolean DEFAULT_PRIORITIZE_VIP_ADDRESS_BASED_SERVERS = Boolean.TRUE;

    public static final String DEFAULT_NFLOADBALANCER_PING_CLASSNAME = DummyPing.class.getName();

    public static final String DEFAULT_NFLOADBALANCER_RULE_CLASSNAME = com.netflix.niws.client.AvailabilityFilteringRule.class.getName();

    public static final String DEFAULT_NFLOADBALANCER_CLASSNAME = com.netflix.niws.client.ZoneAwareNIWSDiscoveryLoadBalancer.class.getName();
    
    public static final String DEFAULT_CLIENT_CLASSNAME = "com.netflix.niws.client.http.RestClient";
    
    public static final String DEFAULT_VIPADDRESS_RESOLVER_CLASSNAME = com.netflix.niws.SimpleVipAddressResolver.class.getName();

    public static final String DEFAULT_PRIME_CONNECTIONS_URI = "/";

    public static final int DEFAULT_MAX_TOTAL_TIME_TO_PRIME_CONNECTIONS = 30*1000;

    public static final int DEFAULT_MAX_RETRIES_PER_SERVER_PRIME_CONNECTION = 2;

    public static final Boolean DEFAULT_ENABLE_PRIME_CONNECTIONS = Boolean.FALSE;

    public static final int DEFAULT_MAX_REQUESTS_ALLOWED_PER_WINDOW = Integer.MAX_VALUE;

    public static final int DEFAULT_REQUEST_THROTTLING_WINDOW_IN_MILLIS = 60*1000;

    public static final Boolean DEFAULT_ENABLE_REQUEST_THROTTLING = Boolean.FALSE;

    public static final Boolean DEFAULT_ENABLE_GZIP_CONTENT_ENCODING_FILTER = Boolean.FALSE;

    public static final Boolean DEFAULT_CONNECTION_POOL_CLEANER_TASK_ENABLED = Boolean.TRUE;

    public static final Boolean DEFAULT_FOLLOW_REDIRECTS = Boolean.TRUE;

    public static final float DEFAULT_PERCENTAGE_NIWS_EVENT_LOGGED = 0.0f;

    public static final int DEFAULT_MAX_AUTO_RETRIES_NEXT_SERVER = 0;

    public static final int DEFAULT_MAX_AUTO_RETRIES = 0;

    public static final int DEFAULT_READ_TIMEOUT = 5000;

    public static final int DEFAULT_CONNECTION_MANAGER_TIMEOUT = 2000;

    public static final int DEFAULT_CONNECT_TIMEOUT = 2000;

    public static final int DEFAULT_MAX_HTTP_CONNECTIONS_PER_HOST = 50;

    public static final int DEFAULT_MAX_TOTAL_HTTP_CONNECTIONS = 200;
    
    public static final Boolean DEFAULT_ENABLE_NIWSSTATS = Boolean.TRUE;
    
    public static final Boolean DEFAULT_ENABLE_NIWSERRORSTATS = Boolean.TRUE;
    
    public static final Boolean DEFAULT_USE_HTTP_CLIENT4 = Boolean.FALSE;
    
    public static final float DEFAULT_MIN_PRIME_CONNECTIONS_RATIO = 1.0f;
    
    public static final String DEFAULT_PRIME_CONNECTIONS_CLASS = "com.netflix.niws.client.HttpPrimeConnection";
    
    public static final String DEFAULT_SEVER_LIST_CLASS = "com.netflix.niws.client.DiscoveryEnabledNIWSServerList";
    
    public static final int DEFAULT_CONNECTION_IDLE_TIMERTASK_REPEAT_IN_MSECS = 30*1000; // every half minute (30 secs)
    
    public static final int DEFAULT_CONNECTIONIDLE_TIME_IN_MSECS = 30*1000; // all connections idle for 30 secs


    
    volatile Map<String, Object> properties = new ConcurrentHashMap<String, Object>();
    
    private static final Logger LOG = LoggerFactory.getLogger(NiwsClientConfig.class);

    private String clientName = null;
    
    private VipAddressResolver resolver = null;

    private boolean enableDynamicProperties = true;
    /**
     * Defaults for the parameters for the thread pool used by batchParallel
     * calls
     */
    public static final int DEFAULT_POOL_MAX_THREADS = DEFAULT_MAX_TOTAL_HTTP_CONNECTIONS;
    public static final int DEFAULT_POOL_MIN_THREADS = 1;
    public static final long DEFAULT_POOL_KEEP_ALIVE_TIME = 15 * 60L;
    public static final TimeUnit DEFAULT_POOL_KEEP_ALIVE_TIME_UNITS = TimeUnit.SECONDS;
    public static final Boolean DEFAULT_ENABLE_ZONE_AFFINITY = Boolean.FALSE;
    public static final Boolean DEFAULT_ENABLE_ZONE_EXCLUSIVITY = Boolean.FALSE;
    public static final int DEFAULT_PORT = 7001;
    public static final Boolean DEFAULT_ENABLE_LOADBALANCER = Boolean.TRUE;

    private static final String PROPERTY_NAMESPACE = "niws.client";

    public static final Boolean DEFAULT_OK_TO_RETRY_ON_ALL_OPERATIONS = Boolean.FALSE;
    
    private static ConcurrentHashMap<String, NiwsClientConfig> namedConfig = new ConcurrentHashMap<String, NiwsClientConfig>();

    public static final Boolean DEFAULT_ENABLE_NIWS_EVENT_LOGGING = Boolean.TRUE;

    private static ConcurrentHashMap<String, ConcurrentHashMap<String, Map<String, HttpVerbUriRegexPropertyValue>>> dynamicConfigMap =
        new ConcurrentHashMap<String, ConcurrentHashMap<String, Map<String, HttpVerbUriRegexPropertyValue>>>();
    
    private static final String[] DYNAMIC_PROPERTY_PREFIX = {"SLA", "NIWSStats", "ResponseCache", "MethodURI"};
    
    private Map<String, DynamicStringProperty> dynamicProperties = new ConcurrentHashMap<String, DynamicStringProperty>();
        
    static{
        ConfigurationManager.getConfigInstance().addConfigurationListener(
                new ExpandedConfigurationListenerAdapter(new NiwsConfigListener()));
    }    
    
    public NiwsClientConfig() {
        this.dynamicProperties.clear();
        this.enableDynamicProperties = false;
    }

    public NiwsClientConfig(Map<String, Object> properties) {
        if (properties != null) {
            for (IClientConfigKey niwsKey: CommonClientConfigKey.values()) {
                String key = niwsKey.key();
                Object value = properties.get(key);
                if (value != null) {
                    this.properties.put(key, value);
                }
            }
        }
        this.dynamicProperties.clear();
        this.enableDynamicProperties = false;
    }
    
    public static NiwsClientConfig getConfigWithDefaultProperties() {
        NiwsClientConfig config = new NiwsClientConfig();
        config.enableDynamicProperties = true;
        //Defaults
        config.putBooleanProperty(CommonClientConfigKey.UseHttpClient4, DEFAULT_USE_HTTP_CLIENT4);
        config.putIntegerProperty(CommonClientConfigKey.MaxHttpConnectionsPerHost, Integer.valueOf(DEFAULT_MAX_HTTP_CONNECTIONS_PER_HOST));
        config.putIntegerProperty(CommonClientConfigKey.MaxTotalHttpConnections, Integer.valueOf(DEFAULT_MAX_TOTAL_HTTP_CONNECTIONS));
        config.putIntegerProperty(CommonClientConfigKey.ConnectTimeout, Integer.valueOf(DEFAULT_CONNECT_TIMEOUT));
        config.putIntegerProperty(CommonClientConfigKey.ConnectionManagerTimeout, Integer.valueOf(DEFAULT_CONNECTION_MANAGER_TIMEOUT));
        config.putIntegerProperty(CommonClientConfigKey.ReadTimeout, Integer.valueOf(DEFAULT_READ_TIMEOUT));
        config.putIntegerProperty(CommonClientConfigKey.MaxAutoRetries, Integer.valueOf(DEFAULT_MAX_AUTO_RETRIES));
        config.putIntegerProperty(CommonClientConfigKey.MaxAutoRetriesNextServer, Integer.valueOf(DEFAULT_MAX_AUTO_RETRIES_NEXT_SERVER));
        config.putBooleanProperty(CommonClientConfigKey.OkToRetryOnAllOperations, DEFAULT_OK_TO_RETRY_ON_ALL_OPERATIONS);
        config.putBooleanProperty(CommonClientConfigKey.EnableNIWSEventLogging, DEFAULT_ENABLE_NIWS_EVENT_LOGGING);
        config.putFloatProperty(CommonClientConfigKey.PercentageNIWSEventLogged, Float.valueOf(DEFAULT_PERCENTAGE_NIWS_EVENT_LOGGED));  // 0=only log what the calling context suggests
        config.putBooleanProperty(CommonClientConfigKey.FollowRedirects, DEFAULT_FOLLOW_REDIRECTS);
        config.putBooleanProperty(CommonClientConfigKey.ConnectionPoolCleanerTaskEnabled, DEFAULT_CONNECTION_POOL_CLEANER_TASK_ENABLED); // default is true for RestClient
        config.putIntegerProperty(CommonClientConfigKey.ConnIdleEvictTimeMilliSeconds,
            Integer.valueOf(DEFAULT_CONNECTIONIDLE_TIME_IN_MSECS));
        config.putIntegerProperty(CommonClientConfigKey.ConnectionCleanerRepeatInterval,
            Integer.valueOf(DEFAULT_CONNECTION_IDLE_TIMERTASK_REPEAT_IN_MSECS));
        config.putBooleanProperty(CommonClientConfigKey.EnableGZIPContentEncodingFilter, DEFAULT_ENABLE_GZIP_CONTENT_ENCODING_FILTER);
        config.putBooleanProperty(CommonClientConfigKey.EnableRequestThrottling, DEFAULT_ENABLE_REQUEST_THROTTLING);
        config.putIntegerProperty(CommonClientConfigKey.RequestThrottlingWindowInMSecs, Integer.valueOf(DEFAULT_REQUEST_THROTTLING_WINDOW_IN_MILLIS));
        config.putIntegerProperty(CommonClientConfigKey.MaxRequestsAllowedPerWindow, Integer.valueOf(DEFAULT_MAX_REQUESTS_ALLOWED_PER_WINDOW));
        String proxyHost = ConfigurationManager.getConfigInstance().getString(getDefaultPropName(CommonClientConfigKey.ProxyHost.key()));
        if (proxyHost != null && proxyHost.length() > 0) {
            config.setProperty(CommonClientConfigKey.ProxyHost, proxyHost);
        }
        Integer proxyPort = ConfigurationManager
                .getConfigInstance()
                .getInteger(
                        getDefaultPropName(CommonClientConfigKey.ProxyPort),
                        (Integer.MIN_VALUE + 1)); // + 1 just to avoid potential clash with user setting
        if (proxyPort != (Integer.MIN_VALUE + 1)) {
            config.setProperty(CommonClientConfigKey.ProxyPort, proxyPort);
        }
        config.putIntegerProperty(CommonClientConfigKey.Port, Integer.valueOf(DEFAULT_PORT));
        config.putBooleanProperty(CommonClientConfigKey.EnablePrimeConnections, DEFAULT_ENABLE_PRIME_CONNECTIONS);
        config.putIntegerProperty(CommonClientConfigKey.MaxRetriesPerServerPrimeConnection, Integer.valueOf(DEFAULT_MAX_RETRIES_PER_SERVER_PRIME_CONNECTION));
        config.putIntegerProperty(CommonClientConfigKey.MaxTotalTimeToPrimeConnections, Integer.valueOf(DEFAULT_MAX_TOTAL_TIME_TO_PRIME_CONNECTIONS));
        config.putStringProperty(CommonClientConfigKey.PrimeConnectionsURI, DEFAULT_PRIME_CONNECTIONS_URI);
        config.putIntegerProperty(CommonClientConfigKey.PoolMinThreads, Integer.valueOf(DEFAULT_POOL_MIN_THREADS));
        config.putIntegerProperty(CommonClientConfigKey.PoolMaxThreads, Integer.valueOf(DEFAULT_POOL_MAX_THREADS));
        config.putLongProperty(CommonClientConfigKey.PoolKeepAliveTime, Long.valueOf(DEFAULT_POOL_KEEP_ALIVE_TIME));
        config.putTimeUnitProperty(CommonClientConfigKey.PoolKeepAliveTimeUnits,DEFAULT_POOL_KEEP_ALIVE_TIME_UNITS);
        config.putBooleanProperty(CommonClientConfigKey.EnableZoneAffinity, DEFAULT_ENABLE_ZONE_AFFINITY);
        config.putBooleanProperty(CommonClientConfigKey.EnableZoneExclusivity, DEFAULT_ENABLE_ZONE_EXCLUSIVITY);
        config.putStringProperty(CommonClientConfigKey.ClientClassName, DEFAULT_CLIENT_CLASSNAME);
        config.putStringProperty(CommonClientConfigKey.NFLoadBalancerClassName, DEFAULT_NFLOADBALANCER_CLASSNAME);
        config.putStringProperty(CommonClientConfigKey.NFLoadBalancerRuleClassName, DEFAULT_NFLOADBALANCER_RULE_CLASSNAME);
        config.putStringProperty(CommonClientConfigKey.NFLoadBalancerPingClassName, DEFAULT_NFLOADBALANCER_PING_CLASSNAME);
        config.putBooleanProperty(CommonClientConfigKey.PrioritizeVipAddressBasedServers, DEFAULT_PRIORITIZE_VIP_ADDRESS_BASED_SERVERS);
        config.putBooleanProperty(CommonClientConfigKey.EnableNIWSStats, DEFAULT_ENABLE_NIWSSTATS);
        config.putBooleanProperty(CommonClientConfigKey.EnableNIWSErrorStats, DEFAULT_ENABLE_NIWSERRORSTATS);
        config.putFloatProperty(CommonClientConfigKey.MinPrimeConnectionsRatio, DEFAULT_MIN_PRIME_CONNECTIONS_RATIO);
        config.putBooleanProperty(CommonClientConfigKey.UseTunnel, Boolean.FALSE);
        config.putStringProperty(CommonClientConfigKey.PrimeConnectionsClassName, DEFAULT_PRIME_CONNECTIONS_CLASS);
        // putBooleanProperty(CommonClientConfigKey.PrioritizeIntStack, Boolean.FALSE);
        config.putStringProperty(CommonClientConfigKey.VipAddressResolverClassName, DEFAULT_VIPADDRESS_RESOLVER_CLASSNAME);
        return config;
    }
    
    
    private void setPropertyInternal(IClientConfigKey propName, Object value) {
        setPropertyInternal(propName.key(), value);
    }

    private String getConfigKey(String propName) {
        return (clientName == null) ? getDefaultPropName(propName) : getInstancePropName(clientName, propName);
    }
    
    private void setPropertyInternal(final String propName, Object value) {
        String stringValue = (value == null) ? "" : String.valueOf(value);
        properties.put(propName, stringValue);
        if (!enableDynamicProperties) {
            return;
        }
        String configKey = getConfigKey(propName);
        final DynamicStringProperty prop = DynamicPropertyFactory.getInstance().getStringProperty(configKey, null);
        Runnable callback = new Runnable() {
            @Override
            public void run() {
                String value = prop.get();
                if (value != null) {
                    properties.put(propName, value);
                } else {
                    properties.remove(propName);
                }
            }
            
            // equals and hashcode needed 
            // since this is anonymous object is later used as a set key
            
            @Override 
            public boolean equals(Object other){
            	if (other == null) {
            		return false;
            	}
            	if (getClass() == other.getClass()) {
                    return toString().equals(other.toString());
                }
                return false;
            }
            
            @Override
            public String toString(){
            	return propName;
            }
            
            @Override
            public int hashCode(){
            	return propName.hashCode();
            }
            
            
        };
        prop.addCallback(callback);
        dynamicProperties.put(propName, prop);
    }
    
    
	// Helper methods which first check if a "default" (with rest client name)
	// property exists. If so, that value is used, else the default value
	// passed as argument is used to put into the properties member variable
    private void putIntegerProperty(IClientConfigKey propName, Integer defaultValue) {
        Integer value = ConfigurationManager.getConfigInstance().getInteger(
                getDefaultPropName(propName), defaultValue);
        setPropertyInternal(propName, value);
    }

    private void putLongProperty(IClientConfigKey propName, Long defaultValue) {
        Long value = ConfigurationManager.getConfigInstance().getLong(
                getDefaultPropName(propName), defaultValue);
        setPropertyInternal(propName, value);
    }
    
    private void putFloatProperty(IClientConfigKey propName, Float defaultValue) {
        Float value = ConfigurationManager.getConfigInstance().getFloat(
                getDefaultPropName(propName), defaultValue);
        setPropertyInternal(propName, value);
    }
    
    private void putTimeUnitProperty(IClientConfigKey propName, TimeUnit defaultValue) {
        TimeUnit value = defaultValue;
        String propValue = ConfigurationManager.getConfigInstance().getString(
                getDefaultPropName(propName));
        if(propValue != null && propValue.length() > 0) {
            value = TimeUnit.valueOf(propValue);
        }
        setPropertyInternal(propName, value);
    }
    
    static String getDefaultPropName(String propName) {
        return PROPERTY_NAMESPACE + "." + propName;
    }

    public static String getDefaultPropName(IClientConfigKey propName) {
        return getDefaultPropName(propName.key());
    }

    
    private void putStringProperty(IClientConfigKey propName, String defaultValue) {
        String value = ConfigurationManager.getConfigInstance().getString(
                getDefaultPropName(propName), defaultValue);
        setPropertyInternal(propName, value);
    }
    
    private void putBooleanProperty(IClientConfigKey propName, Boolean defaultValue) {
        Boolean value = ConfigurationManager.getConfigInstance().getBoolean(
                getDefaultPropName(propName), defaultValue);
        setPropertyInternal(propName, value);
    }
    
    /**
     * Enum Class to contain properties of the Client
     * @author stonse
     *
     */
    public enum NiwsClientConfigKey implements IClientConfigKey {

        AppName(CommonClientConfigKey.AppName.key()),
        Version("Version"),
        Port("Port"),
        SecurePort("SecurePort"),
        VipAddress("VipAddress"),
        DeploymentContextBasedVipAddresses("DeploymentContextBasedVipAddresses"),       
        MaxAutoRetries("MaxAutoRetries"),
        MaxAutoRetriesNextServer("MaxAutoRetriesNextServer"),
        OkToRetryOnAllOperations("OkToRetryOnAllOperations"),
        RequestSpecificRetryOn("RequestSpecificRetryOn"),
        ReceiveBuffferSize("ReceiveBuffferSize"),
        EnableNIWSEventLogging("EnableNIWSEventLogging"),
        EnnableVerboseErrorLogging("EnableVerboseErrorLogging"),
        PercentageNIWSEventLogged("PercentageNIWSEventLogged"),
        EnableRequestThrottling("EnableRequestThrottling"),
        RequestThrottlingWindowInMSecs("RequestThrottlingWindowInMSecs"),
        MaxRequestsAllowedPerWindow("MaxRequestsAllowedPerWindow"),        
        EnablePrimeConnections("EnablePrimeConnections"),
        PrimeConnectionsClassName("PrimeConnectionsClassName"),
        MaxRetriesPerServerPrimeConnection("MaxRetriesPerServerPrimeConnection"),
        MaxTotalTimeToPrimeConnections("MaxTotalTimeToPrimeConnections"),
        MinPrimeConnectionsRatio("MinPrimeConnectionsRatio"),
        PrimeConnectionsURI("PrimeConnectionsURI"),
        PoolMaxThreads("PoolMaxThreads"),
        PoolMinThreads("PoolMinThreads"),
        PoolKeepAliveTime("PoolKeepAliveTime"),
        PoolKeepAliveTimeUnits("PoolKeepAliveTimeUnits"),
        SLA("SLA"),
        SLAMinFailureResponseCode("SLAMinFailureResponseCode"),
        EnableNIWSStats("EnableNIWSStats"), // enable the feature of collecting request stats
        EnableNIWSErrorStats("EnableNIWSErrorStats"), // capture numErrors and other stats per Error Code
        NIWSStats("NIWSStats"), // The property key used per request stat alias

        //HTTP Client Related
        UseHttpClient4("UseHttpClient4"),
        MaxHttpConnectionsPerHost("MaxHttpConnectionsPerHost"),
        MaxTotalHttpConnections("MaxTotalHttpConnections"),
        IsSecure("IsSecure"),
        GZipPayload("GZipPayload"),
        ConnectTimeout("ConnectTimeout"),
        ReadTimeout("ReadTimeout"),
        SendBufferSize("SendBufferSize"),
        StaleCheckingEnabled("StaleCheckingEnabled"),
        Linger("Linger"),
        ConnectionManagerTimeout("ConnectionManagerTimeout"),
        FollowRedirects("FollowRedirects"),
        ConnectionPoolCleanerTaskEnabled("ConnectionPoolCleanerTaskEnabled"),
        ConnIdleEvictTimeMilliSeconds("ConnIdleEvictTimeMilliSeconds"),
        ConnectionCleanerRepeatInterval("ConnectionCleanerRepeatInterval"),
        EnableGZIPContentEncodingFilter("EnableGZIPContentEncodingFilter"),
        ProxyHost("ProxyHost"),
        ProxyPort("ProxyPort"),
        KeyStore("KeyStore"),
        KeyStorePassword("KeyStorePassword"),
        TrustStore("TrustStore"),
        TrustStorePassword("TrustStorePassword"),

        // Client implementation        
        ClientClassName("ClientClassName"),
        
        //LoadBalancer Related
        InitializeNFLoadBalancer("InitializeNFLoadBalancer"),
        NFLoadBalancerClassName("NFLoadBalancerClassName"),
        NFLoadBalancerRuleClassName("NFLoadBalancerRuleClassName"),
        NFLoadBalancerPingClassName("NFLoadBalancerPingClassName"),
        NFLoadBalancerPingInterval("NFLoadBalancerPingInterval"),
        NFLoadBalancerMaxTotalPingTime("NFLoadBalancerMaxTotalPingTime"),
        NIWSServerListClassName("NIWSServerListClassName"),
        NIWSServerListFilterClassName("NIWSServerListFilterClassName"),
        EnableMarkingServerDownOnReachingFailureLimit("EnableMarkingServerDownOnReachingFailureLimit"),
        ServerDownFailureLimit("ServerDownFailureLimit"),
        ServerDownStatWindowInMillis("ServerDownStatWindowInMillis"),
        EnableZoneAffinity("EnableZoneAffinity"),
        EnableZoneExclusivity("EnableZoneExclusivity"),
        PrioritizeVipAddressBasedServers("PrioritizeVipAddressBasedServers"),
        VipAddressResolverClassName("VipAddressResolverClassName"),

        //Tunnelling
        UseTunnel("UseTunnel");

        private final String configKey;

        NiwsClientConfigKey(String configKey) {
            this.configKey = configKey;
        }

        /* (non-Javadoc)
		 * @see com.netflix.niws.client.ClientConfig#key()
		 */
        @Override
		public String key() {
            return configKey;
        }
    }

    public void setClientName(String clientName){
        this.clientName  = clientName;
    }

    /* (non-Javadoc)
	 * @see com.netflix.niws.client.CliengConfig#getClientName()
	 */
    @Override
	public String getClientName() {
        return clientName;
    }

    /* (non-Javadoc)
	 * @see com.netflix.niws.client.CliengConfig#loadProperties(java.lang.String)
	 */
    @Override
	public void loadProperties(String restClientName){
        setClientName(restClientName);
        Configuration props = ConfigurationManager.getConfigInstance().subset(restClientName);        
        for (Iterator<String> keys = props.getKeys(); keys.hasNext(); ){
            String key = keys.next();
            String prop = key;
            if (prop.startsWith(PROPERTY_NAMESPACE)){
                prop = prop.substring(PROPERTY_NAMESPACE.length() + 1);
            }
            setPropertyInternal(prop, props.getProperty(key));
        }
        
        for (String dynamicPropPrefix: DYNAMIC_PROPERTY_PREFIX) {
            ConcurrentHashMap<String, Map<String, HttpVerbUriRegexPropertyValue>> map = new ConcurrentHashMap<String, Map<String, HttpVerbUriRegexPropertyValue>>();
            ConcurrentHashMap<String, Map<String, HttpVerbUriRegexPropertyValue>> previous = dynamicConfigMap.putIfAbsent(dynamicPropPrefix, map);
            if(previous != null) {
                map = previous;
            }
            initializeDynamicConfig(dynamicPropPrefix, map);
        }
    }
    
    @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = "DC_DOUBLECHECK")
    private VipAddressResolver getVipAddressResolver() {
        if (resolver == null) {
            synchronized (this) {
                if (resolver == null) {
                    try {
                        resolver = (VipAddressResolver) Class.forName(
                                (String) getProperty(CommonClientConfigKey.VipAddressResolverClassName)).newInstance();
                    } catch (Throwable e) {
                        LOG.error("Cannot instantiate VipAddressResolver", e);
                    }
                }
            }
        }
        return resolver;
        
    }

    public String resolveDeploymentContextbasedVipAddresses(){
        
        String deploymentContextBasedVipAddressesMacro = (String) getProperty(CommonClientConfigKey.DeploymentContextBasedVipAddresses);
        return getVipAddressResolver().resolve(deploymentContextBasedVipAddressesMacro, this);
    }

    public String getAppName(){
        String appName = null;
        Object an = getProperty(CommonClientConfigKey.AppName);
        if (an!=null){
            appName = "" + an;
        }
        return appName;
    }

    public String getVersion(){
        String version = null;
        Object an = getProperty(CommonClientConfigKey.Version);
        if (an!=null){
            version = "" + an;
        }
        return version;
    }

    /* (non-Javadoc)
	 * @see com.netflix.niws.client.CliengConfig#getProperties()
	 */
    @Override
	public  Map<String, Object> getProperties() {
        return properties;
    }

    /**
     * Set the underlying properties cache. This may cause inconsistencies with dynamic properties.
     * Instead, use {@link #setProperty(NiwsClientConfigKey, Object)} to set property.
     * 
     * @param properties
     */
    @Deprecated 
    public void setProperties(Map properties) {
        this.properties = (Map<String, Object>) properties;
    }

    /* (non-Javadoc)
	 * @see com.netflix.niws.client.CliengConfig#setProperty(com.netflix.niws.client.ClientConfigKey, java.lang.Object)
	 */
    @Override
	public void setProperty(IClientConfigKey key, Object value){
        setPropertyInternal(key.key(), value);
    }

    public IClientConfig applyOverride(IClientConfig override) {
        if (override == null) {
            return this;
        }
        for (IClientConfigKey key: CommonClientConfigKey.values()) {
            Object value = override.getProperty(key);
            if (value != null) {
                setProperty(key, value);
            }
        }
        return this;
    }
    
    /**
     * Set a property. Should use {@link #setProperty(NiwsClientConfigKey, Object)} instead.    
     * 
     * @param key
     * @param value
     */
    @Deprecated
    public void setProperty(String key, Object value){
        setPropertyInternal(key, value);
    }

    /* (non-Javadoc)
	 * @see com.netflix.niws.client.CliengConfig#getProperty(com.netflix.niws.client.ClientConfigKey)
	 */
    @Override
	public Object getProperty(IClientConfigKey key){
        String propName = key.key();
        DynamicStringProperty dynamicProperty = dynamicProperties.get(propName);
        if (dynamicProperty != null) {
            String dynamicValue = dynamicProperty.get();
            if (dynamicValue != null) {
                return dynamicValue;
            }
        }
        return properties.get(propName);
    }

    /* (non-Javadoc)
	 * @see com.netflix.niws.client.CliengConfig#getProperty(com.netflix.niws.client.ClientConfigKey, java.lang.Object)
	 */
    @Override
	public Object getProperty(IClientConfigKey key, Object defaultVal){
        Object val = getProperty(key);
        if (val == null){
            return defaultVal;
        }
        return val;
    }

    public static Object getProperty(Map<String, Object> config, IClientConfigKey key, Object defaultVal) {
        Object val = config.get(key.key());
        if (val == null) {
            return defaultVal;
        }
        return val;
    }

    public static Object getProperty(Map<String, Object> config, IClientConfigKey key) {
        return getProperty(config, key, null);
    }

    public boolean isSecure() {
        Object oo = getProperty(CommonClientConfigKey.IsSecure);
        if (oo != null) {
            return Boolean.parseBoolean(oo.toString());
        } else {
        	return false;
        }
    }

    /* (non-Javadoc)
	 * @see com.netflix.niws.client.CliengConfig#containsProperty(com.netflix.niws.client.ClientConfigKey)
	 */
    @Override
	public boolean containsProperty(IClientConfigKey key){
        Object oo = getProperty(key);
        return oo!=null? true: false;
    }

    @Override
    public String toString(){
        final StringBuilder sb = new StringBuilder();
        String separator = "";

        sb.append("NiwsClientConfig:");
        for (IClientConfigKey key: CommonClientConfigKey.values()) {
            final Object value = getProperty(key);

            sb.append(separator);
            separator = ", ";
            sb.append(key).append(":");
            if (key.key().endsWith("Password") && value instanceof String) {
                sb.append(Strings.repeat("*", ((String) value).length()));
            } else {
                sb.append(value);
            }
        }
        return sb.toString();
    }

    
    private void initializeDynamicConfig(String prefix, 
            ConcurrentHashMap<String, Map<String, HttpVerbUriRegexPropertyValue>> configMapForPrefix) {
        AbstractConfiguration configInstance = ConfigurationManager.getConfigInstance();
        // load any pre-configured dynamic properties
        String niwsPropertyPrefix = getClientName() + "."
        + PROPERTY_NAMESPACE;
        String prefixWithNoDot = niwsPropertyPrefix + "." + prefix;
        String configPrefix = prefixWithNoDot + ".";

        if (configInstance != null) {
            Configuration c = configInstance.subset(prefixWithNoDot);
            if (c != null) {
                Iterator<?> it = c.getKeys();
                if (it != null) {
                    while (it.hasNext()) {
                        String alias = (String) it.next();
                        if (alias != null) {
                            // we have a property of interest - add it to
                            // our
                            // map
                            String value = configInstance.getString(configPrefix + alias);
                            if (value != null) {
                                Map<String, HttpVerbUriRegexPropertyValue> aliasMap = configMapForPrefix.get(getClientName());
                                if (aliasMap == null) {
                                    aliasMap = new ConcurrentHashMap<String, HttpVerbUriRegexPropertyValue>();
                                    Map<String, HttpVerbUriRegexPropertyValue> prev = configMapForPrefix.putIfAbsent(getClientName(),
                                            aliasMap);
                                    if (prev != null) {
                                    	aliasMap = prev;
                                    }
                                }
                                aliasMap.put(alias.trim(),
                                        HttpVerbUriRegexPropertyValue
                                                .getVerbUriRegex(value
                                                        .toString()));

                            }
                        }
                    }
                }
            }
        }

    }
    

    Map<String, HttpVerbUriRegexPropertyValue> getSlaAliasRuleMap() {
        return getDynamicPropMap("SLA");
    }

    private Map<String, HttpVerbUriRegexPropertyValue> getDynamicPropMap(String dynamicPropPrefix) {
        Map<String,HttpVerbUriRegexPropertyValue> map = new HashMap<String,HttpVerbUriRegexPropertyValue>();
        try{
            map = dynamicConfigMap.get(dynamicPropPrefix).get(getClientName());
        }catch(Exception e){
            LOG.warn("Unable to get config Map for <restClientName>.niws.client."
                            + dynamicPropPrefix + " prefix"); 
        }
        return map;
    }
    
    Map<String, HttpVerbUriRegexPropertyValue> getNIWSStatsConfigMap() {
            return getDynamicPropMap("NIWSStats");
    }

    Map<String, HttpVerbUriRegexPropertyValue> getCacheConfigMap() {
        return getDynamicPropMap("ResponseCache");
    }

    public Map<String, HttpVerbUriRegexPropertyValue> getMethodURIConfigMap() {
        return getDynamicPropMap("MethodURI");
    }
    /**
     * Listen to changes in properties for NIWS
     * @author stonse
     *
     */
    private static class NiwsConfigListener extends AbstractDynamicPropertyListener {
        
        private String getClientNameFromConfig(String name) {
            for (String prefix: DYNAMIC_PROPERTY_PREFIX) {
                if (name.contains(PROPERTY_NAMESPACE + "." + prefix)) {
                    return name.substring(0,name.indexOf(PROPERTY_NAMESPACE + "." + prefix) - 1);
                }
            }
            return null;
        }
        
        @Override
        public void handlePropertyEvent(String name, Object value,
                EventType eventType) {
            try {
                String clientName = getClientNameFromConfig(name);

                if (clientName != null) {
                    String niwsPropertyPrefix = clientName + "."
                            + PROPERTY_NAMESPACE;
                    for (String prefix : DYNAMIC_PROPERTY_PREFIX) {
                        String configPrefix = niwsPropertyPrefix + "." + prefix
                                + ".";
                        if (name != null && name.startsWith(configPrefix)) {
                            Map<String, HttpVerbUriRegexPropertyValue> aliasRuleMapForClient = dynamicConfigMap
                                    .get(prefix).get(clientName);
                            if (aliasRuleMapForClient == null) {
                                // no map exists so far, create one
                                aliasRuleMapForClient = new ConcurrentHashMap<String, HttpVerbUriRegexPropertyValue>();
                                Map<String, HttpVerbUriRegexPropertyValue> prev = dynamicConfigMap.get(prefix).putIfAbsent(clientName,
                                        aliasRuleMapForClient);
                                if (prev != null) {
                                	aliasRuleMapForClient = prev;
                                }
                            }

                            String alias = name.substring(configPrefix.length());
                            if (alias != null) {
                                alias = alias.trim();
                                switch (eventType) {
                                case CLEAR:
                                    aliasRuleMapForClient.remove(alias);
                                    break;
                                case ADD:
                                case SET:
                                    if (value != null) {
                                        aliasRuleMapForClient.put(alias,
                                                HttpVerbUriRegexPropertyValue
                                                        .getVerbUriRegex(value
                                                                .toString()));
                                    }
                                    break;
                                }
                            }
                        }
                    }
                }
            } catch (Throwable t) {
                LOG.warn("Unexpected error when checking for dynamic Rest "
                        + "Client property updates", t);
            }
        }
    }
    
    static void setProperty(Properties props, String restClientName, String key, String value){
        props.setProperty( getInstancePropName(restClientName, key), value);
    }

    public static String getInstancePropName(String restClientName,
            IClientConfigKey configKey) {
        return getInstancePropName(restClientName, configKey.key());
    }

    public static String getInstancePropName(String restClientName, String key) {
        return restClientName + "." + PROPERTY_NAMESPACE + "."
                + key;
    }
    
    public static IClientConfig getNamedConfig(String name) {
        NiwsClientConfig config = namedConfig.get(name);
        if (config != null) {
            return config;
        } else {
            config = getConfigWithDefaultProperties();
            config.loadProperties(name);
            NiwsClientConfig old = namedConfig.put(name, config);
            if (old != null) {
                config = old;
            }
            return config;
        }
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_f1160f3_1e333eb/rev_f1160f3-1e333eb/ribbon-core/src/main/java/com/netflix/niws/client/ClientFactory.java;<<<<<<< MINE
import com.netflix.niws.client.NiwsClientConfig.NiwsClientConfigKey;
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_f1160f3_1e333eb/rev_f1160f3-1e333eb/ribbon-core/src/main/java/com/netflix/niws/client/PrimeConnections.java;<<<<<<< MINE
import com.netflix.niws.client.NiwsClientConfig.NiwsClientConfigKey;
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_f1160f3_1e333eb/rev_f1160f3-1e333eb/ribbon-core/src/main/java/com/netflix/niws/client/DynamicServerListLoadBalancer.java;<<<<<<< MINE
import com.netflix.client.config.DefaultClientConfigImpl;
=======
import com.google.common.util.concurrent.ThreadFactoryBuilder;
import com.netflix.loadbalancer.BaseLoadBalancer;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_f1160f3_1e333eb/rev_f1160f3-1e333eb/ribbon-core/src/main/java/com/netflix/niws/client/DynamicServerListLoadBalancer.java;<<<<<<< MINE
import com.google.common.util.concurrent.ThreadFactoryBuilder; 
=======
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_fc5104c_379a202/rev_fc5104c-379a202/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/gadget/portlet/BaseGadgetPortlet.java;<<<<<<< MINE
=======
import com.liferay.portal.model.ResourceConstants;
import com.liferay.portal.model.Role;
import com.liferay.portal.model.RoleConstants;
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_fc5104c_379a202/rev_fc5104c-379a202/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/gadget/portlet/BaseGadgetPortlet.java;<<<<<<< MINE
=======
import com.liferay.portal.security.permission.ActionKeys;
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_fc5104c_379a202/rev_fc5104c-379a202/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/gadget/portlet/BaseGadgetPortlet.java;<<<<<<< MINE
=======
import com.liferay.portal.service.ResourcePermissionLocalServiceUtil;
import com.liferay.portal.service.RoleLocalServiceUtil;
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_fc5104c_379a202/rev_fc5104c-379a202/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/gadget/portlet/BaseGadgetPortlet.java;<<<<<<< MINE
=======
import com.liferay.portlet.expando.model.ExpandoColumn;
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_fc5104c_379a202/rev_fc5104c-379a202/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/gadget/portlet/BaseGadgetPortlet.java;<<<<<<< MINE
			ExpandoColumnLocalServiceUtil.addColumn(
				expandoTable.getTableId(), columnName,
				ExpandoColumnConstants.STRING);
=======
			ExpandoColumn expandoColumn =
				ExpandoColumnLocalServiceUtil.addColumn(
					expandoTable.getTableId(), columnName,
					ExpandoColumnConstants.STRING);

			Role role = RoleLocalServiceUtil.getRole(
				expandoColumn.getCompanyId(), RoleConstants.USER);

			ResourcePermissionLocalServiceUtil.setResourcePermissions(
				expandoColumn.getCompanyId(), ExpandoColumn.class.getName(),
				ResourceConstants.SCOPE_INDIVIDUAL,
				String.valueOf(expandoColumn.getColumnId()), role.getRoleId(),
				new String[] {ActionKeys.UPDATE, ActionKeys.VIEW});
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_2eb053b_b8dae6e/rev_2eb053b-b8dae6e/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
  public RecordWriter getRecordWriter(TaskAttemptContext job)
=======
  public RecordWriter<NullWritable, W> getRecordWriter(TaskAttemptContext job)
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_2eb053b_b8dae6e/rev_2eb053b-b8dae6e/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
  public RecordWriter getRecordWriter(TaskAttemptContext job)
=======
  public RecordWriter<NullWritable, W> getRecordWriter(TaskAttemptContext job)
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_c6d377e_010bf7b/rev_c6d377e-010bf7b/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/editor/portlet/EditorPortlet.java;<<<<<<< MINE
import com.liferay.portal.kernel.util.FileUtil;
=======
>>>>>>> YOURS
/home/taes/taes/projects/liferay-plugins/revisions/rev_c6d377e_010bf7b/rev_c6d377e-010bf7b/portlets/opensocial-portlet/docroot/WEB-INF/src/com/liferay/opensocial/editor/portlet/EditorPortlet.java;<<<<<<< MINE
		String extension = FileUtil.getExtension(fileEntryTitle);

=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_9fc1590_1fa2d2a/rev_9fc1590-1fa2d2a/atlas-gradle-plugin/dexpatch/src/main/java/com/taobao/android/TPatchTool.java;<<<<<<< MINE
import com.taobao.android.tpatch.manifest.AndroidManifestDiffFactory;
=======
import com.taobao.android.task.ExecutorServicesHelper;
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7d88093_1943bcf/rev_7d88093-1943bcf/jodd-madvoc/src/main/java/jodd/madvoc/config/RouteMadvocConfigurator.java;<<<<<<< MINE
import jodd.madvoc.component.MadvocConfig;
=======
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7d88093_1943bcf/rev_7d88093-1943bcf/jodd-madvoc/src/main/java/jodd/madvoc/config/RouteMadvocConfigurator.java;<<<<<<< MINE
import jodd.petite.meta.PetiteInject;
=======
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7d88093_1943bcf/rev_7d88093-1943bcf/jodd-madvoc/src/main/java/jodd/madvoc/config/RouteMadvocConfigurator.java;<<<<<<< MINE
	@PetiteInject
	protected MadvocConfig madvocConfig;

=======
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7d88093_1943bcf/rev_7d88093-1943bcf/jodd-madvoc/src/testInt/java/jodd/madvoc/MyWebApplication2.java;<<<<<<< MINE
=======
// Copyright (c) 2003-2014, Jodd Team (jodd.org). All Rights Reserved.

package jodd.madvoc;

import jodd.log.Logger;
import jodd.log.LoggerFactory;
import jodd.log.impl.SimpleLoggerFactory;

public class MyWebApplication2 extends WebApplication {

	public MyWebApplication2() {
		LoggerFactory.setLoggerFactory(new SimpleLoggerFactory(Logger.Level.DEBUG));
	}
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_dd64dd0_8ff804b/rev_dd64dd0-8ff804b/src/java/com/twitter/elephantbird/pig/load/HBaseSlice.java;<<<<<<< MINE
/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with this
 * work for additional information regarding copyright ownership. The ASF
 * licenses this file to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 * http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations under
 * the License.
 */
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.util.ArrayList;
import java.util.Map;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.UnknownScannerException;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.client.ResultScanner;
import org.apache.hadoop.hbase.client.Scan;
import org.apache.hadoop.hbase.filter.BinaryComparator;
import org.apache.hadoop.hbase.filter.CompareFilter;
import org.apache.hadoop.hbase.filter.FilterList;
import org.apache.hadoop.hbase.filter.RowFilter;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.hadoop.util.StringUtils;
import org.apache.pig.Slice;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;

import com.google.common.collect.Maps;
import com.twitter.elephantbird.pig.util.PigCounterHelper;

/**
 * HBase Slice to load a portion of range of a table. The key range will be
 * [start, end) Modeled from org.apache.hadoop.hbase.mapred.TableSplit.
 */
public class HBaseSlice implements Slice {

  /** A Generated Serial Version UID **/
  private static final long serialVersionUID = 9035916017187148965L;
  private static final Log LOG = LogFactory.getLog(HBaseSlice.class);
  private transient PigCounterHelper counterHelper_;

  // assigned during construction
  /** Table Name **/
  private final byte[] tableName_;
  /** Table Start Row **/
  private final byte[] startRow_;
  /** Table End Row **/
  private final byte[] endRow_;
  /** Table Region Location **/
  private final String regionLocation_;
  /** Input Columns **/
  private final byte[][] inputColumns_;
  /** Whether the row should be loaded **/
  private final boolean loadRowKey_;

  /** BigInteger representations of row range */
  private final BigInteger bigStart_;
  private final BigInteger bigEnd_;
  private final BigDecimal bigRange_;


  private Map<CompareFilter.CompareOp, String> innerFilters_ = Maps.newHashMap();
  private long limit_ = -1;


  // created as part of init
  /** The connection to the table in Hbase **/
  private transient HTable m_table;
  /** The scanner over the table **/
  private transient ResultScanner m_scanner;
  private transient long seenRows_ = 0;

  private transient ArrayList<Object> mProtoTuple;

  /**
   * Record the last processed row, so that we can restart the scanner when an
   * exception happened during scanning a table
   */
  private transient byte[] m_lastRow_;

  /**
   * Constructor
   * 
   * @param tableName
   *            table name
   * @param startRow
   *            start now, inclusive
   * @param endRow
   *            end row, exclusive
   * @param inputColumns
   *            input columns
   * @param location
   *            region location
   */
  public HBaseSlice(byte[] tableName, byte[] startRow, byte[] endRow,
      byte[][] inputColumns, boolean loadRowKey, final String location) {
    tableName_ = tableName;
    startRow_ = startRow;
    endRow_ = endRow;
    inputColumns_ = inputColumns;
    regionLocation_ = location;
    loadRowKey_ = loadRowKey;

    // We have to deal with different byte lengths of keys producing very different
    // BigIntegers (bigendianness is great this way). The code is mostly cribbed
    // from HBase's Bytes class.
    byte [] startPadded;
    byte [] endPadded;
    if (startRow.length < endRow.length) {
      startPadded = Bytes.padTail(startRow, endRow.length - startRow.length);
      endPadded = endRow;
    } else if (endRow.length < startRow.length) {
      startPadded = startRow;
      endPadded = Bytes.padTail(endRow, startRow.length - endRow.length);
    } else {
      startPadded = startRow;
      endPadded = endRow;
    }
    byte [] prependHeader = {1, 0};
    bigStart_ = new BigInteger(Bytes.add(prependHeader, startPadded));
    bigEnd_ = new BigInteger(Bytes.add(prependHeader, endPadded));
    bigRange_ = new BigDecimal(bigEnd_.subtract(bigStart_));
  }

  public void addFilter(CompareFilter.CompareOp compareOp, String filterValue) {
    innerFilters_.put(compareOp, filterValue);
  }

  /** @return table name */
  public byte[] getTableName() {
    return this.tableName_;
  }

  /** @return starting row key */
  public byte[] getStartRow() {
    return this.startRow_;
  }

  /** @return end row key */
  public byte[] getEndRow() {
    return this.endRow_;
  }

  /** @return input columns */
  public byte[][] getInputColumns() {
    return this.inputColumns_;
  }

  /** @return the region's hostname */
  public String getRegionLocation() {
    return this.regionLocation_;
  }

  @Override
  public long getStart() {
    // Not clear how to obtain this in a table...
    return 0;
  }

  @Override
  public long getLength() {
    // Not clear how to obtain this in a table...
    // it seems to be used only for sorting splits
    return 0;
  }

  @Override
  public String[] getLocations() {
    return new String[] { regionLocation_ };
  }

  @Override
  public long getPos() throws IOException {
    // This should be the ordinal tuple in the range;
    // not clear how to calculate...
    return 0;
  }

  @Override
  public float getProgress() throws IOException {

    // No way to know max.. just return 0. Sorry, reporting on the last slice is janky.
    // So is reporting on the first slice, by the way -- it will start out too high, possibly at 100%.
    if (endRow_.length==0) return 0;
    byte[] lastPadded = m_lastRow_;
    if (m_lastRow_.length < endRow_.length) {
      lastPadded = Bytes.padTail(m_lastRow_, endRow_.length - m_lastRow_.length);
    }
    if (m_lastRow_.length < startRow_.length) {
      lastPadded = Bytes.padTail(m_lastRow_, startRow_.length - m_lastRow_.length);
    }
    byte [] prependHeader = {1, 0};
    BigInteger bigLastRow = new BigInteger(Bytes.add(prependHeader, lastPadded));
    BigDecimal processed = new BigDecimal(bigLastRow.subtract(bigStart_));
    try {
      BigDecimal progress = processed.setScale(3).divide(bigRange_, BigDecimal.ROUND_HALF_DOWN);
      return progress.floatValue();
    } catch (java.lang.ArithmeticException e) {
      return 0;
    }
  }

  @Override
  public void init(DataStorage store) throws IOException {
    HBaseConfiguration conf = new HBaseConfiguration();
    // connect to the given table
    m_table = new HTable(conf, tableName_);
    // init the scanner
    initScanner();
  }

  /**
   * Init the table scanner
   * 
   * @throws IOException
   */
  private void initScanner() throws IOException {
    restart(startRow_);
    m_lastRow_ = startRow_;
  }

  /**
   * Restart scanning from survivable exceptions by creating a new scanner.
   * 
   * @param startRow
   *            the start row
   * @throws IOException
   */
  private void restart(byte[] startRow) throws IOException {
    Scan scan;
    if ((endRow_ != null) && (endRow_.length > 0)) {
      scan = new Scan(startRow, endRow_);
    } else {
      scan = new Scan(startRow);
    }

    // Set filters, if any.
    FilterList scanFilter = null;
    if (!innerFilters_.isEmpty()) {
      scanFilter = new FilterList();
      for (Map.Entry<CompareFilter.CompareOp, String>entry  : innerFilters_.entrySet()) {
        scanFilter.addFilter(new RowFilter(entry.getKey(), new BinaryComparator(Bytes.toBytesBinary(entry.getValue()) )));
      }
      scan.setFilter(scanFilter);
    }

    scan.addColumns(inputColumns_);
    this.m_scanner = this.m_table.getScanner(scan);
  }

  @Override
  public boolean next(Tuple value) throws IOException {
    Result result;
    try {
      result = m_scanner.next();
    } catch (UnknownScannerException e) {
      LOG.info("recovered from " + StringUtils.stringifyException(e));
      restart(m_lastRow_);
      if (m_lastRow_ != startRow_) {
        m_scanner.next(); // skip presumed already mapped row
      }
      result = this.m_scanner.next();
    }
    boolean hasMore = result != null && result.size() > 0 && (limit_ < 0 || limit_ > seenRows_);
    if (hasMore) {
      if (counterHelper_ == null) counterHelper_ = new PigCounterHelper();
      counterHelper_.incrCounter(HBaseSlice.class.getName(), Bytes.toString(tableName_) + " rows read", 1);
      m_lastRow_ = result.getRow();
      convertResultToTuple(result, value);
      seenRows_ += 1;
    }
    return hasMore;
  }

  /**
   * Convert a row result to a tuple
   * 
   * @param result
   *            row result
   * @param tuple
   *            tuple
   */
  private void convertResultToTuple(Result result, Tuple tuple) {
    if (mProtoTuple == null)
      mProtoTuple = new ArrayList<Object>(inputColumns_.length + (loadRowKey_ ? 1 : 0));

    if (loadRowKey_) {
      mProtoTuple.add(new DataByteArray(result.getRow()));
    }

    for (byte[] column : inputColumns_) {
      byte[] value = result.getValue(column);
      if (value == null) {
        mProtoTuple.add(null);
      } else {
        mProtoTuple.add(new DataByteArray(value));
      }
    }

    Tuple newT = TupleFactory.getInstance().newTuple(mProtoTuple);
    mProtoTuple.clear();
    tuple.reference(newT);
  }

  @Override
  public void close() throws IOException {
    if (m_scanner != null) {
      m_scanner.close();
      m_scanner = null;
    }
  }

  @Override
  public String toString() {
    return regionLocation_ + ":" + Bytes.toString(startRow_) + ","
    + Bytes.toString(endRow_);
  }

  public void setLimit(String limit) {
    LOG.info("Setting Slice limit to "+Long.valueOf(limit));
    limit_ = Long.valueOf(limit);
  }

}=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_c2e9822_9b24b0d/rev_c2e9822-9b24b0d/atlas-core/src/main/java/android/taobao/atlas/startup/AtlasBridgeApplication.java;<<<<<<< MINE
import android.taobao.atlas.runtime.RuntimeVariables;
=======
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_b308375_38b60c8/rev_b308375-38b60c8/jodd-http/src/main/java/jodd/http/HttpBrowser.java;<<<<<<< MINE

=======
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_b308375_38b60c8/rev_b308375-38b60c8/jodd-http/src/main/java/jodd/http/HttpBrowser.java;<<<<<<< MINE
=======
                
			    Integer maxAge = cookie.getMaxAge();
				if (maxAge != null && maxAge.intValue() == 0) {
				    continue;
				}

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
=======
import com.google.protobuf.Message;
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
import com.twitter.elephantbird.mapreduce.io.ProtobufWritable;
import com.twitter.elephantbird.util.TypeRef;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineRecordWriter.java;<<<<<<< MINE
package com.twitter.elephantbird.mapreduce.output;

import java.io.DataOutputStream;
import java.io.IOException;

import com.twitter.elephantbird.mapreduce.io.ThriftB64LineWritable;
import com.twitter.elephantbird.util.TypeRef;

import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
import org.apache.thrift.TBase;

/**
 * A RecordWriter-derived class for use with the LzoThriftB64LineOutputFormat.
 * Writes data as base64 encoded serialized thrift objects, one per line.
 */

public class LzoThriftB64LineRecordWriter<T extends TBase>
    extends RecordWriter<NullWritable, ThriftB64LineWritable<T>> {
  private static final Logger LOG = LogManager.getLogger(LzoThriftB64LineRecordWriter.class);

  protected final TypeRef typeRef_;
  protected final DataOutputStream out_;

  public LzoThriftB64LineRecordWriter(TypeRef<T> typeRef, DataOutputStream out) {
    typeRef_ = typeRef;
    out_ = out;
  }

  public void write(NullWritable nullWritable, ThriftB64LineWritable<T> thriftWritable)
      throws IOException, InterruptedException {
    thriftWritable.write(out_);
  }

  public void close(TaskAttemptContext taskAttemptContext)
      throws IOException, InterruptedException {
    out_.close();
  }
}=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
import com.hadoop.compression.lzo.LzopCodec;
import com.twitter.elephantbird.mapreduce.io.ThriftB64LineWritable;
=======
import com.twitter.elephantbird.mapreduce.io.ThriftConverter;
import com.twitter.elephantbird.mapreduce.io.ThriftWritable;
import com.twitter.elephantbird.util.ThriftUtils;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.mapreduce.io.ThriftB64LineWritable;
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.mapreduce.input.LzoInputFormat;
import com.twitter.elephantbird.mapreduce.io.ThriftB64LineWritable;
=======
import com.twitter.elephantbird.mapreduce.io.ThriftWritable;
import com.twitter.elephantbird.util.ThriftUtils;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE

=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineRecordReader.java;<<<<<<< MINE
import java.io.IOException;
import java.io.InputStream;

import com.twitter.elephantbird.mapreduce.input.LzoRecordReader;
import com.twitter.elephantbird.mapreduce.io.ThriftB64LineWritable;
import com.twitter.elephantbird.util.TypeRef;

import org.apache.commons.codec.binary.Base64;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.util.LineReader;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/pig/store/LzoProtobufB64LinePigStorage.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.store;

import java.io.IOException;

import org.apache.commons.codec.binary.Base64;
import org.apache.pig.data.Tuple;

import com.google.protobuf.Message;
import com.google.protobuf.Message.Builder;
import com.twitter.elephantbird.pig.util.PigToProtobuf;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * Serializes Pig Tuples into Base-64 encoded, line-delimited protocol buffers.
 * The fields in the pig tuple must correspond exactly to the fields in the protobuf, as
 * no name-matching is performed (names of the tuple fields are not currently accessible to
 * a StoreFunc. It will be in 0.7, so something more flexible will be possible)
 *
 * @param <M> Protocol Buffer Message class being serialized
 */
public abstract class LzoProtobufB64LinePigStorage<M extends Message> extends LzoBaseStoreFunc {

  private TypeRef<M> typeRef_;
  private Base64 base64_ = new Base64();
  private final PigToProtobuf pigToProto_ = new PigToProtobuf();

  protected void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
  }

  public void putNext(Tuple f) throws IOException {
    if (f == null) return;
	Builder builder = Protobufs.getMessageBuilder(typeRef_.getRawClass());
    os_.write(base64_.encode(pigToProto_.tupleToMessage(builder, f).toByteArray()));
    os_.write("\n".getBytes("UTF-8"));
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/pig/util/ProtobufToPig.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

import java.util.List;
import java.util.Map;

import com.google.common.collect.Lists;
import com.google.common.collect.Maps;
import com.google.protobuf.Descriptors.Descriptor;
import com.google.protobuf.Descriptors.EnumValueDescriptor;
import com.google.protobuf.Descriptors.FieldDescriptor;
import com.google.protobuf.ByteString;
import com.google.protobuf.Message;
import com.sun.org.apache.xerces.internal.impl.dv.xs.SchemaDateTimeException;
import com.twitter.data.proto.Misc.CountedMap;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.BagFactory;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.DataType;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * A class for turning codegen'd protos into Pig Tuples and Schemas
 * for custom Pig LoadFuncs.
 * @author Kevin Weil
 */
public class ProtobufToPig {
  private static final Logger LOG = LoggerFactory.getLogger(ProtobufToPig.class);

  private static final TupleFactory tupleFactory_ = TupleFactory.getInstance();
  private static BagFactory bagFactory_ = BagFactory.getInstance();

  public enum CoercionLevel { kNoCoercion, kAllowCoercionToPigMaps }

  private final CoercionLevel coercionLevel_;

  public ProtobufToPig() {
    this(CoercionLevel.kAllowCoercionToPigMaps);
  }

  public ProtobufToPig(CoercionLevel coercionLevel) {
    coercionLevel_ = coercionLevel;
  }
  /**
   * Turn a generic message into a Tuple.  Individual fields that are enums
   * are converted into their string equivalents.  Fields that are not filled
   * out in the protobuf are set to null, unless there is a default field value in
   * which case that is used instead.
   * @param msg the protobuf message
   * @return a pig tuple representing the message.
   */
  public Tuple toTuple(Message msg) {
    if (msg == null) {
      // Pig tuples deal gracefully with nulls.
      // Also, we can be called with null here in recursive calls.
      return null;
    }

    Descriptor msgDescriptor = msg.getDescriptorForType();
    Tuple tuple = tupleFactory_.newTuple(msgDescriptor.getFields().size());
    int curField = 0;
    try {
      // Walk through all the possible fields in the message.
      for (FieldDescriptor fieldDescriptor : msgDescriptor.getFields()) {
        // Get the set value, or the default value, or null.
        Object fieldValue = getFieldValue(msg, fieldDescriptor);

        if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
          tuple.set(curField++, messageToTuple(fieldDescriptor, fieldValue));
        } else {
          tuple.set(curField++, singleFieldToTuple(fieldDescriptor, fieldValue));
        }
      }
    } catch (ExecException e) {
      LOG.warn("Could not convert msg " + msg + " to tuple", e);
    }

    return tuple;
  }

  /**
   * Translate a nested message to a tuple.  If the field is repeated, it walks the list and adds each to a bag.
   * Otherwise, it just adds the given one.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param fieldValue the object representing the value of this field, possibly null.
   * @return the object representing fieldValue in Pig -- either a bag or a tuple.
   */
  @SuppressWarnings("unchecked")
  protected Object messageToTuple(FieldDescriptor fieldDescriptor, Object fieldValue) {
    assert fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE : "messageToTuple called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      // The protobuf contract is that if the field is repeated, then the object returned is actually a List
      // of the underlying datatype, which in this case is a nested message.
      List<Message> messageList = (List<Message>) (fieldValue != null ? fieldValue : Lists.newArrayList());

      // Since protobufs do not have a map type, we use CountedMap to fake it.  Whenever the protobuf has a repeated CountedMap in it,
      // we can force the type into a pig map type.
      if (coercionLevel_ == CoercionLevel.kAllowCoercionToPigMaps &&
          fieldDescriptor.getMessageType().getName().equals(CountedMap.getDescriptor().getName())) {
        Map<Object, Long> map = Maps.newHashMap();
        for (Message m : messageList) {
          CountedMap cm = (CountedMap) m;
          final Long curCount = map.get(cm.getKey());
          map.put(cm.getKey(), (curCount == null ? 0L : curCount) + cm.getValue());
        }
        return map;
      } else {
        DataBag bag = bagFactory_.newDefaultBag();
        for (Message m : messageList) {
          bag.add(new ProtobufTuple(m));
        }
        return bag;
      }
    } else {
      return new ProtobufTuple((Message)fieldValue);
    }
  }

  /**
   * Translate a single field to a tuple.  If the field is repeated, it walks the list and adds each to a bag.
   * Otherwise, it just adds the given one.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param fieldValue the object representing the value of this field, possibly null.
   * @return the object representing fieldValue in Pig -- either a bag or a single field.
   * @throws ExecException if Pig decides to.  Shouldn't happen because we won't walk off the end of a tuple's field set.
   */
  @SuppressWarnings("unchecked")
  protected Object singleFieldToTuple(FieldDescriptor fieldDescriptor, Object fieldValue) throws ExecException {
    assert fieldDescriptor.getType() != FieldDescriptor.Type.MESSAGE : "messageToFieldSchema called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      // The protobuf contract is that if the field is repeated, then the object returned is actually a List
      // of the underlying datatype, which in this case is a "primitive" like int, float, String, etc.
      // We have to make a single-item tuple out of it to put it in the bag.
      DataBag bag = bagFactory_.newDefaultBag();
      List<Object> fieldValueList = (List<Object>) (fieldValue != null ? fieldValue : Lists.newArrayList());
      for (Object singleFieldValue : fieldValueList) {
        Object nonEnumFieldValue = coerceToPigTypes(fieldDescriptor, singleFieldValue);
        Tuple innerTuple = tupleFactory_.newTuple(1);
        innerTuple.set(0, nonEnumFieldValue);
        bag.add(innerTuple);
      }
      return bag;
    } else {
      return coerceToPigTypes(fieldDescriptor, fieldValue);
    }
  }

  /**
   * If the given field value is an enum, translate it to the enum's name as a string, since Pig cannot handle enums.
   * Also, if the given field value is a bool, translate it to 0 or 1 to avoid Pig bools, which can be sketchy.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param fieldValue the object representing the value of this field, possibly null.
   * @return the object, unless it was from an enum field, in which case we return the name of the enum field.
   */
  private Object coerceToPigTypes(FieldDescriptor fieldDescriptor, Object fieldValue) {
    if (fieldDescriptor.getType() == FieldDescriptor.Type.ENUM && fieldValue != null) {
      EnumValueDescriptor enumValueDescriptor = (EnumValueDescriptor)fieldValue;
      return enumValueDescriptor.getName();
    } else if (fieldDescriptor.getType() == FieldDescriptor.Type.BOOL && fieldValue != null) {
      Boolean boolValue = (Boolean)fieldValue;
      return new Integer(boolValue ? 1 : 0);
    } else if (fieldDescriptor.getType() == FieldDescriptor.Type.BYTES && fieldValue != null) {
      ByteString bsValue = (ByteString)fieldValue;
      return new DataByteArray(bsValue.toByteArray());
    }
    return fieldValue;
  }

  /**
   * A utility function for getting the value of a field in a protobuf message.  It first tries the
   * literal set value in the protobuf's field list.  If the value isn't set, and the field has a default
   * value, it uses that.  Otherwise, it returns null.
   * @param msg the protobuf message
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the value of the field, or null if none can be assigned.
   */
  protected Object getFieldValue(Message msg, FieldDescriptor fieldDescriptor) {
    Object o = null;
    Map<FieldDescriptor, Object> setFields = msg.getAllFields();
    if (setFields.containsKey(fieldDescriptor)) {
      o = setFields.get(fieldDescriptor);
    } else if (fieldDescriptor.hasDefaultValue()) {
      o = fieldDescriptor.getDefaultValue();
    }

    return o;
  }

  /**
   * Turn a generic message descriptor into a Schema.  Individual fields that are enums
   * are converted into their string equivalents.
   * @param msgDescriptor the descriptor for the given message type.
   * @return a pig schema representing the message.
   */
  public Schema toSchema(Descriptor msgDescriptor) {
    Schema schema = new Schema();

    try {
      // Walk through all the possible fields in the message.
      for (FieldDescriptor fieldDescriptor : msgDescriptor.getFields()) {
        if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
          schema.add(messageToFieldSchema(fieldDescriptor));
        } else {
          schema.add(singleFieldToFieldSchema(fieldDescriptor));
        }
      }
    } catch (FrontendException e) {
      LOG.warn("Could not convert descriptor " + msgDescriptor + " to schema", e);
    }

    return schema;
  }

  /**
   * Turn a nested message into a Schema object.  For repeated nested messages, it generates a schema for a bag of
   * tuples.  For non-repeated nested messages, it just generates a schema for the tuple itself.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the Schema for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private FieldSchema messageToFieldSchema(FieldDescriptor fieldDescriptor) throws FrontendException {
    assert fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE : "messageToFieldSchema called with field of type " + fieldDescriptor.getType();

    // Since protobufs do not have a map type, we use CountedMap to fake it.  Whenever the protobuf has a repeated CountedMap in it,
    // we can force the type into a pig map type.
    if (coercionLevel_ == CoercionLevel.kAllowCoercionToPigMaps &&
        fieldDescriptor.getMessageType().getName().equals(CountedMap.getDescriptor().getName()) && fieldDescriptor.isRepeated()) {
      return new FieldSchema(fieldDescriptor.getName(), null, DataType.MAP);
    }

    Schema innerSchema = toSchema(fieldDescriptor.getMessageType());

    if (fieldDescriptor.isRepeated()) {
      Schema tupleSchema = new Schema();
      tupleSchema.add(new FieldSchema(fieldDescriptor.getName() + "_tuple", innerSchema, DataType.TUPLE));
      return new FieldSchema(fieldDescriptor.getName(), tupleSchema, DataType.BAG);
    } else {
      return new FieldSchema(fieldDescriptor.getName(), innerSchema, DataType.TUPLE);
    }
  }

  /**
   * Turn a single field into a Schema object.  For repeated single fields, it generates a schema for a bag of single-item tuples.
   * For non-repeated fields, it just generates a standard field schema.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the Schema for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private FieldSchema singleFieldToFieldSchema(FieldDescriptor fieldDescriptor) throws FrontendException {
    assert fieldDescriptor.getType() != FieldDescriptor.Type.MESSAGE : "singleFieldToFieldSchema called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      Schema itemSchema = new Schema();
      itemSchema.add(new FieldSchema(fieldDescriptor.getName(), null, getPigDataType(fieldDescriptor)));
      Schema itemTupleSchema = new Schema();
      itemTupleSchema.add(new FieldSchema(fieldDescriptor.getName() + "_tuple", itemSchema, DataType.TUPLE));

      return new FieldSchema(fieldDescriptor.getName() + "_bag", itemTupleSchema, DataType.BAG);
    } else {
      return new FieldSchema(fieldDescriptor.getName(), null, getPigDataType(fieldDescriptor));
    }
  }

  /**
   * Translate between protobuf's datatype representation and Pig's datatype representation.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the byte representing the pig datatype for the given field type.
   */
  private byte getPigDataType(FieldDescriptor fieldDescriptor) {
    switch (fieldDescriptor.getType()) {
      case INT32:
      case UINT32:
      case SINT32:
      case FIXED32:
      case SFIXED32:
      case BOOL: // We convert booleans to ints for pig output.
        return DataType.INTEGER;
      case INT64:
      case UINT64:
      case SINT64:
      case FIXED64:
      case SFIXED64:
        return DataType.LONG;
      case FLOAT:
        return DataType.FLOAT;
      case DOUBLE:
        return DataType.DOUBLE;
      case STRING:
      case ENUM: // We convert enums to strings for pig output.
        return DataType.CHARARRAY;
      case BYTES:
        return DataType.BYTEARRAY;
      case MESSAGE:
        throw new IllegalArgumentException("getPigDataType called on field " + fieldDescriptor.getFullName() + " of type message.");
      default:
        throw new IllegalArgumentException("Unexpected field type. " + fieldDescriptor.toString() + " " + fieldDescriptor.getFullName() + " " + fieldDescriptor.getType());
    }
  }

  /**
   * Turn a generic message descriptor into a loading schema for a pig script.
   * @param msgDescriptor the descriptor for the given message type.
   * @param loaderClassName the fully qualified classname of the pig loader to use.  Not
   * passed a <code>Class<? extends LoadFunc></code> because in many situations that class
   * is being generated as well, and so doesn't exist in compiled form.
   * @return a pig schema representing the message.
   */
  public String toPigScript(Descriptor msgDescriptor, String loaderClassName) {
    StringBuffer sb = new StringBuffer();
    final int initialTabOffset = 3;

    sb.append("raw_data = load '$INPUT_FILES' using " + loaderClassName + "()").append("\n");
    sb.append(tabs(initialTabOffset)).append("as (").append("\n");
    sb.append(toPigScriptInternal(msgDescriptor, initialTabOffset));
    sb.append(tabs(initialTabOffset)).append(");").append("\n").append("\n");

    return sb.toString();
  }

  /**
   * Turn a generic message descriptor into a loading schema for a pig script.  Individual fields that are enums
   * are converted into their string equivalents.
   * @param msgDescriptor the descriptor for the given message type.
   * @param numTabs the tab depth at the current point in the recursion, for pretty printing.
   * @return a pig schema representing the message.
   */
  private StringBuffer toPigScriptInternal(Descriptor msgDescriptor, int numTabs) {
    StringBuffer sb = new StringBuffer();
    try {
      // Walk through all the possible fields in the message.
      for (FieldDescriptor fieldDescriptor : msgDescriptor.getFields()) {
        // We have to add a comma after every line EXCEPT for the last, or Pig gets mad.
        boolean isLast = (fieldDescriptor == msgDescriptor.getFields().get(msgDescriptor.getFields().size() - 1));
        if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
          sb.append(messageToPigScript(fieldDescriptor, numTabs + 1, isLast));
        } else {
          sb.append(singleFieldToPigScript(fieldDescriptor, numTabs + 1, isLast));
        }
      }
    } catch (FrontendException e) {
      LOG.warn("Could not convert descriptor " + msgDescriptor + " to pig script", e);
    }

    return sb;
  }

  /**
   * Turn a nested message into a pig script load string.  For repeated nested messages, it generates a string for a bag of
   * tuples.  For non-repeated nested messages, it just generates a string for the tuple itself.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param numTabs the tab depth at the current point in the recursion, for pretty printing.
   * @return the pig script load schema for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private StringBuffer messageToPigScript(FieldDescriptor fieldDescriptor, int numTabs, boolean isLast) throws FrontendException {
    assert fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE : "messageToPigScript called with field of type " + fieldDescriptor.getType();

    // Since protobufs do not have a map type, we use CountedMap to fake it.  Whenever the protobuf has a repeated CountedMap in it,
    // we force the type into a pig map type.
    if (coercionLevel_ == CoercionLevel.kAllowCoercionToPigMaps &&
        fieldDescriptor.getMessageType().getName().equals(CountedMap.getDescriptor().getName()) && fieldDescriptor.isRepeated()) {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName())
          .append(": map[]").append(isLast ? "" : ",").append("\n");
    }

    if (fieldDescriptor.isRepeated()) {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append(": bag {").append("\n")
          .append(tabs(numTabs + 1)).append(fieldDescriptor.getName()).append("_tuple: tuple (").append("\n")
          .append(toPigScriptInternal(fieldDescriptor.getMessageType(), numTabs + 2))
          .append(tabs(numTabs + 1)).append(")").append("\n")
          .append(tabs(numTabs)).append("}").append(isLast ? "" : ",").append("\n");
    } else {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append(": tuple (").append("\n")
          .append(toPigScriptInternal(fieldDescriptor.getMessageType(), numTabs + 1))
          .append(tabs(numTabs)).append(")").append(isLast ? "" : ",").append("\n");
    }
  }

  /**
   * Turn a single field into a pig script load string.  For repeated single fields, it generates a string for a bag of single-item tuples.
   * For non-repeated fields, it just generates a standard single-element string.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param numTabs the tab depth at the current point in the recursion, for pretty printing.
   * @return the pig script load string for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private StringBuffer singleFieldToPigScript(FieldDescriptor fieldDescriptor, int numTabs, boolean isLast) throws FrontendException {
    assert fieldDescriptor.getType() != FieldDescriptor.Type.MESSAGE : "singleFieldToPigScript called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append("_bag: bag {").append("\n")
          .append(tabs(numTabs + 1)).append(fieldDescriptor.getName()).append("_tuple: tuple (").append("\n")
          .append(tabs(numTabs + 2)).append(fieldDescriptor.getName()).append(": ").append(getPigScriptDataType(fieldDescriptor)).append("\n")
          .append(tabs(numTabs + 1)).append(")").append("\n")
          .append(tabs(numTabs)).append("}").append(isLast ? "" : ",").append("\n");
    } else {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append(": ")
          .append(getPigScriptDataType(fieldDescriptor)).append(isLast ? "" : ",").append("\n");
    }
  }

  /**
   * Translate between protobuf's datatype representation and Pig's datatype representation.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the byte representing the pig datatype for the given field type.
   */
  private String getPigScriptDataType(FieldDescriptor fieldDescriptor) {
    switch (fieldDescriptor.getType()) {
      case INT32:
      case UINT32:
      case SINT32:
      case FIXED32:
      case SFIXED32:
      case BOOL: // We convert booleans to ints for pig output.
        return "int";
      case INT64:
      case UINT64:
      case SINT64:
      case FIXED64:
      case SFIXED64:
        return "long";
      case FLOAT:
        return "float";
      case DOUBLE:
        return "double";
      case STRING:
      case ENUM: // We convert enums to strings for pig output.
        return "chararray";
      case BYTES:
        return "bytearray";
      case MESSAGE:
        throw new IllegalArgumentException("getPigScriptDataType called on field " + fieldDescriptor.getFullName() + " of type message.");
      default:
        throw new IllegalArgumentException("Unexpected field type. " + fieldDescriptor.toString() + " " + fieldDescriptor.getFullName() + " " + fieldDescriptor.getType());
    }
  }

  private StringBuffer tabs(int numTabs) {
    StringBuffer sb = new StringBuffer();
    for (int i = 0; i < numTabs; i++) {
      sb.append("  ");
    }
    return sb;
  }  
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/pig/util/PigCounterHelper.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

import java.util.Map;

import com.google.common.collect.Maps;
import org.apache.hadoop.mapred.Reporter;
import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigHadoopLogger;
import org.apache.pig.impl.util.Pair;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * A helper class to deal with Hadoop counters in Pig.  They are stored within the singleton
 * PigHadoopLogger instance, but are null for some period of time at job startup, even after
 * Pig has been invoked.  This class buffers counters, trying each time to get a valid Reporter and flushing
 * stored counters each time it does.
 */
public class PigCounterHelper {
  private Map<Pair<String, String>, Long> counterStringMap_ = Maps.newHashMap();
  private Map<Enum<?>, Long> counterEnumMap_ = Maps.newHashMap();
  private Reporter reporter_ = null;

  /**
   * Mocks the Reporter.incrCounter, but adds buffering.
   * See org.apache.hadoop.mapred.Reporter's incrCounter.
   */
  public void incrCounter(String group, String counter, long incr) {
    if (getReporter() != null) { // common case
      getReporter().incrCounter(group, counter, incr);
      if (counterStringMap_.size() > 0) {
        for (Map.Entry<Pair<String, String>, Long> entry : counterStringMap_.entrySet()) {
          getReporter().incrCounter(entry.getKey().first, entry.getKey().second, entry.getValue());
        }
        counterStringMap_.clear();
      }
    } else { // buffer the increments.
      Pair<String, String> key = new Pair<String, String>(group, counter);
      Long currentValue = counterStringMap_.get(key);
      counterStringMap_.put(key, (currentValue == null ? 0 : currentValue) + incr);
    }
  }

  /**
   * Mocks the Reporter.incrCounter, but adds buffering.
   * See org.apache.hadoop.mapred.Reporter's incrCounter.
   */
  public void incrCounter(Enum<?> key, long incr) {
    if (getReporter() != null) {
      getReporter().incrCounter(key, incr);
      if (counterEnumMap_.size() > 0) {
        for (Map.Entry<Enum<?>, Long> entry : counterEnumMap_.entrySet()) {
          getReporter().incrCounter(entry.getKey(), entry.getValue());
        }
        counterEnumMap_.clear();
      }
    } else { // buffer the increments
      Long currentValue = counterEnumMap_.get(key);
      counterEnumMap_.put(key, (currentValue == null ? 0 : currentValue) + incr);
    }
  }

  /**
   * Try for the Reporter object if it hasn't been initialized yet, otherwise just return it.
   * @return the job's reporter object, or null if it isn't retrievable yet.
   */
  private Reporter getReporter() {
    if (reporter_ == null) {
      reporter_ = PigHadoopLogger.getInstance().getReporter();
    }
    return reporter_;
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import java.net.URI;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Map;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapreduce.lib.input.FileSplit;
import org.apache.pig.ExecType;
import org.apache.pig.FuncSpec;
import org.apache.pig.LoadFunc;
import org.apache.pig.PigException;
import org.apache.pig.SamplableLoader;
import org.apache.pig.Slice;
import org.apache.pig.Slicer;
import org.apache.pig.backend.datastorage.ContainerDescriptor;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.backend.datastorage.ElementDescriptor;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.builtin.Utf8StorageConverter;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.io.BufferedPositionedInputStream;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.collect.Lists;
import com.hadoop.compression.lzo.LzoIndex;
import com.hadoop.compression.lzo.LzopCodec;
import com.twitter.elephantbird.pig.util.PigCounterHelper;

/**
 * This class handles LZO-decoding and slicing input LZO files.  It expects the
 * filenames to end in .lzo, otherwise it assumes they are not compressed and skips them.
 * TODO: Improve the logic to accept a mixture of lzo and non-lzo files.
 */
public abstract class LzoBaseLoadFunc extends Utf8StorageConverter implements LoadFunc, Slicer, SamplableLoader {
  private static final Logger LOG = LoggerFactory.getLogger(LzoBaseLoadFunc.class);

  protected final String LZO_EXTENSION = new LzopCodec().getDefaultExtension();

  // This input stream will be our wrapped LZO-decoding stream.
  protected BufferedPositionedInputStream is_;
  protected long end_;
  // The load func spec is the load function name (with classpath) plus the arguments.
  protected FuncSpec loadFuncSpec_;
  // Whether our split begins at the beginning of the data in the file.  Generally one can check
  // for offset == 0, but not with LZO's variable-length file header.
  protected boolean beginsAtHeader_ = false;

  // Making accessing Hadoop counters from Pig slightly more convenient.
  private final PigCounterHelper counterHelper_ = new PigCounterHelper();

  /**
   * Construct a new load func.
   */
  public LzoBaseLoadFunc() {
    // By default, the spec is the class being loaded with no arguments.
    setLoaderSpec(getClass(), new String[] {});
  }

  /**
   * Set whether this chunk begins at the beginning of the entire file,
   * just after the LZO file header.
   * @param beginsAtHeader whether this is the first chunk of the file, and so
   *        begins at the LZO file header offset.
   */
  public void setBeginsAtHeader(boolean beginsAtHeader) {
    beginsAtHeader_ = beginsAtHeader;
  }

  /**
   * The important part of the loader -- given a storage object and a location to load, actually
   * compute the splits.  Walks through each LZO file under the given path and attempts to use the
   * .lzo.index file to slice it.
   *
   * @param store the data storage object.
   * @param location the given location to load, e.g. '/tables/statuses/20090815.lzo' when invoked as
   * a = LOAD '/tables/statuses/20090815.lzo' USING ... AS ...;
   */
  public Slice[] slice(DataStorage store, String location) throws IOException {
    LOG.info("LzoBaseLoadFunc::slice, location = " + location);
    List<LzoSlice> slices = Lists.newArrayList();
    // Compute the set of LZO files matching the given pattern.
    List<ElementDescriptor> globbedFiles = globFiles(store, location);

    for (ElementDescriptor file : globbedFiles) {
      // Make sure to slice according to the per-file split characteristics.
      Map<String, Object> fileStats = file.getStatistics();
      long blockSize = (Long)fileStats.get(ElementDescriptor.BLOCK_SIZE_KEY);
      long fileSize = (Long)fileStats.get(ElementDescriptor.LENGTH_KEY);

      LOG.debug("Slicing LZO file at path " + file + ": block size " + blockSize + " and file size " + fileSize);
      slices.addAll(sliceFile(file.toString(), blockSize, fileSize));
    }
    if (slices.size() == 0) {
      throw new PigException("no files found a path "+location);
    }
    LOG.info("Got " + slices.size() + " LZO slices in total.");
    return slices.toArray(new Slice[slices.size()]);
  }

  /**
   * Nothing to do here, since location can be an unexpanded glob.
   * Also, the idea that validate returns void and instead throws an exception to fail validation is ridiculous.
   */
  public void validate(DataStorage store, String location) throws IOException {
  }

  /**
   * Called on the datanodes during the data loading process, this connects a Map job with an input split.
   * @param filename the name of the file whose split is being loaded.
   * @param is the input stream to the file.
   * @param offset the offset within the file (the input stream is pre-positioned here)
   * @param end the end offset of the input split.
   */
  public void bindTo(String filename, BufferedPositionedInputStream is, long offset, long end) throws IOException {
    LOG.info("LzoBaseLoadFunc::bindTo, filename = " + filename + ", offset = " + offset + ", and end = " + end);
    LOG.debug("InputStream position is: "+is.getPosition());
    is_ = is;
    end_ = end;

    // Override this to do anything loader-specific to the input stream, etc.
    postBind();
    // Override to do any special syncing for moving to the right point of a new input split.
    skipToNextSyncPoint(beginsAtHeader_);

    LOG.debug("InputStream position after skip is: "+is.getPosition());
  }

  /**
   * Override to do anything special after the bindTo function has been called, and before the sync happens.
   */
  public void postBind() throws IOException {
  }

  /**
   * Override to do any special syncing for moving to the right point of a new input split.
   *
   * @param atFirstRecord whether or not this is the first record in the file.  Typically for line-based
   * readers, for example, we want to skip to the next new line at the beginning of an input split because
   * the arbitrary byte offset we're at generally puts us in the middle of a line.  We count on the previous
   * input split to read slightly beyond its offset to the end of the next line to account for this.
   * However, this doesn't hold for the very first record in the file.
   */
  public abstract void skipToNextSyncPoint(boolean atFirstRecord) throws IOException;

  /**
   * Give hints to pig about the output schema -- there are none needed.
   */
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return null;
  }

  /**
   * This seems to always be unimplemented.
   */
  public void fieldsToRead(Schema schema) {
  }

  /**
   * Set the loader spec so any arguments given in the script are tracked, to be reinstantiated by the mappers.
   * @param clazz the class of the load function to use.
   * @param args an array of strings that are fed to the class's constructor.
   */
  protected void setLoaderSpec(Class <? extends LzoBaseLoadFunc> clazz, String[] args) {
    loadFuncSpec_ = new FuncSpec(clazz.getName(), args);
  }

  /**
   * A convenience function for working with Hadoop counter objects from load functions.  The Hadoop
   * reporter object isn't always set up at first, so this class provides brief buffering to ensure
   * that counters are always recorded.
   */
  protected void incrCounter(String group, String counter, long incr) {
    counterHelper_.incrCounter(group, counter, incr);
  }
  
  /** same as incrCounter(pair.first, pair.second, incr). */
  protected void incrCounter(Pair<String, String> groupCounterPair, long incr) {
    counterHelper_.incrCounter(groupCounterPair.first, groupCounterPair.second, incr);
  }
  
  /**
   * A convenience function for working with Hadoop counter objects from load functions.  The Hadoop
   * reporter object isn't always set up at first, so this class provides brief buffering to ensure
   * that counters are always recorded.
   */
  protected void incrCounter(Enum<?> key, long incr) {
    counterHelper_.incrCounter(key, incr);
  }

  /**
   * Called to verify that the stream is readable, i.e. not null and not past the byte offset
   * of the next split.
   * @return true if the input stream is valid and has not yet read past the last byte of the current split.
   */
  protected boolean verifyStream() throws IOException {
    return is_ != null && is_.getPosition() <= end_;
  }

  /**
   * Given a path, glob all the files underneath it, and return all the LZO files.
   * @param store the data store object
   * @param location the input location glob from the pig script
   * @return the set of LZO files matching the location glob
   */
  private List<ElementDescriptor> globFiles(DataStorage store, String location) throws IOException {
    List<ElementDescriptor> files = Lists.newArrayList();
    List<ElementDescriptor> paths = Lists.newArrayList();
    paths.addAll(Arrays.asList(store.asCollection(location)));

    // Note that paths.size increases through the loop as directories are encountered.
    for (int j = 0; j < paths.size(); j++) {
      ElementDescriptor path = paths.get(j);
      ElementDescriptor fullPath = store.asElement(store.getActiveContainer(), path);
      if (fullPath.systemElement()) {
        // Skip Hadoop's private/meta files.
        continue;
      }

      // If it's a directory, add it to the path and go back to the top.
      try {
        if (fullPath instanceof ContainerDescriptor) {
          for (ElementDescriptor child : (ContainerDescriptor)fullPath) {
            paths.add(child);
          }
          continue;
        }
      } catch (Exception e) {
        // See the corresponding part of PigSlicer.java
        int errCode = 2099;
        String msg = "Problem in constructing LZO slices: " + e.getMessage();
        throw new ExecException(msg, errCode, PigException.BUG, e);
      }

      // It's a file.
      // TODO: make this able to read non-LZO data too.
      if (!fullPath.toString().endsWith(LZO_EXTENSION)) {
        continue;
      }
      files.add(fullPath);
    }

    return files;
  }

  /**
   * Given an individual LZO file, break it into input splits according to its block size,
   * then use the index (if it exists) to massage the offsets to LZO block boundaries
   * to allow the file to be split across mappers.
   * @param filename the name of the file being read
   * @param blockSize the Hadoop block size of the file (usually 64 or 128 MB)
   * @param fileSize the total length of the file.
   * @return a list of LzoSlice objects corresponding to the massaged splits.
   */
  private List<LzoSlice> sliceFile(String filename, long blockSize, long fileSize) throws IOException {
    List<LzoSlice> slices = new ArrayList<LzoSlice>();
    Path filePath = new Path(filename);

    LzoIndex index = LzoIndex.readIndex(FileSystem.get(URI.create(filename), new Configuration()), filePath);
    if (index == null || index.isEmpty()) {
      LOG.info("LzoLoadFunc::sliceFile, file " + filename + " and index is empty or nonexistant");
      // If there is no index, or it couldn't be read, don't split.
      slices.add(new LzoSlice(filename, 0, fileSize, loadFuncSpec_));
    } else if (fileSize == 0) {
      LOG.info("LzoLoadFunc::sliceFile, file " + filename + " and fileSize == 0");
      // Add fileSize empty slice.  This is a total hack to deal with the
      // case where hadoop isn't starting maps for empty arrays of
      // InputSplits.  See PIG-619.  This should be removed
      // once we determine why this is.
      slices.add(new LzoSlice(filename, 0, blockSize, loadFuncSpec_));
    } else {
      // There is an index file.  First create the default file splits based on the blocksize.
      List<FileSplit> splits = new ArrayList<FileSplit>();
      for (long pos = 0; pos < fileSize; pos += blockSize) {
        splits.add(new FileSplit(filePath, pos, Math.min(blockSize, fileSize - pos), null));
      }

      LOG.info("LzoLoadFunc::sliceFile, file " + filename + " with size " + fileSize + " into " + splits.size() + " chunks.");
      for (FileSplit split : splits) {
        // Now massage the default splits to LZO block boundaries.
        long start = split.getStart();
        long end = start + split.getLength();

        long lzoStart = index.alignSliceStartToIndex(start, end);
        long lzoEnd = index.alignSliceEndToIndex(end, fileSize);

        if (lzoStart != LzoIndex.NOT_FOUND  && lzoEnd != LzoIndex.NOT_FOUND) {
          slices.add(new LzoSlice(filename, lzoStart, lzoEnd - lzoStart, loadFuncSpec_));
        }
      }
    }

    return slices;
  }

  public long getPosition() throws IOException {
    return is_.getPosition();
  }

  public Tuple getSampledTuple() throws IOException {
    if (getPosition() > end_ ) {
      return null;
    }
    return getNext();
  }

  public long skip(long bytesToSkip) throws IOException {
    long startPos = getPosition();
    is_.skip(bytesToSkip);
    skipToNextSyncPoint(getPosition() == 0 && this.beginsAtHeader_);
    return getPosition() - startPos;
  }

  @Override
  public LoadFunc.RequiredFieldResponse fieldsToRead(LoadFunc.RequiredFieldList requiredFieldList) throws FrontendException {
      return new LoadFunc.RequiredFieldResponse(false);
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;

import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.protobuf.Message;
import com.twitter.elephantbird.mapreduce.io.ProtobufBlockReader;
import com.twitter.elephantbird.mapreduce.io.ProtobufWritable;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
import com.twitter.elephantbird.pig.util.ProtobufTuple;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;


public class LzoProtobufBlockPigLoader<M extends Message> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufBlockPigLoader.class);

  private ProtobufBlockReader<M> reader_ = null;
  private ProtobufWritable<M> value_ = null;
  private TypeRef<M> typeRef_ = null;
  private final ProtobufToPig protoToPig_ = new ProtobufToPig();

  private Pair<String, String> protobufsRead;
  private Pair<String, String> protobufErrors;

  public LzoProtobufBlockPigLoader() {
    LOG.info("LzoProtobufBlockLoader zero-parameter creation");
  }

  /**
   * Set the type parameter so it doesn't get erased by Java.  Must be called before getNext!
   *
   * @param typeRef
   */
  public void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    value_ = new ProtobufWritable<M>(typeRef_);
    String group = "LzoBlocks of " + typeRef_.getRawClass().getName();
    protobufsRead = new Pair<String, String>(group, "Protobufs Read");
    protobufErrors = new Pair<String, String>(group, "Errors");
  }

  @Override
  public void postBind() throws IOException {
    reader_ = new ProtobufBlockReader<M>(is_, typeRef_);
  }

  @Override
  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // We want to explicitly not do any special syncing here, because the reader_
    // handles this automatically.
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }


  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    // If we are past the end of the file split, tell the reader not to read any more new blocks.
    // Then continue reading until the last of the reader's already-parsed values are used up.
    // The next split will start at the next sync point and no records will be missed.
    if (is_.getPosition() > end_) {
      reader_.markNoMoreNewBlocks();
    }

    Tuple t = null;
    if (reader_.readProtobuf(value_)) {
      if (value_.get() == null) {
        incrCounter(protobufErrors, 1);
      }
      t = new ProtobufTuple(value_.get());
      incrCounter(protobufsRead, 1L);
    }
    return t;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return protoToPig_.toSchema(Protobufs.getMessageDescriptor(typeRef_.getRawClass()));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import java.nio.charset.Charset;

import org.apache.commons.codec.binary.Base64;
import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.base.Function;
import com.google.protobuf.Message;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
import com.twitter.elephantbird.pig.util.ProtobufTuple;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * This is the base class for all base64 encoded, line-oriented protocol buffer based pig loaders.
 * Data is expected to be one base64 encoded serialized protocol buffer per line. The specific
 * protocol buffer is a template parameter, generally specified by a codegen'd derived class.
 * See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
 */

public abstract class LzoProtobufB64LinePigLoader<M extends Message> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufB64LinePigLoader.class);

  private TypeRef<M> typeRef_ = null;
  private Function<byte[], M> protoConverter_ = null;
  private final Base64 base64_ = new Base64();
  private final ProtobufToPig protoToPig_ = new ProtobufToPig();

  private static final Charset UTF8 = Charset.forName("UTF-8");
  private static final byte RECORD_DELIMITER = (byte)'\n';

  private Pair<String, String> linesRead;
  private Pair<String, String> protobufsRead;
  private Pair<String, String> protobufErrors;

  public LzoProtobufB64LinePigLoader() {
    LOG.info("LzoProtobufB64LineLoader zero-parameter creation");
  }

  /**
   * Set the type parameter so it doesn't get erased by Java.  Must be called before getNext!
   *
   * @param typeRef
   */
  public void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    protoConverter_ = Protobufs.getProtoConverter(typeRef.getRawClass());
    String group = "LzoB64Lines of " + typeRef_.getRawClass().getName();
    linesRead = new Pair<String, String>(group, "Lines Read");
    protobufsRead = new Pair<String, String>(group, "Protobufs Read");
    protobufErrors = new Pair<String, String>(group, "Errors");
  }

  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // Since we are not block aligned we throw away the first record of each split and count on a different
    // instance to read it.  The only split this doesn't work for is the first.
    if (!atFirstRecord) {
      getNext();
    }
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }

  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    String line;
    Tuple t = null;
    while ((line = is_.readLine(UTF8, RECORD_DELIMITER)) != null) {
      incrCounter(linesRead, 1L);
      M protoValue = protoConverter_.apply(base64_.decode(line.getBytes("UTF-8")));
      if (protoValue != null) {
        t = new ProtobufTuple(protoValue);
        incrCounter(protobufsRead, 1L);
        break;
      } else {
        incrCounter(protobufErrors, 1L);
      }
    }

    return t;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return protoToPig_.toSchema(Protobufs.getMessageDescriptor(typeRef_.getRawClass()));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c01b27b_cebd3d0/rev_c01b27b-cebd3d0/src/java/com/twitter/elephantbird/pig/piggybank/BytesToThriftTuple.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.piggybank;

import java.io.IOException;

import org.apache.pig.EvalFunc;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.thrift.TBase;
import org.apache.thrift.TDeserializer;
import org.apache.thrift.TException;
import org.apache.thrift.protocol.TBinaryProtocol;
import org.apache.thrift.transport.TMemoryBuffer;

import com.twitter.elephantbird.util.TypeRef;

/**
 * This is an abstract UDF for converting serialized Thrift objects into Pig tuples.
 * To create a converter for your Thrift class <code>MyThriftClass</code>, you simply need to extend
 * <code>BytesToThriftTuple</code> with something like this:
 *<pre>
 * {@code
 * public class BytesToSimpleLocation extends BytesToThriftTuple<MyThriftClass> {
 *
 *   public BytesToSimpleLocation() {
 *     setTypeRef(new TypeRef<MyThriftClass>() {});
 *   }
 * }}
 *</pre>
 */
public abstract class BytesToThriftTuple<T extends TBase<?>> extends EvalFunc<Tuple> {

  private final TDeserializer deserializer_ = new TDeserializer(new TBinaryProtocol.Factory());
  private ThriftToPig<T> thriftToTuple_;
  private TypeRef<T> typeRef_;

  /**
   * Set the type parameter so it doesn't get erased by Java.  Must be called by the constructor!
   *
   * @param typeRef
   */
  public void setTypeRef(TypeRef<T> typeRef) {
    typeRef_ = typeRef;
    thriftToTuple_ = ThriftToPig.newInstance(typeRef);
  }


  @Override
  public Tuple exec(org.apache.pig.data.Tuple input) throws IOException {
    if (input == null || input.size() < 1) return null;
    try {
      T tObj = typeRef_.safeNewInstance();
      DataByteArray dbarr = (DataByteArray) input.get(0);
      deserializer_.deserialize(tObj, dbarr.get());
      return thriftToTuple_.getPigTuple(tObj);
    } catch (IOException e) {
      log.warn("Caught exception "+e.getMessage());
      return null;
    } catch (TException e) {
      log.warn("Unable to deserialize Thrift object: "+e);
      return null;
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/examples/src/java/com/twitter/elephantbird/examples/ThriftMRExample.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.examples;

import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

import com.twitter.elephantbird.examples.thrift.Age;
import com.twitter.elephantbird.mapreduce.input.LzoThriftB64LineInputFormat;
import com.twitter.elephantbird.mapreduce.input.LzoThriftBlockInputFormat;
import com.twitter.elephantbird.mapreduce.io.ThriftWritable;
import com.twitter.elephantbird.mapreduce.output.LzoThriftB64LineOutputFormat;
import com.twitter.elephantbird.mapreduce.output.LzoThriftBlockOutputFormat;

/**
 * -Dthrift.test=lzoOut : takes text files with name and age on each line as 
 * input and writes to lzo file with Thrift serilized data. <br>
 * -Dthrift.test=lzoIn : does the reverse. <br><br>
 * 
 * -Dthrift.test.format=Block (or B64Line) to test different formats. <br>
 */

public class ThriftMRExample {

  private ThriftMRExample() {}

  public static class TextMapper extends Mapper<LongWritable, Text, NullWritable, ThriftWritable<Age>> {
    ThriftWritable<Age> tWritable = ThriftWritable.newInstance(Age.class);
    Age age = new Age();
    
    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
      StringTokenizer line = new StringTokenizer(value.toString(), "\t\r\n");
      if (line.hasMoreTokens()
          && age.setName(line.nextToken()) != null
          && line.hasMoreTokens()
          && age.setAge(Integer.parseInt(line.nextToken())) != null) {
          tWritable.set(age);
          context.write(null, tWritable);
      }
    }
  }

  public int runTextToLzo(String[] args, Configuration conf) throws Exception {
    Job job = new Job(conf);
    job.setJobName("Thrift Example : Text to LzoB64Line");

    job.setJarByClass(getClass());
    job.setMapperClass(TextMapper.class);
    job.setNumReduceTasks(0);
    
    job.setInputFormatClass(TextInputFormat.class);
    if (conf.get("thrift.test.format", "B64Line").equals("Block")) {
      job.setOutputFormatClass(LzoThriftBlockOutputFormat.getOutputFormatClass(Age.class, job.getConfiguration()));
    } else { // assume B64Line
      job.setOutputFormatClass(LzoThriftB64LineOutputFormat.getOutputFormatClass(Age.class, job.getConfiguration()));
    }

    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));

    return job.waitForCompletion(true) ? 0 : 1;
  }

  
  public static class LzoMapper extends Mapper<LongWritable, ThriftWritable<Age>, Text, Text> {
    @Override
    protected void map(LongWritable key, ThriftWritable<Age> value, Context context) throws IOException, InterruptedException {
      Age age = value.get();
      context.write(null, new Text(age.getName() + "\t" + age.getAge()));
    }
  }

  public int runLzoToText(String[] args, Configuration conf) throws Exception {
    Job job = new Job(conf);
    job.setJobName("Thrift Example : LzoB64Line to Text");

    job.setJarByClass(getClass());
    job.setMapperClass(LzoMapper.class);
    job.setNumReduceTasks(0);
    
    if (conf.get("thrift.test.format", "B64Line").equals("Block")) {
      job.setInputFormatClass(LzoThriftBlockInputFormat.getInputFormatClass(Age.class, job.getConfiguration()));
    } else {
      job.setInputFormatClass(LzoThriftB64LineInputFormat.getInputFormatClass(Age.class, job.getConfiguration()));      
    }
    job.setOutputFormatClass(TextOutputFormat.class);

    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));

    return job.waitForCompletion(true) ? 0 : 1;
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    args = new GenericOptionsParser(conf, args).getRemainingArgs();
    ThriftMRExample runner = new ThriftMRExample();
    
    if (args.length != 2) {
      System.out.println("Usage: hadoop jar path/to/this.jar " + runner.getClass() + " <input dir> <output dir>");
      System.exit(1);
    }
    
    String test = conf.get("thrift.test", "lzoIn");
    
    if (test.equals("lzoIn"))
      System.exit(runner.runLzoToText(args, conf));
    if (test.equals("lzoOut"))
      System.exit(runner.runTextToLzo(args, conf));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/io/ProtobufPersonWritable.java;<<<<<<< MINE
=======
  public ProtobufPersonWritable(Person m) {
    super(m, new TypeRef<Person>(){});
  }
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/io/ProtobufAddressBookWritable.java;<<<<<<< MINE
=======
  public ProtobufAddressBookWritable(AddressBook m) {
    super(m, new TypeRef<AddressBook>(){});
  }
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/examples/src/gen-java/com/twitter/elephantbird/examples/thrift/AddressBook.java;<<<<<<< MINE
=======
/**
 * Autogenerated by Thrift
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 */
package com.twitter.elephantbird.examples.thrift;

import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;
import java.util.EnumMap;
import java.util.Set;
import java.util.HashSet;
import java.util.EnumSet;
import java.util.Collections;
import java.util.BitSet;
import java.util.Arrays;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.thrift.*;
import org.apache.thrift.meta_data.*;
import org.apache.thrift.protocol.*;

public class AddressBook implements TBase<AddressBook._Fields>, java.io.Serializable, Cloneable, Comparable<AddressBook> {
  private static final TStruct STRUCT_DESC = new TStruct("AddressBook");

  private static final TField PERSONS_FIELD_DESC = new TField("persons", TType.LIST, (short)1);

  public List<Person> persons;

  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
  public enum _Fields implements TFieldIdEnum {
    PERSONS((short)1, "persons");

    private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

    static {
      for (_Fields field : EnumSet.allOf(_Fields.class)) {
        byId.put((int)field._thriftId, field);
        byName.put(field.getFieldName(), field);
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, or null if its not found.
     */
    public static _Fields findByThriftId(int fieldId) {
      return byId.get(fieldId);
    }

    /**
     * Find the _Fields constant that matches fieldId, throwing an exception
     * if it is not found.
     */
    public static _Fields findByThriftIdOrThrow(int fieldId) {
      _Fields fields = findByThriftId(fieldId);
      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
      return fields;
    }

    /**
     * Find the _Fields constant that matches name, or null if its not found.
     */
    public static _Fields findByName(String name) {
      return byName.get(name);
    }

    private final short _thriftId;
    private final String _fieldName;

    _Fields(short thriftId, String fieldName) {
      _thriftId = thriftId;
      _fieldName = fieldName;
    }

    public short getThriftFieldId() {
      return _thriftId;
    }

    public String getFieldName() {
      return _fieldName;
    }
  }

  // isset id assignments

  public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
    put(_Fields.PERSONS, new FieldMetaData("persons", TFieldRequirementType.DEFAULT, 
        new ListMetaData(TType.LIST, 
            new StructMetaData(TType.STRUCT, Person.class))));
  }});

  static {
    FieldMetaData.addStructMetaDataMap(AddressBook.class, metaDataMap);
  }

  public AddressBook() {
  }

  public AddressBook(
    List<Person> persons)
  {
    this();
    this.persons = persons;
  }

  /**
   * Performs a deep copy on <i>other</i>.
   */
  public AddressBook(AddressBook other) {
    if (other.isSetPersons()) {
      List<Person> __this__persons = new ArrayList<Person>();
      for (Person other_element : other.persons) {
        __this__persons.add(new Person(other_element));
      }
      this.persons = __this__persons;
    }
  }

  public AddressBook deepCopy() {
    return new AddressBook(this);
  }

  @Deprecated
  public AddressBook clone() {
    return new AddressBook(this);
  }

  public int getPersonsSize() {
    return (this.persons == null) ? 0 : this.persons.size();
  }

  public java.util.Iterator<Person> getPersonsIterator() {
    return (this.persons == null) ? null : this.persons.iterator();
  }

  public void addToPersons(Person elem) {
    if (this.persons == null) {
      this.persons = new ArrayList<Person>();
    }
    this.persons.add(elem);
  }

  public List<Person> getPersons() {
    return this.persons;
  }

  public AddressBook setPersons(List<Person> persons) {
    this.persons = persons;
    return this;
  }

  public void unsetPersons() {
    this.persons = null;
  }

  /** Returns true if field persons is set (has been asigned a value) and false otherwise */
  public boolean isSetPersons() {
    return this.persons != null;
  }

  public void setPersonsIsSet(boolean value) {
    if (!value) {
      this.persons = null;
    }
  }

  public void setFieldValue(_Fields field, Object value) {
    switch (field) {
    case PERSONS:
      if (value == null) {
        unsetPersons();
      } else {
        setPersons((List<Person>)value);
      }
      break;

    }
  }

  public void setFieldValue(int fieldID, Object value) {
    setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
  }

  public Object getFieldValue(_Fields field) {
    switch (field) {
    case PERSONS:
      return getPersons();

    }
    throw new IllegalStateException();
  }

  public Object getFieldValue(int fieldId) {
    return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
  }

  /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
  public boolean isSet(_Fields field) {
    switch (field) {
    case PERSONS:
      return isSetPersons();
    }
    throw new IllegalStateException();
  }

  public boolean isSet(int fieldID) {
    return isSet(_Fields.findByThriftIdOrThrow(fieldID));
  }

  @Override
  public boolean equals(Object that) {
    if (that == null)
      return false;
    if (that instanceof AddressBook)
      return this.equals((AddressBook)that);
    return false;
  }

  public boolean equals(AddressBook that) {
    if (that == null)
      return false;

    boolean this_present_persons = true && this.isSetPersons();
    boolean that_present_persons = true && that.isSetPersons();
    if (this_present_persons || that_present_persons) {
      if (!(this_present_persons && that_present_persons))
        return false;
      if (!this.persons.equals(that.persons))
        return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    return 0;
  }

  public int compareTo(AddressBook other) {
    if (!getClass().equals(other.getClass())) {
      return getClass().getName().compareTo(other.getClass().getName());
    }

    int lastComparison = 0;
    AddressBook typedOther = (AddressBook)other;

    lastComparison = Boolean.valueOf(isSetPersons()).compareTo(isSetPersons());
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = TBaseHelper.compareTo(persons, typedOther.persons);
    if (lastComparison != 0) {
      return lastComparison;
    }
    return 0;
  }

  public void read(TProtocol iprot) throws TException {
    TField field;
    iprot.readStructBegin();
    while (true)
    {
      field = iprot.readFieldBegin();
      if (field.type == TType.STOP) { 
        break;
      }
      _Fields fieldId = _Fields.findByThriftId(field.id);
      if (fieldId == null) {
        TProtocolUtil.skip(iprot, field.type);
      } else {
        switch (fieldId) {
          case PERSONS:
            if (field.type == TType.LIST) {
              {
                TList _list4 = iprot.readListBegin();
                this.persons = new ArrayList<Person>(_list4.size);
                for (int _i5 = 0; _i5 < _list4.size; ++_i5)
                {
                  Person _elem6;
                  _elem6 = new Person();
                  _elem6.read(iprot);
                  this.persons.add(_elem6);
                }
                iprot.readListEnd();
              }
            } else { 
              TProtocolUtil.skip(iprot, field.type);
            }
            break;
        }
        iprot.readFieldEnd();
      }
    }
    iprot.readStructEnd();

    // check for required fields of primitive type, which can't be checked in the validate method
    validate();
  }

  public void write(TProtocol oprot) throws TException {
    validate();

    oprot.writeStructBegin(STRUCT_DESC);
    if (this.persons != null) {
      oprot.writeFieldBegin(PERSONS_FIELD_DESC);
      {
        oprot.writeListBegin(new TList(TType.STRUCT, this.persons.size()));
        for (Person _iter7 : this.persons)
        {
          _iter7.write(oprot);
        }
        oprot.writeListEnd();
      }
      oprot.writeFieldEnd();
    }
    oprot.writeFieldStop();
    oprot.writeStructEnd();
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder("AddressBook(");
    boolean first = true;

    sb.append("persons:");
    if (this.persons == null) {
      sb.append("null");
    } else {
      sb.append(this.persons);
    }
    first = false;
    sb.append(")");
    return sb.toString();
  }

  public void validate() throws TException {
    // check for required fields
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/examples/src/gen-java/com/twitter/elephantbird/examples/thrift/PhoneType.java;<<<<<<< MINE
=======
/**
 * Autogenerated by Thrift
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 */
package com.twitter.elephantbird.examples.thrift;


import java.util.Map;
import java.util.HashMap;
import org.apache.thrift.TEnum;
public enum PhoneType implements TEnum{
    MOBILE(0),
    HOME(1),
    WORK(2);

  private static final Map<Integer, PhoneType> BY_VALUE = new HashMap<Integer,PhoneType>() {{
    for(PhoneType val : PhoneType.values()) {
      put(val.getValue(), val);
    }
  }};

  private final int value;

  private PhoneType(int value) {
    this.value = value;
  }

  /**
   * Get the integer value of this enum value, as defined in the Thrift IDL.
   */
  public int getValue() {
    return value;
  }

  /**
   * Find a the enum type by its integer value, as defined in the Thrift IDL.
   * @return null if the value is not found.
   */
  public static PhoneType findByValue(int value) { 
    return BY_VALUE.get(value);
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/examples/src/gen-java/com/twitter/elephantbird/examples/thrift/Age.java;<<<<<<< MINE
=======
/**
 * Autogenerated by Thrift
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 */
package com.twitter.elephantbird.examples.thrift;

import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;
import java.util.EnumMap;
import java.util.Set;
import java.util.HashSet;
import java.util.EnumSet;
import java.util.Collections;
import java.util.BitSet;
import java.util.Arrays;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.thrift.*;
import org.apache.thrift.meta_data.*;
import org.apache.thrift.protocol.*;

public class Age implements TBase<Age._Fields>, java.io.Serializable, Cloneable, Comparable<Age> {
  private static final TStruct STRUCT_DESC = new TStruct("Age");

  private static final TField NAME_FIELD_DESC = new TField("name", TType.STRING, (short)1);
  private static final TField AGE_FIELD_DESC = new TField("age", TType.I32, (short)2);

  public String name;
  public int age;

  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
  public enum _Fields implements TFieldIdEnum {
    NAME((short)1, "name"),
    AGE((short)2, "age");

    private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

    static {
      for (_Fields field : EnumSet.allOf(_Fields.class)) {
        byId.put((int)field._thriftId, field);
        byName.put(field.getFieldName(), field);
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, or null if its not found.
     */
    public static _Fields findByThriftId(int fieldId) {
      return byId.get(fieldId);
    }

    /**
     * Find the _Fields constant that matches fieldId, throwing an exception
     * if it is not found.
     */
    public static _Fields findByThriftIdOrThrow(int fieldId) {
      _Fields fields = findByThriftId(fieldId);
      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
      return fields;
    }

    /**
     * Find the _Fields constant that matches name, or null if its not found.
     */
    public static _Fields findByName(String name) {
      return byName.get(name);
    }

    private final short _thriftId;
    private final String _fieldName;

    _Fields(short thriftId, String fieldName) {
      _thriftId = thriftId;
      _fieldName = fieldName;
    }

    public short getThriftFieldId() {
      return _thriftId;
    }

    public String getFieldName() {
      return _fieldName;
    }
  }

  // isset id assignments
  private static final int __AGE_ISSET_ID = 0;
  private BitSet __isset_bit_vector = new BitSet(1);

  public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
    put(_Fields.NAME, new FieldMetaData("name", TFieldRequirementType.DEFAULT, 
        new FieldValueMetaData(TType.STRING)));
    put(_Fields.AGE, new FieldMetaData("age", TFieldRequirementType.DEFAULT, 
        new FieldValueMetaData(TType.I32)));
  }});

  static {
    FieldMetaData.addStructMetaDataMap(Age.class, metaDataMap);
  }

  public Age() {
  }

  public Age(
    String name,
    int age)
  {
    this();
    this.name = name;
    this.age = age;
    setAgeIsSet(true);
  }

  /**
   * Performs a deep copy on <i>other</i>.
   */
  public Age(Age other) {
    __isset_bit_vector.clear();
    __isset_bit_vector.or(other.__isset_bit_vector);
    if (other.isSetName()) {
      this.name = other.name;
    }
    this.age = other.age;
  }

  public Age deepCopy() {
    return new Age(this);
  }

  @Deprecated
  public Age clone() {
    return new Age(this);
  }

  public String getName() {
    return this.name;
  }

  public Age setName(String name) {
    this.name = name;
    return this;
  }

  public void unsetName() {
    this.name = null;
  }

  /** Returns true if field name is set (has been asigned a value) and false otherwise */
  public boolean isSetName() {
    return this.name != null;
  }

  public void setNameIsSet(boolean value) {
    if (!value) {
      this.name = null;
    }
  }

  public int getAge() {
    return this.age;
  }

  public Age setAge(int age) {
    this.age = age;
    setAgeIsSet(true);
    return this;
  }

  public void unsetAge() {
    __isset_bit_vector.clear(__AGE_ISSET_ID);
  }

  /** Returns true if field age is set (has been asigned a value) and false otherwise */
  public boolean isSetAge() {
    return __isset_bit_vector.get(__AGE_ISSET_ID);
  }

  public void setAgeIsSet(boolean value) {
    __isset_bit_vector.set(__AGE_ISSET_ID, value);
  }

  public void setFieldValue(_Fields field, Object value) {
    switch (field) {
    case NAME:
      if (value == null) {
        unsetName();
      } else {
        setName((String)value);
      }
      break;

    case AGE:
      if (value == null) {
        unsetAge();
      } else {
        setAge((Integer)value);
      }
      break;

    }
  }

  public void setFieldValue(int fieldID, Object value) {
    setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
  }

  public Object getFieldValue(_Fields field) {
    switch (field) {
    case NAME:
      return getName();

    case AGE:
      return new Integer(getAge());

    }
    throw new IllegalStateException();
  }

  public Object getFieldValue(int fieldId) {
    return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
  }

  /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
  public boolean isSet(_Fields field) {
    switch (field) {
    case NAME:
      return isSetName();
    case AGE:
      return isSetAge();
    }
    throw new IllegalStateException();
  }

  public boolean isSet(int fieldID) {
    return isSet(_Fields.findByThriftIdOrThrow(fieldID));
  }

  @Override
  public boolean equals(Object that) {
    if (that == null)
      return false;
    if (that instanceof Age)
      return this.equals((Age)that);
    return false;
  }

  public boolean equals(Age that) {
    if (that == null)
      return false;

    boolean this_present_name = true && this.isSetName();
    boolean that_present_name = true && that.isSetName();
    if (this_present_name || that_present_name) {
      if (!(this_present_name && that_present_name))
        return false;
      if (!this.name.equals(that.name))
        return false;
    }

    boolean this_present_age = true;
    boolean that_present_age = true;
    if (this_present_age || that_present_age) {
      if (!(this_present_age && that_present_age))
        return false;
      if (this.age != that.age)
        return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    return 0;
  }

  public int compareTo(Age other) {
    if (!getClass().equals(other.getClass())) {
      return getClass().getName().compareTo(other.getClass().getName());
    }

    int lastComparison = 0;
    Age typedOther = (Age)other;

    lastComparison = Boolean.valueOf(isSetName()).compareTo(isSetName());
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = TBaseHelper.compareTo(name, typedOther.name);
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = Boolean.valueOf(isSetAge()).compareTo(isSetAge());
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = TBaseHelper.compareTo(age, typedOther.age);
    if (lastComparison != 0) {
      return lastComparison;
    }
    return 0;
  }

  public void read(TProtocol iprot) throws TException {
    TField field;
    iprot.readStructBegin();
    while (true)
    {
      field = iprot.readFieldBegin();
      if (field.type == TType.STOP) { 
        break;
      }
      _Fields fieldId = _Fields.findByThriftId(field.id);
      if (fieldId == null) {
        TProtocolUtil.skip(iprot, field.type);
      } else {
        switch (fieldId) {
          case NAME:
            if (field.type == TType.STRING) {
              this.name = iprot.readString();
            } else { 
              TProtocolUtil.skip(iprot, field.type);
            }
            break;
          case AGE:
            if (field.type == TType.I32) {
              this.age = iprot.readI32();
              setAgeIsSet(true);
            } else { 
              TProtocolUtil.skip(iprot, field.type);
            }
            break;
        }
        iprot.readFieldEnd();
      }
    }
    iprot.readStructEnd();

    // check for required fields of primitive type, which can't be checked in the validate method
    validate();
  }

  public void write(TProtocol oprot) throws TException {
    validate();

    oprot.writeStructBegin(STRUCT_DESC);
    if (this.name != null) {
      oprot.writeFieldBegin(NAME_FIELD_DESC);
      oprot.writeString(this.name);
      oprot.writeFieldEnd();
    }
    oprot.writeFieldBegin(AGE_FIELD_DESC);
    oprot.writeI32(this.age);
    oprot.writeFieldEnd();
    oprot.writeFieldStop();
    oprot.writeStructEnd();
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder("Age(");
    boolean first = true;

    sb.append("name:");
    if (this.name == null) {
      sb.append("null");
    } else {
      sb.append(this.name);
    }
    first = false;
    if (!first) sb.append(", ");
    sb.append("age:");
    sb.append(this.age);
    first = false;
    sb.append(")");
    return sb.toString();
  }

  public void validate() throws TException {
    // check for required fields
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/examples/src/gen-java/com/twitter/elephantbird/examples/thrift/Person.java;<<<<<<< MINE
=======
/**
 * Autogenerated by Thrift
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 */
package com.twitter.elephantbird.examples.thrift;

import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;
import java.util.EnumMap;
import java.util.Set;
import java.util.HashSet;
import java.util.EnumSet;
import java.util.Collections;
import java.util.BitSet;
import java.util.Arrays;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.thrift.*;
import org.apache.thrift.meta_data.*;
import org.apache.thrift.protocol.*;

public class Person implements TBase<Person._Fields>, java.io.Serializable, Cloneable, Comparable<Person> {
  private static final TStruct STRUCT_DESC = new TStruct("Person");

  private static final TField NAME_FIELD_DESC = new TField("name", TType.STRING, (short)1);
  private static final TField ID_FIELD_DESC = new TField("id", TType.I32, (short)2);
  private static final TField EMAIL_FIELD_DESC = new TField("email", TType.STRING, (short)3);
  private static final TField PHONES_FIELD_DESC = new TField("phones", TType.LIST, (short)4);

  public String name;
  public int id;
  public String email;
  public List<PhoneNumber> phones;

  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
  public enum _Fields implements TFieldIdEnum {
    NAME((short)1, "name"),
    ID((short)2, "id"),
    EMAIL((short)3, "email"),
    PHONES((short)4, "phones");

    private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

    static {
      for (_Fields field : EnumSet.allOf(_Fields.class)) {
        byId.put((int)field._thriftId, field);
        byName.put(field.getFieldName(), field);
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, or null if its not found.
     */
    public static _Fields findByThriftId(int fieldId) {
      return byId.get(fieldId);
    }

    /**
     * Find the _Fields constant that matches fieldId, throwing an exception
     * if it is not found.
     */
    public static _Fields findByThriftIdOrThrow(int fieldId) {
      _Fields fields = findByThriftId(fieldId);
      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
      return fields;
    }

    /**
     * Find the _Fields constant that matches name, or null if its not found.
     */
    public static _Fields findByName(String name) {
      return byName.get(name);
    }

    private final short _thriftId;
    private final String _fieldName;

    _Fields(short thriftId, String fieldName) {
      _thriftId = thriftId;
      _fieldName = fieldName;
    }

    public short getThriftFieldId() {
      return _thriftId;
    }

    public String getFieldName() {
      return _fieldName;
    }
  }

  // isset id assignments
  private static final int __ID_ISSET_ID = 0;
  private BitSet __isset_bit_vector = new BitSet(1);

  public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
    put(_Fields.NAME, new FieldMetaData("name", TFieldRequirementType.DEFAULT, 
        new FieldValueMetaData(TType.STRING)));
    put(_Fields.ID, new FieldMetaData("id", TFieldRequirementType.DEFAULT, 
        new FieldValueMetaData(TType.I32)));
    put(_Fields.EMAIL, new FieldMetaData("email", TFieldRequirementType.DEFAULT, 
        new FieldValueMetaData(TType.STRING)));
    put(_Fields.PHONES, new FieldMetaData("phones", TFieldRequirementType.DEFAULT, 
        new ListMetaData(TType.LIST, 
            new StructMetaData(TType.STRUCT, PhoneNumber.class))));
  }});

  static {
    FieldMetaData.addStructMetaDataMap(Person.class, metaDataMap);
  }

  public Person() {
  }

  public Person(
    String name,
    int id,
    String email,
    List<PhoneNumber> phones)
  {
    this();
    this.name = name;
    this.id = id;
    setIdIsSet(true);
    this.email = email;
    this.phones = phones;
  }

  /**
   * Performs a deep copy on <i>other</i>.
   */
  public Person(Person other) {
    __isset_bit_vector.clear();
    __isset_bit_vector.or(other.__isset_bit_vector);
    if (other.isSetName()) {
      this.name = other.name;
    }
    this.id = other.id;
    if (other.isSetEmail()) {
      this.email = other.email;
    }
    if (other.isSetPhones()) {
      List<PhoneNumber> __this__phones = new ArrayList<PhoneNumber>();
      for (PhoneNumber other_element : other.phones) {
        __this__phones.add(new PhoneNumber(other_element));
      }
      this.phones = __this__phones;
    }
  }

  public Person deepCopy() {
    return new Person(this);
  }

  @Deprecated
  public Person clone() {
    return new Person(this);
  }

  public String getName() {
    return this.name;
  }

  public Person setName(String name) {
    this.name = name;
    return this;
  }

  public void unsetName() {
    this.name = null;
  }

  /** Returns true if field name is set (has been asigned a value) and false otherwise */
  public boolean isSetName() {
    return this.name != null;
  }

  public void setNameIsSet(boolean value) {
    if (!value) {
      this.name = null;
    }
  }

  public int getId() {
    return this.id;
  }

  public Person setId(int id) {
    this.id = id;
    setIdIsSet(true);
    return this;
  }

  public void unsetId() {
    __isset_bit_vector.clear(__ID_ISSET_ID);
  }

  /** Returns true if field id is set (has been asigned a value) and false otherwise */
  public boolean isSetId() {
    return __isset_bit_vector.get(__ID_ISSET_ID);
  }

  public void setIdIsSet(boolean value) {
    __isset_bit_vector.set(__ID_ISSET_ID, value);
  }

  public String getEmail() {
    return this.email;
  }

  public Person setEmail(String email) {
    this.email = email;
    return this;
  }

  public void unsetEmail() {
    this.email = null;
  }

  /** Returns true if field email is set (has been asigned a value) and false otherwise */
  public boolean isSetEmail() {
    return this.email != null;
  }

  public void setEmailIsSet(boolean value) {
    if (!value) {
      this.email = null;
    }
  }

  public int getPhonesSize() {
    return (this.phones == null) ? 0 : this.phones.size();
  }

  public java.util.Iterator<PhoneNumber> getPhonesIterator() {
    return (this.phones == null) ? null : this.phones.iterator();
  }

  public void addToPhones(PhoneNumber elem) {
    if (this.phones == null) {
      this.phones = new ArrayList<PhoneNumber>();
    }
    this.phones.add(elem);
  }

  public List<PhoneNumber> getPhones() {
    return this.phones;
  }

  public Person setPhones(List<PhoneNumber> phones) {
    this.phones = phones;
    return this;
  }

  public void unsetPhones() {
    this.phones = null;
  }

  /** Returns true if field phones is set (has been asigned a value) and false otherwise */
  public boolean isSetPhones() {
    return this.phones != null;
  }

  public void setPhonesIsSet(boolean value) {
    if (!value) {
      this.phones = null;
    }
  }

  public void setFieldValue(_Fields field, Object value) {
    switch (field) {
    case NAME:
      if (value == null) {
        unsetName();
      } else {
        setName((String)value);
      }
      break;

    case ID:
      if (value == null) {
        unsetId();
      } else {
        setId((Integer)value);
      }
      break;

    case EMAIL:
      if (value == null) {
        unsetEmail();
      } else {
        setEmail((String)value);
      }
      break;

    case PHONES:
      if (value == null) {
        unsetPhones();
      } else {
        setPhones((List<PhoneNumber>)value);
      }
      break;

    }
  }

  public void setFieldValue(int fieldID, Object value) {
    setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
  }

  public Object getFieldValue(_Fields field) {
    switch (field) {
    case NAME:
      return getName();

    case ID:
      return new Integer(getId());

    case EMAIL:
      return getEmail();

    case PHONES:
      return getPhones();

    }
    throw new IllegalStateException();
  }

  public Object getFieldValue(int fieldId) {
    return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
  }

  /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
  public boolean isSet(_Fields field) {
    switch (field) {
    case NAME:
      return isSetName();
    case ID:
      return isSetId();
    case EMAIL:
      return isSetEmail();
    case PHONES:
      return isSetPhones();
    }
    throw new IllegalStateException();
  }

  public boolean isSet(int fieldID) {
    return isSet(_Fields.findByThriftIdOrThrow(fieldID));
  }

  @Override
  public boolean equals(Object that) {
    if (that == null)
      return false;
    if (that instanceof Person)
      return this.equals((Person)that);
    return false;
  }

  public boolean equals(Person that) {
    if (that == null)
      return false;

    boolean this_present_name = true && this.isSetName();
    boolean that_present_name = true && that.isSetName();
    if (this_present_name || that_present_name) {
      if (!(this_present_name && that_present_name))
        return false;
      if (!this.name.equals(that.name))
        return false;
    }

    boolean this_present_id = true;
    boolean that_present_id = true;
    if (this_present_id || that_present_id) {
      if (!(this_present_id && that_present_id))
        return false;
      if (this.id != that.id)
        return false;
    }

    boolean this_present_email = true && this.isSetEmail();
    boolean that_present_email = true && that.isSetEmail();
    if (this_present_email || that_present_email) {
      if (!(this_present_email && that_present_email))
        return false;
      if (!this.email.equals(that.email))
        return false;
    }

    boolean this_present_phones = true && this.isSetPhones();
    boolean that_present_phones = true && that.isSetPhones();
    if (this_present_phones || that_present_phones) {
      if (!(this_present_phones && that_present_phones))
        return false;
      if (!this.phones.equals(that.phones))
        return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    return 0;
  }

  public int compareTo(Person other) {
    if (!getClass().equals(other.getClass())) {
      return getClass().getName().compareTo(other.getClass().getName());
    }

    int lastComparison = 0;
    Person typedOther = (Person)other;

    lastComparison = Boolean.valueOf(isSetName()).compareTo(isSetName());
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = TBaseHelper.compareTo(name, typedOther.name);
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = Boolean.valueOf(isSetId()).compareTo(isSetId());
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = TBaseHelper.compareTo(id, typedOther.id);
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = Boolean.valueOf(isSetEmail()).compareTo(isSetEmail());
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = TBaseHelper.compareTo(email, typedOther.email);
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = Boolean.valueOf(isSetPhones()).compareTo(isSetPhones());
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = TBaseHelper.compareTo(phones, typedOther.phones);
    if (lastComparison != 0) {
      return lastComparison;
    }
    return 0;
  }

  public void read(TProtocol iprot) throws TException {
    TField field;
    iprot.readStructBegin();
    while (true)
    {
      field = iprot.readFieldBegin();
      if (field.type == TType.STOP) { 
        break;
      }
      _Fields fieldId = _Fields.findByThriftId(field.id);
      if (fieldId == null) {
        TProtocolUtil.skip(iprot, field.type);
      } else {
        switch (fieldId) {
          case NAME:
            if (field.type == TType.STRING) {
              this.name = iprot.readString();
            } else { 
              TProtocolUtil.skip(iprot, field.type);
            }
            break;
          case ID:
            if (field.type == TType.I32) {
              this.id = iprot.readI32();
              setIdIsSet(true);
            } else { 
              TProtocolUtil.skip(iprot, field.type);
            }
            break;
          case EMAIL:
            if (field.type == TType.STRING) {
              this.email = iprot.readString();
            } else { 
              TProtocolUtil.skip(iprot, field.type);
            }
            break;
          case PHONES:
            if (field.type == TType.LIST) {
              {
                TList _list0 = iprot.readListBegin();
                this.phones = new ArrayList<PhoneNumber>(_list0.size);
                for (int _i1 = 0; _i1 < _list0.size; ++_i1)
                {
                  PhoneNumber _elem2;
                  _elem2 = new PhoneNumber();
                  _elem2.read(iprot);
                  this.phones.add(_elem2);
                }
                iprot.readListEnd();
              }
            } else { 
              TProtocolUtil.skip(iprot, field.type);
            }
            break;
        }
        iprot.readFieldEnd();
      }
    }
    iprot.readStructEnd();

    // check for required fields of primitive type, which can't be checked in the validate method
    validate();
  }

  public void write(TProtocol oprot) throws TException {
    validate();

    oprot.writeStructBegin(STRUCT_DESC);
    if (this.name != null) {
      oprot.writeFieldBegin(NAME_FIELD_DESC);
      oprot.writeString(this.name);
      oprot.writeFieldEnd();
    }
    oprot.writeFieldBegin(ID_FIELD_DESC);
    oprot.writeI32(this.id);
    oprot.writeFieldEnd();
    if (this.email != null) {
      oprot.writeFieldBegin(EMAIL_FIELD_DESC);
      oprot.writeString(this.email);
      oprot.writeFieldEnd();
    }
    if (this.phones != null) {
      oprot.writeFieldBegin(PHONES_FIELD_DESC);
      {
        oprot.writeListBegin(new TList(TType.STRUCT, this.phones.size()));
        for (PhoneNumber _iter3 : this.phones)
        {
          _iter3.write(oprot);
        }
        oprot.writeListEnd();
      }
      oprot.writeFieldEnd();
    }
    oprot.writeFieldStop();
    oprot.writeStructEnd();
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder("Person(");
    boolean first = true;

    sb.append("name:");
    if (this.name == null) {
      sb.append("null");
    } else {
      sb.append(this.name);
    }
    first = false;
    if (!first) sb.append(", ");
    sb.append("id:");
    sb.append(this.id);
    first = false;
    if (!first) sb.append(", ");
    sb.append("email:");
    if (this.email == null) {
      sb.append("null");
    } else {
      sb.append(this.email);
    }
    first = false;
    if (!first) sb.append(", ");
    sb.append("phones:");
    if (this.phones == null) {
      sb.append("null");
    } else {
      sb.append(this.phones);
    }
    first = false;
    sb.append(")");
    return sb.toString();
  }

  public void validate() throws TException {
    // check for required fields
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/examples/src/gen-java/com/twitter/elephantbird/examples/thrift/PhoneNumber.java;<<<<<<< MINE
=======
/**
 * Autogenerated by Thrift
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 */
package com.twitter.elephantbird.examples.thrift;

import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;
import java.util.EnumMap;
import java.util.Set;
import java.util.HashSet;
import java.util.EnumSet;
import java.util.Collections;
import java.util.BitSet;
import java.util.Arrays;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.thrift.*;
import org.apache.thrift.meta_data.*;
import org.apache.thrift.protocol.*;

public class PhoneNumber implements TBase<PhoneNumber._Fields>, java.io.Serializable, Cloneable, Comparable<PhoneNumber> {
  private static final TStruct STRUCT_DESC = new TStruct("PhoneNumber");

  private static final TField NUMBER_FIELD_DESC = new TField("number", TType.STRING, (short)1);
  private static final TField TYPE_FIELD_DESC = new TField("type", TType.I32, (short)2);

  public String number;
  /**
   * 
   * @see PhoneType
   */
  public PhoneType type;

  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
  public enum _Fields implements TFieldIdEnum {
    NUMBER((short)1, "number"),
    /**
     * 
     * @see PhoneType
     */
    TYPE((short)2, "type");

    private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

    static {
      for (_Fields field : EnumSet.allOf(_Fields.class)) {
        byId.put((int)field._thriftId, field);
        byName.put(field.getFieldName(), field);
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, or null if its not found.
     */
    public static _Fields findByThriftId(int fieldId) {
      return byId.get(fieldId);
    }

    /**
     * Find the _Fields constant that matches fieldId, throwing an exception
     * if it is not found.
     */
    public static _Fields findByThriftIdOrThrow(int fieldId) {
      _Fields fields = findByThriftId(fieldId);
      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
      return fields;
    }

    /**
     * Find the _Fields constant that matches name, or null if its not found.
     */
    public static _Fields findByName(String name) {
      return byName.get(name);
    }

    private final short _thriftId;
    private final String _fieldName;

    _Fields(short thriftId, String fieldName) {
      _thriftId = thriftId;
      _fieldName = fieldName;
    }

    public short getThriftFieldId() {
      return _thriftId;
    }

    public String getFieldName() {
      return _fieldName;
    }
  }

  // isset id assignments

  public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
    put(_Fields.NUMBER, new FieldMetaData("number", TFieldRequirementType.DEFAULT, 
        new FieldValueMetaData(TType.STRING)));
    put(_Fields.TYPE, new FieldMetaData("type", TFieldRequirementType.OPTIONAL, 
        new EnumMetaData(TType.ENUM, PhoneType.class)));
  }});

  static {
    FieldMetaData.addStructMetaDataMap(PhoneNumber.class, metaDataMap);
  }

  public PhoneNumber() {
  }

  public PhoneNumber(
    String number)
  {
    this();
    this.number = number;
  }

  /**
   * Performs a deep copy on <i>other</i>.
   */
  public PhoneNumber(PhoneNumber other) {
    if (other.isSetNumber()) {
      this.number = other.number;
    }
    if (other.isSetType()) {
      this.type = other.type;
    }
  }

  public PhoneNumber deepCopy() {
    return new PhoneNumber(this);
  }

  @Deprecated
  public PhoneNumber clone() {
    return new PhoneNumber(this);
  }

  public String getNumber() {
    return this.number;
  }

  public PhoneNumber setNumber(String number) {
    this.number = number;
    return this;
  }

  public void unsetNumber() {
    this.number = null;
  }

  /** Returns true if field number is set (has been asigned a value) and false otherwise */
  public boolean isSetNumber() {
    return this.number != null;
  }

  public void setNumberIsSet(boolean value) {
    if (!value) {
      this.number = null;
    }
  }

  /**
   * 
   * @see PhoneType
   */
  public PhoneType getType() {
    return this.type;
  }

  /**
   * 
   * @see PhoneType
   */
  public PhoneNumber setType(PhoneType type) {
    this.type = type;
    return this;
  }

  public void unsetType() {
    this.type = null;
  }

  /** Returns true if field type is set (has been asigned a value) and false otherwise */
  public boolean isSetType() {
    return this.type != null;
  }

  public void setTypeIsSet(boolean value) {
    if (!value) {
      this.type = null;
    }
  }

  public void setFieldValue(_Fields field, Object value) {
    switch (field) {
    case NUMBER:
      if (value == null) {
        unsetNumber();
      } else {
        setNumber((String)value);
      }
      break;

    case TYPE:
      if (value == null) {
        unsetType();
      } else {
        setType((PhoneType)value);
      }
      break;

    }
  }

  public void setFieldValue(int fieldID, Object value) {
    setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
  }

  public Object getFieldValue(_Fields field) {
    switch (field) {
    case NUMBER:
      return getNumber();

    case TYPE:
      return getType();

    }
    throw new IllegalStateException();
  }

  public Object getFieldValue(int fieldId) {
    return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
  }

  /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
  public boolean isSet(_Fields field) {
    switch (field) {
    case NUMBER:
      return isSetNumber();
    case TYPE:
      return isSetType();
    }
    throw new IllegalStateException();
  }

  public boolean isSet(int fieldID) {
    return isSet(_Fields.findByThriftIdOrThrow(fieldID));
  }

  @Override
  public boolean equals(Object that) {
    if (that == null)
      return false;
    if (that instanceof PhoneNumber)
      return this.equals((PhoneNumber)that);
    return false;
  }

  public boolean equals(PhoneNumber that) {
    if (that == null)
      return false;

    boolean this_present_number = true && this.isSetNumber();
    boolean that_present_number = true && that.isSetNumber();
    if (this_present_number || that_present_number) {
      if (!(this_present_number && that_present_number))
        return false;
      if (!this.number.equals(that.number))
        return false;
    }

    boolean this_present_type = true && this.isSetType();
    boolean that_present_type = true && that.isSetType();
    if (this_present_type || that_present_type) {
      if (!(this_present_type && that_present_type))
        return false;
      if (!this.type.equals(that.type))
        return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    return 0;
  }

  public int compareTo(PhoneNumber other) {
    if (!getClass().equals(other.getClass())) {
      return getClass().getName().compareTo(other.getClass().getName());
    }

    int lastComparison = 0;
    PhoneNumber typedOther = (PhoneNumber)other;

    lastComparison = Boolean.valueOf(isSetNumber()).compareTo(isSetNumber());
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = TBaseHelper.compareTo(number, typedOther.number);
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = Boolean.valueOf(isSetType()).compareTo(isSetType());
    if (lastComparison != 0) {
      return lastComparison;
    }
    lastComparison = TBaseHelper.compareTo(type, typedOther.type);
    if (lastComparison != 0) {
      return lastComparison;
    }
    return 0;
  }

  public void read(TProtocol iprot) throws TException {
    TField field;
    iprot.readStructBegin();
    while (true)
    {
      field = iprot.readFieldBegin();
      if (field.type == TType.STOP) { 
        break;
      }
      _Fields fieldId = _Fields.findByThriftId(field.id);
      if (fieldId == null) {
        TProtocolUtil.skip(iprot, field.type);
      } else {
        switch (fieldId) {
          case NUMBER:
            if (field.type == TType.STRING) {
              this.number = iprot.readString();
            } else { 
              TProtocolUtil.skip(iprot, field.type);
            }
            break;
          case TYPE:
            if (field.type == TType.I32) {
              this.type = PhoneType.findByValue(iprot.readI32());
            } else { 
              TProtocolUtil.skip(iprot, field.type);
            }
            break;
        }
        iprot.readFieldEnd();
      }
    }
    iprot.readStructEnd();

    // check for required fields of primitive type, which can't be checked in the validate method
    validate();
  }

  public void write(TProtocol oprot) throws TException {
    validate();

    oprot.writeStructBegin(STRUCT_DESC);
    if (this.number != null) {
      oprot.writeFieldBegin(NUMBER_FIELD_DESC);
      oprot.writeString(this.number);
      oprot.writeFieldEnd();
    }
    if (this.type != null) {
      if (isSetType()) {
        oprot.writeFieldBegin(TYPE_FIELD_DESC);
        oprot.writeI32(this.type.getValue());
        oprot.writeFieldEnd();
      }
    }
    oprot.writeFieldStop();
    oprot.writeStructEnd();
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder("PhoneNumber(");
    boolean first = true;

    sb.append("number:");
    if (this.number == null) {
      sb.append("null");
    } else {
      sb.append(this.number);
    }
    first = false;
    if (isSetType()) {
      if (!first) sb.append(", ");
      sb.append("type:");
      if (this.type == null) {
        sb.append("null");
      } else {
        String type_name = type.name();
        if (type_name != null) {
          sb.append(type_name);
          sb.append(" (");
        }
        sb.append(this.type);
        if (type_name != null) {
          sb.append(")");
        }
      }
      first = false;
    }
    sb.append(")");
    return sb.toString();
  }

  public void validate() throws TException {
    // check for required fields
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/util/HadoopUtils.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.util;

import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.JobContext;
import org.apache.hadoop.mapreduce.TaskInputOutputContext;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * Various Hadoop specific utilities.
 */
public class HadoopUtils {
  private static final Logger LOG = LoggerFactory.getLogger(HadoopUtils.class);

  /**
   * MapReduce counters are available only with {@link TaskInputOutputContext},
   * but most interfaces use super classes, though the actual obejct is a 
   * subclass (e.g. Mapper.Context). <br> <br>
   * 
   * This utility method checks the type and returns the appropriate counter.
   * In the rare (may be unexpected) case where ctx is not a 
   * TaskInputOutputContext, a dummy counter is returned after printing
   * a warning.
   */
  public static Counter getCounter(JobContext ctx, String group, String counter) {
    if (ctx instanceof TaskInputOutputContext<?, ?, ?, ?>) {
      return ((TaskInputOutputContext<?, ?, ?, ?>)ctx).getCounter(group, counter);
    }
    String name = group + ":" + counter;
    LOG.warn("Context is not a TaskInputOutputContext. "
        + "will return a dummy counter for '" + name + "'");
    return new Counter(name, name) {};
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/util/ThriftUtils.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.util;

import java.lang.reflect.Field;

import org.apache.hadoop.conf.Configuration;
import org.apache.thrift.TBase;

public class ThriftUtils {

  private static final String CLASS_CONF_PREFIX = "elephantbird.thirft.class.for.";

  public static void setClassConf(Configuration jobConf, Class<?> genericClass,
                                  Class<? extends TBase<?>> thriftClass) {
    jobConf.set(CLASS_CONF_PREFIX + genericClass.getName(), thriftClass.getName());
  }


  /**
   * Verify that clazz is a Thrift class. i.e. is a subclass of TBase
   */
  private static void verifyAncestry(Class<?> tClass) {
    if (!TBase.class.isAssignableFrom(tClass)) {
      throw new ClassCastException(tClass.getName() + " is not a Thrift class");
    }
  }

  /**
   * Returns TypeRef for the Thrift class that was set using setClass(jobConf);
   */
  public static<M extends TBase<?>> TypeRef<M> getTypeRef(Configuration jobConf, Class<?> genericClass) {
    String className = jobConf.get(CLASS_CONF_PREFIX + genericClass.getName());
    if (className == null) {
      throw new RuntimeException(CLASS_CONF_PREFIX + genericClass.getName() + " is not set");
    }

    Class<?> tClass = null;
    try {
      tClass = jobConf.getClassByName(className);
    } catch (ClassNotFoundException e) {
      throw new RuntimeException(e);
    }

    verifyAncestry(tClass);

    return new TypeRef<M>(tClass){};
  }

  /**
   * returns TypeRef for a thrift class.
   */
  public static<M extends TBase<?>> TypeRef<M> getTypeRef(String thriftClassName) {
    try {
      Class<?> tClass = Class.forName(thriftClassName);
      verifyAncestry(tClass);

      return new TypeRef<M>(tClass){};
    } catch (ClassNotFoundException e) {
      throw new RuntimeException(e);
    }
  }

   /**
   * Returns value of a fieldName in an object.
   */
  public static <M> M getFieldValue(Object containingObject, String fieldName, Class<M> fieldClass) {
    return getFieldValue(containingObject.getClass(), containingObject, fieldName, fieldClass);
  }

  /**
   * Returns value of a static field with given name in containingClass.
   */
  public static <M> M getFieldValue(Class<?> containingClass, String fieldName, Class<M> fieldClass) {
    return getFieldValue(containingClass, null, fieldName, fieldClass);
  }

  private static <M> M getFieldValue(Class<?> containingClass, Object obj, String fieldName, Class<M> fieldClass) {
    try {
      Field field = containingClass.getDeclaredField(fieldName);
      return fieldClass.cast(field.get(obj));
    } catch (Exception e) {
      throw new RuntimeException("while trying to find " + fieldName + " in "
                                  +  containingClass.getName(), e);
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
=======
    //XXX Remove this.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
import java.io.DataOutputStream;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
import com.hadoop.compression.lzo.LzopCodec;
=======
import com.twitter.elephantbird.mapreduce.io.ProtobufBlockWriter;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
    extends FileOutputFormat<NullWritable, W> {
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufBlockOutputFormat.class);
=======
    extends LzoOutputFormat<M, W> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
    Configuration conf = job.getConfiguration();
    LzopCodec codec = new LzopCodec();
    codec.setConf(conf);

    Path file = getDefaultWorkFile(job, codec.getDefaultExtension());
    FileSystem fs = file.getFileSystem(conf);
    FSDataOutputStream fileOut = fs.create(file, false);

    return new LzoProtobufBlockRecordWriter<M, W>(typeRef_, new DataOutputStream(codec.createOutputStream(fileOut)));
=======
    return new LzoBinaryBlockRecordWriter<M, W>(
        new ProtobufBlockWriter<M>(getOutputStream(job), typeRef_.getRawClass()));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftBlockOutputFormat.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.output;

import java.io.IOException;

import com.twitter.elephantbird.mapreduce.io.ThriftBlockWriter;
import com.twitter.elephantbird.mapreduce.io.ThriftWritable;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.thrift.TBase;

/**
 * Data is written as one base64 encoded serialized thrift per line. <br><br>
 * 
 * Do not use LzoThriftB64LineOutputFormat.class directly for setting 
 * OutputFormat class for a job. Use getOutputFormatClass() instead.
 */
public class LzoThriftBlockOutputFormat<M extends TBase<?>>
    extends LzoOutputFormat<M, ThriftWritable<M>> {  
  
  public LzoThriftBlockOutputFormat() {}
  
  @SuppressWarnings("unchecked")
  public static <M extends TBase<?>> Class<LzoThriftBlockOutputFormat>
     getOutputFormatClass(Class<M> thriftClass, Configuration jobConf) {
    
    ThriftUtils.setClassConf(jobConf, LzoThriftBlockOutputFormat.class, thriftClass);
    return LzoThriftBlockOutputFormat.class;
  }
  
  public RecordWriter<NullWritable, ThriftWritable<M>> getRecordWriter(TaskAttemptContext job)
      throws IOException, InterruptedException {
    
    TypeRef<M> typeRef = ThriftUtils.getTypeRef(job.getConfiguration(), LzoThriftBlockOutputFormat.class);  
    return new LzoBinaryBlockRecordWriter<M, ThriftWritable<M>>(
        new ThriftBlockWriter<M>(getOutputStream(job), typeRef.getRawClass()));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoBinaryBlockRecordWriter.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.output;

import java.io.IOException;

import com.twitter.elephantbird.mapreduce.io.BinaryBlockWriter;
import com.twitter.elephantbird.mapreduce.io.BinaryWritable;

import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;

/**
 * A writer for LZO-encoded blocks of protobuf or Thrift objects, generally read by
 * a ProtobufBlockWriter or similar.
 */
public class LzoBinaryBlockRecordWriter<M, W extends BinaryWritable<M>>
    extends RecordWriter<NullWritable, W> {
 
  private BinaryBlockWriter<M> writer_;
  
  public LzoBinaryBlockRecordWriter(BinaryBlockWriter<M> writer) {
    writer_ = writer;
  }

  public void write(NullWritable nullWritable, W protoWritable)
      throws IOException, InterruptedException {
    writer_.write(protoWritable.get());
    // the counters are not accessible
  }

  public void close(TaskAttemptContext taskAttemptContext)
      throws IOException, InterruptedException {
    writer_.finish();
    writer_.close();
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
import java.io.DataOutputStream;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
import com.hadoop.compression.lzo.LzopCodec;
=======
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
    extends FileOutputFormat<NullWritable, W> {
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufB64LineOutputFormat.class);

=======
    extends LzoOutputFormat<M, W> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
    Configuration conf = job.getConfiguration();
    LzopCodec codec = new LzopCodec();
    codec.setConf(conf);

    Path file = getDefaultWorkFile(job, codec.getDefaultExtension());
    FileSystem fs = file.getFileSystem(conf);
    FSDataOutputStream fileOut = fs.create(file, false);

    return new LzoProtobufB64LineRecordWriter<M, W>(typeRef_,
        new DataOutputStream(codec.createOutputStream(fileOut)));
=======
    return new LzoBinaryB64LineRecordWriter<M, W>(new ProtobufConverter<M>(typeRef_), getOutputStream(job));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoBinaryB64LineRecordWriter.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.output;

import java.io.DataOutputStream;
import java.io.IOException;

import com.twitter.elephantbird.mapreduce.io.BinaryConverter;
import com.twitter.elephantbird.mapreduce.io.BinaryWritable;

import org.apache.commons.codec.binary.Base64;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;

/**
 * A RecordWriter-derived class for use with the LzoProtobufB64LineOutputFormat.
 * Writes data as base64 encoded serialized protocol buffers, one per line.
 */

public class LzoBinaryB64LineRecordWriter<M, W extends BinaryWritable<M>>
    extends RecordWriter<NullWritable, W> {

  private final BinaryConverter<M> protoConverter_;
  private final DataOutputStream out_;
  private final Base64 base64_;
  
  public LzoBinaryB64LineRecordWriter(BinaryConverter<M> converter, DataOutputStream out) {
    protoConverter_ = converter;
    out_ = out;
    base64_ = new Base64();
  }

  public void write(NullWritable nullWritable, W protobufWritable)
      throws IOException, InterruptedException {
    byte[] b64Bytes = base64_.encode(protoConverter_.toBytes(protobufWritable.get()));
    out_.write(b64Bytes);
    out_.write("\n".getBytes("UTF-8"));
  }

  public void close(TaskAttemptContext taskAttemptContext)
      throws IOException, InterruptedException {
    out_.close();
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
import java.io.DataOutputStream;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
import com.hadoop.compression.lzo.LzopCodec;
=======
import com.twitter.elephantbird.mapreduce.io.ThriftConverter;
import com.twitter.elephantbird.mapreduce.io.ThriftWritable;
import com.twitter.elephantbird.util.ThriftUtils;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.mapreduce.io.ThriftB64LineWritable;
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
 * This is the output format class for base64 encoded, line-oriented thrift based formats. Data is
 * written as one base64 encoded serialized thrift object per line. It takes one template parameter, the 
 * thrift type. This parameter is saved in a TypeRef for use in the getRecordWriter factory method.
=======
 * Data is written as one base64 encoded serialized thrift per line. <br><br>
 * 
 * Do not use LzoThriftB64LineOutputFormat.class directly for setting 
 * OutputFormat class for a job. Use getOutputFormatClass() instead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
public class LzoThriftB64LineOutputFormat<T extends TBase>
    extends FileOutputFormat<NullWritable, ThriftB64LineWritable<T>> {
  private static final Logger LOG = LogManager.getLogger(LzoThriftB64LineOutputFormat.class);

  protected TypeRef<T> typeRef_;

  protected void setTypeRef(TypeRef<T> typeRef) {
    typeRef_ = typeRef;
=======
public class LzoThriftB64LineOutputFormat<M extends TBase<?>>
    extends LzoOutputFormat<M, ThriftWritable<M>> {  
  
  public LzoThriftB64LineOutputFormat() {}
  
  @SuppressWarnings("unchecked")
  public static <M extends TBase<?>> Class<LzoThriftB64LineOutputFormat>
     getOutputFormatClass(Class<M> thriftClass, Configuration jobConf) {
    
    ThriftUtils.setClassConf(jobConf, LzoThriftB64LineOutputFormat.class, thriftClass);
    return LzoThriftB64LineOutputFormat.class;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE

  public RecordWriter getRecordWriter(TaskAttemptContext job)
=======
  
  public RecordWriter<NullWritable, ThriftWritable<M>> getRecordWriter(TaskAttemptContext job)
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
    Configuration conf = job.getConfiguration();
    LzopCodec codec = new LzopCodec();
    codec.setConf(conf);

    Path file = getDefaultWorkFile(job, codec.getDefaultExtension());
    FileSystem fs = file.getFileSystem(conf);
    FSDataOutputStream fileOut = fs.create(file, false);

    return new LzoThriftB64LineRecordWriter<T>(typeRef_,
            new DataOutputStream(codec.createOutputStream(fileOut)));
=======
    
    TypeRef<M> typeRef = ThriftUtils.getTypeRef(job.getConfiguration(), LzoThriftB64LineOutputFormat.class);  
    return new LzoBinaryB64LineRecordWriter<M, ThriftWritable<M>>(new ThriftConverter<M>(typeRef), getOutputStream(job));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/output/LzoOutputFormat.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.output;

import java.io.DataOutputStream;
import java.io.IOException;

import com.hadoop.compression.lzo.LzopCodec;
import com.twitter.elephantbird.mapreduce.io.BinaryWritable;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

/**
 * Base class for Lzo outputformats.
 * provides an helper method to create lzo output stream.
 */
public abstract class LzoOutputFormat<M, W extends BinaryWritable<M>>
    extends FileOutputFormat<NullWritable, W> {
  
  /**
   * Helper method to create lzo output file needed to create RecordWriter
   */
  protected DataOutputStream getOutputStream(TaskAttemptContext job)
                  throws IOException, InterruptedException {
    Configuration conf = job.getConfiguration();
    LzopCodec codec = new LzopCodec();
    codec.setConf(conf);

    Path file = getDefaultWorkFile(job, codec.getDefaultExtension());
    FileSystem fs = file.getFileSystem(conf);
    FSDataOutputStream fileOut = fs.create(file, false);
    return new DataOutputStream(codec.createOutputStream(fileOut)); 
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufB64LineInputFormat.class);
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoBinaryBlockRecordReader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.input;

import java.io.IOException;
import java.io.InputStream;

import com.twitter.elephantbird.mapreduce.io.BinaryBlockReader;
import com.twitter.elephantbird.mapreduce.io.BinaryWritable;
import com.twitter.elephantbird.util.HadoopUtils;
import com.twitter.elephantbird.util.TypeRef;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.InputSplit;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * A reader for LZO-encoded protobuf blocks, generally written by
 * a ProtobufBlockWriter or similar.  Returns <position, protobuf> pairs.
 */

public class LzoBinaryBlockRecordReader<M, W extends BinaryWritable<M>> extends LzoRecordReader<LongWritable, W> {
  private static final Logger LOG = LoggerFactory.getLogger(LzoBinaryBlockRecordReader.class);

  private final LongWritable key_;
  private final W value_;
  private final TypeRef<M> typeRef_;

  private final BinaryBlockReader<M> reader_;

  private Counter recordsReadCounter;
  private Counter recordErrorsCounter;

  public LzoBinaryBlockRecordReader(TypeRef<M> typeRef, BinaryBlockReader<M> reader, W binaryWritable) {
    key_ = new LongWritable();
    value_ = binaryWritable;
    reader_ = reader;
    typeRef_ = typeRef;
  }

  @Override
  public synchronized void close() throws IOException {
    if (reader_ != null) {
      reader_.close();
    }
  }

  @Override
  public LongWritable getCurrentKey() throws IOException, InterruptedException {
    return key_;
  }

  @Override
  public W getCurrentValue() throws IOException, InterruptedException {
    return value_;
  }

  @Override
  protected void createInputReader(InputStream input, Configuration conf) throws IOException {
    reader_.setInputStream(input);
  }

  @Override
  public void initialize(InputSplit genericSplit, TaskAttemptContext context)
                                     throws IOException, InterruptedException {
    String group = "LzoBlocks of " + typeRef_.getRawClass().getName();
    recordsReadCounter = HadoopUtils.getCounter(context, group, "Records Read");
    recordErrorsCounter = HadoopUtils.getCounter(context, group, "Errors");

    super.initialize(genericSplit, context);
  }

  @Override
  protected void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // No need to skip to the sync point here; the block reader will do it for us.
    LOG.debug("LzoProtobufBlockRecordReader.skipToNextSyncPoint called with atFirstRecord = " + atFirstRecord);
  }

  @Override
  public boolean nextKeyValue() throws IOException, InterruptedException {
    // If we are past the end of the file split, tell the reader not to read any more new blocks.
    // Then continue reading until the last of the reader's already-parsed values are used up.
    // The next split will start at the next sync point and no records will be missed.
    if (pos_ > end_) {
      reader_.markNoMoreNewBlocks();
    }
    if (reader_.readNext(value_)) {
      if (value_.get() == null) {
        recordErrorsCounter.increment(1);
      }
      recordsReadCounter.increment(1);
      key_.set(pos_);
      pos_ = getLzoFilePos();
      return true;
    }

    return false;
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufBlockInputFormat.class);
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE
import java.io.IOException;
import java.io.InputStream;

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.LongWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE

public class LzoProtobufBlockRecordReader<M extends Message, W extends ProtobufWritable<M>>
    extends LzoRecordReader<LongWritable, W> {
=======
public class LzoProtobufBlockRecordReader<M extends Message, W extends ProtobufWritable<M>> extends LzoBinaryBlockRecordReader<M, W> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE
  private final LongWritable key_;
  private final W value_;
  private final TypeRef<M> typeRef_;

  private ProtobufBlockReader<M> reader_;

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE
    typeRef_ = typeRef;
    LOG.info("LzoProtobufBlockRecordReader, type args are " + typeRef_.getRawClass());
    key_ = new LongWritable();
    value_ = protobufWritable;
  }

  @Override
  public synchronized void close() throws IOException {
    if (reader_ != null) {
      reader_.close();
    }
  }

  @Override
  public LongWritable getCurrentKey() throws IOException, InterruptedException {
    return key_;
  }

  @Override
  public W getCurrentValue() throws IOException, InterruptedException {
    return value_;
  }

  @Override
  protected void createInputReader(InputStream input, Configuration conf) throws IOException {
    reader_ = new ProtobufBlockReader<M>(input, typeRef_);
  }

  @Override
  protected void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // No need to skip to the sync point here; the block reader will do it for us.
    LOG.debug("LzoProtobufBlockRecordReader.skipToNextSyncPoint called with atFirstRecord = " + atFirstRecord);
  }

  @Override
  public boolean nextKeyValue() throws IOException, InterruptedException {
    // If we are past the end of the file split, tell the reader not to read any more new blocks.
    // Then continue reading until the last of the reader's already-parsed values are used up.
    // The next split will start at the next sync point and no records will be missed.
    if (pos_ > end_) {
      reader_.markNoMoreNewBlocks();
    }
    if (reader_.readProtobuf(value_)) {
      key_.set(pos_);
      pos_ = getLzoFilePos();
      return true;
    }

    return false;
=======
    // input stream for the reader will be set by LzoBinaryBlockRecordReader
    super(typeRef, new ProtobufBlockReader<M>(null, typeRef), protobufWritable);
    LOG.info("LzoProtobufBlockRecordReader, type args are " + typeRef.getRawClass());
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.mapreduce.input.LzoInputFormat;
=======
import com.twitter.elephantbird.mapreduce.io.ThriftWritable;
import com.twitter.elephantbird.util.ThriftUtils;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.mapreduce.io.ThriftB64LineWritable;
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
 * This is the base class for all base64 encoded, line-oriented thrift based input formats.
 * Data is expected to be one base64 encoded serialized thrift message per line. It has two template
 * parameters, the thrift type and the thrift writable for that type.  This class cannot be instantiated
 * directly as an input format because Hadoop works via reflection, and Java type erasure makes it
 * impossible to instantiate a templatized class via reflection with the correct template parameter.
 * Instead, we codegen derived input format classes for any given thrift object which instantiate the
 * template parameter directly, as well as set the typeRef argument so that the template
 * parameter can be remembered. 
=======
 * Reads line from an lzo compressed text file, base64 decodes it, and then
 * deserializes that into the Thrift object.  
 * Returns <position, thriftObject> pairs. <br><br>
 * 
 * Do not use LzoThriftB64LineInputFormat.class directly for setting 
 * InputFormat class for a job. Use getInputFormatClass() instead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE

public class LzoThriftB64LineInputFormat <T extends TBase, W extends ThriftB64LineWritable<T>> extends LzoInputFormat<LongWritable, W> {
  private TypeRef<T> typeRef_;
  private W thriftWritable_;

  public LzoThriftB64LineInputFormat() {
  }

  protected void setTypeRef(TypeRef<T> typeRef) {
    typeRef_ = typeRef;
  }

  protected void setThriftWritable(W thriftWritable) {
    thriftWritable_ = thriftWritable;
=======
public class LzoThriftB64LineInputFormat<M extends TBase<?>>  
                extends LzoInputFormat<LongWritable, ThriftWritable<M>> {
  
  public LzoThriftB64LineInputFormat() {}
  
  /**
   * Returns {@link LzoThriftB64LineInputFormat} class for setting up a job.
   * Sets an internal configuration in jobConf so that Task instantiates 
   * appropriate object for this generic class based on thriftClass
   */
  @SuppressWarnings("unchecked")
  public static <M extends TBase<?>> Class<LzoThriftB64LineInputFormat>
     getInputFormatClass(Class<M> thriftClass, Configuration jobConf) {
    ThriftUtils.setClassConf(jobConf, LzoThriftB64LineInputFormat.class, thriftClass);
    return LzoThriftB64LineInputFormat.class;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE

=======
  
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
  public RecordReader<LongWritable, W> createRecordReader(InputSplit split,
=======
  public RecordReader<LongWritable, ThriftWritable<M>> createRecordReader(InputSplit split,
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
    return new LzoThriftB64LineRecordReader<T, W>(typeRef_, thriftWritable_);
=======
    
    TypeRef<M> typeRef = ThriftUtils.getTypeRef(taskAttempt.getConfiguration(), LzoThriftB64LineInputFormat.class); 
    return new LzoThriftB64LineRecordReader<M>(typeRef);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
=======
  
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineRecordReader.java;<<<<<<< MINE
import java.io.IOException;
import java.io.InputStream;

import com.twitter.elephantbird.mapreduce.input.LzoRecordReader;
import com.twitter.elephantbird.util.TypeRef;
import com.twitter.elephantbird.mapreduce.io.ThriftB64LineWritable;
import org.apache.commons.codec.binary.Base64;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.util.LineReader;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineRecordReader.java;<<<<<<< MINE
import org.apache.thrift.TDeserializer;
import org.apache.thrift.TException;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineRecordReader.java;<<<<<<< MINE
/**
 * Reads line from an lzo compressed text file, base64 decodes it, and then
 * deserializes that into the templatized thrift writable. Returns <position, thrift>
 * pairs
 */
public class  LzoThriftB64LineRecordReader<T extends TBase, W extends ThriftB64LineWritable<T>>
    extends LzoRecordReader<LongWritable, W> {
=======
import com.twitter.elephantbird.mapreduce.io.ThriftWritable;
import com.twitter.elephantbird.mapreduce.io.ThriftConverter;
import com.twitter.elephantbird.util.TypeRef;

public class  LzoThriftB64LineRecordReader<M extends TBase<?>> extends LzoBinaryB64LineRecordReader<M, ThriftWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineRecordReader.java;<<<<<<< MINE
  private LineReader lineReader_;

  private final Text line_ = new Text();
  private final LongWritable key_ = new LongWritable();
  private final TypeRef<T> typeRef_;
  private final W thriftWritable_;
  private final Base64 base64_ = new Base64();
  private final TDeserializer deserializer_ = new TDeserializer();

  public LzoThriftB64LineRecordReader(TypeRef<T> typeRef, W thriftWritable) {
    typeRef_ = typeRef;
    thriftWritable_ = thriftWritable;
    LOG.info("LzoProtobufBlockRecordReader, type args are " + typeRef_.getRawClass());
  }

  @Override
  public synchronized void close() throws IOException {
    if (lineReader_ != null) {
      lineReader_.close();
    }
  }

  @Override
  public LongWritable getCurrentKey() throws IOException, InterruptedException {
    return key_;
  }

  @Override
  public W getCurrentValue() throws IOException, InterruptedException {
    return thriftWritable_;
  }

  @Override
  protected void createInputReader(InputStream input, Configuration conf) throws IOException {
    lineReader_ = new LineReader(input, conf);
  }

  @Override
  protected void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    if (!atFirstRecord) {
      lineReader_.readLine(new Text());
    }
  }

  @Override
  public boolean nextKeyValue() throws IOException, InterruptedException {
    // Since the lzop codec reads everything in lzo blocks, we can't stop if pos == end.
    // Instead we wait for the next block to be read in, when pos will be > end.
    while (pos_ <= end_) {
      key_.set(pos_);

      int newSize = lineReader_.readLine(line_);
      if (newSize == 0) {
        return false;
      }
      pos_ = getLzoFilePos();
      byte[] lineBytes = line_.toString().getBytes("UTF-8");
      T thriftValue = typeRef_.safeNewInstance();
      try {
        deserializer_.deserialize(thriftValue, base64_.decode(lineBytes));
      }
      catch (TException e) {
        // TODO: increment counter.
        continue;
      }

      thriftWritable_.set(thriftValue);
      return true;
    }

    return false;
=======
  public LzoThriftB64LineRecordReader(TypeRef<M> typeRef) {
    super(typeRef, new ThriftWritable<M>(typeRef), new ThriftConverter<M>(typeRef));
    LOG.info("LzoTProtoB64LineRecordReader, type is " + typeRef.getRawClass());
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
import java.io.IOException;
import java.io.InputStream;
=======
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import com.google.protobuf.Message;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
import com.google.common.base.Function;
import com.google.protobuf.Message;
=======
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
import com.twitter.elephantbird.util.Protobufs;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
import org.apache.commons.codec.binary.Base64;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.util.LineReader;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
 * deserializes that into the templatized protobuf object.  Returns <position, protobuf>
 * pairs.
=======
 * deserializes that into the templatized protobuf object.
 * Returns <position, protobuf> pairs.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
public class  LzoProtobufB64LineRecordReader<M extends Message, W extends ProtobufWritable<M>> extends LzoRecordReader<LongWritable, W> {
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufBlockRecordReader.class);

  private LineReader lineReader_;

  private final Text line_ = new Text();
  private final LongWritable key_ = new LongWritable();
  private final W value_;
  private final TypeRef<M> typeRef_;
  private final Base64 base64_ = new Base64();
  private final Function<byte[], M> protoConverter_;
=======
public class  LzoProtobufB64LineRecordReader<M extends Message, W extends ProtobufWritable<M>> extends LzoBinaryB64LineRecordReader<M, W> {
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufB64LineRecordReader.class);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
    typeRef_ = typeRef;
    protoConverter_ = Protobufs.getProtoConverter(typeRef_.getRawClass());
    LOG.info("LzoProtobufBlockRecordReader, type args are " + typeRef_.getRawClass());
    value_ = protobufWritable;
  }

  @Override
  public synchronized void close() throws IOException {
    if (lineReader_ != null) {
      lineReader_.close();
    }
  }

  @Override
  public LongWritable getCurrentKey() throws IOException, InterruptedException {
    return key_;
  }

  @Override
  public W getCurrentValue() throws IOException, InterruptedException {
    return value_;
  }

  @Override
  protected void createInputReader(InputStream input, Configuration conf) throws IOException {
    lineReader_ = new LineReader(input, conf);
  }

  @Override
  protected void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    if (!atFirstRecord) {
      lineReader_.readLine(new Text());
    }
  }

  @Override
  public boolean nextKeyValue() throws IOException, InterruptedException {
    // Since the lzop codec reads everything in lzo blocks, we can't stop if pos == end.
    // Instead we wait for the next block to be read in, when pos will be > end.
    while (pos_ <= end_) {
      key_.set(pos_);

      int newSize = lineReader_.readLine(line_);
      if (newSize == 0) {
        return false;
      }
      pos_ = getLzoFilePos();
      byte[] lineBytes = line_.toString().getBytes("UTF-8");
      M protoValue = protoConverter_.apply(base64_.decode(lineBytes));
      if (protoValue == null) {
        continue;
      }

      value_.set(protoValue);
      return true;
    }

    return false;
=======
    super(typeRef, protobufWritable, new ProtobufConverter<M>(typeRef));
    LOG.info("LzoProtobufB64LineRecordReader, type args are " + typeRef.getRawClass());
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftBlockInputFormat.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.input;

import java.io.IOException;

import com.twitter.elephantbird.mapreduce.io.ThriftWritable;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.mapreduce.InputSplit;
import org.apache.hadoop.mapreduce.RecordReader;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.thrift.TBase;

/**
 * Reads Thrift objects written in blocks using LzoThriftBlockOutputFormat
 * <br><br>
 *
 * Do not use LzoThriftBlockInputFormat.class directly for setting
 * InputFormat class for a job. Use getInputFormatClass() instead.
 */
public class LzoThriftBlockInputFormat<M extends TBase<?>>
                extends LzoInputFormat<LongWritable, ThriftWritable<M>> {
  // implementation is exactly same as LzoThriftB64LineINputFormat

  public LzoThriftBlockInputFormat() {}

  /**
   * Returns {@link LzoThriftBlockInputFormat} class for setting up a job.
   * Sets an internal configuration in jobConf so that Task instantiates
   * appropriate object for this generic class based on thriftClass
   */
  @SuppressWarnings("unchecked")
  public static <M extends TBase<?>> Class<LzoThriftBlockInputFormat>
     getInputFormatClass(Class<M> thriftClass, Configuration jobConf) {
    ThriftUtils.setClassConf(jobConf, LzoThriftBlockInputFormat.class, thriftClass);
    return LzoThriftBlockInputFormat.class;
  }

  @Override
  public RecordReader<LongWritable, ThriftWritable<M>> createRecordReader(InputSplit split,
      TaskAttemptContext taskAttempt) throws IOException, InterruptedException {

    TypeRef<M> typeRef = ThriftUtils.getTypeRef(taskAttempt.getConfiguration(), LzoThriftBlockInputFormat.class);
    return new LzoThriftBlockRecordReader<M>(typeRef);
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoGenericProtobufBlockInputFormat.java;<<<<<<< MINE
  private static final Logger LOG = LoggerFactory.getLogger(LzoGenericProtobufBlockInputFormat.class);
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoInputFormat.java;<<<<<<< MINE
    FileSystem fs = FileSystem.get(job.getConfiguration());
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoInputFormat.java;<<<<<<< MINE
        LzoIndex index = LzoIndex.readIndex(fs, file);
=======
        LzoIndex index = LzoIndex.readIndex(file.getFileSystem(job.getConfiguration()), file);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoInputFormat.java;<<<<<<< MINE
    FileSystem fs = FileSystem.get(job.getConfiguration());
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoInputFormat.java;<<<<<<< MINE
      long lzoEnd = index.alignSliceEndToIndex(end, fs.getFileStatus(file).getLen());
=======
      long lzoEnd = index.alignSliceEndToIndex(end, file.getFileSystem(job.getConfiguration()).getFileStatus(file).getLen());
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoBinaryB64LineRecordReader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.input;

import java.io.IOException;
import java.io.InputStream;

import com.twitter.elephantbird.mapreduce.io.BinaryConverter;
import com.twitter.elephantbird.mapreduce.io.BinaryWritable;
import com.twitter.elephantbird.util.HadoopUtils;
import com.twitter.elephantbird.util.TypeRef;

import org.apache.commons.codec.binary.Base64;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.InputSplit;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.util.LineReader;

/**
 * Reads line from an lzo compressed text file, base64 decodes it, and then
 * deserializes that into the templatized object.  Returns <position, protobuf>
 * pairs.
 */
public class  LzoBinaryB64LineRecordReader<M, W extends BinaryWritable<M>> extends LzoRecordReader<LongWritable, W> {

  private LineReader lineReader_;

  private final Text line_ = new Text();
  private final LongWritable key_ = new LongWritable();
  private final W value_;
  private TypeRef<M> typeRef_;

  private final Base64 base64_ = new Base64();
  private final BinaryConverter<M> converter_;

  private Counter linesReadCounter;
  private Counter recordsReadCounter;
  private Counter recordErrorsCounter;

  protected LzoBinaryB64LineRecordReader(TypeRef<M> typeRef, W protobufWritable, BinaryConverter<M> protoConverter) {
    typeRef_ = typeRef;
    converter_ = protoConverter;
    value_ = protobufWritable;
  }

  @Override
  public synchronized void close() throws IOException {
    if (lineReader_ != null) {
      lineReader_.close();
    }
  }

  @Override
  public LongWritable getCurrentKey() throws IOException, InterruptedException {
    return key_;
  }

  @Override
  public W getCurrentValue() throws IOException, InterruptedException {
    return value_;
  }

  @Override
  protected void createInputReader(InputStream input, Configuration conf) throws IOException {
    lineReader_ = new LineReader(input, conf);
  }

  public void initialize(InputSplit genericSplit, TaskAttemptContext context)
                                      throws IOException, InterruptedException {
    String group = "LzoB64Lines of " + typeRef_.getRawClass().getName();
    linesReadCounter = HadoopUtils.getCounter(context, group, "Lines Read");
    recordsReadCounter = HadoopUtils.getCounter(context, group, "Records Read");
    recordErrorsCounter = HadoopUtils.getCounter(context, group, "Errors");

    super.initialize(genericSplit, context);
  }

  @Override
  protected void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    if (!atFirstRecord) {
      lineReader_.readLine(new Text());
    }
  }

  @Override
  public boolean nextKeyValue() throws IOException, InterruptedException {
    // Since the lzop codec reads everything in lzo blocks, we can't stop if pos == end.
    // Instead we wait for the next block to be read in, when pos will be > end.
    while (pos_ <= end_) {
      key_.set(pos_);

      int newSize = lineReader_.readLine(line_);
      if (newSize == 0) {
        return false;
      }
      linesReadCounter.increment(1);

      pos_ = getLzoFilePos();
      byte[] lineBytes = line_.toString().getBytes("UTF-8");
      M protoValue = converter_.fromBytes(base64_.decode(lineBytes));
      recordsReadCounter.increment(1);

      if (protoValue == null) {
        recordErrorsCounter.increment(1);
        continue;
      }

      value_.set(protoValue);
      return true;
    }

    return false;
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftBlockRecordReader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.input;

import com.twitter.elephantbird.mapreduce.io.ThriftBlockReader;
import com.twitter.elephantbird.mapreduce.io.ThriftWritable;
import com.twitter.elephantbird.util.TypeRef;

import org.apache.thrift.TBase;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * A reader for LZO-encoded protobuf blocks, generally written by
 * a ProtobufBlockWriter or similar.  Returns <position, protobuf> pairs.
 */
public class LzoThriftBlockRecordReader<M extends TBase<?>> extends LzoBinaryBlockRecordReader<M, ThriftWritable<M>> {
  private static final Logger LOG = LoggerFactory.getLogger(LzoThriftBlockRecordReader.class);

  public LzoThriftBlockRecordReader(TypeRef<M> typeRef) {
    // input stream for the reader will be set by LzoBinaryBlockRecordReader
    super(typeRef, new ThriftBlockReader<M>(null, typeRef), new ThriftWritable<M>(typeRef));
    LOG.info("LzoThriftBlockRecordReader, type args are " + typeRef.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ThriftConverter.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.io;

import org.apache.thrift.TBase;
import org.apache.thrift.TDeserializer;
import org.apache.thrift.TException;
import org.apache.thrift.TSerializer;

import com.twitter.elephantbird.util.TypeRef;

public class ThriftConverter<M extends TBase<?>> implements BinaryConverter<M> {

  private TypeRef<M> typeRef;
  private TSerializer serializer;
  private TDeserializer deserializer;

  /**
   * Returns a ThriftConverter for a given Thrift class.
   */
  public static <M extends TBase<?>> ThriftConverter<M> newInstance(Class<M> tClass) {
    return new ThriftConverter<M>(new TypeRef<M>(tClass){});
  }

  public static <M extends TBase<?>> ThriftConverter<M> newInstance(TypeRef<M> typeRef) {
    return new ThriftConverter<M>(typeRef);
  }

  public ThriftConverter(TypeRef<M> typeRef) {
    this.typeRef = typeRef;
  }

  @Override
  public M fromBytes(byte[] messageBuffer) {
    if (deserializer == null)
      deserializer = new TDeserializer();
    try {
      M message = typeRef.safeNewInstance();
      deserializer.deserialize(message, messageBuffer);
      return message;
    } catch (TException e) {
      // print a warning?
      return null;
    }
  }

  @Override
  public byte[] toBytes(M message) {
    if (serializer == null)
      serializer = new TSerializer();
    try {
      return serializer.serialize(message);
    } catch (TException e) {
      return null;
    }
  }

  @Override
  public boolean equals(Object obj) {
    if (this == obj)
      return true;
    try {
      return typeRef.getType().equals(((ThriftConverter<?>)obj).typeRef.getType());
    } catch (ClassCastException e) {
      return false;
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ThriftBlockReader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.io;

import java.io.InputStream;

import com.twitter.elephantbird.util.TypeRef;

import org.apache.thrift.TBase;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/** A class to read blocks of Thrift objects.
 * See the {@link ProtobufBlockReader} for more info.
 */
public class ThriftBlockReader<M extends TBase<?>> extends BinaryBlockReader<M> {
  private static final Logger LOG = LoggerFactory.getLogger(ThriftBlockReader.class);

  public ThriftBlockReader(InputStream in, TypeRef<M> typeRef) {
    super(in, new ThriftConverter<M>(typeRef));
    LOG.info("ThriftBlockReader, my typeClass is " + typeRef.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/BinaryWritable.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.io;

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;

import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.WritableComparable;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


/**
 * A Hadoop Writable wrapper around a serialized messages like Protocol buffers.
 */
public abstract class BinaryWritable<M> implements WritableComparable<BinaryWritable<M>> {
  private static final Logger LOG = LoggerFactory.getLogger(BinaryWritable.class);

  private M message;
  private BinaryConverter<M> converter;

  protected BinaryWritable(M message, BinaryConverter<M> converter) {
    this.message = message;
    this.converter = converter;
  }

  public M get() {
    return message;
  }

  public void clear() {
    message = null;
  }

  public void set(M message) {
    this.message = message;
  }

  public void write(DataOutput out) throws IOException {
    byte[] bytes = null;
    if (message != null) {
      bytes = converter.toBytes(message);
      if (bytes == null) {
        // should we throw an IOException instead?
        LOG.warn("Could not serialize " + message.getClass());
      }
    }
    if (bytes != null) {
      out.writeInt(bytes.length);
      out.write(bytes, 0, bytes.length);
    } else {
      out.writeInt(0);
    }
  }

  public void readFields(DataInput in) throws IOException {
    int size = in.readInt();
    if (size > 0) {
      byte[] messageBytes = new byte[size];
      in.readFully(messageBytes, 0, size);
      message = converter.fromBytes(messageBytes);
    }
  }

  @Override
  public int compareTo(BinaryWritable<M> other) {
    byte[] bytes = converter.toBytes(message);
    byte[] otherBytes = converter.toBytes(other.get());
    return BytesWritable.Comparator.compareBytes(bytes, 0, bytes.length, otherBytes, 0, otherBytes.length);
  }

  @Override
  public boolean equals(Object obj) {
    if (obj == null)
      return false;

    BinaryWritable<?> other;
    try {
      other = (BinaryWritable<?>)obj;
    } catch (ClassCastException e) {
      return false;
    }
    if (message != null)
      return message.equals(other.message);
    if (other.message == null) // contained objects in both writables are null.
      return converter.equals(other.converter);

    return false;
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/BinaryBlockWriter.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.io;

import java.io.IOException;
import java.io.OutputStream;

import com.google.protobuf.ByteString;
import com.google.protobuf.Message;
import com.twitter.data.proto.BlockStorage.SerializedBlock;
import com.twitter.elephantbird.util.Protobufs;

/** 
 * A class to write blocks of serialized objects.
 */
public abstract class BinaryBlockWriter<M> {
  protected static final int DEFAULT_NUM_RECORDS_PER_BLOCK = 100;

  private final OutputStream out_;
  private final int numRecordsPerBlock_;
  private final Class<M> protobufClass_;
  private final BinaryConverter<M> protoConverter_;
  private int numRecordsWritten_ = 0;
  private SerializedBlock.Builder builder_;

  protected BinaryBlockWriter(OutputStream out, Class<M> protoClass, BinaryConverter<M> protoConverter, int numRecordsPerBlock) {
    out_ = out;
    numRecordsPerBlock_ = numRecordsPerBlock;
    protobufClass_ = protoClass;
    protoConverter_ = protoConverter;
    
    builder_ = reinitializeBlockBuilder();
  }

  public void write(M message) throws IOException {
    if (message instanceof Message) {
      //a small hack to avoid extra copy, since we need a ByteString anyway.
      builder_.addProtoBlobs(((Message)message).toByteString());
    } else {
      builder_.addProtoBlobs(ByteString.copyFrom(protoConverter_.toBytes(message)));
    }
    
    numRecordsWritten_++;

    if (builder_.getProtoBlobsCount() == numRecordsPerBlock_) {
      serialize();
      builder_ = reinitializeBlockBuilder();
    }
  }

  public SerializedBlock.Builder reinitializeBlockBuilder() {
    return SerializedBlock.newBuilder()
                          .setVersion(1)
                          .setProtoClassName(protobufClass_.getCanonicalName());
  }


  public void finish() throws IOException {
    if (builder_.getProtoBlobsCount() > 0) {
      serialize();
    }
  }

  public void close() throws IOException {
    out_.close();
  }

  protected void serialize() throws IOException {
    SerializedBlock block = builder_.build();
    out_.write(Protobufs.KNOWN_GOOD_POSITION_MARKER);
    writeRawLittleEndian32(block.getSerializedSize());
    block.writeTo(out_);
  }

  private void writeRawLittleEndian32(int size) throws IOException {
     out_.write((size) & 0xFF);
     out_.write((size >> 8) & 0xFF);
     out_.write((size >> 16) & 0xFF);
     out_.write((size >> 24) & 0xFF);
   }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ThriftBlockWriter.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.io;

import java.io.OutputStream;

import org.apache.thrift.TBase;

import com.twitter.elephantbird.util.TypeRef;

/**
 * A class to write blocks of Thrift data of type M.
 * See {@link ProtobufBlockWriter} for more documentation.  
 */
public class ThriftBlockWriter<M extends TBase<?>> extends BinaryBlockWriter<M> {
  
  public ThriftBlockWriter(OutputStream out, Class<M> protoClass) {
    super(out, protoClass, new ThriftConverter<M>(new TypeRef<M>(protoClass){}), DEFAULT_NUM_RECORDS_PER_BLOCK);
  }
  
  public ThriftBlockWriter(OutputStream out, Class<M> protoClass, int numRecordsPerBlock) {
    super(out, protoClass, new ThriftConverter<M>(new TypeRef<M>(protoClass){}), numRecordsPerBlock);
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/BinaryBlockReader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.io;

import java.io.IOException;
import java.io.InputStream;

import com.twitter.data.proto.BlockStorage.SerializedBlock;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.StreamSearcher;

import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.IOUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/** 
 * A class to read blocks of binary objects like protobufs. 
 */
public abstract class BinaryBlockReader<M> {
  private static final Logger LOG = LoggerFactory.getLogger(BinaryBlockReader.class);

  // though any type of objects can be stored, each block itself is 
  // stored as a protocolbuf (SerializedBlock).
  
  private InputStream in_;
  private final StreamSearcher searcher_;
  private final BinaryConverter<M> protoConverter_;
  private SerializedBlock curBlock_;
  private int numLeftToReadThisBlock_ = 0;
  private boolean readNewBlocks_ = true;

  protected BinaryBlockReader(InputStream in, BinaryConverter<M> protoConverter) {
    in_ = in;
    protoConverter_ = protoConverter;
    searcher_ = new StreamSearcher(Protobufs.KNOWN_GOOD_POSITION_MARKER);
  }

  public void close() throws IOException {
    if (in_ != null)
      in_.close();
  }

  /**
   * Sets input stream. Sometimes the actual input stream might be created 
   * away from the constructor.
   */
  public void setInputStream(InputStream in) {
    in_ = in; // not closing existing in_, normally it is null
  }
  
  /**
   * Returns next deserialized object. null indicates end of stream.
   */
  public M readNext() throws IOException {
    byte[] blob = readNextProtoBytes();
    return blob == null ?
        null : protoConverter_.fromBytes(blob);
  }

  /**
   * Returns true if new proto object was read into writable, false other wise.
   */
  public boolean readNext(BinaryWritable<M> writable) throws IOException {
    byte[] blob = readNextProtoBytes();
    if (blob != null) {
      writable.set(protoConverter_.fromBytes(blob));
      return true;
    }
    return false;
  }
  
  /**
   * Return byte blob for the next proto object. null indicates end of stream;
   */
  public byte[] readNextProtoBytes() throws IOException {
    if (!setupNewBlockIfNeeded()) {
      return null;
    }

    int blobIndex = curBlock_.getProtoBlobsCount() - numLeftToReadThisBlock_;
    numLeftToReadThisBlock_--;
    return curBlock_.getProtoBlobs(blobIndex).toByteArray();
  }
  
  /**
   * returns true if bytes for next object are written to writable, false
   * other wise.
   */
  public boolean readNextProtoBytes(BytesWritable writable) throws IOException {
    byte[] blob = readNextProtoBytes();
    if (blob != null) {
      writable.set(blob, 0, blob.length);
      return true;
    }
    return false;  
  }
  
  public void markNoMoreNewBlocks() {
    readNewBlocks_ = false;
  }

  public boolean skipToNextSyncPoint() throws IOException {
    return searcher_.search(in_);
  }

  public SerializedBlock parseNextBlock() throws IOException {
    LOG.debug("BlockReader: none left to read, skipping to sync point");
    if (!skipToNextSyncPoint()) {
      LOG.debug("BlockReader: SYNC point eof");
      // EOF if there are no more sync markers.
      return null;
    }

    int blockSize = readInt();
    LOG.debug("BlockReader: found sync point, next block has size " + blockSize);
    if (blockSize < 0) {
      LOG.debug("ProtobufReader: reading size after sync point eof");
      // EOF if the size cannot be read.
      return null;
    }

    byte[] byteArray = new byte[blockSize];
    IOUtils.readFully(in_, byteArray, 0, blockSize);
    SerializedBlock block = SerializedBlock.parseFrom(byteArray);

    numLeftToReadThisBlock_ = block.getProtoBlobsCount();
    LOG.debug("ProtobufReader: number in next block is " + numLeftToReadThisBlock_);
    return block;
  }

  private boolean setupNewBlockIfNeeded() throws IOException {
    if (numLeftToReadThisBlock_ == 0) {
      if (!readNewBlocks_) {
        // If the reader has been told not to read more blocks, stop.
        // This happens when a map boundary has been crossed in a map job, for example.
        // The goal then is to finsh reading what has been parsed, but let the next split
        // handle everything starting at the next sync point.
        return false;
      }
      curBlock_ = parseNextBlock();
      if (curBlock_ == null) {
        // If there is nothing, it likely means EOF. Signal that processing is done.
        return false;
      }
    }

    return true;
  }

  private int readInt() throws IOException {
    int b = in_.read();
    if (b == -1) {
      return -1;
    }

    return b | (in_.read() << 8) | (in_.read() << 16) | (in_.read() << 24);
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufWritable.java;<<<<<<< MINE
import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;

import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.WritableComparable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufWritable.java;<<<<<<< MINE
import com.google.common.base.Function;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufWritable.java;<<<<<<< MINE
import com.twitter.elephantbird.util.Protobufs;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufWritable.java;<<<<<<< MINE
public class ProtobufWritable<M extends Message> implements WritableComparable<ProtobufWritable<M>> {
=======
public class ProtobufWritable<M extends Message> extends BinaryWritable<M> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufWritable.java;<<<<<<< MINE
  private M message_;
  private final Function<byte[], M> protoConverter_;
  
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufWritable.java;<<<<<<< MINE
    message_ = message;
    protoConverter_ = Protobufs.getProtoConverter(typeRef.getRawClass());
    LOG.debug("ProtobufWritable, typeClass is " + typeRef.getRawClass() + " and message is " + message_);
  }

  public M get() {
    return message_;
  }

  public int getLength() {
    return message_ != null ? message_.getSerializedSize() : 0;
  }

  public void clear() {
    message_ = null;
  }

  public void set(M message) {
    message_ = message;
  }

  public void write(DataOutput out) throws IOException {
    out.writeInt(getLength());
    if (message_ != null) {
      byte[] byteArray = message_.toByteArray();
      out.write(byteArray, 0, byteArray.length);
    }
  }

  public void readFields(DataInput in) throws IOException {
    int size = in.readInt();
    if (size > 0) {
      byte[] messageBytes = new byte[size];
      in.readFully(messageBytes, 0, size);
      message_ = protoConverter_.apply(messageBytes);
    }
  }

	@Override
  public int compareTo(ProtobufWritable<M> other) {
	  byte[] bytes = message_.toByteArray();
	  byte[] otherBytes = other.get().toByteArray();
	  return BytesWritable.Comparator.compareBytes(bytes, 0, bytes.length, otherBytes, 0, otherBytes.length);
=======
    super(message, new ProtobufConverter<M>(typeRef));
    LOG.debug("ProtobufWritable, typeClass is " + typeRef.getRawClass());
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ThriftWritable.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.io;

import org.apache.thrift.TBase;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.util.TypeRef;

/**
 * {@link BinaryWritable} for Thrift 
 */
public class ThriftWritable<M extends TBase<?>> extends BinaryWritable<M> {
  private static final Logger LOG = LoggerFactory.getLogger(ThriftWritable.class);
  
  /**
   * Returns a ThriftWritable for a given Thrift class.
   */
  public static <M extends TBase<?>> ThriftWritable<M> newInstance(Class<M> tClass) {
    return new ThriftWritable<M>(new TypeRef<M>(tClass){});
  }
  
  public ThriftWritable(TypeRef<M> typeRef) {
    this(null, typeRef);
  }

  public ThriftWritable(M message, TypeRef<M> typeRef) {
    super(message, new ThriftConverter<M>(typeRef));
    LOG.debug("TProtoWritable, typeClass is " + typeRef.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/BinaryConverter.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.io;

/**
 * A simple interface to serialize and deserialize objects
 */
public interface BinaryConverter<M> {
  /* TODO : What about exceptions?
   */

  /** Returns deserialized object. A return of null normally implies an error. */ 
  M fromBytes(byte[] messageBuffer);
  
  byte[] toBytes(M message);
  
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
import java.io.IOException;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
import com.google.protobuf.Descriptors;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
import com.twitter.data.proto.BlockStorage.SerializedBlock;
import com.twitter.elephantbird.util.Protobufs;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
=======
import com.twitter.elephantbird.util.TypeRef;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
/* A class to write blocks of protobuf data of type M.  To use, just instantiate
=======
/**
 * A class to write blocks of protobuf data of type M.  To use, just instantiate
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
public class ProtobufBlockWriter {
  private static final Logger LOG = LoggerFactory.getLogger(ProtobufBlockWriter.class);
  protected static final int DEFAULT_NUM_RECORDS_PER_BLOCK = 100;

  protected final OutputStream out_;
  protected final int numRecordsPerBlock_;
  protected final Class<? extends Message> protobufClass_;
  protected final Descriptors.Descriptor msgDescriptor_;

  protected int numRecordsWritten_ = 0;
  protected SerializedBlock.Builder builder_;

  public ProtobufBlockWriter(OutputStream out, Class<? extends Message> protoClass) {
    this(out, protoClass, DEFAULT_NUM_RECORDS_PER_BLOCK);
  }

  public ProtobufBlockWriter(OutputStream out, Class<? extends Message> protoClass, int numRecordsPerBlock) {
    out_ = out;
    numRecordsPerBlock_ = numRecordsPerBlock;
    protobufClass_ = protoClass;
    msgDescriptor_ = Protobufs.getMessageDescriptor(protobufClass_);

    builder_ = reinitializeBlockBuilder();
=======
public class ProtobufBlockWriter<M extends Message> extends BinaryBlockWriter<M> {
  
  public ProtobufBlockWriter(OutputStream out, Class<M> protoClass) {
    super(out, protoClass, new ProtobufConverter<M>(new TypeRef<M>(protoClass){}), DEFAULT_NUM_RECORDS_PER_BLOCK);
  }
  
  public ProtobufBlockWriter(OutputStream out, Class<M> protoClass, int numRecordsPerBlock) {
    super(out, protoClass, new ProtobufConverter<M>(new TypeRef<M>(protoClass){}), numRecordsPerBlock);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE

  public void write(Message message) throws IOException {
    builder_.addProtoBlobs(message.toByteString());
    numRecordsWritten_++;

    if (builder_.getProtoBlobsCount() == numRecordsPerBlock_) {
      serialize();
      builder_ = reinitializeBlockBuilder();
    }
  }

  public SerializedBlock.Builder reinitializeBlockBuilder() {
    return SerializedBlock.newBuilder()
                          .setVersion(1)
                          .setProtoClassName(protobufClass_.getCanonicalName());
  }


  public void finish() throws IOException {
    if (builder_.getProtoBlobsCount() > 0) {
      serialize();
    }
  }

  public void close() throws IOException {
    out_.close();
  }

  protected void serialize() throws IOException {
    SerializedBlock block = builder_.build();
    out_.write(Protobufs.KNOWN_GOOD_POSITION_MARKER);
    writeRawLittleEndian32(block.getSerializedSize());
    block.writeTo(out_);
  }

  private void writeRawLittleEndian32(int size) throws IOException {
     out_.write((size) & 0xFF);
     out_.write((size >> 8) & 0xFF);
     out_.write((size >> 16) & 0xFF);
     out_.write((size >> 24) & 0xFF);
   }
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufConverter.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.mapreduce.io;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.protobuf.InvalidProtocolBufferException;
import com.google.protobuf.Message;
import com.google.protobuf.UninitializedMessageException;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * {@link BinaryConverter} for Protobufs
 */
public class ProtobufConverter<M extends Message> implements BinaryConverter<M> {
  private static final Logger LOG = LoggerFactory.getLogger(ProtobufConverter.class);

  private Message.Builder protoBuilder;
  private TypeRef<M> typeRef;

  public ProtobufConverter(TypeRef<M> typeRef) {
    this.typeRef = typeRef;
  }

  @SuppressWarnings("unchecked")
  @Override
  public M fromBytes(byte[] messageBuffer) {
    try {
      if (protoBuilder == null) {
        protoBuilder = Protobufs.getMessageBuilder(typeRef.getRawClass());
      }
      return  (M) protoBuilder.clone().mergeFrom(messageBuffer).build();
    } catch (InvalidProtocolBufferException e) {
      LOG.error("Invalid Protocol Buffer exception building " + typeRef.getRawClass().getName(), e);
    } catch(UninitializedMessageException ume) {
      LOG.error("Uninitialized Message Exception in building " + typeRef.getRawClass().getName(), ume);
    }
    return null;
  }

  @Override
  public byte[] toBytes(M message) {
    return message.toByteArray();
  }

  @Override
  public boolean equals(Object obj) {
    if (this == obj)
      return true;
    try {
      return typeRef.getType().equals(((ProtobufConverter<?>)obj).typeRef.getType());
    } catch (ClassCastException e) {
      return false;
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
import com.google.common.base.Function;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
import com.twitter.data.proto.BlockStorage.SerializedBlock;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.StreamSearcher;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
import org.apache.hadoop.io.IOUtils;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
public class ProtobufBlockReader<M extends Message> {
=======
public class ProtobufBlockReader<M extends Message> extends BinaryBlockReader<M> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
  private final InputStream in_;
  private final StreamSearcher searcher_;
  private final Function<byte[], M> protoConverter_;
  private SerializedBlock curBlock_;
  private int numLeftToReadThisBlock_ = 0;
  private boolean readNewBlocks_ = true;

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
=======
    super(in, new ProtobufConverter<M>(typeRef));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
    in_ = in;
    protoConverter_ = Protobufs.getProtoConverter(typeRef.getRawClass());
    searcher_ = new StreamSearcher(Protobufs.KNOWN_GOOD_POSITION_MARKER);
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE

  public void close() throws IOException {
    in_.close();
  }

=======
  
  // for backward compatibility :
  
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
    message.clear();

    if (!setupNewBlockIfNeeded()) {
      return false;
    }

    int blobIndex = curBlock_.getProtoBlobsCount() - numLeftToReadThisBlock_;
    byte[] blob = curBlock_.getProtoBlobs(blobIndex).toByteArray();
    message.set(protoConverter_.apply(blob));
    numLeftToReadThisBlock_--;
    return true;
=======
    return readNext(message);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE

=======
  
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
    if (!setupNewBlockIfNeeded()) {
      return false;
    }

    int blobIndex = curBlock_.getProtoBlobsCount() - numLeftToReadThisBlock_;
    byte[] blob = curBlock_.getProtoBlobs(blobIndex).toByteArray();
    message.set(blob, 0, blob.length);
    numLeftToReadThisBlock_--;
    return true;
  }

  public void markNoMoreNewBlocks() {
    readNewBlocks_ = false;
  }

  public boolean skipToNextSyncPoint() throws IOException {
    return searcher_.search(in_);
  }

  public SerializedBlock parseNextBlock() throws IOException {
    LOG.debug("ProtobufReader: none left to read, skipping to sync point");
    if (!skipToNextSyncPoint()) {
      LOG.debug("ProtobufReader: SYNC point eof");
      // EOF if there are no more sync markers.
      return null;
    }

    int blockSize = readInt();
    LOG.debug("ProtobufReader: found sync point, next block has size " + blockSize);
    if (blockSize < 0) {
      LOG.debug("ProtobufReader: reading size after sync point eof");
      // EOF if the size cannot be read.
      return null;
    }

    byte[] byteArray = new byte[blockSize];
    IOUtils.readFully(in_, byteArray, 0, blockSize);
    SerializedBlock block = SerializedBlock.parseFrom(byteArray);

    numLeftToReadThisBlock_ = block.getProtoBlobsCount();
    LOG.debug("ProtobufReader: number in next block is " + numLeftToReadThisBlock_);
    return block;
  }

  private boolean setupNewBlockIfNeeded() throws IOException {
    if (numLeftToReadThisBlock_ == 0) {
      if (!readNewBlocks_) {
        // If the reader has been told not to read more blocks, stop.
        // This happens when a map boundary has been crossed in a map job, for example.
        // The goal then is to finsh reading what has been parsed, but let the next split
        // handle everything starting at the next sync point.
        return false;
      }
      curBlock_ = parseNextBlock();
      if (curBlock_ == null) {
        // If there is nothing, it likely means EOF. Signal that processing is done.
        return false;
      }
    }

    return true;
  }

  private int readInt() throws IOException {
    int b = in_.read();
    if (b == -1) {
      return -1;
    }

    return b | (in_.read() << 8) | (in_.read() << 16) | (in_.read() << 24);
=======
    return readNextProtoBytes(message);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/store/LzoProtobufB64LinePigStorage.java;<<<<<<< MINE
import java.util.List;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/store/LzoProtobufB64LinePigStorage.java;<<<<<<< MINE
import com.google.protobuf.Descriptors.FieldDescriptor;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/util/ThiftToPig.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

public class ThiftToPig {

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/util/ProtobufToPig.java;<<<<<<< MINE
=======
import com.sun.org.apache.xerces.internal.impl.dv.xs.SchemaDateTimeException;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/util/ProtobufToPig.java;<<<<<<< MINE
  }
=======
  }  
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/util/PigCounterHelper.java;<<<<<<< MINE
  private static final Logger LOG = LoggerFactory.getLogger(PigCounterHelper.class);

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/util/PigCounterHelper.java;<<<<<<< MINE
    Pair<String, String> key = new Pair<String, String>(group, counter);
    Long currentValue = counterStringMap_.get(key);
    counterStringMap_.put(key, (currentValue == null ? 0 : currentValue) + incr);

    if (getReporter() != null) {
      for (Map.Entry<Pair<String, String>, Long> entry : counterStringMap_.entrySet()) {
        getReporter().incrCounter(entry.getKey().first, entry.getKey().second, entry.getValue());
=======
    if (getReporter() != null) { // common case
      getReporter().incrCounter(group, counter, incr);
      if (counterStringMap_.size() > 0) {
        for (Map.Entry<Pair<String, String>, Long> entry : counterStringMap_.entrySet()) {
          getReporter().incrCounter(entry.getKey().first, entry.getKey().second, entry.getValue());
        }
        counterStringMap_.clear();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/util/PigCounterHelper.java;<<<<<<< MINE
      counterStringMap_.clear();
=======
    } else { // buffer the increments.
      Pair<String, String> key = new Pair<String, String>(group, counter);
      Long currentValue = counterStringMap_.get(key);
      counterStringMap_.put(key, (currentValue == null ? 0 : currentValue) + incr);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/util/PigCounterHelper.java;<<<<<<< MINE
    Long currentValue = counterEnumMap_.get(key);
    counterEnumMap_.put(key, (currentValue == null ? 0 : currentValue) + incr);

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/util/PigCounterHelper.java;<<<<<<< MINE
      for (Map.Entry<Enum<?>, Long> entry : counterEnumMap_.entrySet()) {
        getReporter().incrCounter(entry.getKey(), entry.getValue());
=======
      getReporter().incrCounter(key, incr);
      if (counterEnumMap_.size() > 0) {
        for (Map.Entry<Enum<?>, Long> entry : counterEnumMap_.entrySet()) {
          getReporter().incrCounter(entry.getKey(), entry.getValue());
        }
        counterEnumMap_.clear();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/util/PigCounterHelper.java;<<<<<<< MINE
      counterEnumMap_.clear();
=======
    } else { // buffer the increments
      Long currentValue = counterEnumMap_.get(key);
      counterEnumMap_.put(key, (currentValue == null ? 0 : currentValue) + incr);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoThriftB64LinePigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import java.nio.charset.Charset;

import org.apache.commons.codec.binary.Base64;
import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.apache.thrift.TBase;
import org.apache.thrift.TException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.mapreduce.io.ThriftConverter;
import com.twitter.elephantbird.pig.piggybank.ThriftToPig;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

public class LzoThriftB64LinePigLoader<M extends TBase<?>> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoThriftB64LinePigLoader.class);

  private final TypeRef<M> typeRef_;
  private final ThriftConverter<M> converter_;
  private final Base64 base64_ = new Base64();
  private final ThriftToPig<M> thriftToPig_;

  private static final Charset UTF8 = Charset.forName("UTF-8");
  private static final byte RECORD_DELIMITER = (byte)'\n';

  private Pair<String, String> linesRead;
  private Pair<String, String> thriftStructsRead;
  private Pair<String, String> thriftErrors;

  public LzoThriftB64LinePigLoader(String thriftClassName) {
    typeRef_ = ThriftUtils.getTypeRef(thriftClassName);
    converter_ = ThriftConverter.newInstance(typeRef_);
    thriftToPig_ =  ThriftToPig.newInstance(typeRef_);

    String group = "LzoB64Lines of " + typeRef_.getRawClass().getName();
    linesRead = new Pair<String, String>(group, "Lines Read");
    thriftStructsRead = new Pair<String, String>(group, "Thrift Structs");
    thriftErrors = new Pair<String, String>(group, "Errors");

    setLoaderSpec(getClass(), new String[]{thriftClassName});
  }

  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // Since we are not block aligned we throw away the first record of each split and count on a different
    // instance to read it.  The only split this doesn't work for is the first.
    if (!atFirstRecord) {
      getNext();
    }
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }

  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    String line;
    Tuple t = null;
    while ((line = is_.readLine(UTF8, RECORD_DELIMITER)) != null) {
      incrCounter(linesRead, 1L);
      M value = converter_.fromBytes(base64_.decode(line.getBytes("UTF-8")));
      if (value != null) {
        try {
          t = thriftToPig_.getPigTuple(value);
          incrCounter(thriftStructsRead, 1L);
          break;
        } catch (TException e) {
          incrCounter(thriftErrors, 1L);
          LOG.warn("ThriftToTuple error :", e); // may be struct mismatch
        }
      }
    }

    return t;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return ThriftToPig.toSchema(typeRef_.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoThriftBlockPigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;

import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.apache.thrift.TBase;
import org.apache.thrift.TException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.mapreduce.io.ThriftBlockReader;
import com.twitter.elephantbird.pig.piggybank.ThriftToPig;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;


public class LzoThriftBlockPigLoader<M extends TBase<?>> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoThriftBlockPigLoader.class);

  private final TypeRef<M> typeRef_;
  private final ThriftToPig<M> thriftToPig_;
  private ThriftBlockReader<M> reader_;

  private Pair<String, String> thriftStructsRead;
  private Pair<String, String> thriftErrors;

  public LzoThriftBlockPigLoader(String thriftClassName) {
    typeRef_ = ThriftUtils.getTypeRef(thriftClassName);
    thriftToPig_ =  ThriftToPig.newInstance(typeRef_);

    String group = "LzoBlocks of " + typeRef_.getRawClass().getName();
    thriftStructsRead = new Pair<String, String>(group, "Thrift Structs Read");
    thriftErrors = new Pair<String, String>(group, "Errors");

    setLoaderSpec(getClass(), new String[]{thriftClassName});
  }

  @Override
  public void postBind() throws IOException {
    reader_ = new ThriftBlockReader<M>(is_, typeRef_);
  }

  @Override
  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // We want to explicitly not do any special syncing here, because the reader_
    // handles this automatically.
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }

  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    // If we are past the end of the file split, tell the reader not to read any more new blocks.
    // Then continue reading until the last of the reader's already-parsed values are used up.
    // The next split will start at the next sync point and no records will be missed.
    if (is_.getPosition() > end_) {
      reader_.markNoMoreNewBlocks();
    }

    M value;
    while ((value = reader_.readNext()) != null) {
      try {
        Tuple t = thriftToPig_.getPigTuple(value);
        incrCounter(thriftStructsRead, 1L);
        return t;
      } catch (TException e) {
        incrCounter(thriftErrors, 1L);
        LOG.warn("ThriftToTuple error :", e); // may be corrupt data.
        // try next
      }
    }
    return null;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return ThriftToPig.toSchema(typeRef_.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
=======
import org.apache.pig.impl.util.Pair;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE

=======
  
  /** same as incrCounter(pair.first, pair.second, incr). */
  protected void incrCounter(Pair<String, String> groupCounterPair, long incr) {
    counterHelper_.incrCounter(groupCounterPair.first, groupCounterPair.second, incr);
  }
  
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
import org.apache.pig.LoadFunc;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
import org.apache.pig.impl.logicalLayer.FrontendException;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
=======
import org.apache.pig.impl.util.Pair;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
  protected enum LzoProtobufBlockPigLoaderCounters { ProtobufsRead }
=======
  private Pair<String, String> protobufsRead;
  private Pair<String, String> protobufErrors;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
=======
    String group = "LzoBlocks of " + typeRef_.getRawClass().getName();
    protobufsRead = new Pair<String, String>(group, "Protobufs Read");
    protobufErrors = new Pair<String, String>(group, "Errors");
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
=======
      if (value_.get() == null) {
        incrCounter(protobufErrors, 1);
      }
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
      incrCounter(LzoProtobufBlockPigLoaderCounters.ProtobufsRead, 1L);
=======
      incrCounter(protobufsRead, 1L);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
import org.apache.pig.LoadFunc;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
import org.apache.pig.impl.logicalLayer.FrontendException;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
import org.apache.pig.impl.util.Pair;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
  protected enum LzoProtobufB64LinePigLoaderCounts { LinesRead, ProtobufsRead }
=======
  private Pair<String, String> linesRead;
  private Pair<String, String> protobufsRead;
  private Pair<String, String> protobufErrors;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
    String group = "LzoB64Lines of " + typeRef_.getRawClass().getName();
    linesRead = new Pair<String, String>(group, "Lines Read");
    protobufsRead = new Pair<String, String>(group, "Protobufs Read");
    protobufErrors = new Pair<String, String>(group, "Errors");
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
      incrCounter(LzoProtobufB64LinePigLoaderCounts.LinesRead, 1L);
=======
      incrCounter(linesRead, 1L);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
        incrCounter(LzoProtobufB64LinePigLoaderCounts.ProtobufsRead, 1L);
=======
        incrCounter(protobufsRead, 1L);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
      } else {
        incrCounter(protobufErrors, 1L);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/piggybank/ThriftToPig.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.piggybank;

import java.util.ArrayDeque;
import java.util.Deque;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import org.apache.pig.LoadFunc;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.BagFactory;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.DataType;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
import org.apache.thrift.TBase;
import org.apache.thrift.TEnum;
import org.apache.thrift.TException;
import org.apache.thrift.TFieldIdEnum;
import org.apache.thrift.meta_data.EnumMetaData;
import org.apache.thrift.meta_data.FieldMetaData;
import org.apache.thrift.meta_data.FieldValueMetaData;
import org.apache.thrift.meta_data.ListMetaData;
import org.apache.thrift.meta_data.MapMetaData;
import org.apache.thrift.meta_data.SetMetaData;
import org.apache.thrift.meta_data.StructMetaData;
import org.apache.thrift.protocol.TField;
import org.apache.thrift.protocol.TList;
import org.apache.thrift.protocol.TMap;
import org.apache.thrift.protocol.TMessage;
import org.apache.thrift.protocol.TProtocol;
import org.apache.thrift.protocol.TSet;
import org.apache.thrift.protocol.TStruct;
import org.apache.thrift.protocol.TType;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.collect.ImmutableMap;
import com.google.common.collect.Lists;
import com.google.common.collect.Maps;
import com.twitter.elephantbird.pig.load.LzoThriftB64LinePigLoader;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

/**
 * <li> converts a Thrift struct to a Pig tuple
 * <li> utilities to provide schema for Pig loaders and Pig scripts
 */
public class ThriftToPig<M extends TBase<?>> {
  private static final Logger LOG = LoggerFactory.getLogger(ThriftToPig.class);

  /* TODO :
   * 1. Add lazy deserialization like ProtobufTuple does. Not sure if it can be done
   *    efficiently for Thrift.
   * 2. Converting Enum to names (strings) is supported only in the common
   *    case where Enum is part of a struct. Enum used directly in containers
   *    (e.g. list<SomeEnum>) are still integers. The issue is that Thrift
   *    does not explicitly tell that it is writing an Enum. We need to
   *    deduce that from the context. In the case of Structs, we already
   *    maintain this contexts.
   *
   *    In order to support enums-to-strings correctly we need to maintain more
   *    state and we should always know exact context/recursion of Thrift
   *    struct's write() method.
   *
   *    This is certainly do-able. Once we keep track of serialization
   *    so closely, we not far from implementing our own generic write() method.
   *    implementing generic write method will let us deserialize thrift buffer
   *    directly to a Pig Tuple and there is no need to use a Thrift object
   *    as intermediate step. This will also let us support
   *    lazy-deserialization and projections efficiently since we direclty
   *    access the thrift buffer.
   */
  private static BagFactory bagFactory_ = BagFactory.getInstance();
  private static TupleFactory tupleFactory_  = TupleFactory.getInstance();

  private Class<? extends TBase<?>> tClass_;
  private ThriftProtocol tProtocol_ = new ThriftProtocol();
  private Deque<PigContainer> containerStack_ = new ArrayDeque<PigContainer>();
  private PigContainer curContainer_;
  private Tuple curTuple_;

  // We want something that provides a generic interface for populating
  // Pig Tuples, Bags, and Maps. This does the trick.

  private abstract class PigContainer {
    StructDescriptor structDesc; // The current thrift struct being written
    FieldDescriptor curFieldDesc;
    public abstract Object getContents();
    public abstract void add(Object o) throws TException;

    /** set curFieldDesc if the container is is Thrift Struct. */
    public void setCurField(TField tField) throws TException {
      if (structDesc != null) {
        curFieldDesc = structDesc.fieldMap.get(tField.id);
        if (curFieldDesc == null) {
          throw new TException("Unexpected TField " + tField + " for " + tClass_.getName());
        }
      }
    }
  }

  private class TupleWrap extends PigContainer {

    private final Tuple t;

    public TupleWrap(int size) {
      t = tupleFactory_.newTuple(size);
    }

    public Object getContents() { return t; }

    public void add(Object o) throws TException {
      if (curFieldDesc == null) {
        throw new TException("Internal Error. curFieldDesc is not set");
      }
      if (curFieldDesc.enumMap != null && // map enum to string
          (o = curFieldDesc.enumMap.get(o)) == null) {
        throw new TException("cound not find Enum string");
      }
      try {
        t.set(curFieldDesc.tupleIdx, o);
       } catch (ExecException e) {
          throw new TException(e);
       }
    }
  }

  private class BagWrap extends PigContainer {
    List<Tuple> tuples;

    public BagWrap(int size) {
      tuples =  Lists.newArrayListWithCapacity(size);
    }

    @Override
    public void add(Object o) throws TException {
      // Pig bags contain tuples of objects, so we must wrap a tuple around
      // everything we get.
      if (o instanceof Tuple) {
        tuples.add((Tuple) o);
      } else {
        tuples.add(tupleFactory_.newTuple(o));
      }
    }

    @Override
    public Object getContents() {
      return bagFactory_.newDefaultBag(tuples);
    }
  }

  private class MapWrap extends PigContainer {
    private final Map<String, Object> map;
    String currKey = null;

    public MapWrap(int size) {
      map = new HashMap<String, Object>(size);
    }

    @Override
    public void add(Object o) throws TException {
      //we alternate between String keys and (converted) DataByteArray values.
      if (currKey == null) {
        try {
          currKey = (String) o;
        } catch (ClassCastException e) {
          throw new TException("Only String keys are allowed in maps.");
        }
      } else {
        map.put(currKey, o);
        currKey = null;
      }
    }

    @Override
    public Object getContents() {
      return map;
    }
  }


  private void pushContainer(PigContainer c) {
    containerStack_.addLast(c);
    curContainer_ = c;
  }

  private PigContainer popContainer() throws TException {
    PigContainer c = containerStack_.removeLast();
    curContainer_ = containerStack_.peekLast();
    if (curContainer_ == null) { // All done!
      curTuple_ = (Tuple) c.getContents();
    } else {
      curContainer_.add(c.getContents());
    }
    return c;
  }

  public static <M extends TBase<?>> ThriftToPig<M> newInstance(Class<M> tClass) {
    return new ThriftToPig<M>(tClass);
  }

  public static <M extends TBase<?>> ThriftToPig<M> newInstance(TypeRef<M> typeRef) {
    return new ThriftToPig<M>(typeRef.getRawClass());
  }

  public ThriftToPig(Class<M> tClass) {
    this.tClass_ = tClass;
    structMap = Maps.newHashMap();
    updateStructMap(tClass_);
    structMap = ImmutableMap.copyOf(structMap);
    reset();
  }

  /**
   * The protocol should be reset before each object that is serialized.
   * This is important since, the protocol itself can not reliably
   * realize if it at the beginning of a new object. It can not always
   * rely on the last object being correct written because of
   * any exceptions while processing previous object.
   */
  public void reset() {
    containerStack_.clear();
    curContainer_ = null;
    curTuple_ = null;
  }

  /**
   * Converts a thrift object to Pig tuple.
   * Throws TException in case of any errors.
   */
  public Tuple getPigTuple(M thriftObj) throws TException {
    reset();
    thriftObj.write(tProtocol_);
    if (curTuple_ != null) {
      return curTuple_;
    }
    // unexpected
    throw new TException("Internal error. tuple is not set");
  }

  /**
   * returns 'enum int -> enum name' mapping
   */
  static private Map<Integer, String> extractEnumMap(FieldValueMetaData field) {
    MetaData f = new MetaData(field);
    if (!f.isEnum()) {
      return null;
    }
    Map<Integer, String> map = Maps.newHashMap();
    for(TEnum e : f.getEnumClass().getEnumConstants()) {
      map.put(e.getValue(), e.toString());
    }
    return ImmutableMap.copyOf(map);
  }

  /**
   * holds relevant info for a field in a Thrift Struct including
   * index into tuple array.
   */
  private static class FieldDescriptor {
    TFieldIdEnum fieldEnum;
    int tupleIdx;
    Map<Integer, String> enumMap = null; // set for enums
  }

  /**
   * describes a Thrift struct. Contains following info :
   * <li> Thrift field descriptor map
   * <li> ...
   */
  private static class StructDescriptor {
    Map<Short, FieldDescriptor> fieldMap;

    public StructDescriptor(Class<? extends TBase<?>> tClass) {
      fieldMap = Maps.newHashMap();
      int idx = 0;
      for (Entry<? extends TFieldIdEnum, FieldMetaData> e : FieldMetaData.getStructMetaDataMap(tClass).entrySet()) {
        FieldDescriptor desc = new FieldDescriptor();
        desc.fieldEnum = e.getKey();
        desc.tupleIdx = idx++;
        if (e.getValue().valueMetaData.type == TType.ENUM) {
          desc.enumMap = extractEnumMap(e.getValue().valueMetaData);
        }
        fieldMap.put(desc.fieldEnum.getThriftFieldId(), desc);
      }
      fieldMap = ImmutableMap.copyOf(fieldMap);
    }
  }

  private Map<TStruct, StructDescriptor> structMap;

  private void updateStructMap(Class<? extends TBase<?>> tClass) {
    final TStruct tStruct = getStructDesc(tClass);

    if (structMap.get(tStruct) != null) {
      return;
    }

    StructDescriptor desc = new StructDescriptor(tClass);
    LOG.debug("adding struct descriptor for " + tClass.getName()
        + " with " + desc.fieldMap.size() + " fields");
    structMap.put(tStruct, desc);
    // recursively add any referenced classes.
    for (FieldMetaData field : FieldMetaData.getStructMetaDataMap(tClass).values()) {
      updateStructMap(field.valueMetaData);
    }
  }

  /**
   * Look for any class embedded in the in the container or struct fields
   * and update the struct map with them.
   */
  private void updateStructMap(FieldValueMetaData field) {
    MetaData f = new MetaData(field);

    if (f.isStruct()) {
      updateStructMap(f.getStructClass());
    }

    if (f.isList()) {
      updateStructMap(f.getListElem());
    }

    if (f.isMap()) {
      if (f.getMapKey().type != TType.STRING) {
        throw new IllegalArgumentException("Pig does not support maps with non-string keys "
            + "while initializing ThriftToPig for " + tClass_.getName());
      }
      updateStructMap(f.getMapKey());
      updateStructMap(f.getMapValue());
    }

    if (f.isSet()) {
      updateStructMap(f.getSetElem());
    }
  }

  private class ThriftProtocol extends TProtocol {

    ThriftProtocol() {
      super(null); // this protocol is not used for transport.
    }

    @Override
    public void writeBinary(byte[] bin) throws TException {
      curContainer_.add(new DataByteArray(bin));
    }

    @Override
    public void writeBool(boolean b) throws TException {
      curContainer_.add(Integer.valueOf(b ? 1 : 0));
    }

    @Override
    public void writeByte(byte b) throws TException {
      curContainer_.add(Integer.valueOf(b));
    }

    @Override
    public void writeDouble(double dub) throws TException {
      curContainer_.add(Double.valueOf(dub));
    }

    @Override
    public void writeFieldBegin(TField field) throws TException {
      curContainer_.setCurField(field);
    }

    @Override
    public void writeFieldEnd() throws TException {
    }

    @Override
    public void writeFieldStop() throws TException {
    }

    @Override
    public void writeI16(short i16) throws TException {
      curContainer_.add(Integer.valueOf(i16));
    }

    @Override
    public void writeI32(int i32) throws TException {
      curContainer_.add(i32);
    }

    @Override
    public void writeI64(long i64) throws TException {
      curContainer_.add(i64);
    }

    @Override
    public void writeListBegin(TList list) throws TException {
      pushContainer(new BagWrap(list.size));
    }

    @Override
    public void writeListEnd() throws TException {
      popContainer();
    }

    @Override
    public void writeMapBegin(TMap map) throws TException {
      pushContainer(new MapWrap(map.size));
    }

    @Override
    public void writeMapEnd() throws TException {
      popContainer();
    }

    @Override
    public void writeSetBegin(TSet set) throws TException {
      pushContainer(new BagWrap(set.size));
    }

    @Override
    public void writeSetEnd() throws TException {
      popContainer();
    }

    @Override
    public void writeString(String str) throws TException {
      curContainer_.add(str);
    }

    @Override
    public void writeStructBegin(TStruct struct) throws TException {
      StructDescriptor desc = structMap.get(struct);
      if (desc == null) {
        throw new TException("Unexpected TStruct " + struct.name + " for " + tClass_.getName());
      }
      PigContainer c = new TupleWrap(desc.fieldMap.size());
      c.structDesc = desc;
      pushContainer(c);
    }

    @Override
    public void writeStructEnd() throws TException {
      popContainer();
    }

    @Override
    public void writeMessageBegin(TMessage message) throws TException {
      throw new TException("method not implemented.");
    }
    @Override
    public void writeMessageEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public byte[] readBinary() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public boolean readBool() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public byte readByte() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public double readDouble() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TField readFieldBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readFieldEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public short readI16() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public int readI32() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public long readI64() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TList readListBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readListEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TMap readMapBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readMapEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TMessage readMessageBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readMessageEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TSet readSetBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readSetEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public String readString() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TStruct readStructBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readStructEnd() throws TException {
      throw new TException("method not implemented.");
    }
  }

  /**
   * A utility class to help with type checking of a ThriftField.
   * Avoids checking type and not-so-readable casting in many places.
   */
  static class MetaData {
    final FieldValueMetaData field;

    MetaData(FieldValueMetaData field) {
      this.field = field;
    }

    FieldValueMetaData getField() {
      return field;
    }

    // List
    boolean isList() {
      return field instanceof ListMetaData;
    }

    FieldValueMetaData getListElem() {
      return ((ListMetaData)field).elemMetaData;
    }

    // Enum
    boolean isEnum() {
      return field instanceof EnumMetaData;
    }

    Class<? extends TEnum> getEnumClass() {
      return ((EnumMetaData)field).enumClass;
    }

    // Map
    boolean isMap() {
      return field instanceof MapMetaData;
    }

    FieldValueMetaData getMapKey() {
      return ((MapMetaData)field).keyMetaData;
    }

    FieldValueMetaData getMapValue() {
      return ((MapMetaData)field).valueMetaData;
    }

    // Set
    boolean isSet() {
      return field instanceof SetMetaData;
    }

    FieldValueMetaData getSetElem() {
      return ((SetMetaData)field).elemMetaData;
    }

    // Struct
    boolean isStruct() {
      return field instanceof StructMetaData;
    }

    @SuppressWarnings("unchecked")
    Class<? extends TBase<?>> getStructClass() {
      return (Class <? extends TBase<?>>)((StructMetaData)field).structClass;
    }
  }

  /**
   * Returns Pig schema for the Thrift struct.
   */
  public static Schema toSchema(Class<? extends TBase<?>> tClass) {
    Schema schema = new Schema();

    try {
      for (Entry<? extends TFieldIdEnum, FieldMetaData> e : FieldMetaData.getStructMetaDataMap(tClass).entrySet()) {
        FieldMetaData meta = e.getValue();
        FieldValueMetaData field = e.getValue().valueMetaData;
        MetaData fm = new MetaData(field);
        if (fm.isStruct()) {
          schema.add(new FieldSchema(meta.fieldName, toSchema(fm.getStructClass()), DataType.TUPLE));
        } else if (fm.isEnum()) { // enums in Structs are strings (enums in containers are not, yet)
          schema.add(new FieldSchema(meta.fieldName, null, DataType.CHARARRAY));
        } else {
          schema.add(singleFieldToFieldSchema(meta.fieldName, field));
        }
      }
    } catch (FrontendException t) {
      throw new RuntimeException(t);
    }

    return schema;
  }

  private static FieldSchema singleFieldToFieldSchema(String fieldName, FieldValueMetaData field) throws FrontendException {

    MetaData fm = new MetaData(field);

    switch (field.type) {
      case TType.LIST:
        return new FieldSchema(fieldName, singleFieldToTupleSchema(fieldName + "_tuple", fm.getListElem()), DataType.BAG);
      case TType.SET:
        return new FieldSchema(fieldName, singleFieldToTupleSchema(fieldName + "_tuple", fm.getSetElem()), DataType.BAG);
      case TType.MAP:
        // can not specify types for maps in Pig.
        return new FieldSchema(fieldName, null, DataType.MAP);
      default:
        return new FieldSchema(fieldName, null, getPigDataType(field));
    }
  }

  /**
   * Returns a schema with single tuple (for Pig bags).
   */
  private static Schema singleFieldToTupleSchema(String fieldName, FieldValueMetaData field) throws FrontendException {
    MetaData fm = new MetaData(field);
    FieldSchema fieldSchema = null;

    switch (field.type) {
      case TType.STRUCT:
        fieldSchema = new FieldSchema(fieldName, toSchema(fm.getStructClass()), DataType.TUPLE);
        break;
      case TType.LIST:
        fieldSchema = singleFieldToFieldSchema(fieldName, fm.getListElem());
        break;
      case TType.SET:
        fieldSchema = singleFieldToFieldSchema(fieldName, fm.getSetElem());
        break;
      default:
        fieldSchema = new FieldSchema(fieldName, null, getPigDataType(fm.getField()));
    }

    Schema schema = new Schema();
    schema.add(fieldSchema);
    return schema;
  }

  private static byte getPigDataType(FieldValueMetaData field) {
    switch (field.type) {
      case TType.BOOL:
      case TType.BYTE:
      case TType.I16:
      case TType.I32:
      case TType.ENUM: // will revisit this once Enums in containers are also strings.
        return DataType.INTEGER;
      case TType.I64:
        return DataType.LONG;
      case TType.STRING:
        return DataType.CHARARRAY;
      default:
        throw new IllegalArgumentException("Unexpected type where a simple type is expected : " + field.type);
    }
  }

  /**
   * Turn a Thrift Struct into a loading schema for a pig script.
   */
  public static String toPigScript(Class<? extends TBase<?>> thriftClass,
                                   Class<? extends LoadFunc> pigLoader) {
    StringBuilder sb = new StringBuilder();
    /* we are commenting out explicit schema specification. The schema is 
     * included mainly to help the readers of the pig script. Pig learns the 
     * schema directly from the loader. 
     * If explicit schema is not commented, we might have surprising results
     * when a Thrift class (possibly in control of another team) changes, 
     * but the Pig script is not updated. Commenting it out work around this. 
     */
    StringBuilder prefix = new StringBuilder("       --  ");
    sb.append("raw_data = load '$INPUT_FILES' using ")
      .append(pigLoader.getName())
      .append("('")
      .append(thriftClass.getName())
      .append("');\n")
      .append(prefix)
      .append("as ");
    prefix.append("   ");

    try {
      stringifySchema(sb, toSchema(thriftClass), DataType.TUPLE, prefix);
    } catch (FrontendException e) {
      throw new RuntimeException(e);
    }

    sb.append("\n");
    return sb.toString();
  }

  /**
   * Print formatted schema. This is a modified version of
   * {@link Schema#stringifySchema(StringBuilder, Schema, byte)}
   * with support for (indented) pretty printing.
   */
  // This is used for building up output string
  // type can only be BAG or TUPLE
  public static void stringifySchema(StringBuilder sb,
                                     Schema schema,
                                     byte type,
                                     StringBuilder prefix)
                                          throws FrontendException{
      // this is a modified version of {@link Schema#stringifySchema(StringBuilder, Schema, byte)}
      if (type == DataType.TUPLE) {
          sb.append("(") ;
      }
      else if (type == DataType.BAG) {
          sb.append("{") ;
      }

      prefix.append("  ");
      sb.append("\n").append(prefix);

      if (schema == null) {
          sb.append("null") ;
      }
      else {
          boolean isFirst = true ;
          for (int i=0; i< schema.size() ;i++) {

              if (!isFirst) {
                  sb.append(",\n").append(prefix);
              }
              else {
                  isFirst = false ;
              }

              FieldSchema fs = schema.getField(i) ;

              if(fs == null) {
                  sb.append("null");
                  continue;
              }

              if (fs.alias != null) {
                  sb.append(fs.alias);
                  sb.append(": ");
              }

              if (DataType.isAtomic(fs.type)) {
                  sb.append(DataType.findTypeName(fs.type)) ;
              }
              else if ( (fs.type == DataType.TUPLE) ||
                        (fs.type == DataType.BAG) ) {
                  // safety net
                  if (schema != fs.schema) {
                      stringifySchema(sb, fs.schema, fs.type, prefix) ;
                  }
                  else {
                      throw new AssertionError("Schema refers to itself "
                                               + "as inner schema") ;
                  }
              } else if (fs.type == DataType.MAP) {
                  sb.append(DataType.findTypeName(fs.type) + "[ ]") ;
              } else {
                  sb.append(DataType.findTypeName(fs.type)) ;
              }
          }
      }

      prefix.setLength(prefix.length()-2);
      sb.append("\n").append(prefix);

      if (type == DataType.TUPLE) {
          sb.append(")") ;
      }
      else if (type == DataType.BAG) {
          sb.append("}") ;
      }
  }


  private class TProtoForStruct extends ThriftProtocol {
    // essentially a hack to get to STRUCT_DESC in a Thrift class
    TStruct structDesc;
    public void writeStructBegin(TStruct struct) throws TException {
      structDesc = struct;
      throw new TException("expected");
    }
  }

  private TStruct getStructDesc(Class<? extends TBase<?>> tClass) {
    // hack to get hold of STRUCT_DESC of a thrift class :
    // writeStructBegin() uses this descriptor.
    TProtoForStruct proto = new TProtoForStruct();
    try {
      tClass.newInstance().write(proto);
    } catch (TException e) {
    } catch (Throwable t) {
      throw new RuntimeException(t);
    }
    return proto.structDesc;
  }

  public static void main(String[] args) throws Exception {
    if (args.length > 0) {
      Class<? extends TBase<?>> tClass = ThriftUtils.getTypeRef(args[0]).getRawClass();
      System.out.println(args[0] + " : " + toSchema(tClass).toString());
      System.out.println(toPigScript(tClass, LzoThriftB64LinePigLoader.class));
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/piggybank/BytesToThriftTuple.java;<<<<<<< MINE
private final ThriftToTuple<T> thriftToTuple_ = new ThriftToTuple<T>();
=======
  private ThriftToPig<T> thriftToTuple_;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/piggybank/BytesToThriftTuple.java;<<<<<<< MINE
  private T thriftObj_ = null;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/piggybank/BytesToThriftTuple.java;<<<<<<< MINE
=======
    thriftToTuple_ = ThriftToPig.newInstance(typeRef);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/piggybank/BytesToThriftTuple.java;<<<<<<< MINE
      if (thriftObj_ == null) {
        thriftObj_ = typeRef_.safeNewInstance();
      }
=======
      T tObj = typeRef_.safeNewInstance();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/java/com/twitter/elephantbird/pig/piggybank/BytesToThriftTuple.java;<<<<<<< MINE
      deserializer_.deserialize(thriftObj_, dbarr.get());
      return thriftToTuple_.convert(thriftObj_);
=======
      deserializer_.deserialize(tObj, dbarr.get());
      return thriftToTuple_.getPigTuple(tObj);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
import static org.junit.Assert.assertTrue;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
=======
import org.apache.pig.data.Tuple;
import org.apache.thrift.TBase;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
import org.apache.thrift.transport.TMemoryBuffer;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
=======
import com.twitter.data.proto.tutorial.thrift.PhoneNumber;
import com.twitter.data.proto.tutorial.thrift.PhoneType;
import com.twitter.elephantbird.util.TypeRef;

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
=======
  static <M extends TBase<?>> Tuple toTuple(M obj) throws TException {
    // it is very inefficient to create one ThriftToPig for each Thrift object,
    // but good enough for unit testing.
    return ThriftToPig.newInstance(new TypeRef<M>(obj.getClass()){}).getPigTuple(obj);
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
    TMemoryBuffer buffer = new TMemoryBuffer(1024);
    ThriftToPigProtocol proto = new ThriftToPigProtocol(buffer);
=======
    assertEquals(
        "1-0-35-27000-16777216-6000000000-3.141592653589793-JSON THIS! \"-"+ooe.zomg_unicode+"-0-base64-{(1),(2),(3)}-{(1),(2),(3)}-{(1L),(2L),(3L)}",
        toTuple(ooe).toDelimitedString("-"));

    assertEquals("(31337,I am a bonk... xor!)-(1,0,35,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \","+n.my_ooe.zomg_unicode+",0,base64,{(1),(2),(3)},{(1),(2),(3)},{(1L),(2L),(3L)})",
        toTuple(n).toDelimitedString("-"));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
    ooe.write(proto);
=======
    assertEquals("{(1,0,34,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \"," + ooe.zomg_unicode +
        ",0,base64,{(1),(2),(3)},{(1),(2),(3)},{(1L),(2L),(3L)}),(1,0,35,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \"," +
        ooe.zomg_unicode + ",0,base64,{(1),(2),(3)},{(1),(2),(3)},{(1L),(2L),(3L)})}-{({}),({(then a one, two),(three!),(FOUR!!)}),({(and a one),(and a two)})}-{zero={}, three={}, two={(1,Wait.),(2,What?)}}",
        (toTuple(hm).toDelimitedString("-")));

    // Test null fields :
    OneOfEach mostly_ooe = new OneOfEach(ooe);
    mostly_ooe.setBase64(null);
    mostly_ooe.setI16_list(null);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
       "1-0-35-27000-16777216-6000000000-3.141592653589793-JSON THIS! \"-"+ooe.zomg_unicode+"-0-base64-(1,2,3)-(1,2,3)-(1L,2L,3L)",
        proto.getPigTuple().toDelimitedString("-"));
=======
        "1-0-35-27000-16777216-6000000000-3.141592653589793-JSON THIS! \"-"+ooe.zomg_unicode+"-0--{(1),(2),(3)}--{(1L),(2L),(3L)}",
        toTuple(mostly_ooe).toDelimitedString("-"));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
    n.write(proto);
    assertEquals("(31337,I am a bonk... xor!)-(1,0,35,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \","+n.my_ooe.zomg_unicode+",0,base64,(1,2,3),(1,2,3),(1L,2L,3L))",
        proto.getPigTuple().toDelimitedString("-"));

    hm.write(proto);
    assertEquals("((1,0,34,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \"," + ooe.zomg_unicode +
        ",0,base64,(1,2,3),(1,2,3),(1L,2L,3L)),(1,0,35,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \"," +
        ooe.zomg_unicode + ",0,base64,(1,2,3),(1,2,3),(1L,2L,3L)))-{(),(then a one, two,three!,FOUR!!),(and a one,and a two)}-{zero=(), three=(), two=((1,Wait.),(2,What?))}",
        (proto.getPigTuple().toDelimitedString("-")));
=======
    Nesting n2 = new Nesting(n);
    n2.getMy_bonk().setMessage(null);
    n2.setMy_ooe(mostly_ooe);
    assertEquals("(31337,)-(1,0,35,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \","+n.my_ooe.zomg_unicode+",0,,{(1),(2),(3)},,{(1L),(2L),(3L)})",
        toTuple(n2).toDelimitedString("-"));

    // test enum.
    PhoneNumber ph = new PhoneNumber();
    ph.setNumber("415-555-5555");
    ph.setType(PhoneType.HOME);
    assertEquals("415-555-5555,HOME", toTuple(ph).toDelimitedString(","));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
    assertTrue(true);
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8eed34e_cebd3d0/rev_8eed34e-cebd3d0/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/java/com/twitter/elephantbird/examples/ProtobufMRExample.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.examples;

import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

import com.twitter.elephantbird.examples.proto.Examples.Age;
import com.twitter.elephantbird.mapreduce.input.LzoProtobufB64LineInputFormat;
import com.twitter.elephantbird.mapreduce.input.LzoProtobufBlockInputFormat;
import com.twitter.elephantbird.mapreduce.io.ProtobufWritable;
import com.twitter.elephantbird.mapreduce.output.LzoProtobufB64LineOutputFormat;
import com.twitter.elephantbird.mapreduce.output.LzoProtobufBlockOutputFormat;

/**
 * -Dproto.test=lzoOut : takes text files with name and age on each line as
 * input and writes to lzo file with Protobuf serilized data. <br>
 * -Dproto.test=lzoIn : does the reverse. <br><br>
 *
 * -Dproto.test.format=Block (or B64Line) to test different formats. <br>
 */

public class ProtobufMRExample {
  // This is intentionally very similar to ThriftMRExample.

  private ProtobufMRExample() {}

  public static class TextMapper extends Mapper<LongWritable, Text, NullWritable, ProtobufWritable<Age>> {
    ProtobufWritable<Age> protoWritable = ProtobufWritable.newInstance(Age.class);

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
      StringTokenizer line = new StringTokenizer(value.toString(), "\t\r\n");
      String name;

      if (line.hasMoreTokens()
          && (name = line.nextToken()) != null
          && line.hasMoreTokens()) {
          protoWritable.set(Age.newBuilder()
                              .setName(name)
                              .setAge(Integer.parseInt(line.nextToken()))
                              .build());
          context.write(null, protoWritable);
      }
    }
  }

  public int runTextToLzo(String[] args, Configuration conf) throws Exception {
    Job job = new Job(conf);
    job.setJobName("Protobuf Example : Text to LzoB64Line");

    job.setJarByClass(getClass());
    job.setMapperClass(TextMapper.class);
    job.setNumReduceTasks(0);

    job.setInputFormatClass(TextInputFormat.class);
    if (conf.get("proto.test.format", "B64Line").equals("Block")) {
      job.setOutputFormatClass(LzoProtobufBlockOutputFormat.getOutputFormatClass(Age.class, job.getConfiguration()));
    } else { // assume B64Line
      job.setOutputFormatClass(LzoProtobufB64LineOutputFormat.getOutputFormatClass(Age.class, job.getConfiguration()));
    }

    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));

    return job.waitForCompletion(true) ? 0 : 1;
  }

  public static class LzoMapper extends Mapper<LongWritable, ProtobufWritable<Age>, Text, Text> {
    @Override
    protected void map(LongWritable key, ProtobufWritable<Age> value, Context context) throws IOException, InterruptedException {
      Age age = value.get();
      System.err.println("XXXXXXXXX got here!!");
      context.write(null, new Text(age.getName() + "\t" + age.getAge()));
    }
  }

  public int runLzoToText(String[] args, Configuration conf) throws Exception {
    Job job = new Job(conf);
    job.setJobName("Protobuf Example : LzoB64Line to Text");

    job.setJarByClass(getClass());
    job.setMapperClass(LzoMapper.class);
    job.setNumReduceTasks(0);

    if (conf.get("proto.test.format", "B64Line").equals("Block")) {
      job.setInputFormatClass(LzoProtobufBlockInputFormat.getInputFormatClass(Age.class, job.getConfiguration()));
    } else {
      job.setInputFormatClass(LzoProtobufB64LineInputFormat.getInputFormatClass(Age.class, job.getConfiguration()));
    }
    job.setOutputFormatClass(TextOutputFormat.class);

    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));

    return job.waitForCompletion(true) ? 0 : 1;
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    args = new GenericOptionsParser(conf, args).getRemainingArgs();
    ProtobufMRExample runner = new ProtobufMRExample();

    if (args.length != 2) {
      System.out.println("Usage: hadoop jar path/to/this.jar " + runner.getClass() + " <input dir> <output dir>");
      System.exit(1);
    }

    String test = conf.get("proto.test", "lzoIn");

    if (test.equals("lzoIn"))
      System.exit(runner.runLzoToText(args, conf));
    if (test.equals("lzoOut"))
      System.exit(runner.runTextToLzo(args, conf));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoAddressBookProtobufBlockOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufAddressBookWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoAddressBookProtobufBlockOutputFormat.java;<<<<<<< MINE
public class LzoAddressBookProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<AddressBook, ProtobufAddressBookWritable> {
=======
public class LzoAddressBookProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<AddressBook> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoAddressBookProtobufB64LineOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufAddressBookWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoAddressBookProtobufB64LineOutputFormat.java;<<<<<<< MINE
public class LzoAddressBookProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<AddressBook, ProtobufAddressBookWritable> {
=======
public class LzoAddressBookProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<AddressBook> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoPersonProtobufBlockOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufPersonWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoPersonProtobufBlockOutputFormat.java;<<<<<<< MINE
public class LzoPersonProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<Person, ProtobufPersonWritable> {
=======
public class LzoPersonProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<Person> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoPersonProtobufB64LineOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufPersonWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoPersonProtobufB64LineOutputFormat.java;<<<<<<< MINE
public class LzoPersonProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<Person, ProtobufPersonWritable> {
=======
public class LzoPersonProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<Person> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufBlockInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufPersonWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufBlockInputFormat.java;<<<<<<< MINE
public class LzoPersonProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<Person, ProtobufPersonWritable> {
=======
public class LzoPersonProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<Person> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufBlockInputFormat.java;<<<<<<< MINE
    setProtobufWritable(new ProtobufPersonWritable());
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufB64LineInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufAddressBookWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufB64LineInputFormat.java;<<<<<<< MINE
public class LzoAddressBookProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<AddressBook, ProtobufAddressBookWritable> {
=======
public class LzoAddressBookProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<AddressBook> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufB64LineInputFormat.java;<<<<<<< MINE
    setProtobufWritable(new ProtobufAddressBookWritable());
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufB64LineInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufPersonWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufB64LineInputFormat.java;<<<<<<< MINE
public class LzoPersonProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<Person, ProtobufPersonWritable> {
=======
public class LzoPersonProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<Person> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufB64LineInputFormat.java;<<<<<<< MINE
    setProtobufWritable(new ProtobufPersonWritable());
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufBlockInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufAddressBookWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufBlockInputFormat.java;<<<<<<< MINE
public class LzoAddressBookProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<AddressBook, ProtobufAddressBookWritable> {
=======
public class LzoAddressBookProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<AddressBook> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufBlockInputFormat.java;<<<<<<< MINE
    setProtobufWritable(new ProtobufAddressBookWritable());
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/examples/src/gen-java/com/twitter/elephantbird/examples/proto/Examples.java;<<<<<<< MINE
=======
// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: examples.proto

package com.twitter.elephantbird.examples.proto;

public final class Examples {
  private Examples() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public static final class Age extends
      com.google.protobuf.GeneratedMessage {
    // Use Age.newBuilder() to construct.
    private Age() {
      initFields();
    }
    private Age(boolean noInit) {}
    
    private static final Age defaultInstance;
    public static Age getDefaultInstance() {
      return defaultInstance;
    }
    
    public Age getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.twitter.elephantbird.examples.proto.Examples.internal_static_com_twitter_elephantbird_examples_proto_Age_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.twitter.elephantbird.examples.proto.Examples.internal_static_com_twitter_elephantbird_examples_proto_Age_fieldAccessorTable;
    }
    
    // optional string name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private boolean hasName;
    private java.lang.String name_ = "";
    public boolean hasName() { return hasName; }
    public java.lang.String getName() { return name_; }
    
    // optional int32 age = 2;
    public static final int AGE_FIELD_NUMBER = 2;
    private boolean hasAge;
    private int age_ = 0;
    public boolean hasAge() { return hasAge; }
    public int getAge() { return age_; }
    
    private void initFields() {
    }
    public final boolean isInitialized() {
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (hasName()) {
        output.writeString(1, getName());
      }
      if (hasAge()) {
        output.writeInt32(2, getAge());
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (hasName()) {
        size += com.google.protobuf.CodedOutputStream
          .computeStringSize(1, getName());
      }
      if (hasAge()) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, getAge());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(com.twitter.elephantbird.examples.proto.Examples.Age prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder> {
      private com.twitter.elephantbird.examples.proto.Examples.Age result;
      
      // Construct using com.twitter.elephantbird.examples.proto.Examples.Age.newBuilder()
      private Builder() {}
      
      private static Builder create() {
        Builder builder = new Builder();
        builder.result = new com.twitter.elephantbird.examples.proto.Examples.Age();
        return builder;
      }
      
      protected com.twitter.elephantbird.examples.proto.Examples.Age internalGetResult() {
        return result;
      }
      
      public Builder clear() {
        if (result == null) {
          throw new IllegalStateException(
            "Cannot call clear() after build().");
        }
        result = new com.twitter.elephantbird.examples.proto.Examples.Age();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(result);
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.twitter.elephantbird.examples.proto.Examples.Age.getDescriptor();
      }
      
      public com.twitter.elephantbird.examples.proto.Examples.Age getDefaultInstanceForType() {
        return com.twitter.elephantbird.examples.proto.Examples.Age.getDefaultInstance();
      }
      
      public boolean isInitialized() {
        return result.isInitialized();
      }
      public com.twitter.elephantbird.examples.proto.Examples.Age build() {
        if (result != null && !isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return buildPartial();
      }
      
      private com.twitter.elephantbird.examples.proto.Examples.Age buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        if (!isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return buildPartial();
      }
      
      public com.twitter.elephantbird.examples.proto.Examples.Age buildPartial() {
        if (result == null) {
          throw new IllegalStateException(
            "build() has already been called on this Builder.");
        }
        com.twitter.elephantbird.examples.proto.Examples.Age returnMe = result;
        result = null;
        return returnMe;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.twitter.elephantbird.examples.proto.Examples.Age) {
          return mergeFrom((com.twitter.elephantbird.examples.proto.Examples.Age)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(com.twitter.elephantbird.examples.proto.Examples.Age other) {
        if (other == com.twitter.elephantbird.examples.proto.Examples.Age.getDefaultInstance()) return this;
        if (other.hasName()) {
          setName(other.getName());
        }
        if (other.hasAge()) {
          setAge(other.getAge());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                return this;
              }
              break;
            }
            case 10: {
              setName(input.readString());
              break;
            }
            case 16: {
              setAge(input.readInt32());
              break;
            }
          }
        }
      }
      
      
      // optional string name = 1;
      public boolean hasName() {
        return result.hasName();
      }
      public java.lang.String getName() {
        return result.getName();
      }
      public Builder setName(java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  result.hasName = true;
        result.name_ = value;
        return this;
      }
      public Builder clearName() {
        result.hasName = false;
        result.name_ = getDefaultInstance().getName();
        return this;
      }
      
      // optional int32 age = 2;
      public boolean hasAge() {
        return result.hasAge();
      }
      public int getAge() {
        return result.getAge();
      }
      public Builder setAge(int value) {
        result.hasAge = true;
        result.age_ = value;
        return this;
      }
      public Builder clearAge() {
        result.hasAge = false;
        result.age_ = 0;
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:com.twitter.elephantbird.examples.proto.Age)
    }
    
    static {
      defaultInstance = new Age(true);
      com.twitter.elephantbird.examples.proto.Examples.internalForceInit();
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:com.twitter.elephantbird.examples.proto.Age)
  }
  
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_com_twitter_elephantbird_examples_proto_Age_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_com_twitter_elephantbird_examples_proto_Age_fieldAccessorTable;
  
  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\016examples.proto\022\'com.twitter.elephantbi" +
      "rd.examples.proto\" \n\003Age\022\014\n\004name\030\001 \001(\t\022\013" +
      "\n\003age\030\002 \001(\005B\nB\010Examples"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_com_twitter_elephantbird_examples_proto_Age_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_com_twitter_elephantbird_examples_proto_Age_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_com_twitter_elephantbird_examples_proto_Age_descriptor,
              new java.lang.String[] { "Name", "Age", },
              com.twitter.elephantbird.examples.proto.Examples.Age.class,
              com.twitter.elephantbird.examples.proto.Examples.Age.Builder.class);
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        }, assigner);
  }
  
  public static void internalForceInit() {}
  
  // @@protoc_insertion_point(outer_class_scope)
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
=======
  private static final String CLASS_CONF_PREFIX = "elephantbird.protobuf.class.for.";

  /**
   * Returns Protobuf class. The class name could be either normal name or
   * its canonical name (canonical name does not have a $ for inner classes).
   */
  public static Class<? extends Message> getProtobufClass(String protoClassName) {
    return getProtobufClass(null, protoClassName);
  }

  private static Class<? extends Message> getProtobufClass(Configuration conf, String protoClassName) {
    // Try both normal name and canonical name of the class.
    Class<?> protoClass = null;
    try {
      if (conf == null) {
        protoClass = Class.forName(protoClassName);
      } else {
        protoClass = conf.getClassByName(protoClassName);
      }
    } catch (ClassNotFoundException e) {
      // the class name might be canonical name.
      protoClass = getInnerProtobufClass(protoClassName);
    }

    return protoClass.asSubclass(Message.class);
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
  
  /**
   * Creates a Function to repeatedly convert byte arrays into Messages. Using such a function
   * is more efficient than the static <code>parseFrom</code> method, since it avoids some of the
   * reflection overhead of the static function.
   */
  public static <M extends Message> Function<byte[], M> getProtoConverter(final Class<M> protoClass) {
    //XXX Remove this.
    return new Function<byte[], M>() {
      private Message.Builder protoBuilder = null; 
      
      @SuppressWarnings("unchecked")
      @Override
      public M apply(byte[] bytes) {
        try {
          if (protoBuilder == null) {
            protoBuilder = Protobufs.getMessageBuilder(protoClass);
          }
          return  (M) protoBuilder.clone().mergeFrom(bytes).build();
        } catch (InvalidProtocolBufferException e) {
          LOG.error("Invalid Protocol Buffer exception building " + protoClass.getName(), e);
          return null;
        } catch(UninitializedMessageException ume) {
	  LOG.error("Uninitialized Message Exception in building " + protoClass.getName(), ume);
	  return null;
        }
      }
    };
  }
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
=======

  /**
   * Returns typeref for a Protobuf class
   */
  public static<M extends Message> TypeRef<M> getTypeRef(String protoClassName) {
    return new TypeRef<M>(getProtobufClass(protoClassName)){};
  }

  /**
   * Returns TypeRef for the Protobuf class that was set using setClass(jobConf);
   */
  public static<M extends Message> TypeRef<M> getTypeRef(Configuration jobConf, Class<?> genericClass) {
    String className = jobConf.get(CLASS_CONF_PREFIX + genericClass.getName());
    if (className == null) {
      throw new RuntimeException(CLASS_CONF_PREFIX + genericClass.getName() + " is not set");
    }
    return new TypeRef<M>(getProtobufClass(jobConf, className)){};
  }

  public static void setClassConf(Configuration jobConf, Class<?> genericClass,
      Class<? extends Message> protoClass) {
    jobConf.set(CLASS_CONF_PREFIX + genericClass.getName(), protoClass.getName());
  }
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.util.Protobufs;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
 * This is the base class for all blocked protocol buffer based output formats.  See
 * the ProtobufBlockWriter class for the on-disk format. It has two template
 * parameters, the protobuf and the writable for that protobuf.  This class cannot be instantiated
 * directly as an input format because Hadoop works via reflection, and Java type erasure makes it
 * impossible to instantiate a templatized class via reflection with the correct template parameter.
 * Instead, we codegen derived output format classes for any given protobuf which instantiate the
 * template parameter directly, as well as set the typeRef argument so that the template
 * parameter can be remembered.  See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
=======
 * Class for all blocked protocol buffer based output formats.  See
 * the ProtobufBlockWriter class for the on-disk format. <br><br>
 *
 * Do not use LzoProtobufBlockOutputFormat.class directly for setting
 * OutputFormat class for a job. Use getOutputFormatClass() instead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
public abstract class LzoProtobufBlockOutputFormat<M extends Message, W extends ProtobufWritable<M>>
    extends LzoOutputFormat<M, W> {
=======
public class LzoProtobufBlockOutputFormat<M extends Message> extends LzoOutputFormat<M, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
  public RecordWriter<NullWritable, W> getRecordWriter(TaskAttemptContext job)
=======
  public LzoProtobufBlockOutputFormat() {}

  /**
   * Returns {@link LzoProtobufB64LineOutputFormat} class.
   * Sets an internal configuration in jobConf so that remote Tasks
   * instantiate appropriate object for this generic class based on protoClass
   */
  @SuppressWarnings("unchecked")
  public static <M extends Message> Class<LzoProtobufBlockOutputFormat>
     getOutputFormatClass(Class<M> protoClass, Configuration jobConf) {

    Protobufs.setClassConf(jobConf, LzoProtobufBlockOutputFormat.class, protoClass);
    return LzoProtobufBlockOutputFormat.class;
  }

  public RecordWriter<NullWritable, ProtobufWritable<M>> getRecordWriter(TaskAttemptContext job)
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
    return new LzoBinaryBlockRecordWriter<M, W>(
=======
    if (typeRef_ == null) { // i.e. if not set by a subclass
      typeRef_ = Protobufs.getTypeRef(job.getConfiguration(), LzoProtobufBlockOutputFormat.class);
    }

    return new LzoBinaryBlockRecordWriter<M, ProtobufWritable<M>>(
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapreduce.input.LzoProtobufBlockInputFormat;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.util.Protobufs;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
 * This is the base class for all base64 encoded, line-oriented protocol buffer based output formats.
 * Data is written as one base64 encoded serialized protocol buffer per line. It has two template
 * parameters, the protobuf and the writable for that protobuf.  This class cannot be instantiated
 * directly as an input format because Hadoop works via reflection, and Java type erasure makes it
 * impossible to instantiate a templatized class via reflection with the correct template parameter.
 * Instead, we codegen derived output format classes for any given protobuf which instantiate the
 * template parameter directly, as well as set the typeRef argument so that the template
 * parameter can be remembered.  See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
=======
 * This is the class for all base64 encoded, line-oriented protocol buffer based output formats.
 * Data is written as one base64 encoded serialized protocol buffer per line.<br><br>
 *
 * Do not use LzoProtobufB64LineOutputFormat.class directly for setting
 * OutputFormat class for a job. Use getOutputFormatClass() in stead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
public abstract class LzoProtobufB64LineOutputFormat<M extends Message, W extends ProtobufWritable<M>>
    extends LzoOutputFormat<M, W> {
=======
public class LzoProtobufB64LineOutputFormat<M extends Message> extends LzoOutputFormat<M, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
  public RecordWriter<NullWritable, W> getRecordWriter(TaskAttemptContext job)
=======
  public LzoProtobufB64LineOutputFormat() {}

  /**
   * Returns {@link LzoProtobufBlockOutputFormat} class.
   * Sets an internal configuration in jobConf so that remote Tasks
   * instantiate appropriate object for this generic class based on protoClass
   */
  @SuppressWarnings("unchecked")
  public static <M extends Message> Class<LzoProtobufB64LineOutputFormat>
     getOutputFormatClass(Class<M> protoClass, Configuration jobConf) {

    Protobufs.setClassConf(jobConf, LzoProtobufB64LineOutputFormat.class, protoClass);
    return LzoProtobufB64LineOutputFormat.class;
  }


  public RecordWriter<NullWritable, ProtobufWritable<M>> getRecordWriter(TaskAttemptContext job)
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
    return new LzoBinaryB64LineRecordWriter<M, W>(new ProtobufConverter<M>(typeRef_), getOutputStream(job));
=======
    if (typeRef_ == null) {
      typeRef_ = Protobufs.getTypeRef(job.getConfiguration(), LzoProtobufB64LineOutputFormat.class);
    }

    return new LzoBinaryB64LineRecordWriter<M, ProtobufWritable<M>>(ProtobufConverter.newInstance(typeRef_), getOutputStream(job));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.util.Protobufs;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
 * Data is expected to be one base64 encoded serialized protocol buffer per line. It has two template
 * parameters, the protobuf and the writable for that protobuf.  This class cannot be instantiated
 * directly as an input format because Hadoop works via reflection, and Java type erasure makes it
 * impossible to instantiate a templatized class via reflection with the correct template parameter.
 * Instead, we codegen derived input format classes for any given protobuf which instantiate the
 * template parameter directly, as well as set the typeRef argument so that the template
 * parameter can be remembered.  See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
=======
 * Data is expected to be one base64 encoded serialized protocol buffer per line.
 * <br><br>
 *
 * Do not use LzoProtobufB64LineInputFormat.class directly for setting
 * InputFormat class for a job. Use getInputFormatClass() instead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
public abstract class LzoProtobufB64LineInputFormat<M extends Message, W extends ProtobufWritable<M>> extends LzoInputFormat<LongWritable, W> {
=======
public class LzoProtobufB64LineInputFormat<M extends Message> extends LzoInputFormat<LongWritable, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
  private W protobufWritable_;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
=======
  // should remove this.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
  protected void setProtobufWritable(W protobufWritable) {
    protobufWritable_ = protobufWritable;
=======
  /**
   * Returns {@link LzoProtobufB64LineInputFormat} class.
   * Sets an internal configuration in jobConf so that remote Tasks
   * instantiate appropriate object based on protoClass.
   */
  @SuppressWarnings("unchecked")
  public static <M extends Message> Class<LzoProtobufB64LineInputFormat>
     getInputFormatClass(Class<M> protoClass, Configuration jobConf) {
    Protobufs.setClassConf(jobConf, LzoProtobufB64LineInputFormat.class, protoClass);
    return LzoProtobufB64LineInputFormat.class;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
  public RecordReader<LongWritable, W> createRecordReader(InputSplit split,
=======
  public RecordReader<LongWritable, ProtobufWritable<M>> createRecordReader(InputSplit split,
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE

    return new LzoProtobufB64LineRecordReader<M, W>(typeRef_, protobufWritable_);
=======
    if (typeRef_ == null) {
      typeRef_ = Protobufs.getTypeRef(taskAttempt.getConfiguration(), LzoProtobufB64LineInputFormat.class);
    }
    return new LzoProtobufB64LineRecordReader<M>(typeRef_);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.util.Protobufs;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
 * the ProtobufBlockWriter to write your data, this input format can read it. It has two template
 * parameters, the protobuf and the writable for that protobuf.  This class cannot be instantiated
 * directly as an input format because Hadoop works via reflection, and Java type erasure makes it
 * impossible to instantiate a templatized class via reflection with the correct template parameter.
 * Instead, we codegen derived input format classes for any given protobuf which instantiate the
 * template parameter directly, as well as set the typeRef argument so that the template
 * parameter can be remembered.  See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
=======
 * the ProtobufBlockWriter to write your data, this input format can read it.
 * <br> <br>
 *
 * Do not use LzoProtobufBlockInputFormat.class directly for setting
 * InputFormat class for a job. Use getInputFormatClass() instead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
public abstract class LzoProtobufBlockInputFormat<M extends Message, W extends ProtobufWritable<M>> extends LzoInputFormat<LongWritable, W> {
=======
public class LzoProtobufBlockInputFormat<M extends Message> extends LzoInputFormat<LongWritable, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
  private W protobufWritable_;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
  protected void setProtobufWritable(W protobufWritable) {
    protobufWritable_ = protobufWritable;
=======
  /**
   * Returns {@link LzoProtobufBlockInputFormat} class.
   * Sets an internal configuration in jobConf so that remote Tasks
   * instantiate appropriate object based on protoClass.
   */
  @SuppressWarnings("unchecked")
  public static <M extends Message> Class<LzoProtobufBlockInputFormat>
     getInputFormatClass(Class<M> protoClass, Configuration jobConf) {
    Protobufs.setClassConf(jobConf, LzoProtobufBlockInputFormat.class, protoClass);
    return LzoProtobufBlockInputFormat.class;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
  public RecordReader<LongWritable, W> createRecordReader(InputSplit split,
=======
  public RecordReader<LongWritable, ProtobufWritable<M>> createRecordReader(InputSplit split,
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE

    return new LzoProtobufBlockRecordReader<M, W>(typeRef_, protobufWritable_);
=======
    if (typeRef_ == null) {
      typeRef_ = Protobufs.getTypeRef(taskAttempt.getConfiguration(), LzoProtobufBlockInputFormat.class);
    }
    return new LzoProtobufBlockRecordReader<M>(typeRef_);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE
public class LzoProtobufBlockRecordReader<M extends Message, W extends ProtobufWritable<M>> extends LzoBinaryBlockRecordReader<M, W> {
=======
public class LzoProtobufBlockRecordReader<M extends Message> extends LzoBinaryBlockRecordReader<M, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE
  public LzoProtobufBlockRecordReader(TypeRef<M> typeRef, W protobufWritable) {
=======
  public LzoProtobufBlockRecordReader(TypeRef<M> typeRef) {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE
    super(typeRef, new ProtobufBlockReader<M>(null, typeRef), protobufWritable);
=======
    super(typeRef, new ProtobufBlockReader<M>(null, typeRef), new ProtobufWritable<M>(typeRef));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
public class  LzoProtobufB64LineRecordReader<M extends Message, W extends ProtobufWritable<M>> extends LzoBinaryB64LineRecordReader<M, W> {
=======
public class  LzoProtobufB64LineRecordReader<M extends Message> extends LzoBinaryB64LineRecordReader<M, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
  public LzoProtobufB64LineRecordReader(TypeRef<M> typeRef, W protobufWritable) {
    super(typeRef, protobufWritable, new ProtobufConverter<M>(typeRef));
=======
  public LzoProtobufB64LineRecordReader(TypeRef<M> typeRef) {
    super(typeRef, new ProtobufWritable<M>(typeRef), ProtobufConverter.newInstance(typeRef));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufWritable.java;<<<<<<< MINE
=======

  /**
   * Returns a ThriftWritable for a given Thrift class.
   */
  public static <M extends Message> ProtobufWritable<M> newInstance(Class<M> tClass) {
    return new ProtobufWritable<M>(new TypeRef<M>(tClass){});
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
    super(out, protoClass, new ProtobufConverter<M>(new TypeRef<M>(protoClass){}), DEFAULT_NUM_RECORDS_PER_BLOCK);
=======
    super(out, protoClass, ProtobufConverter.newInstance(protoClass), DEFAULT_NUM_RECORDS_PER_BLOCK);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
    super(out, protoClass, new ProtobufConverter<M>(new TypeRef<M>(protoClass){}), numRecordsPerBlock);
=======
    super(out, protoClass, ProtobufConverter.newInstance(protoClass), numRecordsPerBlock);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufConverter.java;<<<<<<< MINE
=======

  /**
   * Returns a ProtobufConverter for a given Protobuf class.
   */
  public static <M extends Message> ProtobufConverter<M> newInstance(Class<M> protoClass) {
    return new ProtobufConverter<M>(new TypeRef<M>(protoClass){});
  }

  public static <M extends Message> ProtobufConverter<M> newInstance(TypeRef<M> typeRef) {
    return new ProtobufConverter<M>(typeRef);
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufConverter.java;<<<<<<< MINE
      LOG.error("Invalid Protocol Buffer exception building " + typeRef.getRawClass().getName(), e);
=======
      LOG.error("Invalid Protobuf exception while building " + typeRef.getRawClass().getName(), e);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufConverter.java;<<<<<<< MINE
      LOG.error("Uninitialized Message Exception in building " + typeRef.getRawClass().getName(), ume);
=======
      LOG.error("Uninitialized Message Exception while building " + typeRef.getRawClass().getName(), ume);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
    super(in, new ProtobufConverter<M>(typeRef));
=======
    super(in, ProtobufConverter.newInstance(typeRef));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockOutputFormatGenerator.java;<<<<<<< MINE
    sb.append("import %s.mapreduce.io.Protobuf%sWritable;", packageName_, descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockOutputFormatGenerator.java;<<<<<<< MINE
    sb.append("public class Lzo%sProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<%s, Protobuf%sWritable> {", descriptorProto_.getName(), descriptorProto_.getName(), descriptorProto_.getName()).endl();
=======
    sb.append("public class Lzo%sProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<%s> {", descriptorProto_.getName(), descriptorProto_.getName()).endl();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockInputFormatGenerator.java;<<<<<<< MINE
    sb.append("import %s.mapreduce.io.Protobuf%sWritable;", packageName_, descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockInputFormatGenerator.java;<<<<<<< MINE
    sb.append("public class Lzo%sProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<%s, Protobuf%sWritable> {", descriptorProto_.getName(), descriptorProto_.getName(), descriptorProto_.getName()).endl();
=======
    sb.append("public class Lzo%sProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<%s> {", descriptorProto_.getName(), descriptorProto_.getName()).endl();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockInputFormatGenerator.java;<<<<<<< MINE
    sb.append("    setProtobufWritable(new Protobuf%sWritable());", descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LineOutputFormatGenerator.java;<<<<<<< MINE
    sb.append("import %s.mapreduce.io.Protobuf%sWritable;", packageName_, descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LineOutputFormatGenerator.java;<<<<<<< MINE
    sb.append("public class Lzo%sProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<%s, Protobuf%sWritable> {", descriptorProto_.getName(), descriptorProto_.getName(), descriptorProto_.getName()).endl();
=======
    sb.append("public class Lzo%sProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<%s> {", descriptorProto_.getName(), descriptorProto_.getName()).endl();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LineInputFormatGenerator.java;<<<<<<< MINE
    sb.append("import %s.mapreduce.io.Protobuf%sWritable;", packageName_, descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LineInputFormatGenerator.java;<<<<<<< MINE
    sb.append("public class Lzo%sProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<%s, Protobuf%sWritable> {", descriptorProto_.getName(), descriptorProto_.getName(), descriptorProto_.getName()).endl();
=======
    sb.append("public class Lzo%sProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<%s> {", descriptorProto_.getName(), descriptorProto_.getName()).endl();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LineInputFormatGenerator.java;<<<<<<< MINE
    sb.append("    setProtobufWritable(new Protobuf%sWritable());", descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
=======
  public LzoProtobufBlockPigLoader(String protoClassName) {
    TypeRef<M> typeRef = Protobufs.getTypeRef(protoClassName);
    setTypeRef(typeRef);
    setLoaderSpec(getClass(), new String[]{protoClassName});
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
public abstract class LzoProtobufB64LinePigLoader<M extends Message> extends LzoBaseLoadFunc {
=======
public class LzoProtobufB64LinePigLoader<M extends Message> extends LzoBaseLoadFunc {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
  private Function<byte[], M> protoConverter_ = null;
=======
  private ProtobufConverter<M> protoConverter_ = null;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
  public LzoProtobufB64LinePigLoader(String protoClassName) {
    TypeRef<M> typeRef = Protobufs.getTypeRef(protoClassName);
    setTypeRef(typeRef);
    setLoaderSpec(getClass(), new String[]{protoClassName});
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
    protoConverter_ = Protobufs.getProtoConverter(typeRef.getRawClass());
=======
    protoConverter_ = ProtobufConverter.newInstance(typeRef);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
      M protoValue = protoConverter_.apply(base64_.decode(line.getBytes("UTF-8")));
=======
      M protoValue = protoConverter_.fromBytes(base64_.decode(line.getBytes("UTF-8")));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
  private Function<byte[], M> protoConverter_ = null;
=======
  private ProtobufConverter<M> protoConverter_ = null;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
    protoConverter_ = Protobufs.getProtoConverter(typeRef.getRawClass());
=======
    protoConverter_ = ProtobufConverter.newInstance(typeRef);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
      M value_ = protoConverter_.apply(bytes.get());
=======
      M value_ = protoConverter_.fromBytes(bytes.get());
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
  
  @Test 
=======

  @Test
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b0d7a3e_6abbab9/rev_b0d7a3e-6abbab9/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
    Function<byte[], AddressBook> protoConverter = Protobufs.getProtoConverter(AddressBook.class);
    assertEquals(ab_, protoConverter.apply(abBytes_));
=======
    ProtobufConverter<AddressBook> protoConverter = ProtobufConverter.newInstance(AddressBook.class);
    assertEquals(ab_, protoConverter.fromBytes(abBytes_));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d5876bb_b813096/rev_d5876bb-b813096/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE

=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d5876bb_b813096/rev_d5876bb-b813096/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
  @Override
  public RecordWriter<NullWritable, W> getRecordWriter(TaskAttemptContext job)
=======
  public LzoProtobufBlockOutputFormat() {}

  /**
   * Returns {@link LzoProtobufB64LineOutputFormat} class.
   * Sets an internal configuration in jobConf so that remote Tasks
   * instantiate appropriate object for this generic class based on protoClass
   */
  @SuppressWarnings("unchecked")
  public static <M extends Message> Class<LzoProtobufBlockOutputFormat>
     getOutputFormatClass(Class<M> protoClass, Configuration jobConf) {

    Protobufs.setClassConf(jobConf, LzoProtobufBlockOutputFormat.class, protoClass);
    return LzoProtobufBlockOutputFormat.class;
  }

  public RecordWriter<NullWritable, ProtobufWritable<M>> getRecordWriter(TaskAttemptContext job)
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d5876bb_b813096/rev_d5876bb-b813096/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d5876bb_b813096/rev_d5876bb-b813096/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
  @Override
  public RecordWriter<NullWritable, W> getRecordWriter(TaskAttemptContext job)
=======
  public LzoProtobufB64LineOutputFormat() {}

  /**
   * Returns {@link LzoProtobufBlockOutputFormat} class.
   * Sets an internal configuration in jobConf so that remote Tasks
   * instantiate appropriate object for this generic class based on protoClass
   */
  @SuppressWarnings("unchecked")
  public static <M extends Message> Class<LzoProtobufB64LineOutputFormat>
     getOutputFormatClass(Class<M> protoClass, Configuration jobConf) {

    Protobufs.setClassConf(jobConf, LzoProtobufB64LineOutputFormat.class, protoClass);
    return LzoProtobufB64LineOutputFormat.class;
  }


  public RecordWriter<NullWritable, ProtobufWritable<M>> getRecordWriter(TaskAttemptContext job)
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d5876bb_b813096/rev_d5876bb-b813096/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;

import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.protobuf.Message;
import com.twitter.elephantbird.mapreduce.io.ProtobufBlockReader;
import com.twitter.elephantbird.mapreduce.io.ProtobufWritable;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
import com.twitter.elephantbird.pig.util.ProtobufTuple;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;


public class LzoProtobufBlockPigLoader<M extends Message> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufBlockPigLoader.class);

  private ProtobufBlockReader<M> reader_ = null;
  private ProtobufWritable<M> value_ = null;
  private TypeRef<M> typeRef_ = null;
  private final ProtobufToPig protoToPig_ = new ProtobufToPig();

  private Pair<String, String> protobufsRead;
  private Pair<String, String> protobufErrors;

  public LzoProtobufBlockPigLoader() {
    LOG.info("LzoProtobufBlockLoader zero-parameter creation");
  }

  public LzoProtobufBlockPigLoader(String protoClassName) {
    TypeRef<M> typeRef = Protobufs.getTypeRef(protoClassName);
    setTypeRef(typeRef);
    setLoaderSpec(getClass(), new String[]{protoClassName});
  }

  /**
   * Set the type parameter so it doesn't get erased by Java.  Must be called before getNext!
   *
   * @param typeRef
   */
  public void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    value_ = new ProtobufWritable<M>(typeRef_);
    String group = "LzoBlocks of " + typeRef_.getRawClass().getName();
    protobufsRead = new Pair<String, String>(group, "Protobufs Read");
    protobufErrors = new Pair<String, String>(group, "Errors");
  }

  @Override
  public void postBind() throws IOException {
    reader_ = new ProtobufBlockReader<M>(is_, typeRef_);
  }

  @Override
  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // We want to explicitly not do any special syncing here, because the reader_
    // handles this automatically.
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }


  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    // If we are past the end of the file split, tell the reader not to read any more new blocks.
    // Then continue reading until the last of the reader's already-parsed values are used up.
    // The next split will start at the next sync point and no records will be missed.
    if (is_.getPosition() > end_) {
      reader_.markNoMoreNewBlocks();
    }

    Tuple t = null;
    if (reader_.readProtobuf(value_)) {
      if (value_.get() == null) {
        incrCounter(protobufErrors, 1);
      }
      t = new ProtobufTuple(value_.get());
      incrCounter(protobufsRead, 1L);
    }
    return t;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return protoToPig_.toSchema(Protobufs.getMessageDescriptor(typeRef_.getRawClass()));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d5876bb_b813096/rev_d5876bb-b813096/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import java.nio.charset.Charset;

import org.apache.commons.codec.binary.Base64;
import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.base.Function;
import com.google.protobuf.Message;
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
import com.twitter.elephantbird.pig.util.ProtobufTuple;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * This is the base class for all base64 encoded, line-oriented protocol buffer based pig loaders.
 * Data is expected to be one base64 encoded serialized protocol buffer per line. The specific
 * protocol buffer is a template parameter, generally specified by a codegen'd derived class.
 * See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
 */

public class LzoProtobufB64LinePigLoader<M extends Message> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufB64LinePigLoader.class);

  private TypeRef<M> typeRef_ = null;
  private ProtobufConverter<M> protoConverter_ = null;
  private final Base64 base64_ = new Base64();
  private final ProtobufToPig protoToPig_ = new ProtobufToPig();

  private static final Charset UTF8 = Charset.forName("UTF-8");
  private static final byte RECORD_DELIMITER = (byte)'\n';

  private Pair<String, String> linesRead;
  private Pair<String, String> protobufsRead;
  private Pair<String, String> protobufErrors;

  public LzoProtobufB64LinePigLoader() {
    LOG.info("LzoProtobufB64LineLoader zero-parameter creation");
  }

  public LzoProtobufB64LinePigLoader(String protoClassName) {
    TypeRef<M> typeRef = Protobufs.getTypeRef(protoClassName);
    setTypeRef(typeRef);
    setLoaderSpec(getClass(), new String[]{protoClassName});
  }

  /**
   * Set the type parameter so it doesn't get erased by Java.  Must be called before getNext!
   *
   * @param typeRef
   */
  public void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    protoConverter_ = ProtobufConverter.newInstance(typeRef);
    String group = "LzoB64Lines of " + typeRef_.getRawClass().getName();
    linesRead = new Pair<String, String>(group, "Lines Read");
    protobufsRead = new Pair<String, String>(group, "Protobufs Read");
    protobufErrors = new Pair<String, String>(group, "Errors");
  }

  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // Since we are not block aligned we throw away the first record of each split and count on a different
    // instance to read it.  The only split this doesn't work for is the first.
    if (!atFirstRecord) {
      getNext();
    }
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }

  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    String line;
    Tuple t = null;
    while ((line = is_.readLine(UTF8, RECORD_DELIMITER)) != null) {
      incrCounter(linesRead, 1L);
      M protoValue = protoConverter_.fromBytes(base64_.decode(line.getBytes("UTF-8")));
      if (protoValue != null) {
        t = new ProtobufTuple(protoValue);
        incrCounter(protobufsRead, 1L);
        break;
      } else {
        incrCounter(protobufErrors, 1L);
      }
    }

    return t;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return protoToPig_.toSchema(Protobufs.getMessageDescriptor(typeRef_.getRawClass()));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d5876bb_b813096/rev_d5876bb-b813096/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.piggybank;

import java.io.IOException;

import org.apache.pig.EvalFunc;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;

import com.google.common.base.Function;
import com.google.protobuf.Message;
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
import com.twitter.elephantbird.pig.util.ProtobufTuple;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * The base class for a Pig UDF that takes as input a tuple containing a single element, the
 * bytes of a serialized protocol buffer as a DataByteArray.  It outputs the protobuf in
 * expanded form.  The specific protocol buffer is a template parameter, generally specified by a
 * codegen'd derived class. See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
 */
public abstract class ProtobufBytesToTuple<M extends Message> extends EvalFunc<Tuple> {
  private TypeRef<M> typeRef_ = null;
  private ProtobufConverter<M> protoConverter_ = null;
  private final ProtobufToPig protoToPig_ = new ProtobufToPig();

  /**
   * Set the type parameter so it doesn't get erased by Java. Must be called during
   * initialization.
   * @param typeRef
   */
  public void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    protoConverter_ = ProtobufConverter.newInstance(typeRef);
  }

  @Override
  public Tuple exec(Tuple input) throws IOException {
    if (input == null || input.size() < 1) return null;
    try {
      DataByteArray bytes = (DataByteArray) input.get(0);
      M value_ = protoConverter_.fromBytes(bytes.get());
      return new ProtobufTuple(value_);
    } catch (IOException e) {
      return null;
    }
  }

  @Override
  public Schema outputSchema(Schema input) {
    return protoToPig_.toSchema(Protobufs.getMessageDescriptor(typeRef_.getRawClass()));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_fa133ef_2e3ee1e/rev_fa133ef-2e3ee1e/jodd-core/src/main/java/jodd/util/Wildcard.java;<<<<<<< MINE
	public static boolean match(String string, String pattern) {
=======
	public static boolean match(CharSequence string, CharSequence pattern) {
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_fa133ef_2e3ee1e/rev_fa133ef-2e3ee1e/jodd-core/src/main/java/jodd/util/Wildcard.java;<<<<<<< MINE
	 * Checks if two strings are equals or if they {@link #match(String, String)}.
=======
	 * Checks if two strings are equals or if they {@link #match(CharSequence, CharSequence)}.
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_fa133ef_2e3ee1e/rev_fa133ef-2e3ee1e/jodd-core/src/main/java/jodd/util/Wildcard.java;<<<<<<< MINE
	public static boolean equalsOrMatch(String string, String pattern) {
=======
	public static boolean equalsOrMatch(CharSequence string, CharSequence pattern) {
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_fa133ef_2e3ee1e/rev_fa133ef-2e3ee1e/jodd-core/src/main/java/jodd/util/Wildcard.java;<<<<<<< MINE
	private static boolean match(String string, String pattern, int sNdx, int pNdx) {
=======
	private static boolean match(CharSequence string, CharSequence pattern, int sNdx, int pNdx) {
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_fa133ef_2e3ee1e/rev_fa133ef-2e3ee1e/jodd-core/src/main/java/jodd/util/Wildcard.java;<<<<<<< MINE
	 * @see #match(String, String)
=======
	 * @see #match(CharSequence, CharSequence)
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/java/com/twitter/elephantbird/examples/ProtobufMRExample.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.examples;

import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

import com.twitter.elephantbird.examples.proto.Examples.Age;
import com.twitter.elephantbird.mapreduce.input.LzoProtobufB64LineInputFormat;
import com.twitter.elephantbird.mapreduce.input.LzoProtobufBlockInputFormat;
import com.twitter.elephantbird.mapreduce.io.ProtobufWritable;
import com.twitter.elephantbird.mapreduce.output.LzoProtobufB64LineOutputFormat;
import com.twitter.elephantbird.mapreduce.output.LzoProtobufBlockOutputFormat;

/**
 * -Dproto.test=lzoOut : takes text files with name and age on each line as
 * input and writes to lzo file with Protobuf serilized data. <br>
 * -Dproto.test=lzoIn : does the reverse. <br><br>
 *
 * -Dproto.test.format=Block (or B64Line) to test different formats. <br>
 */

public class ProtobufMRExample {
  // This is intentionally very similar to ThriftMRExample.

  private ProtobufMRExample() {}

  public static class TextMapper extends Mapper<LongWritable, Text, NullWritable, ProtobufWritable<Age>> {
    ProtobufWritable<Age> protoWritable = ProtobufWritable.newInstance(Age.class);

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
      StringTokenizer line = new StringTokenizer(value.toString(), "\t\r\n");
      String name;

      if (line.hasMoreTokens()
          && (name = line.nextToken()) != null
          && line.hasMoreTokens()) {
          protoWritable.set(Age.newBuilder()
                              .setName(name)
                              .setAge(Integer.parseInt(line.nextToken()))
                              .build());
          context.write(null, protoWritable);
      }
    }
  }

  public int runTextToLzo(String[] args, Configuration conf) throws Exception {
    Job job = new Job(conf);
    job.setJobName("Protobuf Example : Text to LzoB64Line");

    job.setJarByClass(getClass());
    job.setMapperClass(TextMapper.class);
    job.setNumReduceTasks(0);

    job.setInputFormatClass(TextInputFormat.class);
    if (conf.get("proto.test.format", "B64Line").equals("Block")) {
      job.setOutputFormatClass(LzoProtobufBlockOutputFormat.getOutputFormatClass(Age.class, job.getConfiguration()));
    } else { // assume B64Line
      job.setOutputFormatClass(LzoProtobufB64LineOutputFormat.getOutputFormatClass(Age.class, job.getConfiguration()));
    }

    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));

    return job.waitForCompletion(true) ? 0 : 1;
  }

  public static class LzoMapper extends Mapper<LongWritable, ProtobufWritable<Age>, Text, Text> {
    @Override
    protected void map(LongWritable key, ProtobufWritable<Age> value, Context context) throws IOException, InterruptedException {
      Age age = value.get();
      System.err.println("XXXXXXXXX got here!!");
      context.write(null, new Text(age.getName() + "\t" + age.getAge()));
    }
  }

  public int runLzoToText(String[] args, Configuration conf) throws Exception {
    Job job = new Job(conf);
    job.setJobName("Protobuf Example : LzoB64Line to Text");

    job.setJarByClass(getClass());
    job.setMapperClass(LzoMapper.class);
    job.setNumReduceTasks(0);

    if (conf.get("proto.test.format", "B64Line").equals("Block")) {
      job.setInputFormatClass(LzoProtobufBlockInputFormat.getInputFormatClass(Age.class, job.getConfiguration()));
    } else {
      job.setInputFormatClass(LzoProtobufB64LineInputFormat.getInputFormatClass(Age.class, job.getConfiguration()));
    }
    job.setOutputFormatClass(TextOutputFormat.class);

    FileInputFormat.setInputPaths(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));

    return job.waitForCompletion(true) ? 0 : 1;
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    args = new GenericOptionsParser(conf, args).getRemainingArgs();
    ProtobufMRExample runner = new ProtobufMRExample();

    if (args.length != 2) {
      System.out.println("Usage: hadoop jar path/to/this.jar " + runner.getClass() + " <input dir> <output dir>");
      System.exit(1);
    }

    String test = conf.get("proto.test", "lzoIn");

    if (test.equals("lzoIn"))
      System.exit(runner.runLzoToText(args, conf));
    if (test.equals("lzoOut"))
      System.exit(runner.runTextToLzo(args, conf));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoAddressBookProtobufBlockOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufAddressBookWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoAddressBookProtobufBlockOutputFormat.java;<<<<<<< MINE
public class LzoAddressBookProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<AddressBook, ProtobufAddressBookWritable> {
=======
public class LzoAddressBookProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<AddressBook> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoAddressBookProtobufB64LineOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufAddressBookWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoAddressBookProtobufB64LineOutputFormat.java;<<<<<<< MINE
public class LzoAddressBookProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<AddressBook, ProtobufAddressBookWritable> {
=======
public class LzoAddressBookProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<AddressBook> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoPersonProtobufBlockOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufPersonWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoPersonProtobufBlockOutputFormat.java;<<<<<<< MINE
public class LzoPersonProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<Person, ProtobufPersonWritable> {
=======
public class LzoPersonProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<Person> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoPersonProtobufB64LineOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufPersonWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/output/LzoPersonProtobufB64LineOutputFormat.java;<<<<<<< MINE
public class LzoPersonProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<Person, ProtobufPersonWritable> {
=======
public class LzoPersonProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<Person> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufBlockInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufPersonWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufBlockInputFormat.java;<<<<<<< MINE
public class LzoPersonProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<Person, ProtobufPersonWritable> {
=======
public class LzoPersonProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<Person> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufBlockInputFormat.java;<<<<<<< MINE
    setProtobufWritable(new ProtobufPersonWritable());
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufB64LineInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufAddressBookWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufB64LineInputFormat.java;<<<<<<< MINE
public class LzoAddressBookProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<AddressBook, ProtobufAddressBookWritable> {
=======
public class LzoAddressBookProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<AddressBook> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufB64LineInputFormat.java;<<<<<<< MINE
    setProtobufWritable(new ProtobufAddressBookWritable());
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufB64LineInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufPersonWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufB64LineInputFormat.java;<<<<<<< MINE
public class LzoPersonProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<Person, ProtobufPersonWritable> {
=======
public class LzoPersonProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<Person> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoPersonProtobufB64LineInputFormat.java;<<<<<<< MINE
    setProtobufWritable(new ProtobufPersonWritable());
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufBlockInputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.examples.proto.mapreduce.io.ProtobufAddressBookWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufBlockInputFormat.java;<<<<<<< MINE
public class LzoAddressBookProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<AddressBook, ProtobufAddressBookWritable> {
=======
public class LzoAddressBookProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<AddressBook> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/mapreduce/input/LzoAddressBookProtobufBlockInputFormat.java;<<<<<<< MINE
    setProtobufWritable(new ProtobufAddressBookWritable());
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/examples/src/gen-java/com/twitter/elephantbird/examples/proto/Examples.java;<<<<<<< MINE
=======
// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: examples.proto

package com.twitter.elephantbird.examples.proto;

public final class Examples {
  private Examples() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public static final class Age extends
      com.google.protobuf.GeneratedMessage {
    // Use Age.newBuilder() to construct.
    private Age() {
      initFields();
    }
    private Age(boolean noInit) {}
    
    private static final Age defaultInstance;
    public static Age getDefaultInstance() {
      return defaultInstance;
    }
    
    public Age getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.twitter.elephantbird.examples.proto.Examples.internal_static_com_twitter_elephantbird_examples_proto_Age_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.twitter.elephantbird.examples.proto.Examples.internal_static_com_twitter_elephantbird_examples_proto_Age_fieldAccessorTable;
    }
    
    // optional string name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private boolean hasName;
    private java.lang.String name_ = "";
    public boolean hasName() { return hasName; }
    public java.lang.String getName() { return name_; }
    
    // optional int32 age = 2;
    public static final int AGE_FIELD_NUMBER = 2;
    private boolean hasAge;
    private int age_ = 0;
    public boolean hasAge() { return hasAge; }
    public int getAge() { return age_; }
    
    private void initFields() {
    }
    public final boolean isInitialized() {
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (hasName()) {
        output.writeString(1, getName());
      }
      if (hasAge()) {
        output.writeInt32(2, getAge());
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (hasName()) {
        size += com.google.protobuf.CodedOutputStream
          .computeStringSize(1, getName());
      }
      if (hasAge()) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, getAge());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static com.twitter.elephantbird.examples.proto.Examples.Age parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(com.twitter.elephantbird.examples.proto.Examples.Age prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder> {
      private com.twitter.elephantbird.examples.proto.Examples.Age result;
      
      // Construct using com.twitter.elephantbird.examples.proto.Examples.Age.newBuilder()
      private Builder() {}
      
      private static Builder create() {
        Builder builder = new Builder();
        builder.result = new com.twitter.elephantbird.examples.proto.Examples.Age();
        return builder;
      }
      
      protected com.twitter.elephantbird.examples.proto.Examples.Age internalGetResult() {
        return result;
      }
      
      public Builder clear() {
        if (result == null) {
          throw new IllegalStateException(
            "Cannot call clear() after build().");
        }
        result = new com.twitter.elephantbird.examples.proto.Examples.Age();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(result);
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.twitter.elephantbird.examples.proto.Examples.Age.getDescriptor();
      }
      
      public com.twitter.elephantbird.examples.proto.Examples.Age getDefaultInstanceForType() {
        return com.twitter.elephantbird.examples.proto.Examples.Age.getDefaultInstance();
      }
      
      public boolean isInitialized() {
        return result.isInitialized();
      }
      public com.twitter.elephantbird.examples.proto.Examples.Age build() {
        if (result != null && !isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return buildPartial();
      }
      
      private com.twitter.elephantbird.examples.proto.Examples.Age buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        if (!isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return buildPartial();
      }
      
      public com.twitter.elephantbird.examples.proto.Examples.Age buildPartial() {
        if (result == null) {
          throw new IllegalStateException(
            "build() has already been called on this Builder.");
        }
        com.twitter.elephantbird.examples.proto.Examples.Age returnMe = result;
        result = null;
        return returnMe;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.twitter.elephantbird.examples.proto.Examples.Age) {
          return mergeFrom((com.twitter.elephantbird.examples.proto.Examples.Age)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(com.twitter.elephantbird.examples.proto.Examples.Age other) {
        if (other == com.twitter.elephantbird.examples.proto.Examples.Age.getDefaultInstance()) return this;
        if (other.hasName()) {
          setName(other.getName());
        }
        if (other.hasAge()) {
          setAge(other.getAge());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                return this;
              }
              break;
            }
            case 10: {
              setName(input.readString());
              break;
            }
            case 16: {
              setAge(input.readInt32());
              break;
            }
          }
        }
      }
      
      
      // optional string name = 1;
      public boolean hasName() {
        return result.hasName();
      }
      public java.lang.String getName() {
        return result.getName();
      }
      public Builder setName(java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  result.hasName = true;
        result.name_ = value;
        return this;
      }
      public Builder clearName() {
        result.hasName = false;
        result.name_ = getDefaultInstance().getName();
        return this;
      }
      
      // optional int32 age = 2;
      public boolean hasAge() {
        return result.hasAge();
      }
      public int getAge() {
        return result.getAge();
      }
      public Builder setAge(int value) {
        result.hasAge = true;
        result.age_ = value;
        return this;
      }
      public Builder clearAge() {
        result.hasAge = false;
        result.age_ = 0;
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:com.twitter.elephantbird.examples.proto.Age)
    }
    
    static {
      defaultInstance = new Age(true);
      com.twitter.elephantbird.examples.proto.Examples.internalForceInit();
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:com.twitter.elephantbird.examples.proto.Age)
  }
  
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_com_twitter_elephantbird_examples_proto_Age_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_com_twitter_elephantbird_examples_proto_Age_fieldAccessorTable;
  
  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\016examples.proto\022\'com.twitter.elephantbi" +
      "rd.examples.proto\" \n\003Age\022\014\n\004name\030\001 \001(\t\022\013" +
      "\n\003age\030\002 \001(\005B\nB\010Examples"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_com_twitter_elephantbird_examples_proto_Age_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_com_twitter_elephantbird_examples_proto_Age_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_com_twitter_elephantbird_examples_proto_Age_descriptor,
              new java.lang.String[] { "Name", "Age", },
              com.twitter.elephantbird.examples.proto.Examples.Age.class,
              com.twitter.elephantbird.examples.proto.Examples.Age.Builder.class);
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        }, assigner);
  }
  
  public static void internalForceInit() {}
  
  // @@protoc_insertion_point(outer_class_scope)
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
=======
  private static final String CLASS_CONF_PREFIX = "elephantbird.protobuf.class.for.";

  /**
   * Returns Protobuf class. The class name could be either normal name or
   * its canonical name (canonical name does not have a $ for inner classes).
   */
  public static Class<? extends Message> getProtobufClass(String protoClassName) {
    return getProtobufClass(null, protoClassName);
  }

  private static Class<? extends Message> getProtobufClass(Configuration conf, String protoClassName) {
    // Try both normal name and canonical name of the class.
    Class<?> protoClass = null;
    try {
      if (conf == null) {
        protoClass = Class.forName(protoClassName);
      } else {
        protoClass = conf.getClassByName(protoClassName);
      }
    } catch (ClassNotFoundException e) {
      // the class name might be canonical name.
      protoClass = getInnerProtobufClass(protoClassName);
    }

    return protoClass.asSubclass(Message.class);
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
  
  /**
   * Creates a Function to repeatedly convert byte arrays into Messages. Using such a function
   * is more efficient than the static <code>parseFrom</code> method, since it avoids some of the
   * reflection overhead of the static function.
   */
  public static <M extends Message> Function<byte[], M> getProtoConverter(final Class<M> protoClass) {
    //XXX Remove this.
    return new Function<byte[], M>() {
      private Message.Builder protoBuilder = null; 
      
      @SuppressWarnings("unchecked")
      @Override
      public M apply(byte[] bytes) {
        try {
          if (protoBuilder == null) {
            protoBuilder = Protobufs.getMessageBuilder(protoClass);
          }
          return  (M) protoBuilder.clone().mergeFrom(bytes).build();
        } catch (InvalidProtocolBufferException e) {
          LOG.error("Invalid Protocol Buffer exception building " + protoClass.getName(), e);
          return null;
        } catch(UninitializedMessageException ume) {
	  LOG.error("Uninitialized Message Exception in building " + protoClass.getName(), ume);
	  return null;
        }
      }
    };
  }
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
=======

  /**
   * Returns typeref for a Protobuf class
   */
  public static<M extends Message> TypeRef<M> getTypeRef(String protoClassName) {
    return new TypeRef<M>(getProtobufClass(protoClassName)){};
  }

  /**
   * Returns TypeRef for the Protobuf class that was set using setClass(jobConf);
   */
  public static<M extends Message> TypeRef<M> getTypeRef(Configuration jobConf, Class<?> genericClass) {
    String className = jobConf.get(CLASS_CONF_PREFIX + genericClass.getName());
    if (className == null) {
      throw new RuntimeException(CLASS_CONF_PREFIX + genericClass.getName() + " is not set");
    }
    return new TypeRef<M>(getProtobufClass(jobConf, className)){};
  }

  public static void setClassConf(Configuration jobConf, Class<?> genericClass,
      Class<? extends Message> protoClass) {
    jobConf.set(CLASS_CONF_PREFIX + genericClass.getName(), protoClass.getName());
  }
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.util.Protobufs;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
 * This is the base class for all blocked protocol buffer based output formats.  See
 * the ProtobufBlockWriter class for the on-disk format. It has two template
 * parameters, the protobuf and the writable for that protobuf.  This class cannot be instantiated
 * directly as an input format because Hadoop works via reflection, and Java type erasure makes it
 * impossible to instantiate a templatized class via reflection with the correct template parameter.
 * Instead, we codegen derived output format classes for any given protobuf which instantiate the
 * template parameter directly, as well as set the typeRef argument so that the template
 * parameter can be remembered.  See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
=======
 * Class for all blocked protocol buffer based output formats.  See
 * the ProtobufBlockWriter class for the on-disk format. <br><br>
 *
 * Do not use LzoProtobufBlockOutputFormat.class directly for setting
 * OutputFormat class for a job. Use getOutputFormatClass() instead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
public abstract class LzoProtobufBlockOutputFormat<M extends Message, W extends ProtobufWritable<M>>
    extends LzoOutputFormat<M, W> {
=======
public class LzoProtobufBlockOutputFormat<M extends Message> extends LzoOutputFormat<M, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
  public RecordWriter<NullWritable, W> getRecordWriter(TaskAttemptContext job)
=======
  public LzoProtobufBlockOutputFormat() {}

  /**
   * Returns {@link LzoProtobufB64LineOutputFormat} class.
   * Sets an internal configuration in jobConf so that remote Tasks
   * instantiate appropriate object for this generic class based on protoClass
   */
  @SuppressWarnings("unchecked")
  public static <M extends Message> Class<LzoProtobufBlockOutputFormat>
     getOutputFormatClass(Class<M> protoClass, Configuration jobConf) {

    Protobufs.setClassConf(jobConf, LzoProtobufBlockOutputFormat.class, protoClass);
    return LzoProtobufBlockOutputFormat.class;
  }

  public RecordWriter<NullWritable, ProtobufWritable<M>> getRecordWriter(TaskAttemptContext job)
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufBlockOutputFormat.java;<<<<<<< MINE
    return new LzoBinaryBlockRecordWriter<M, W>(
=======
    if (typeRef_ == null) { // i.e. if not set by a subclass
      typeRef_ = Protobufs.getTypeRef(job.getConfiguration(), LzoProtobufBlockOutputFormat.class);
    }

    return new LzoBinaryBlockRecordWriter<M, ProtobufWritable<M>>(
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapreduce.input.LzoProtobufBlockInputFormat;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.util.Protobufs;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
 * This is the base class for all base64 encoded, line-oriented protocol buffer based output formats.
 * Data is written as one base64 encoded serialized protocol buffer per line. It has two template
 * parameters, the protobuf and the writable for that protobuf.  This class cannot be instantiated
 * directly as an input format because Hadoop works via reflection, and Java type erasure makes it
 * impossible to instantiate a templatized class via reflection with the correct template parameter.
 * Instead, we codegen derived output format classes for any given protobuf which instantiate the
 * template parameter directly, as well as set the typeRef argument so that the template
 * parameter can be remembered.  See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
=======
 * This is the class for all base64 encoded, line-oriented protocol buffer based output formats.
 * Data is written as one base64 encoded serialized protocol buffer per line.<br><br>
 *
 * Do not use LzoProtobufB64LineOutputFormat.class directly for setting
 * OutputFormat class for a job. Use getOutputFormatClass() in stead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
public abstract class LzoProtobufB64LineOutputFormat<M extends Message, W extends ProtobufWritable<M>>
    extends LzoOutputFormat<M, W> {
=======
public class LzoProtobufB64LineOutputFormat<M extends Message> extends LzoOutputFormat<M, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
  public RecordWriter<NullWritable, W> getRecordWriter(TaskAttemptContext job)
=======
  public LzoProtobufB64LineOutputFormat() {}

  /**
   * Returns {@link LzoProtobufBlockOutputFormat} class.
   * Sets an internal configuration in jobConf so that remote Tasks
   * instantiate appropriate object for this generic class based on protoClass
   */
  @SuppressWarnings("unchecked")
  public static <M extends Message> Class<LzoProtobufB64LineOutputFormat>
     getOutputFormatClass(Class<M> protoClass, Configuration jobConf) {

    Protobufs.setClassConf(jobConf, LzoProtobufB64LineOutputFormat.class, protoClass);
    return LzoProtobufB64LineOutputFormat.class;
  }


  public RecordWriter<NullWritable, ProtobufWritable<M>> getRecordWriter(TaskAttemptContext job)
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
    return new LzoBinaryB64LineRecordWriter<M, W>(new ProtobufConverter<M>(typeRef_), getOutputStream(job));
=======
    if (typeRef_ == null) {
      typeRef_ = Protobufs.getTypeRef(job.getConfiguration(), LzoProtobufB64LineOutputFormat.class);
    }

    return new LzoBinaryB64LineRecordWriter<M, ProtobufWritable<M>>(ProtobufConverter.newInstance(typeRef_), getOutputStream(job));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.util.Protobufs;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
 * Data is expected to be one base64 encoded serialized protocol buffer per line. It has two template
 * parameters, the protobuf and the writable for that protobuf.  This class cannot be instantiated
 * directly as an input format because Hadoop works via reflection, and Java type erasure makes it
 * impossible to instantiate a templatized class via reflection with the correct template parameter.
 * Instead, we codegen derived input format classes for any given protobuf which instantiate the
 * template parameter directly, as well as set the typeRef argument so that the template
 * parameter can be remembered.  See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
=======
 * Data is expected to be one base64 encoded serialized protocol buffer per line.
 * <br><br>
 *
 * Do not use LzoProtobufB64LineInputFormat.class directly for setting
 * InputFormat class for a job. Use getInputFormatClass() instead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
public abstract class LzoProtobufB64LineInputFormat<M extends Message, W extends ProtobufWritable<M>> extends LzoInputFormat<LongWritable, W> {
=======
public class LzoProtobufB64LineInputFormat<M extends Message> extends LzoInputFormat<LongWritable, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
  private W protobufWritable_;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
=======
  // should remove this.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
  protected void setProtobufWritable(W protobufWritable) {
    protobufWritable_ = protobufWritable;
=======
  /**
   * Returns {@link LzoProtobufB64LineInputFormat} class.
   * Sets an internal configuration in jobConf so that remote Tasks
   * instantiate appropriate object based on protoClass.
   */
  @SuppressWarnings("unchecked")
  public static <M extends Message> Class<LzoProtobufB64LineInputFormat>
     getInputFormatClass(Class<M> protoClass, Configuration jobConf) {
    Protobufs.setClassConf(jobConf, LzoProtobufB64LineInputFormat.class, protoClass);
    return LzoProtobufB64LineInputFormat.class;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
  public RecordReader<LongWritable, W> createRecordReader(InputSplit split,
=======
  public RecordReader<LongWritable, ProtobufWritable<M>> createRecordReader(InputSplit split,
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE

    return new LzoProtobufB64LineRecordReader<M, W>(typeRef_, protobufWritable_);
=======
    if (typeRef_ == null) {
      typeRef_ = Protobufs.getTypeRef(taskAttempt.getConfiguration(), LzoProtobufB64LineInputFormat.class);
    }
    return new LzoProtobufB64LineRecordReader<M>(typeRef_);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.util.Protobufs;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
=======

import org.apache.hadoop.conf.Configuration;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
 * the ProtobufBlockWriter to write your data, this input format can read it. It has two template
 * parameters, the protobuf and the writable for that protobuf.  This class cannot be instantiated
 * directly as an input format because Hadoop works via reflection, and Java type erasure makes it
 * impossible to instantiate a templatized class via reflection with the correct template parameter.
 * Instead, we codegen derived input format classes for any given protobuf which instantiate the
 * template parameter directly, as well as set the typeRef argument so that the template
 * parameter can be remembered.  See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
=======
 * the ProtobufBlockWriter to write your data, this input format can read it.
 * <br> <br>
 *
 * Do not use LzoProtobufBlockInputFormat.class directly for setting
 * InputFormat class for a job. Use getInputFormatClass() instead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
public abstract class LzoProtobufBlockInputFormat<M extends Message, W extends ProtobufWritable<M>> extends LzoInputFormat<LongWritable, W> {
=======
public class LzoProtobufBlockInputFormat<M extends Message> extends LzoInputFormat<LongWritable, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
  private W protobufWritable_;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
  protected void setProtobufWritable(W protobufWritable) {
    protobufWritable_ = protobufWritable;
=======
  /**
   * Returns {@link LzoProtobufBlockInputFormat} class.
   * Sets an internal configuration in jobConf so that remote Tasks
   * instantiate appropriate object based on protoClass.
   */
  @SuppressWarnings("unchecked")
  public static <M extends Message> Class<LzoProtobufBlockInputFormat>
     getInputFormatClass(Class<M> protoClass, Configuration jobConf) {
    Protobufs.setClassConf(jobConf, LzoProtobufBlockInputFormat.class, protoClass);
    return LzoProtobufBlockInputFormat.class;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE
  public RecordReader<LongWritable, W> createRecordReader(InputSplit split,
=======
  public RecordReader<LongWritable, ProtobufWritable<M>> createRecordReader(InputSplit split,
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockInputFormat.java;<<<<<<< MINE

    return new LzoProtobufBlockRecordReader<M, W>(typeRef_, protobufWritable_);
=======
    if (typeRef_ == null) {
      typeRef_ = Protobufs.getTypeRef(taskAttempt.getConfiguration(), LzoProtobufBlockInputFormat.class);
    }
    return new LzoProtobufBlockRecordReader<M>(typeRef_);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE
public class LzoProtobufBlockRecordReader<M extends Message, W extends ProtobufWritable<M>> extends LzoBinaryBlockRecordReader<M, W> {
=======
public class LzoProtobufBlockRecordReader<M extends Message> extends LzoBinaryBlockRecordReader<M, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE
  public LzoProtobufBlockRecordReader(TypeRef<M> typeRef, W protobufWritable) {
=======
  public LzoProtobufBlockRecordReader(TypeRef<M> typeRef) {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufBlockRecordReader.java;<<<<<<< MINE
    super(typeRef, new ProtobufBlockReader<M>(null, typeRef), protobufWritable);
=======
    super(typeRef, new ProtobufBlockReader<M>(null, typeRef), new ProtobufWritable<M>(typeRef));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
public class  LzoProtobufB64LineRecordReader<M extends Message, W extends ProtobufWritable<M>> extends LzoBinaryB64LineRecordReader<M, W> {
=======
public class  LzoProtobufB64LineRecordReader<M extends Message> extends LzoBinaryB64LineRecordReader<M, ProtobufWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineRecordReader.java;<<<<<<< MINE
  public LzoProtobufB64LineRecordReader(TypeRef<M> typeRef, W protobufWritable) {
    super(typeRef, protobufWritable, new ProtobufConverter<M>(typeRef));
=======
  public LzoProtobufB64LineRecordReader(TypeRef<M> typeRef) {
    super(typeRef, new ProtobufWritable<M>(typeRef), ProtobufConverter.newInstance(typeRef));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufWritable.java;<<<<<<< MINE
=======

  /**
   * Returns a ThriftWritable for a given Thrift class.
   */
  public static <M extends Message> ProtobufWritable<M> newInstance(Class<M> tClass) {
    return new ProtobufWritable<M>(new TypeRef<M>(tClass){});
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
    super(out, protoClass, new ProtobufConverter<M>(new TypeRef<M>(protoClass){}), DEFAULT_NUM_RECORDS_PER_BLOCK);
=======
    super(out, protoClass, ProtobufConverter.newInstance(protoClass), DEFAULT_NUM_RECORDS_PER_BLOCK);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockWriter.java;<<<<<<< MINE
    super(out, protoClass, new ProtobufConverter<M>(new TypeRef<M>(protoClass){}), numRecordsPerBlock);
=======
    super(out, protoClass, ProtobufConverter.newInstance(protoClass), numRecordsPerBlock);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufConverter.java;<<<<<<< MINE
=======

  /**
   * Returns a ProtobufConverter for a given Protobuf class.
   */
  public static <M extends Message> ProtobufConverter<M> newInstance(Class<M> protoClass) {
    return new ProtobufConverter<M>(new TypeRef<M>(protoClass){});
  }

  public static <M extends Message> ProtobufConverter<M> newInstance(TypeRef<M> typeRef) {
    return new ProtobufConverter<M>(typeRef);
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufConverter.java;<<<<<<< MINE
      LOG.error("Invalid Protocol Buffer exception building " + typeRef.getRawClass().getName(), e);
=======
      LOG.error("Invalid Protobuf exception while building " + typeRef.getRawClass().getName(), e);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufConverter.java;<<<<<<< MINE
      LOG.error("Uninitialized Message Exception in building " + typeRef.getRawClass().getName(), ume);
=======
      LOG.error("Uninitialized Message Exception while building " + typeRef.getRawClass().getName(), ume);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
    super(in, new ProtobufConverter<M>(typeRef));
=======
    super(in, ProtobufConverter.newInstance(typeRef));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/mapreduce/io/ProtobufBlockReader.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockOutputFormatGenerator.java;<<<<<<< MINE
    sb.append("import %s.mapreduce.io.Protobuf%sWritable;", packageName_, descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockOutputFormatGenerator.java;<<<<<<< MINE
    sb.append("public class Lzo%sProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<%s, Protobuf%sWritable> {", descriptorProto_.getName(), descriptorProto_.getName(), descriptorProto_.getName()).endl();
=======
    sb.append("public class Lzo%sProtobufBlockOutputFormat extends LzoProtobufBlockOutputFormat<%s> {", descriptorProto_.getName(), descriptorProto_.getName()).endl();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockInputFormatGenerator.java;<<<<<<< MINE
    sb.append("import %s.mapreduce.io.Protobuf%sWritable;", packageName_, descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockInputFormatGenerator.java;<<<<<<< MINE
    sb.append("public class Lzo%sProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<%s, Protobuf%sWritable> {", descriptorProto_.getName(), descriptorProto_.getName(), descriptorProto_.getName()).endl();
=======
    sb.append("public class Lzo%sProtobufBlockInputFormat extends LzoProtobufBlockInputFormat<%s> {", descriptorProto_.getName(), descriptorProto_.getName()).endl();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockInputFormatGenerator.java;<<<<<<< MINE
    sb.append("    setProtobufWritable(new Protobuf%sWritable());", descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LineOutputFormatGenerator.java;<<<<<<< MINE
    sb.append("import %s.mapreduce.io.Protobuf%sWritable;", packageName_, descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LineOutputFormatGenerator.java;<<<<<<< MINE
    sb.append("public class Lzo%sProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<%s, Protobuf%sWritable> {", descriptorProto_.getName(), descriptorProto_.getName(), descriptorProto_.getName()).endl();
=======
    sb.append("public class Lzo%sProtobufB64LineOutputFormat extends LzoProtobufB64LineOutputFormat<%s> {", descriptorProto_.getName(), descriptorProto_.getName()).endl();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LineInputFormatGenerator.java;<<<<<<< MINE
    sb.append("import %s.mapreduce.io.Protobuf%sWritable;", packageName_, descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LineInputFormatGenerator.java;<<<<<<< MINE
    sb.append("public class Lzo%sProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<%s, Protobuf%sWritable> {", descriptorProto_.getName(), descriptorProto_.getName(), descriptorProto_.getName()).endl();
=======
    sb.append("public class Lzo%sProtobufB64LineInputFormat extends LzoProtobufB64LineInputFormat<%s> {", descriptorProto_.getName(), descriptorProto_.getName()).endl();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LineInputFormatGenerator.java;<<<<<<< MINE
    sb.append("    setProtobufWritable(new Protobuf%sWritable());", descriptorProto_.getName()).endl();
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
=======
  public LzoProtobufBlockPigLoader(String protoClassName) {
    TypeRef<M> typeRef = Protobufs.getTypeRef(protoClassName);
    setTypeRef(typeRef);
    setLoaderSpec(getClass(), new String[]{protoClassName});
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
public abstract class LzoProtobufB64LinePigLoader<M extends Message> extends LzoBaseLoadFunc {
=======
public class LzoProtobufB64LinePigLoader<M extends Message> extends LzoBaseLoadFunc {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
  private Function<byte[], M> protoConverter_ = null;
=======
  private ProtobufConverter<M> protoConverter_ = null;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
  public LzoProtobufB64LinePigLoader(String protoClassName) {
    TypeRef<M> typeRef = Protobufs.getTypeRef(protoClassName);
    setTypeRef(typeRef);
    setLoaderSpec(getClass(), new String[]{protoClassName});
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
    protoConverter_ = Protobufs.getProtoConverter(typeRef.getRawClass());
=======
    protoConverter_ = ProtobufConverter.newInstance(typeRef);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
      M protoValue = protoConverter_.apply(base64_.decode(line.getBytes("UTF-8")));
=======
      M protoValue = protoConverter_.fromBytes(base64_.decode(line.getBytes("UTF-8")));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
  private Function<byte[], M> protoConverter_ = null;
=======
  private ProtobufConverter<M> protoConverter_ = null;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
    protoConverter_ = Protobufs.getProtoConverter(typeRef.getRawClass());
=======
    protoConverter_ = ProtobufConverter.newInstance(typeRef);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
      M value_ = protoConverter_.apply(bytes.get());
=======
      M value_ = protoConverter_.fromBytes(bytes.get());
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
  
  @Test 
=======

  @Test
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_1416fa5_839a574/rev_1416fa5-839a574/src/test/com/twitter/elephantbird/util/TestProtobufs.java;<<<<<<< MINE
    Function<byte[], AddressBook> protoConverter = Protobufs.getProtoConverter(AddressBook.class);
    assertEquals(ab_, protoConverter.apply(abBytes_));
=======
    ProtobufConverter<AddressBook> protoConverter = ProtobufConverter.newInstance(AddressBook.class);
    assertEquals(ab_, protoConverter.fromBytes(abBytes_));
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/TestUtils.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor;

public class TestUtils {
    public static String stringWithLength(int length) {
        StringBuilder stringBuilder = new StringBuilder();
        for (int i = 0; i < length; i++) {
            stringBuilder.append((char) (i + 65));
        }
        return stringBuilder.toString();
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/ValidationConstraintContextTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor;

import org.junit.Test;

import static org.junit.Assert.assertEquals;
import static org.mockito.Matchers.eq;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.verify;

public class ValidationConstraintContextTest {

    @Test
    public void testConstructor() throws Exception {
        Vtor vtor = mock(Vtor.class);
        Object target = new Object();
        ValidationConstraintContext context = new ValidationConstraintContext(vtor, target, "niceConstraint");
        assertEquals(context.getName(), "niceConstraint");
        assertEquals(context.getTarget(), target);
        assertEquals(context.getValidator(), vtor);
    }

    @Test
    public void testValidateWithin() throws Exception {
        Vtor vtor = mock(Vtor.class);
        Object target = new Object();
        ValidationConstraintContext context = new ValidationConstraintContext(vtor, target, "niceConstraint");

        ValidationContext vctx = mock(ValidationContext.class);
        Object value = new Object();
        //when
        context.validateWithin(vctx, value);
        //then
        verify(vtor).validate(eq(vctx), eq(value), eq("niceConstraint"));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/VtorExceptionTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor;

import org.junit.Test;

import static org.junit.Assert.assertEquals;

public class VtorExceptionTest {

    @Test
    public void testConstructor1() {
        //given
        RuntimeException cause = new RuntimeException("test");
        //when
        VtorException vtorException = new VtorException(cause);
        //then
        assertEquals("created instance must have the same cause as was given to its constructor", vtorException.getCause(), cause);
    }

    @Test
    public void testConstructor2() {
        //given
        String message = "test";
        //when
        VtorException vtorException = new VtorException(message);
        //then
        assertEquals("created instance must have the same message as was given to its constructor", vtorException.getMessage(), message);
    }

    @Test
    public void testConstructor3() {
        //given
        String message = "test";
        RuntimeException cause = new RuntimeException();
        //when
        VtorException vtorException = new VtorException(message, cause);
        //then
        assertEquals("created instance must return message with cause details when create instance with message and some cause", vtorException.getMessage(), message+"; <--- java.lang.RuntimeException");
        assertEquals("created instance must have the same cause as was given to its constructor", vtorException.getCause(), cause);
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/VtorMatchProfilesWithResetedProfilesTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor;

import org.junit.Before;
import org.junit.Test;

import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

public class VtorMatchProfilesWithResetedProfilesTest {
    private Vtor vtor;

    @Before
    public void setup() {
        //given
        vtor = new Vtor();
        vtor.resetProfiles();
    }

    @Test
    public void testValidateAllProfilesByDefaultIsTrue() {
        vtor.setValidateAllProfilesByDefault(true);
        assertTrue("any profile must match when property ValidateAllProfilesByDefault is active",
                vtor.matchProfiles(new String[]{"testProfile"}));
    }

    @Test
    public void testNullProfiles() {
        assertTrue("result mast be true when match null value instead of profiles",
                vtor.matchProfiles(null));
    }

    @Test
    public void testEmptyListOfProfiles() {
        assertTrue("result mast be true when match an empty list of profiles",
                vtor.matchProfiles(new String[]{}));
    }

    @Test
    public void testOneProfileIsEmpty() {
        assertTrue("result mast be true when match a list with an empty profile",
                vtor.matchProfiles(new String[]{"", "testProfile"}));
    }

    @Test
    public void testOneProfileIsDefault() {
        assertTrue("result mast be true when match a list with a default profile",
                vtor.matchProfiles(new String[]{Vtor.DEFAULT_PROFILE, "testProfile"}));
    }

    @Test
    public void testNonSpecialProfiles(){
        assertFalse("result must be false when match non special profiles",
                vtor.matchProfiles(new String[]{"testProfile1", "testProfile2"}));
    }

}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/VtorTestSupport.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor;

import java.util.List;
import java.util.Map;

public class VtorTestSupport {
    protected Check createCheckWithProfile(String name, String profile, ValidationConstraint constraint) {
        Check check = new Check(name, constraint);
        check.setProfiles(profile);
        return check;
    }

    protected ValidationContext mockValidationContext(Map<String, List<Check>> constraints) {
        ValidationContext res = new ValidationContext();
        res.map.putAll(constraints);
        return res;
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/VtorMatchProfilesTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor;

import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;

import static junit.framework.TestCase.assertFalse;
import static org.junit.Assert.assertTrue;

public class VtorMatchProfilesTest {
    private Vtor vtor;

    @Before
    public void setup() {
        vtor = new Vtor();
    }

    @Test
    public void testAllProfiles() {
        assertTrue("result must be true when match a list with one element which is *", vtor.matchProfiles(new String[]{Vtor.ALL_PROFILES}));
        assertFalse("result must be false when match a list with many elements", vtor.matchProfiles(new String[]{Vtor.ALL_PROFILES, "someProfile"}));
    }

    @Test
    public void testMatchProfilesAgainstSomeProfile() {
        //when
        vtor.useProfile("testProfile1");

        //then
        assertFalse("result must be false when match null value",
                vtor.matchProfiles(null));

        assertFalse("result must be false when match list of profiles without any assigned profiles",
                vtor.matchProfiles(new String[]{"testProfile2", "testProfile3"}));

        assertTrue("result must be true when match list of profiles with one assigned profile",
                vtor.matchProfiles(new String[]{"testProfile1", "testProfile2", "testProfile3"}));

        assertTrue("result must be true when match list of profiles with one assigned profile",
                vtor.matchProfiles(new String[]{"testProfile1", "testProfile2", "testProfile3"}));

        assertTrue("result must be true when match list of profiles with one assigned profile",
                vtor.matchProfiles(new String[]{"testProfile1", "testProfile2", "testProfile3"}));

        assertTrue("result must be true when match list of profiles with one assigned profile",
                vtor.matchProfiles(new String[]{"testProfile1", "testProfile2", "testProfile3"}));

        assertTrue("result must be true when match unordered list of profiles with one assigned profile",
                vtor.matchProfiles(new String[]{"testProfile2", "testProfile1", "testProfile3"}));

        assertFalse("result must be false when match a list of profiles with one wrong mandatory profile",
                vtor.matchProfiles(new String[]{"+testProfile2", "testProfile1", "testProfile3"}));

        assertFalse("result must be false when match a list of profiles with one assigned profile which was marked as optional",
                vtor.matchProfiles(new String[]{"testProfile2", "-testProfile1", "testProfile3"}));
    }

    @Test
    public void testDefaultProfile() {
        //when
        vtor.useProfile(Vtor.DEFAULT_PROFILE);

        //then
        assertTrue("result must be true when match null value", vtor.matchProfiles(null));
        assertTrue("result must be true when match a list with empty profile", vtor.matchProfiles(new String[]{"testProfile2", "", "testProfile3"}));
        assertFalse("result must be false when match a list without empty profile", vtor.matchProfiles(new String[]{"testProfile2", "testProfile3"}));
    }

}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/ViolationTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor;

import org.junit.Test;

import java.lang.annotation.Annotation;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNull;
import static org.mockito.Mockito.mock;

public class ViolationTest {

    @Test
    public void testConstructor1() throws Exception {
        //given
        Object validatedObject = new Object();
        Object invalidValue = new Object();

        //when
        Violation violation = new Violation("niceViolation", validatedObject, invalidValue);

        //then
        assertEquals("validatedObject must be equal to a validatedObject which was given to constructor", violation.getValidatedObject(), validatedObject);
        assertEquals("invalidValue must be equal to a invalidValue which was given to constructor", violation.getInvalidValue(), invalidValue);
        assertNull("violation must be null", violation.getCheck());
        assertNull("constraint must be null", violation.getConstraint());
    }

    @Test
    public void testConstructor2() throws Exception {
        //given
        Object validatedObject = new Object();
        Object invalidValue = new Object();
        ValidationConstraint constr = mock(ValidationConstraint.class);
        Check niceCheck = new Check("niceCheck", constr);

        //when
        Violation violation = new Violation("niceViolation", validatedObject, invalidValue, niceCheck);

        //then
        assertEquals("name must be equal to a name of violation which was given to constructor", violation.getName(), "niceViolation");
        assertEquals("ValidatedObject must be equal to a ValidatedObject which was given to constructor", violation.getValidatedObject(), validatedObject);
        assertEquals("InvalidValue must be equal to a InvalidValue which was given to constructor", violation.getInvalidValue(), invalidValue);
        assertEquals("Check must be equal to a Check which was given to constructor", violation.getCheck(), niceCheck);
        assertEquals("Constraint must be equal to a Constraint which was given to constructor", violation.getConstraint(), constr);
    }


    @Test
    public void testToString() throws Exception {
        //given
        Object validatedObject = new Object();
        Object invalidValue = new Object();
        Violation violation = new Violation("niceViolation", validatedObject, invalidValue, new Check("niceCheck", new TestValidationConstraint()));

        //when
        String toString = violation.toString();

        //then
        assertEquals(toString, "Violation{niceViolation:jodd.vtor.ViolationTest$TestValidationConstraint}");
    }

    private static class TestValidationConstraint implements ValidationConstraint {
        @Override
        public void configure(Annotation annotation) {

        }

        @Override
        public boolean isValid(ValidationConstraintContext vcc, Object value) {
            return false;
        }
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/ManualTest.java;<<<<<<< MINE
=======
		assertNull(v.getCheck().getMessage());
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/MinLengthConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import jodd.vtor.TestUtils;
import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class MinLengthConstraintTest extends ConstraintTestBase {
    @Test
    public void testConstructor1() {
        MinLengthConstraint minLengthConstraint = new MinLengthConstraint();
        assertEquals("value must be default", minLengthConstraint.getMin(), 0);
    }

    @Test
    public void testConstructor2() {
        MinLengthConstraint minLengthConstraint = new MinLengthConstraint(10);
        assertEquals("value must be the same as was given to constructor", minLengthConstraint.getMin(), 10);
    }

    @Test
    public void testSetMin() {
        MinLengthConstraint minLengthConstraint = new MinLengthConstraint();
        minLengthConstraint.setMin(10);
        assertEquals("min value must be the same as was given to set method", minLengthConstraint.getMin(), 10);
    }

    @Test
    public void testConfigure() {
        MinLengthConstraint minLengthConstraint = new MinLengthConstraint();
        MinLength annotation = mock(MinLength.class);
        stub(annotation.value()).toReturn(10);

        minLengthConstraint.configure(annotation);
        assertEquals("min value must be the same as was set to annotation when configure", minLengthConstraint.getMin(), 10);
    }

    @Test
    public void testValidate_WithNullValue() {
        assertTrue("result must be true when validate a null value", MinLengthConstraint.validate(null, 1));
    }

    @Test
    public void testIsValid() {
        int min = 3;
        MinLengthConstraint minLengthConstraint = new MinLengthConstraint(min);
        assertTrue("result must be true when validate string with length greater than min", minLengthConstraint.isValid(mockContext(), TestUtils.stringWithLength(min)));
        assertTrue("result must be true when validate string with length equal to min", minLengthConstraint.isValid(mockContext(), TestUtils.stringWithLength(min)));
        assertFalse("result must be false when validate string with length less than min", minLengthConstraint.isValid(mockContext(), TestUtils.stringWithLength(min - 1)));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/AssertValidConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import jodd.vtor.ValidationConstraintContext;
import jodd.vtor.ValidationContext;
import org.junit.Test;

import static org.junit.Assert.assertTrue;
import static org.mockito.Matchers.eq;
import static org.mockito.Matchers.isNull;
import static org.mockito.Mockito.*;

public class AssertValidConstraintTest extends ConstraintTestBase {

    @Test
    public void testIsValid_withNullValue() {
        //given
        ValidationContext targetValidationContext = mock(ValidationContext.class);
        AssertValidConstraint assertValidConstraint = new AssertValidConstraint(targetValidationContext);
        ValidationConstraintContext vcc = mockContext();

        //when
        boolean valid = assertValidConstraint.isValid(vcc, null);

        //then
        assertTrue("result must be true when validate null value", valid);
        verify(vcc, never()).validateWithin(eq(targetValidationContext), isNull());
    }

    @Test
    public void testIsValid() {
        //given
        ValidationContext targetValidationContext = mock(ValidationContext.class);
        AssertValidConstraint assertValidConstraint = new AssertValidConstraint(targetValidationContext);
        ValidationConstraintContext vcc = mockContext();
        Object someValue = new Object();
        //this method is empty so nothing to check
        assertValidConstraint.configure(null);

        //when validate some value
        boolean valid = assertValidConstraint.isValid(vcc, someValue);

        //then validateWithin must be called for validated value
        assertTrue("result must be true when validate not value", valid);
        //validateWithin must be called for validated value
        verify(vcc).validateWithin(eq(targetValidationContext), eq(someValue));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/NotNullConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import org.junit.Test;

import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

public class NotNullConstraintTest extends ConstraintTestBase {

    @Test
    public void testIsValid() {
        NotNullConstraint notNullConstraint = new NotNullConstraint();
        //this is an empty method nothing can be verified
        notNullConstraint.configure(null);

        assertTrue("result must be true when validate not null value", notNullConstraint.isValid(mockContext(), new Object()));
        assertFalse("result must be false when validate null value", notNullConstraint.isValid(mockContext(), null));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/RangeConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class RangeConstraintTest extends ConstraintTestBase {

    @Test
    public void testConstructor1() {
        RangeConstraint rangeConstraint = new RangeConstraint();
        assertEquals("value must be default", rangeConstraint.getMin(), 0.0, 0.01);
        assertEquals("value must be default", rangeConstraint.getMax(), 0.0, 0.01);
    }

    @Test
    public void testConstructor2() {
        RangeConstraint rangeConstraint = new RangeConstraint(1.1, 10.1);
        assertEquals("min value must be the same as was given to constructor", rangeConstraint.getMin(), 1.1, 0.01);
        assertEquals("max value must be the same as was given to constructor", rangeConstraint.getMax(), 10.1, 0.01);
    }


    @Test
    public void testSetMinMax() {
        RangeConstraint rangeConstraint = new RangeConstraint();
        rangeConstraint.setMin(1.1);
        rangeConstraint.setMax(10.1);
        assertEquals("method must return the same value as was given to set method", rangeConstraint.getMin(), 1.1, 0.01);
        assertEquals("method must return the same value as was given to set method", rangeConstraint.getMax(), 10.1, 0.01);
    }

    @Test
    public void testConfigure() {
        RangeConstraint rangeConstraint = new RangeConstraint();
        Range annotation = mock(Range.class);
        stub(annotation.min()).toReturn(1.1);
        stub(annotation.max()).toReturn(10.1);

        rangeConstraint.configure(annotation);
        assertEquals("method must return the same value as was set to annotation when configure", rangeConstraint.getMin(), 1.1, 0.01);
        assertEquals("method must return the same value as was set to annotation when configure", rangeConstraint.getMax(), 10.1, 0.01);
    }

    @Test
    public void testValidate_WithValIsNull() {
        assertTrue("result must be true when validate null value", RangeConstraint.validate(null, 1, 2));
    }

    @Test
    public void testIsValid() {
        assertFalse("result must be false when validate value less than min", new RangeConstraint(1.1, 2.0).isValid(mockContext(), "1.0"));
        assertFalse("result must be false when validate value grater than max", new RangeConstraint(1.1, 3.0).isValid(mockContext(), "3.1"));
        assertTrue("result must be true when validate value grater than min and less than max", new RangeConstraint(2.0, 3.0).isValid(mockContext(), "2.8"));
        assertTrue("result must be true when validate value equal to min", new RangeConstraint(2.1, 3.0).isValid(mockContext(), "2.1"));
        assertTrue("result must be true when validate value equal to max", new RangeConstraint(1.0, 2.1).isValid(mockContext(), "2.1"));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/WildcardMatchConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class WildcardMatchConstraintTest extends ConstraintTestBase {

    @Test
    public void testConstructor1() {
        WildcardMatchConstraint wildcardMatchConstraint = new WildcardMatchConstraint();
        assertNull("pattern value must be null by default", wildcardMatchConstraint.getPattern());
    }

    @Test
    public void testConstructor2() {
        String pattern = "foo";
        WildcardMatchConstraint wildcardMatchConstraint = new WildcardMatchConstraint(pattern);
        assertEquals("pattern must be the same as was given to constructor", wildcardMatchConstraint.getPattern(), pattern);
    }

    @Test
    public void testSetPattern() {
        WildcardMatchConstraint wildcardMatchConstraint = new WildcardMatchConstraint();
        String pattern = "foo";
        wildcardMatchConstraint.setPattern(pattern);
        assertEquals("method must return the same pattern as was given to set method", wildcardMatchConstraint.getPattern(), pattern);
    }

    @Test
    public void testConfigure() {
        WildcardMatchConstraint wildcardMatchConstraint = new WildcardMatchConstraint();
        WildcardMatch annotation = mock(WildcardMatch.class);
        String pattern = "foo";
        stub(annotation.value()).toReturn(pattern);
        wildcardMatchConstraint.configure(annotation);
        assertEquals("method must return the same pattern as was set to annotation when configure", wildcardMatchConstraint.getPattern(), pattern);
    }

    @Test
    public void testValidate_WithValIsNull() {
        assertTrue("result must be true when validate null value", WildcardMatchConstraint.validate(null, "*"));
    }

    @Test
    public void testIsValid() {
        assertTrue(new WildcardMatchConstraint("a?c").isValid(mockContext(), "abc"));
        assertFalse(new WildcardMatchConstraint("axc").isValid(mockContext(), "abc"));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/AssertTrueConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import org.junit.Test;

import static org.junit.Assert.assertTrue;

public class AssertTrueConstraintTest extends ConstraintTestBase {

    @Test
    public void testAssertTrue() {
        AssertTrueConstraint assertTrueConstraint = new AssertTrueConstraint();
        //this is an empty method nothing can be verified
        assertTrueConstraint.configure(null);
        assertTrue(assertTrueConstraint.isValid(mockContext(), "on"));
        assertTrue(assertTrueConstraint.isValid(mockContext(), null));
        assertTrue(assertTrueConstraint.isValid(mockContext(), Boolean.TRUE));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/EqualToDeclaredFieldConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import jodd.vtor.ValidationConstraintContext;
import jodd.vtor.VtorException;
import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class EqualToDeclaredFieldConstraintTest extends ConstraintTestBase {

    @Test
    public void testValidate_withNullValue() {
        assertTrue("result must be true when validate null value",
                EqualToDeclaredFieldConstraint.validate(new Object(), null, "someField"));
    }

    @Test
    public void testConstructor() {
        EqualToDeclaredFieldConstraint equalToDeclaredFieldConstraint = new EqualToDeclaredFieldConstraint();
        assertNull(equalToDeclaredFieldConstraint.getFieldName());
        String fieldName = "testField";
        equalToDeclaredFieldConstraint = new EqualToDeclaredFieldConstraint(fieldName);
        assertEquals("field name must be the same as was given to constructor", equalToDeclaredFieldConstraint.getFieldName(), fieldName);
    }

    @Test
    public void testSetFieldName() {
        EqualToDeclaredFieldConstraint equalToDeclaredFieldConstraint = new EqualToDeclaredFieldConstraint();
        String fieldName = "someField";
        equalToDeclaredFieldConstraint.setFieldName(fieldName);
        assertEquals("value must be the same as was given to set method", equalToDeclaredFieldConstraint.getFieldName(), fieldName);
    }

    @Test
    public void testConfigure() {
        EqualToDeclaredFieldConstraint equalToDeclaredFieldConstraint = new EqualToDeclaredFieldConstraint();
        //set a field name through an annotation
        EqualToDeclaredField fldAnnotation = mock(EqualToDeclaredField.class);
        String field = "anotherField";
        stub(fldAnnotation.value()).toReturn(field);

        equalToDeclaredFieldConstraint.configure(fldAnnotation);
        assertEquals("field name must be the same as was set to annotation when configure",
                equalToDeclaredFieldConstraint.getFieldName(), field);
    }

    @Test
    public void testIsValid_forEqualValues() {
        EqualToDeclaredFieldConstraint equalToDeclaredFieldConstraint = new EqualToDeclaredFieldConstraint("testField");
        ValidationConstraintContext cvv = mockContext();
        stub(cvv.getTarget()).toReturn(new TestValue("someValue"));

        assertTrue("result must be true when field and value are equals",  equalToDeclaredFieldConstraint.isValid(cvv, "someValue"));
    }

    @Test
    public void testIsValid_forDifferentValues() {
        EqualToDeclaredFieldConstraint equalToDeclaredFieldConstraint = new EqualToDeclaredFieldConstraint("testField");
        ValidationConstraintContext cvv = mockContext();
        stub(cvv.getTarget()).toReturn(new TestValue("someValue"));

        assertFalse("result must be false when validated field and value are different",  equalToDeclaredFieldConstraint.isValid(cvv, "wrongValue"));
    }

    @Test(expected = VtorException.class)
    public void testValidate_FieldNotFound() {
        TestValue testVal = new TestValue("someValue");
        EqualToDeclaredFieldConstraint.validate(testVal, "someValue", "wrongField");
        fail("EqualToDeclaredFieldConstraint should throw VtorException when receive nonexistent field name");
    }

    @Test
    public void testValidate_FieldValueIsNull() {
        TestValue testVal = new TestValue(null);
        assertFalse("result must be false when field value is null", EqualToDeclaredFieldConstraint.validate(testVal, "someValue", "testField"));
    }

    public static class TestValue {
        private String testField;

        public TestValue(String testField) {
            this.testField = testField;
        }
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/TimeBeforeConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import jodd.datetime.JDateTime;
import jodd.datetime.JDateTimeDefault;
import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class TimeBeforeConstraintTest extends ConstraintTestBase {

    @Test
    public void testConstructor1() {
        TimeBeforeConstraint timeBeforeConstraint = new TimeBeforeConstraint();
        assertNull("time value must be null by default", timeBeforeConstraint.getTime());
    }

    @Test
    public void testConstructor2() {
        JDateTime time = new JDateTime();
        TimeBeforeConstraint timeBeforeConstraint = new TimeBeforeConstraint(time);
        assertEquals("time must be the same as was given to constructor", timeBeforeConstraint.getTime(), time);
    }

    @Test
    public void testSetTime() {
        TimeBeforeConstraint timeBeforeConstraint = new TimeBeforeConstraint();
        JDateTime time = new JDateTime();
        timeBeforeConstraint.setTime(time);
        assertEquals("method must return the same time as was given to set method", timeBeforeConstraint.getTime(), time);
    }

    @Test
    public void testConfigure() {
        TimeBeforeConstraint timeBeforeConstraint = new TimeBeforeConstraint();
        JDateTime time = new JDateTime();
        timeBeforeConstraint.setTime(time);
        TimeBefore annotation = mock(TimeBefore.class);
        stub(annotation.value()).toReturn(JDateTimeDefault.formatter.convert(time, JDateTimeDefault.format));

        timeBeforeConstraint.configure(annotation);
        assertEquals("method must return the same time as was set to annotation when configure", timeBeforeConstraint.getTime(), time);
    }

    @Test
    public void testValidate_WithValIsNull() {
        assertTrue("result must be true when validate null value", TimeBeforeConstraint.validate(null, new JDateTime("2011-05-01 10:11:12.344")));
    }

    @Test
    public void testIsValid() {
        JDateTime time = new JDateTime("2011-05-01 10:11:12.344");
        TimeBeforeConstraint constraint = new TimeBeforeConstraint(time.clone());

        assertFalse("result must be true when validate time which is equal to constraint time", constraint.isValid(mockContext(), time.clone()));
        assertTrue("result must be false when validate time which is less than constraint time", constraint.isValid(mockContext(), time.clone().subMinute(1)));
        assertFalse("result must be true when validate time which is greater than constraint time", constraint.isValid(mockContext(), time.clone().addMinute(1)));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/AssertFalseConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import jodd.vtor.ValidationConstraintContext;
import org.junit.Test;

import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

public class AssertFalseConstraintTest extends ConstraintTestBase {

    @Test
    public void testAssertFalse() {
        AssertFalseConstraint assertFalseConstraint = new AssertFalseConstraint();
        //this is an empty method nothing can be verified
        assertFalseConstraint.configure(null);
        ValidationConstraintContext vc = mockContext();
        assertTrue(assertFalseConstraint.isValid(mockContext(), "false"));
        assertTrue(assertFalseConstraint.isValid(vc, null));
        assertTrue(assertFalseConstraint.isValid(vc, Boolean.FALSE));
    }

    @Test
    public void testAssertTrue() {
        AssertFalseConstraint assertFalseConstraint = new AssertFalseConstraint();
        //this is an empty method nothing can be verified
        assertFalseConstraint.configure(null);
        ValidationConstraintContext vc = mockContext();
        assertFalse(assertFalseConstraint.isValid(mockContext(), "true"));
        assertFalse(assertFalseConstraint.isValid(vc, Boolean.TRUE));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/LengthConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import jodd.vtor.TestUtils;
import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class LengthConstraintTest extends ConstraintTestBase {
    @Test
    public void testValidate_WithNullValue() {
        assertTrue("result must be true when validate a null value", LengthConstraint.validate(null, 1, 2));
    }

    @Test
    public void testConstructor1() {
        LengthConstraint lengthConstraint = new LengthConstraint();
        assertEquals("value must be default", lengthConstraint.getMin(), 0);
        assertEquals("value must be default", lengthConstraint.getMax(), 0);
    }

    @Test
    public void testConstructor2() {
        LengthConstraint lengthConstraint = new LengthConstraint(5, 10);
        assertEquals("min value must be the same as was given to constructor", lengthConstraint.getMin(), 5);
        assertEquals("max value must be the same as was given to constructor", lengthConstraint.getMax(), 10);
    }

    @Test
    public void testSetMinMax() {
        LengthConstraint lengthConstraint = new LengthConstraint();
        lengthConstraint.setMin(5);
        lengthConstraint.setMax(10);
        assertEquals("min value must be the same as was given to set method", lengthConstraint.getMin(), 5);
        assertEquals("max value must be the same as was given to set method", lengthConstraint.getMax(), 10);
    }

    @Test
    public void testConfigure() {
        LengthConstraint lengthConstraint = new LengthConstraint();
        Length annotation = mock(Length.class);
        stub(annotation.min()).toReturn(5);
        stub(annotation.max()).toReturn(10);

        lengthConstraint.configure(annotation);
        assertEquals("min value must be the same as was set to annotation when configure", lengthConstraint.getMin(), 5);
        assertEquals("max value must be the same as was set to annotation when configure", lengthConstraint.getMax(), 10);
    }

    @Test
    public void testLengthConstraint() {
        LengthConstraint lengthConstraint = new LengthConstraint(4, 6);
        assertFalse("result must be false when validate string with length 7 ", lengthConstraint.isValid(mockContext(), TestUtils.stringWithLength(7)));
        assertFalse("result must be false when validate string with length 3", lengthConstraint.isValid(mockContext(), TestUtils.stringWithLength(3)));
        assertTrue("result must be true when validate string with length 4", lengthConstraint.isValid(mockContext(), TestUtils.stringWithLength(4)));
        assertTrue("result must be true when validate string with length 6", lengthConstraint.isValid(mockContext(), TestUtils.stringWithLength(6)));
        assertTrue("result must be true when validate string with length 5", lengthConstraint.isValid(mockContext(), TestUtils.stringWithLength(5)));
    }


}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/ConstraintTestBase.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import jodd.vtor.ValidationConstraintContext;

import static org.mockito.Mockito.mock;

public class ConstraintTestBase {

    protected ValidationConstraintContext mockContext() {
        return mock(ValidationConstraintContext.class);
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/WildcardPathMatchConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class WildcardPathMatchConstraintTest extends ConstraintTestBase {

    @Test
    public void testConstructor1() {
        WildcardPathMatchConstraint wildcardPathMatchConstraint = new WildcardPathMatchConstraint();
        assertNull(wildcardPathMatchConstraint.getPattern());
    }

    @Test
    public void testConstructor2() {
        WildcardPathMatchConstraint wildcardPathMatchConstraint = new WildcardPathMatchConstraint("foo");
        assertEquals(wildcardPathMatchConstraint.getPattern(), "foo");
    }

    @Test
    public void testSetPattern() {
        WildcardPathMatchConstraint wildcardPathMatchConstraint = new WildcardPathMatchConstraint();
        String pattern = "foo";
        wildcardPathMatchConstraint.setPattern(pattern);

        assertEquals("method must return the same pattern as was given to set method", wildcardPathMatchConstraint.getPattern(), pattern);
    }

    @Test
    public void testConfigure() {
        WildcardPathMatchConstraint wildcardPathMatchConstraint = new WildcardPathMatchConstraint();
        WildcardPathMatch annotation = mock(WildcardPathMatch.class);
        String pattern = "foo";
        stub(annotation.value()).toReturn(pattern);

        wildcardPathMatchConstraint.configure(annotation);
        assertEquals("method must return the same pattern as was set to annotation when configure", wildcardPathMatchConstraint.getPattern(), pattern);
    }

    @Test
    public void testValidate_WithValIsNull() {
        assertTrue(WildcardPathMatchConstraint.validate(null, "*"));
    }

    @Test
    public void testIsValid() {
        assertTrue(new WildcardPathMatchConstraint("/dir/**").isValid(mockContext(), "/dir/abc"));
        assertFalse(new WildcardPathMatchConstraint("/dir/abz").isValid(mockContext(), "/dir/abc"));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/HasSubstringConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class HasSubstringConstraintTest extends ConstraintTestBase {

    @Test
    public void testConstructor1() {
        String someStr = "someStr";
        HasSubstringConstraint hasSubstringConstraint = new HasSubstringConstraint(someStr, true);
        assertEquals("string must be the same as was given to constructor", hasSubstringConstraint.getSubstring(), someStr);
        assertTrue(hasSubstringConstraint.isIgnoreCase());
    }

    @Test
    public void testConstructor2() {
        HasSubstringConstraint hasSubstringConstraint = new HasSubstringConstraint();
        assertNull(hasSubstringConstraint.getSubstring());
        assertFalse(hasSubstringConstraint.isIgnoreCase());
    }

    @Test
    public void testConfigure() {
        HasSubstringConstraint hasSubstringConstraint = new HasSubstringConstraint();
        HasSubstring annotation = mock(HasSubstring.class);
        String substring = "testString";
        boolean ignoreCase = true;
        stub(annotation.value()).toReturn(substring);
        stub(annotation.ignoreCase()).toReturn(ignoreCase);

        hasSubstringConstraint.configure(annotation);
        assertEquals("substring must be the same as was set to annotation when configure",
                hasSubstringConstraint.getSubstring(), substring);

        assertEquals("ignoreCase must be the same as was set to annotation when configure",
                hasSubstringConstraint.isIgnoreCase(), ignoreCase);

    }

    @Test
    public void testSetSubstring() {
        HasSubstringConstraint hasSubstringConstraint = new HasSubstringConstraint();
        String someStr = "someStr";
        hasSubstringConstraint.setSubstring(someStr);
        assertEquals("string must be the same as was given to set method", hasSubstringConstraint.getSubstring(), someStr);
    }

    @Test
    public void testSetIgnoreCase() {
        HasSubstringConstraint hasSubstringConstraint = new HasSubstringConstraint();
        hasSubstringConstraint.setIgnoreCase(true);
        assertTrue("IgnoreCase must be the same as was given to set method", hasSubstringConstraint.isIgnoreCase());
    }

    @Test
    public void testValidate_WithNullValue() {
        HasSubstringConstraint hasSubstringConstraint = new HasSubstringConstraint();
        assertTrue("result must be true when validate a null value", hasSubstringConstraint.isValid(mockContext(), null));
    }

    @Test
    public void testIgnoreCase_False() {
        HasSubstringConstraint hasSubstringConstraint = new HasSubstringConstraint();
        hasSubstringConstraint.setSubstring("al");
        hasSubstringConstraint.setIgnoreCase(false);

        assertTrue("result mast be true when validate low case string", hasSubstringConstraint.isValid(mockContext(), "value"));
        assertFalse("result mast be false when validate upper case string", hasSubstringConstraint.isValid(mockContext(), "VALUE"));
        assertFalse("result must be false when validate string without substring", hasSubstringConstraint.isValid(mockContext(), "FOO"));
    }

    @Test
    public void testIgnoreCase_True() {
        HasSubstringConstraint hasSubstringConstraint = new HasSubstringConstraint();
        hasSubstringConstraint.setSubstring("al");
        hasSubstringConstraint.setIgnoreCase(true);

        assertTrue("result mast be true when validate low case string", hasSubstringConstraint.isValid(mockContext(), "value"));
        assertTrue("result mast be true when validate upper case string", hasSubstringConstraint.isValid(mockContext(), "VALUE"));
        assertFalse("result must be false when validate string without substring", hasSubstringConstraint.isValid(mockContext(), "FOO"));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/TimeAfterConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import jodd.datetime.JDateTime;
import jodd.datetime.JDateTimeDefault;
import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class TimeAfterConstraintTest extends ConstraintTestBase {

    @Test
    public void testConstructor1() {
        TimeAfterConstraint timeAfterConstraint = new TimeAfterConstraint();
        assertNull("time value must be null by default", timeAfterConstraint.getTime());
    }

    @Test
    public void testConstructor2() {
        JDateTime time = new JDateTime();
        TimeAfterConstraint timeAfterConstraint = new TimeAfterConstraint(time);
        assertEquals("time must be the same as was given to constructor", timeAfterConstraint.getTime(), time);
    }

    @Test
    public void testSetTime() {
        TimeAfterConstraint timeAfterConstraint = new TimeAfterConstraint();
        JDateTime time = new JDateTime();
        timeAfterConstraint.setTime(time);
        assertEquals("method must return the same time as was given to set method", timeAfterConstraint.getTime(), time);
    }

    @Test
    public void testConfigure() {
        TimeAfterConstraint timeAfterConstraint = new TimeAfterConstraint();
        JDateTime time = new JDateTime();
        TimeAfter annotation = mock(TimeAfter.class);
        stub(annotation.value()).toReturn(JDateTimeDefault.formatter.convert(time, JDateTimeDefault.format));

        timeAfterConstraint.configure(annotation);
        assertEquals("method must return the same time as was set to annotation when configure", timeAfterConstraint.getTime(), time);
    }

    @Test
    public void testValidate_WithValIsNull() {
        assertTrue("result must be true when validate null value", TimeAfterConstraint.validate(null, new JDateTime("2011-05-01 10:11:12.344")));
    }

    @Test
    public void testIsValid() {
        JDateTime time = new JDateTime("2011-05-01 10:11:12.344");
        TimeAfterConstraint constraint = new TimeAfterConstraint(time.clone());

        assertFalse("result must be true when validate time which is equal to constraint time", constraint.isValid(mockContext(), time.clone()));
        assertFalse("result must be false when validate time which is less than constraint time", constraint.isValid(mockContext(), time.clone().subMinute(1)));
        assertTrue("result must be true when validate time which is greater than constraint time", constraint.isValid(mockContext(), time.clone().addMinute(1)));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/NotBlankConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import org.junit.Test;

import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

public class NotBlankConstraintTest extends ConstraintTestBase {

    @Test
    public void testValidate_WithNullValue() {
        assertTrue("result must be true when validate a null value", NotBlankConstraint.validate(null));
    }

    @Test
    public void testIsValid() {
        NotBlankConstraint notBlankConstraint = new NotBlankConstraint();
        //this is an empty method nothing can be verified
        notBlankConstraint.configure(null);

        assertTrue("result must be true when validate not empty string", notBlankConstraint.isValid(mockContext(), "abc"));
        assertTrue("result must be true when validate string with space at the beginning", notBlankConstraint.isValid(mockContext(), " abc"));
        assertFalse("result must be false when validate string with space", notBlankConstraint.isValid(mockContext(), " "));
        assertFalse("result must be false when validate empty", notBlankConstraint.isValid(mockContext(), ""));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/MaxConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class MaxConstraintTest extends ConstraintTestBase {

    @Test
    public void testConstructor1() {
        MaxConstraint maxConstraint = new MaxConstraint();
        assertEquals("value must be default", maxConstraint.getMax(), 0.0, 0.01);
    }

    @Test
    public void testConstructor2() {
        MaxConstraint maxConstraint = new MaxConstraint(0.1);
        assertEquals("max value must be the same as was given to constructor", maxConstraint.getMax(), 0.1, 0.01);
    }

    @Test
    public void testSetMax() {
        MaxConstraint maxConstraint = new MaxConstraint();
        maxConstraint.setMax(0.1);
        assertEquals("max value must be the same as was given to set method", maxConstraint.getMax(), 0.1, 0.01);
    }

    @Test
    public void testConfigure() {
        MaxConstraint maxConstraint = new MaxConstraint();
        Max annotation = mock(Max.class);
        stub(annotation.value()).toReturn(0.1);

        maxConstraint.configure(annotation);
        assertEquals("max value must be the same as was set to annotation when configure", maxConstraint.getMax(), 0.1, 0.01);    }


    @Test
    public void testValidate_WithNullValue() {
        assertTrue("result must be true when validate a null value", MaxConstraint.validate(null, 12.1));
    }

    @Test
    public void testIsValid() {
        assertTrue("result must be true when validated value is less than max", new MaxConstraint(12.5).isValid(mockContext(), "12.1"));
        assertFalse("result must be true when validated value is grater than max", new MaxConstraint(12.5).isValid(mockContext(), "12.6"));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/MinConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class MinConstraintTest extends ConstraintTestBase {
    @Test
    public void testConstructor1() {
        MinConstraint minConstraint = new MinConstraint();
        assertEquals("value must be default", minConstraint.getMin(), 0.0, 0.01);
    }

    @Test
    public void testConstructor2() {
        MinConstraint minConstraint = new MinConstraint(10.0);
        assertEquals("max value must be the same as was given to constructor", minConstraint.getMin(), 10.0, 0.01);
    }

    @Test
    public void testSetMin() {
        MinConstraint minConstraint = new MinConstraint();
        minConstraint.setMin(10);
        assertEquals("method must return the same value as was given to set method", minConstraint.getMin(), 10.0, 0.01);
    }

    @Test
    public void testConfigure() {
        MinConstraint minConstraint = new MinConstraint();
        Min annotation = mock(Min.class);
        stub(annotation.value()).toReturn(10.0);

        minConstraint.configure(annotation);
        assertEquals("method must return the same value as was set to annotation when configure", minConstraint.getMin(), 10.0, 0.01);
    }

    @Test
    public void testIsValid() {
        MinConstraint minConstraint = new MinConstraint(12.5);
        assertTrue("result must be true when validate a value which is greater than minValue", minConstraint.isValid(mockContext(), "12.6"));
        assertFalse("result must be false when validate a value which is less than minValue", minConstraint.isValid(mockContext(), "12.1"));
    }

    @Test
    public void testValidate_WithValIsNull() {
        assertTrue("result must be true when validate null value", MinConstraint.validate(null, 12.5));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/EqualToFieldConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import jodd.vtor.ValidationConstraintContext;
import jodd.vtor.VtorException;
import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class EqualToFieldConstraintTest extends ConstraintTestBase {
    @Test
    public void testValidate_withNullValue() {
        assertTrue("result must be true when validate null value",
                EqualToFieldConstraint.validate(new Object(), null, "someField"));
    }

    @Test
    public void testConstructor1() {
        EqualToFieldConstraint equalToFieldConstraint = new EqualToFieldConstraint();
        assertNull(equalToFieldConstraint.getFieldName());
    }

    @Test
    public void testConstructor2() {
        String fieldName = "testField";
        EqualToFieldConstraint equalToFieldConstraint = new EqualToFieldConstraint(fieldName);
        assertEquals("field name must be the same as was given to constructor", equalToFieldConstraint.getFieldName(), fieldName);
    }

    @Test
    public void testSetFieldName() {
        EqualToFieldConstraint equalToFieldConstraint = new EqualToFieldConstraint();
        String fieldName = "someField";
        equalToFieldConstraint.setFieldName(fieldName);
        assertEquals("value must be the same as was given to set method", equalToFieldConstraint.getFieldName(), fieldName);
    }

    @Test
    public void testConfigure() {
        EqualToFieldConstraint equalToFieldConstraint = new EqualToFieldConstraint();
        //set a field name through an annotation
        EqualToField fldAnnotation = mock(EqualToField.class);
        String fieldName = "anotherField";
        stub(fldAnnotation.value()).toReturn(fieldName);

        equalToFieldConstraint.configure(fldAnnotation);
        assertEquals("field name must be the same as was set to annotation when configure",
                equalToFieldConstraint.getFieldName(), fieldName);
    }

    @Test
    public void testIsValid_forEqualValues() {
        EqualToFieldConstraint equalToDeclaredFieldConstraint = new EqualToFieldConstraint("testField");
        ValidationConstraintContext cvv = mockContext();
        stub(cvv.getTarget()).toReturn(new TestBean("someValue"));

        assertTrue("result must be true when field and value are equals", equalToDeclaredFieldConstraint.isValid(cvv, "someValue"));
    }

    @Test
    public void testIsValid_forDifferentValues() {
        EqualToFieldConstraint equalToDeclaredFieldConstraint = new EqualToFieldConstraint("testField");
        ValidationConstraintContext cvv = mockContext();
        stub(cvv.getTarget()).toReturn(new TestBean("someValue"));
        assertFalse("result must be false when validated field and value are different", equalToDeclaredFieldConstraint.isValid(cvv, "wrongValue"));
    }

    @Test(expected = VtorException.class)
    public void testValidate_FieldNotFound() {
        TestBean testVal = new TestBean("someValue");
        EqualToFieldConstraint.validate(testVal, "someValue", "wrongField");
        fail("EqualToFieldConstraint should throw VtorException when receive nonexistent field name");
    }

    @Test
    public void testValidate_FieldValueIsNull() {
        TestBean testVal = new TestBean(null);
        assertFalse("result must be false when field value is null", EqualToFieldConstraint.validate(testVal, "someValue", "testField"));
    }

    public static class TestBean {
        private String testField;

        public TestBean(String testField) {
            this.testField = testField;
        }

        public String getTestField() {
            return testField;
        }

        public void setTestField(String testField) {
            this.testField = testField;
        }
    }
}>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_7afb21f_a3241cf/rev_7afb21f-a3241cf/jodd-vtor/src/test/java/jodd/vtor/constraint/MaxLengthConstraintTest.java;<<<<<<< MINE
=======
// Copyright (c) 2003-present, Jodd Team (http://jodd.org)
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
// this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

package jodd.vtor.constraint;

import jodd.vtor.TestUtils;
import org.junit.Test;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.stub;

public class MaxLengthConstraintTest extends ConstraintTestBase {

    @Test
    public void testConstructor1() {
        MaxLengthConstraint maxLengthConstraint = new MaxLengthConstraint();
        assertEquals("value must be default", maxLengthConstraint.getMax(), 0);
    }

    @Test
    public void testConstructor2() {
        MaxLengthConstraint maxLengthConstraint = new MaxLengthConstraint(10);
        assertEquals("max value must be the same as was given to constructor", maxLengthConstraint.getMax(), 10);
    }

    @Test
    public void testSetMax() {
        MaxLengthConstraint maxLengthConstraint = new MaxLengthConstraint();
        int maxValue = 100;
        maxLengthConstraint.setMax(maxValue);
        assertEquals("method must return the same value as was given to set method", maxLengthConstraint.getMax(), maxValue);
    }

    @Test
    public void testConfigure() {
        MaxLengthConstraint maxLengthConstraint = new MaxLengthConstraint();
        MaxLength annotation = mock(MaxLength.class);
        int maxValue = 100;
        stub(annotation.value()).toReturn(maxValue);

        maxLengthConstraint.configure(annotation);
        assertEquals("method must return the same value as was set to annotation when configure", maxLengthConstraint.getMax(), maxValue);
    }

    @Test
    public void testValidate_WithValIsNull() {
        assertTrue("result must be true when validate null value", MaxLengthConstraint.validate(null, 1));
    }

    @Test
    public void testMaxLengthConstraint() {
        MaxLengthConstraint maxLengthConstraint = new MaxLengthConstraint(3);
        assertTrue("result must be true when validate a string with size less than maxValue", maxLengthConstraint.isValid(mockContext(), TestUtils.stringWithLength(3)));
        assertFalse("result must be false when validate a string with size greater than maxValue", maxLengthConstraint.isValid(mockContext(), TestUtils.stringWithLength(4)));
    }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8d0b4a1_811f95b/rev_8d0b4a1-811f95b/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
 * InputFormat class for a job. Use getInputFormatClass() instead.
=======
 * InputFormat class for a job. Use getInputFormatClass() or newInstance(typeRef) instead.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8d0b4a1_811f95b/rev_8d0b4a1-811f95b/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
=======
  public LzoProtobufB64LineInputFormat(TypeRef<M> typeRef) {
    super();
    this.typeRef_ = typeRef;
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8d0b4a1_811f95b/rev_8d0b4a1-811f95b/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
  @SuppressWarnings("unchecked")
=======
  @SuppressWarnings("rawtypes")
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_8d0b4a1_811f95b/rev_8d0b4a1-811f95b/src/java/com/twitter/elephantbird/mapreduce/input/LzoProtobufB64LineInputFormat.java;<<<<<<< MINE
=======
  public static<M extends Message> LzoProtobufB64LineInputFormat<M> newInstance(TypeRef<M> typeRef) {
    return new LzoProtobufB64LineInputFormat<M>(typeRef);
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_6c5529a_64bb16e/rev_6c5529a-64bb16e/src/java/com/twitter/elephantbird/pig/piggybank/ThriftToPig.java;<<<<<<< MINE
    /* we are commenting out explicit schema specification. The schema is 
     * included mainly to help the readers of the pig script. Pig learns the 
     * schema directly from the loader. 
=======
    /* we are commenting out explicit schema specification. The schema is
     * included mainly to help the readers of the pig script. Pig learns the
     * schema directly from the loader.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_6c5529a_64bb16e/rev_6c5529a-64bb16e/src/java/com/twitter/elephantbird/pig/piggybank/ThriftToPig.java;<<<<<<< MINE
     * when a Thrift class (possibly in control of another team) changes, 
     * but the Pig script is not updated. Commenting it out work around this. 
=======
     * when a Thrift class (possibly in control of another team) changes,
     * but the Pig script is not updated. Commenting it out work around this.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_6c5529a_64bb16e/rev_6c5529a-64bb16e/src/java/com/twitter/elephantbird/pig/piggybank/ThriftToPig.java;<<<<<<< MINE

  private class TProtoForStruct extends ThriftProtocol {
    // essentially a hack to get to STRUCT_DESC in a Thrift class
    TStruct structDesc;
    @Override
    public void writeStructBegin(TStruct struct) throws TException {
      structDesc = struct;
      throw new TException("expected");
    }
  }

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
 * 
 * Do not use LzoThriftB64LineOutputFormat.class directly for setting 
=======
 *
 * Do not use LzoThriftB64LineOutputFormat.class directly for setting
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
public class LzoThriftB64LineOutputFormat<M extends TBase<?>>
    extends LzoOutputFormat<M, ThriftWritable<M>> {

=======
public class LzoThriftB64LineOutputFormat<M extends TBase<?, ?>>
    extends LzoOutputFormat<M, ThriftWritable<M>> {

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
    
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE

  @Override
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/output/LzoThriftB64LineOutputFormat.java;<<<<<<< MINE
    
    TypeRef<M> typeRef = ThriftUtils.getTypeRef(job.getConfiguration(), LzoThriftB64LineOutputFormat.class);  
=======

    TypeRef<M> typeRef = ThriftUtils.getTypeRef(job.getConfiguration(), LzoThriftB64LineOutputFormat.class);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
 * deserializes that into the Thrift object.  
=======
 * deserializes that into the Thrift object.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
 * 
 * Do not use LzoThriftB64LineInputFormat.class directly for setting 
=======
 *
 * Do not use LzoThriftB64LineInputFormat.class directly for setting
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
public class LzoThriftB64LineInputFormat<M extends TBase<?>>
=======
public class LzoThriftB64LineInputFormat<M extends TBase<?, ?>>
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE

  TypeRef<M> typeRef_ = null;

=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE

  public LzoThriftB64LineInputFormat(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
  }

=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
   * Sets an internal configuration in jobConf so that Task instantiates 
=======
   * Sets an internal configuration in jobConf so that Task instantiates
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE

  public static<M extends TBase<?>> LzoThriftB64LineInputFormat<M> newInstance(TypeRef<M> typeRef) {
    return new LzoThriftB64LineInputFormat<M>(typeRef);
  }

=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/mapreduce/input/LzoThriftB64LineInputFormat.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/pig/load/LzoThriftB64LinePigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import java.nio.charset.Charset;

import org.apache.commons.codec.binary.Base64;
import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.apache.thrift.TBase;
import org.apache.thrift.TException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.mapreduce.io.ThriftConverter;
import com.twitter.elephantbird.pig.piggybank.ThriftToPig;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

public class LzoThriftB64LinePigLoader<M extends TBase<?, ?>> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoThriftB64LinePigLoader.class);

  private final TypeRef<M> typeRef_;
  private final ThriftConverter<M> converter_;
  private final Base64 base64_ = new Base64();
  private final ThriftToPig<M> thriftToPig_;

  private static final Charset UTF8 = Charset.forName("UTF-8");
  private static final byte RECORD_DELIMITER = (byte)'\n';

  private Pair<String, String> linesRead;
  private Pair<String, String> thriftStructsRead;
  private Pair<String, String> thriftErrors;

  public LzoThriftB64LinePigLoader(String thriftClassName) {
    typeRef_ = ThriftUtils.getTypeRef(thriftClassName);
    converter_ = ThriftConverter.newInstance(typeRef_);
    thriftToPig_ =  ThriftToPig.newInstance(typeRef_);

    String group = "LzoB64Lines of " + typeRef_.getRawClass().getName();
    linesRead = new Pair<String, String>(group, "Lines Read");
    thriftStructsRead = new Pair<String, String>(group, "Thrift Structs");
    thriftErrors = new Pair<String, String>(group, "Errors");

    setLoaderSpec(getClass(), new String[]{thriftClassName});
  }

  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // Since we are not block aligned we throw away the first record of each split and count on a different
    // instance to read it.  The only split this doesn't work for is the first.
    if (!atFirstRecord) {
      getNext();
    }
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }

  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    String line;
    Tuple t = null;
    while ((line = is_.readLine(UTF8, RECORD_DELIMITER)) != null) {
      incrCounter(linesRead, 1L);
      M value = converter_.fromBytes(base64_.decode(line.getBytes("UTF-8")));
      if (value != null) {
        try {
          t = thriftToPig_.getPigTuple(value);
          incrCounter(thriftStructsRead, 1L);
          break;
        } catch (TException e) {
          incrCounter(thriftErrors, 1L);
          LOG.warn("ThriftToTuple error :", e); // may be struct mismatch
        }
      }
    }

    return t;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return ThriftToPig.toSchema(typeRef_.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/pig/load/LzoThriftBlockPigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;

import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.apache.thrift.TBase;
import org.apache.thrift.TException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.mapreduce.io.ThriftBlockReader;
import com.twitter.elephantbird.pig.piggybank.ThriftToPig;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;


public class LzoThriftBlockPigLoader<M extends TBase<?, ?>> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoThriftBlockPigLoader.class);

  private final TypeRef<M> typeRef_;
  private final ThriftToPig<M> thriftToPig_;
  private ThriftBlockReader<M> reader_;

  private Pair<String, String> thriftStructsRead;
  private Pair<String, String> thriftErrors;

  public LzoThriftBlockPigLoader(String thriftClassName) {
    typeRef_ = ThriftUtils.getTypeRef(thriftClassName);
    thriftToPig_ =  ThriftToPig.newInstance(typeRef_);

    String group = "LzoBlocks of " + typeRef_.getRawClass().getName();
    thriftStructsRead = new Pair<String, String>(group, "Thrift Structs Read");
    thriftErrors = new Pair<String, String>(group, "Errors");

    setLoaderSpec(getClass(), new String[]{thriftClassName});
  }

  @Override
  public void postBind() throws IOException {
    reader_ = new ThriftBlockReader<M>(is_, typeRef_);
  }

  @Override
  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // We want to explicitly not do any special syncing here, because the reader_
    // handles this automatically.
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }

  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    // If we are past the end of the file split, tell the reader not to read any more new blocks.
    // Then continue reading until the last of the reader's already-parsed values are used up.
    // The next split will start at the next sync point and no records will be missed.
    if (is_.getPosition() > end_) {
      reader_.markNoMoreNewBlocks();
    }

    M value;
    while ((value = reader_.readNext()) != null) {
      try {
        Tuple t = thriftToPig_.getPigTuple(value);
        incrCounter(thriftStructsRead, 1L);
        return t;
      } catch (TException e) {
        incrCounter(thriftErrors, 1L);
        LOG.warn("ThriftToTuple error :", e); // may be corrupt data.
        // try next
      }
    }
    return null;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return ThriftToPig.toSchema(typeRef_.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/pig/load/HBaseSlice.java;<<<<<<< MINE
=======
/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with this
 * work for additional information regarding copyright ownership. The ASF
 * licenses this file to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations under
 * the License.
 */
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.UnknownScannerException;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.client.ResultScanner;
import org.apache.hadoop.hbase.client.Scan;
import org.apache.hadoop.hbase.filter.BinaryComparator;
import org.apache.hadoop.hbase.filter.CompareFilter;
import org.apache.hadoop.hbase.filter.FilterList;
import org.apache.hadoop.hbase.filter.RowFilter;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.hadoop.util.StringUtils;
import org.apache.pig.Slice;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;

import com.google.common.collect.Maps;
import com.twitter.elephantbird.pig.util.PigCounterHelper;

/**
 * HBase Slice to load a portion of range of a table. The key range will be
 * [start, end) Modeled from org.apache.hadoop.hbase.mapred.TableSplit.
 */
public class HBaseSlice implements Slice {

  /** A Generated Serial Version UID **/
  private static final long serialVersionUID = 9035916017187148965L;
  private static final Log LOG = LogFactory.getLog(HBaseSlice.class);
  private transient PigCounterHelper counterHelper_;

  // assigned during construction
  /** Table Name **/
  private final byte[] tableName_;
  /** Table Start Row **/
  private final byte[] startRow_;
  /** Table End Row **/
  private final byte[] endRow_;
  /** Table Region Location **/
  private final String regionLocation_;
  /** Input Columns **/
  private final List<byte[][]> inputColumns_;
  /** Whether the row should be loaded **/
  private final boolean loadRowKey_;

  /** BigInteger representations of row range */
  private final BigInteger bigStart_;
  private final BigInteger bigEnd_;
  private final BigDecimal bigRange_;


  private Map<CompareFilter.CompareOp, String> innerFilters_ = Maps.newHashMap();
  private long limit_ = -1;


  // created as part of init
  /** The connection to the table in Hbase **/
  private transient HTable m_table;
  /** The scanner over the table **/
  private transient ResultScanner m_scanner;
  private transient long seenRows_ = 0;

  private transient ArrayList<Object> mProtoTuple;

  /**
   * Record the last processed row, so that we can restart the scanner when an
   * exception happened during scanning a table
   */
  private transient byte[] m_lastRow_;

  /**
   * Constructor
   *
   * @param tableName
   *            table name
   * @param startRow
   *            start now, inclusive
   * @param endRow
   *            end row, exclusive
   * @param inputColumns
   *            input columns
   * @param location
   *            region location
   */
  public HBaseSlice(byte[] tableName, byte[] startRow, byte[] endRow,
      List<byte[][]> inputColumns, boolean loadRowKey, final String location) {
    tableName_ = tableName;
    startRow_ = startRow;
    endRow_ = endRow;
    inputColumns_ = inputColumns;
    regionLocation_ = location;
    loadRowKey_ = loadRowKey;

    // We have to deal with different byte lengths of keys producing very different
    // BigIntegers (bigendianness is great this way). The code is mostly cribbed
    // from HBase's Bytes class.
    byte [] startPadded;
    byte [] endPadded;
    if (startRow.length < endRow.length) {
      startPadded = Bytes.padTail(startRow, endRow.length - startRow.length);
      endPadded = endRow;
    } else if (endRow.length < startRow.length) {
      startPadded = startRow;
      endPadded = Bytes.padTail(endRow, startRow.length - endRow.length);
    } else {
      startPadded = startRow;
      endPadded = endRow;
    }
    byte [] prependHeader = {1, 0};
    bigStart_ = new BigInteger(Bytes.add(prependHeader, startPadded));
    bigEnd_ = new BigInteger(Bytes.add(prependHeader, endPadded));
    bigRange_ = new BigDecimal(bigEnd_.subtract(bigStart_));
  }

  public void addFilter(CompareFilter.CompareOp compareOp, String filterValue) {
    innerFilters_.put(compareOp, filterValue);
  }

  /** @return table name */
  public byte[] getTableName() {
    return this.tableName_;
  }

  /** @return starting row key */
  public byte[] getStartRow() {
    return this.startRow_;
  }

  /** @return end row key */
  public byte[] getEndRow() {
    return this.endRow_;
  }

  /** @return input columns */
  public List<byte[][]> getInputColumns() {
    return this.inputColumns_;
  }

  /** @return the region's hostname */
  public String getRegionLocation() {
    return this.regionLocation_;
  }

  @Override
  public long getStart() {
    // Not clear how to obtain this in a table...
    return 0;
  }

  @Override
  public long getLength() {
    // Not clear how to obtain this in a table...
    // it seems to be used only for sorting splits
    return 0;
  }

  @Override
  public String[] getLocations() {
    return new String[] { regionLocation_ };
  }

  @Override
  public long getPos() throws IOException {
    // This should be the ordinal tuple in the range;
    // not clear how to calculate...
    return 0;
  }

  @Override
  public float getProgress() throws IOException {

    // No way to know max.. just return 0. Sorry, reporting on the last slice is janky.
    // So is reporting on the first slice, by the way -- it will start out too high, possibly at 100%.
    if (endRow_.length==0) return 0;
    byte[] lastPadded = m_lastRow_;
    if (m_lastRow_.length < endRow_.length) {
      lastPadded = Bytes.padTail(m_lastRow_, endRow_.length - m_lastRow_.length);
    }
    if (m_lastRow_.length < startRow_.length) {
      lastPadded = Bytes.padTail(m_lastRow_, startRow_.length - m_lastRow_.length);
    }
    byte [] prependHeader = {1, 0};
    BigInteger bigLastRow = new BigInteger(Bytes.add(prependHeader, lastPadded));
    BigDecimal processed = new BigDecimal(bigLastRow.subtract(bigStart_));
    try {
      BigDecimal progress = processed.setScale(3).divide(bigRange_, BigDecimal.ROUND_HALF_DOWN);
      return progress.floatValue();
    } catch (java.lang.ArithmeticException e) {
      return 0;
    }
  }

  @Override
  public void init(DataStorage store) throws IOException {
    Configuration conf = HBaseConfiguration.create();
    // connect to the given table
    m_table = new HTable(conf, tableName_);
    // init the scanner
    initScanner();
  }

  /**
   * Init the table scanner
   *
   * @throws IOException
   */
  private void initScanner() throws IOException {
    restart(startRow_);
    m_lastRow_ = startRow_;
  }

  /**
   * Restart scanning from survivable exceptions by creating a new scanner.
   *
   * @param startRow
   *            the start row
   * @throws IOException
   */
  private void restart(byte[] startRow) throws IOException {
    Scan scan;
    if ((endRow_ != null) && (endRow_.length > 0)) {
      scan = new Scan(startRow, endRow_);
    } else {
      scan = new Scan(startRow);
    }

    // Set filters, if any.
    FilterList scanFilter = null;
    if (!innerFilters_.isEmpty()) {
      scanFilter = new FilterList();
      for (Map.Entry<CompareFilter.CompareOp, String>entry  : innerFilters_.entrySet()) {
        scanFilter.addFilter(new RowFilter(entry.getKey(), new BinaryComparator(Bytes.toBytesBinary(entry.getValue()) )));
      }
      scan.setFilter(scanFilter);
    }

    for (byte[][] col : inputColumns_) {
      scan.addColumn(col[0], col[1]);
    }
    this.m_scanner = this.m_table.getScanner(scan);
  }

  @Override
  public boolean next(Tuple value) throws IOException {
    Result result;
    try {
      result = m_scanner.next();
    } catch (UnknownScannerException e) {
      LOG.info("recovered from " + StringUtils.stringifyException(e));
      restart(m_lastRow_);
      if (m_lastRow_ != startRow_) {
        m_scanner.next(); // skip presumed already mapped row
      }
      result = this.m_scanner.next();
    }
    boolean hasMore = result != null && result.size() > 0 && (limit_ < 0 || limit_ > seenRows_);
    if (hasMore) {
      if (counterHelper_ == null) counterHelper_ = new PigCounterHelper();
      counterHelper_.incrCounter(HBaseSlice.class.getName(), Bytes.toString(tableName_) + " rows read", 1);
      m_lastRow_ = result.getRow();
      convertResultToTuple(result, value);
      seenRows_ += 1;
    }
    return hasMore;
  }

  /**
   * Convert a row result to a tuple
   *
   * @param result
   *            row result
   * @param tuple
   *            tuple
   */
  private void convertResultToTuple(Result result, Tuple tuple) {
    if (mProtoTuple == null)
      mProtoTuple = new ArrayList<Object>(inputColumns_.size() + (loadRowKey_ ? 1 : 0));

    if (loadRowKey_) {
      mProtoTuple.add(new DataByteArray(result.getRow()));
    }

    for (byte[][] column : inputColumns_) {
      byte[] value = result.getValue(column[0], column[1]);
      if (value == null) {
        mProtoTuple.add(null);
      } else {
        mProtoTuple.add(new DataByteArray(value));
      }
    }

    Tuple newT = TupleFactory.getInstance().newTuple(mProtoTuple);
    mProtoTuple.clear();
    tuple.reference(newT);
  }

  @Override
  public void close() throws IOException {
    if (m_scanner != null) {
      m_scanner.close();
      m_scanner = null;
    }
  }

  @Override
  public String toString() {
    return regionLocation_ + ":" + Bytes.toString(startRow_) + ","
    + Bytes.toString(endRow_);
  }

  public void setLimit(String limit) {
    LOG.info("Setting Slice limit to "+Long.valueOf(limit));
    limit_ = Long.valueOf(limit);
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/pig/load/HBaseLoader.java;<<<<<<< MINE
=======
/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with this
 * work for additional information regarding copyright ownership. The ASF
 * licenses this file to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations under
 * the License.
 */
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import java.util.List;
import java.util.Map;

import org.apache.commons.cli.CommandLine;
import org.apache.commons.cli.CommandLineParser;
import org.apache.commons.cli.GnuParser;
import org.apache.commons.cli.HelpFormatter;
import org.apache.commons.cli.Options;
import org.apache.commons.cli.ParseException;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.HConstants;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.filter.BinaryComparator;
import org.apache.hadoop.hbase.filter.RowFilter;
import org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.pig.ExecType;
import org.apache.pig.LoadFunc;
import org.apache.pig.Slice;
import org.apache.pig.Slicer;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.io.BufferedPositionedInputStream;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;

import com.google.common.collect.Lists;

/**
 * A <code>Slicer</code> that splits the hbase table into {@link HBaseSlice}s.
 * Actual loading is done in {@link HBaseSlice}. Derived from the HbaseStorage implementation
 * in 0.6 Piggybank.
 * <br>
 * TODO: row version controls<br>
 */
public class HBaseLoader implements Slicer,
LoadFunc {

  private static final Log LOG = LogFactory.getLog(HBaseLoader.class);

  private List<byte[][]> cols_;
  private HTable table_;
  private final Configuration conf_;
  private final boolean loadRowKey_;
  private final CommandLine configuredOptions_;
  private final static Options validOptions_ = new Options();
  private final static CommandLineParser parser_ = new GnuParser();

  private static void populateValidOptions() {
    validOptions_.addOption("loadKey", false, "Load Key");
    validOptions_.addOption("gt", true, "Records must be greater than this value (binary, double-slash-escaped)");
    validOptions_.addOption("lt", true, "Records must be less than this value (binary, double-slash-escaped)");
    validOptions_.addOption("gte", true, "Records must be greater than or equal to this value");
    validOptions_.addOption("lte", true, "Records must be less than or equal to this value");
    validOptions_.addOption("caching", true, "Number of rows scanners should cache");
    validOptions_.addOption("limit", true, "Per-region limit");
  }

  /**
   * Constructor. Construct a HBase Table loader to load the cells of the
   * provided columns.
   *
   * @param columnList
   *            columnlist that is a presented string delimited by space.
   * @throws ParseException
   */
  public HBaseLoader(String columnList) throws ParseException {
    this(columnList, "");
    LOG.info("no-arg constructor");
  }

  /**
   *
   * @param columnList
   * @param optString Loader options. Known options:<ul>
   * <li>-loadKey=(true|false)  Load the row key as the first column
   * <li>-gt=minKeyVal
   * <li>-lt=maxKeyVal
   * <li>-gte=minKeyVal
   * <li>-lte=maxKeyVal
   * <li>-caching=numRows  number of rows to cache (faster scans, more memory).
   * </ul>
   * @throws ParseException
   */
  public HBaseLoader(String columnList, String optString) throws ParseException {
    populateValidOptions();
    String[] colNames = columnList.split(" ");
    String[] optsArr = optString.split(" ");
    try {
      configuredOptions_ = parser_.parse(validOptions_, optsArr);
    } catch (ParseException e) {
      HelpFormatter formatter = new HelpFormatter();
      formatter.printHelp( "", validOptions_ );
      throw e;
    }
    loadRowKey_ = configuredOptions_.hasOption("loadKey");
    cols_ = Lists.newArrayListWithExpectedSize(colNames.length);
    for (int i = 0; i < colNames.length; i++) {
      cols_.add(Bytes.toByteArrays(colNames[i].split(":")));
    }

    conf_ = HBaseConfiguration.create();
  }

  @Override
  public Slice[] slice(DataStorage store, String tablename)
  throws IOException {
    validate(store, tablename);
    if (configuredOptions_.hasOption("caching")) {
      table_.setScannerCaching(Integer.valueOf(configuredOptions_.getOptionValue("caching")));
    }

    byte[][] startKeys = table_.getStartKeys();
    if (startKeys == null || startKeys.length == 0) {
      throw new IOException("Expecting at least one region");
    }
    if (cols_ == null || cols_.size() == 0) {
      throw new IOException("Expecting at least one column");
    }

    // one region one slice
    List<HBaseSlice> slices = Lists.newArrayList();
    for (int i = 0; i < startKeys.length; i++) {

      byte[] endKey = ((i + 1) < startKeys.length) ? startKeys[i + 1] : HConstants.LAST_ROW;

      // skip if the region doesn't satisfy configured options
      if ((skipRegion(CompareOp.LESS, startKeys[i], configuredOptions_.getOptionValue("lt"))) ||
          (skipRegion(CompareOp.GREATER, endKey, configuredOptions_.getOptionValue("gt"))) ||
          (skipRegion(CompareOp.GREATER, endKey, configuredOptions_.getOptionValue("gte"))) ||
          (skipRegion(CompareOp.LESS_OR_EQUAL, startKeys[i], configuredOptions_.getOptionValue("lte")))) {
        continue;
      }
      String regionLocation = table_.getRegionLocation(startKeys[i]).getServerAddress().getHostname();
      HBaseSlice slice = new HBaseSlice(table_.getTableName(), startKeys[i],
          endKey, cols_, loadRowKey_, regionLocation);

      if (configuredOptions_.hasOption("limit")) slice.setLimit(configuredOptions_.getOptionValue("limit"));
      if (configuredOptions_.hasOption("gt")) slice.addFilter(CompareOp.GREATER, slashisize(configuredOptions_.getOptionValue("gt")));
      if (configuredOptions_.hasOption("lt")) slice.addFilter(CompareOp.LESS, slashisize(configuredOptions_.getOptionValue("lt")));
      if (configuredOptions_.hasOption("gte")) slice.addFilter(CompareOp.GREATER_OR_EQUAL, slashisize(configuredOptions_.getOptionValue("gte")));
      if (configuredOptions_.hasOption("lte")) slice.addFilter(CompareOp.LESS_OR_EQUAL, slashisize(configuredOptions_.getOptionValue("lte")));
      slices.add(slice);
    }

    return slices.toArray(new HBaseSlice[] {});
  }

  private boolean skipRegion(CompareOp op, byte[] key, String option ) {
    if (option == null) return false;
    BinaryComparator comp = new BinaryComparator(Bytes.toBytesBinary(slashisize(option)));
    RowFilter rowFilter = new RowFilter(op, comp);
    return rowFilter.filterRowKey(key, 0, key.length);
  }

  /**
   * replace sequences of two slashes ("\\") with one slash ("\")
   * (not escaping a slash in grunt is disallowed, but a double slash doesn't get converted
   * into a regular slash, so we have to do it instead)
   * @param str
   * @return
   */
  private String slashisize(String str) {
    return str.replace("\\\\", "\\");
  }

  @Override
  public void validate(DataStorage store, String tablename)
  throws IOException {
    ensureTable(tablename);
  }

  private void ensureTable(String tablename) throws IOException {
    LOG.info("tablename: " + tablename);

    // We're looking for the right scheme here (actually, we don't
    // care what the scheme is as long as it is one and it's
    // different from hdfs and file. If the user specified to use
    // the multiquery feature and did not specify a scheme we will
    // have transformed it to an absolute path. In that case we'll
    // take the last component and guess that's what was
    // meant. We'll print a warning in that case.
    int index;
    if(-1 != (index = tablename.indexOf("://"))) {
      if (tablename.startsWith("hdfs:")
          || tablename.startsWith("file:")) {
        index = tablename.lastIndexOf("/");
        if (-1 == index) {
          index = tablename.lastIndexOf("\\");
        }

        if (-1 == index) {
          throw new IOException("Got tablename: "+tablename
              +". Either turn off multiquery (-no_multiquery)"
              +" or specify load path as \"hbase://<tablename>\".");
        } else {
          String in = tablename;
          tablename = tablename.substring(index+1);
          LOG.warn("Got tablename: "+in+" Assuming you meant table: "
              +tablename+". Either turn off multiquery (-no_multiquery) "
              +"or specify load path as \"hbase://<tablename>\" "
              +"to avoid this warning.");
        }
      } else {
        tablename = tablename.substring(index+3);
      }
    }

    if (table_ == null) {
      table_ = new HTable(conf_, tablename);
    }
  }

  // HBase LoadFunc
  // Most of the action happens in the Slice class.

  @Override
  public void bindTo(String fileName, BufferedPositionedInputStream is,
      long offset, long end) throws IOException {
    // do nothing
  }

  @Override
  public Schema determineSchema(String fileName, ExecType execType,
      DataStorage storage) throws IOException {
    // do nothing
    return null;
  }

  @Override
  public LoadFunc.RequiredFieldResponse fieldsToRead(LoadFunc.RequiredFieldList requiredFieldList) throws FrontendException {
      return new LoadFunc.RequiredFieldResponse(false);
  }

  @Override
  public Tuple getNext() throws IOException {
    // do nothing
    return null;
  }

  @Override
  public String bytesToCharArray(byte[] b) throws IOException {
    return Bytes.toString(b);
  }

  @Override
  public Double bytesToDouble(byte[] b) throws IOException {
    if (Bytes.SIZEOF_DOUBLE > b.length){
      return Bytes.toDouble(Bytes.padHead(b, Bytes.SIZEOF_DOUBLE - b.length));
    } else {
      return Bytes.toDouble(Bytes.head(b, Bytes.SIZEOF_DOUBLE));
    }
  }

  @Override
  public Float bytesToFloat(byte[] b) throws IOException {
    if (Bytes.SIZEOF_FLOAT > b.length){
      return Bytes.toFloat(Bytes.padHead(b, Bytes.SIZEOF_FLOAT - b.length));
    } else {
      return Bytes.toFloat(Bytes.head(b, Bytes.SIZEOF_FLOAT));
    }
  }

  @Override
  public Integer bytesToInteger(byte[] b) throws IOException {
    if (Bytes.SIZEOF_INT > b.length){
      return Bytes.toInt(Bytes.padHead(b, Bytes.SIZEOF_INT - b.length));
    } else {
      return Bytes.toInt(Bytes.head(b, Bytes.SIZEOF_INT));
    }
  }

  @Override
  public Long bytesToLong(byte[] b) throws IOException {
    if (Bytes.SIZEOF_LONG > b.length){
      return Bytes.toLong(Bytes.padHead(b, Bytes.SIZEOF_LONG - b.length));
    } else {
      return Bytes.toLong(Bytes.head(b, Bytes.SIZEOF_LONG));
    }
  }

  /**
   * NOT IMPLEMENTED
   */
   @Override
   public Map<String, Object> bytesToMap(byte[] b) throws IOException {
     throw new ExecException("can't generate a Map from byte[]");
   }

   /**
    * NOT IMPLEMENTED
    */
   @Override
   public Tuple bytesToTuple(byte[] b) throws IOException {
     throw new ExecException("can't generate a Tuple from byte[]");
   }

   /**
    * NOT IMPLEMENTED
    */
   @Override
   public DataBag bytesToBag(byte[] b) throws IOException {
     throw new ExecException("can't generate DataBags from byte[]");
   }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/pig/piggybank/ThriftToPig.java;<<<<<<< MINE
  private final Class<? extends TBase<?>> tClass_;
  private final ThriftProtocol tProtocol_ = new ThriftProtocol();
  private final Deque<PigContainer> containerStack_ = new ArrayDeque<PigContainer>();
=======
  private Class<? extends TBase<?, ?>> tClass_;
  private ThriftProtocol tProtocol_ = new ThriftProtocol();
  private Deque<PigContainer> containerStack_ = new ArrayDeque<PigContainer>();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b87762a_3125301/rev_b87762a-3125301/src/java/com/twitter/elephantbird/pig/piggybank/BytesToThriftTuple.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.piggybank;

import java.io.IOException;

import org.apache.pig.EvalFunc;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.thrift.TBase;
import org.apache.thrift.TDeserializer;
import org.apache.thrift.TException;
import org.apache.thrift.protocol.TBinaryProtocol;
import org.apache.thrift.transport.TMemoryBuffer;

import com.twitter.elephantbird.util.TypeRef;

/**
 * This is an abstract UDF for converting serialized Thrift objects into Pig tuples.
 * To create a converter for your Thrift class <code>MyThriftClass</code>, you simply need to extend
 * <code>BytesToThriftTuple</code> with something like this:
 *<pre>
 * {@code
 * public class BytesToSimpleLocation extends BytesToThriftTuple<MyThriftClass> {
 *
 *   public BytesToSimpleLocation() {
 *     setTypeRef(new TypeRef<MyThriftClass>() {});
 *   }
 * }}
 *</pre>
 */
public abstract class BytesToThriftTuple<T extends TBase<?, ?>> extends EvalFunc<Tuple> {

  private final TDeserializer deserializer_ = new TDeserializer(new TBinaryProtocol.Factory());
  private ThriftToPig<T> thriftToTuple_;
  private TypeRef<T> typeRef_;

  /**
   * Set the type parameter so it doesn't get erased by Java.  Must be called by the constructor!
   *
   * @param typeRef
   */
  public void setTypeRef(TypeRef<T> typeRef) {
    typeRef_ = typeRef;
    thriftToTuple_ = ThriftToPig.newInstance(typeRef);
  }


  @Override
  public Tuple exec(org.apache.pig.data.Tuple input) throws IOException {
    if (input == null || input.size() < 1) return null;
    try {
      T tObj = typeRef_.safeNewInstance();
      DataByteArray dbarr = (DataByteArray) input.get(0);
      deserializer_.deserialize(tObj, dbarr.get());
      return thriftToTuple_.getPigTuple(tObj);
    } catch (IOException e) {
      log.warn("Caught exception "+e.getMessage());
      return null;
    } catch (TException e) {
      log.warn("Unable to deserialize Thrift object: "+e);
      return null;
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_b5a2a9f_0ca5859/rev_b5a2a9f-0ca5859/curator-framework/src/main/java/com/netflix/curator/framework/imps/CuratorTransactionImpl.java;<<<<<<< MINE
=======
/*
 *
 *  Copyright 2011 Netflix, Inc.
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 */

package com.netflix.curator.framework.imps;

import com.google.common.base.Preconditions;
import com.google.common.collect.ImmutableList;
import com.netflix.curator.RetryLoop;
import com.netflix.curator.framework.api.Pathable;
import com.netflix.curator.framework.api.transaction.CuratorTransaction;
import com.netflix.curator.framework.api.transaction.CuratorTransactionBridge;
import com.netflix.curator.framework.api.transaction.CuratorTransactionFinal;
import com.netflix.curator.framework.api.transaction.CuratorTransactionResult;
import com.netflix.curator.framework.api.transaction.OperationType;
import com.netflix.curator.framework.api.transaction.TransactionCheckBuilder;
import com.netflix.curator.framework.api.transaction.TransactionCreateBuilder;
import com.netflix.curator.framework.api.transaction.TransactionDeleteBuilder;
import com.netflix.curator.framework.api.transaction.TransactionSetDataBuilder;
import org.apache.zookeeper.KeeperException;
import org.apache.zookeeper.Op;
import org.apache.zookeeper.OpResult;
import org.apache.zookeeper.ZooDefs;
import org.apache.zookeeper.data.Stat;
import java.util.Collection;
import java.util.List;
import java.util.concurrent.Callable;
import java.util.concurrent.atomic.AtomicBoolean;

class CuratorTransactionImpl implements CuratorTransaction, CuratorTransactionBridge, CuratorTransactionFinal
{
    private final CuratorFrameworkImpl              client;
    private final CuratorMultiTransactionRecord     transaction;

    private boolean         isCommitted = false;

    CuratorTransactionImpl(CuratorFrameworkImpl client)
    {
        this.client = client;
        transaction = new CuratorMultiTransactionRecord();
    }

    @Override
    public CuratorTransactionFinal and()
    {
        return this;
    }

    @Override
    public TransactionCreateBuilder create()
    {
        Preconditions.checkState(!isCommitted, "transaction already committed");

        return new CreateBuilderImpl(client).asTransactionCreateBuilder(this, transaction);
    }

    @Override
    public TransactionDeleteBuilder delete()
    {
        Preconditions.checkState(!isCommitted, "transaction already committed");

        return new DeleteBuilderImpl(client).asTransactionDeleteBuilder(this, transaction);
    }

    @Override
    public TransactionSetDataBuilder setData()
    {
        Preconditions.checkState(!isCommitted, "transaction already committed");

        return new SetDataBuilderImpl(client).asTransactionSetDataBuilder(this, transaction);
    }

    @Override
    public TransactionCheckBuilder check()
    {
        Preconditions.checkState(!isCommitted, "transaction already committed");

        return new TransactionCheckBuilder()
        {
            private int         version = -1;

            @Override
            public CuratorTransactionBridge forPath(String path) throws Exception
            {
                String      fixedPath = client.fixForNamespace(path);
                transaction.add(Op.check(fixedPath, version), OperationType.CHECK, path);

                return CuratorTransactionImpl.this;
            }

            @Override
            public Pathable<CuratorTransactionBridge> withVersion(int version)
            {
                this.version = version;
                return this;
            }
        };
    }

    @Override
    public Collection<CuratorTransactionResult> commit() throws Exception
    {
        Preconditions.checkState(!isCommitted, "transaction already committed");
        isCommitted = true;

        final AtomicBoolean firstTime = new AtomicBoolean(true);
        List<OpResult>      resultList = RetryLoop.callWithRetry
        (
            client.getZookeeperClient(),
            new Callable<List<OpResult>>()
            {
                @Override
                public List<OpResult> call() throws Exception
                {
                    return doOperation(firstTime);
                }
            }
        );
        
        if ( resultList.size() != transaction.metadataSize() )
        {
            throw new IllegalStateException(String.format("Result size (%d) doesn't match input size (%d)", resultList.size(), transaction.metadataSize()));
        }

        ImmutableList.Builder<CuratorTransactionResult>     builder = ImmutableList.builder();
        for ( int i = 0; i < resultList.size(); ++i )
        {
            OpResult                                    opResult = resultList.get(i);
            CuratorMultiTransactionRecord.TypeAndPath   metadata = transaction.getMetadata(i);
            CuratorTransactionResult                    curatorResult = makeCuratorResult(opResult, metadata);
            builder.add(curatorResult);
        }

        return builder.build();
    }

    private List<OpResult> doOperation(AtomicBoolean firstTime) throws Exception
    {
        boolean         localFirstTime = firstTime.getAndSet(false);
        if ( !localFirstTime )
        {

        }

        List<OpResult>  opResults = client.getZooKeeper().multi(transaction);
        if ( opResults.size() > 0 )
        {
            OpResult        firstResult = opResults.get(0);
            if ( firstResult.getType() == ZooDefs.OpCode.error )
            {
                OpResult.ErrorResult        error = (OpResult.ErrorResult)firstResult;
                KeeperException.Code        code = KeeperException.Code.get(error.getErr());
                if ( code == null )
                {
                    code = KeeperException.Code.UNIMPLEMENTED;
                }
                throw KeeperException.create(code);
            }
        }
        return opResults;
    }

    private CuratorTransactionResult makeCuratorResult(OpResult opResult, CuratorMultiTransactionRecord.TypeAndPath metadata)
    {
        String                                      resultPath = null;
        Stat resultStat = null;
        switch ( opResult.getType() )
        {
            default:
            {
                // NOP
                break;
            }

            case ZooDefs.OpCode.create:
            {
                OpResult.CreateResult       createResult = (OpResult.CreateResult)opResult;
                resultPath = client.unfixForNamespace(createResult.getPath());
                break;
            }

            case ZooDefs.OpCode.setData:
            {
                OpResult.SetDataResult      setDataResult = (OpResult.SetDataResult)opResult;
                resultStat = setDataResult.getStat();
                break;
            }
        }

        return new CuratorTransactionResult(metadata.type, metadata.forPath, resultPath, resultStat);
    }
}>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_b5a2a9f_0ca5859/rev_b5a2a9f-0ca5859/curator-framework/src/main/java/com/netflix/curator/framework/imps/CuratorFrameworkImpl.java;<<<<<<< MINE
=======
    public CuratorTransaction inTransaction()
    {
        Preconditions.checkState(state.get() == State.STARTED, "instance must be started before calling this method");

        return new CuratorTransactionImpl(this);
    }

    @Override
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_1ee1673_859a623/rev_1ee1673-859a623/curator-recipes/src/main/java/com/netflix/curator/framework/recipes/queue/DistributedQueue.java;<<<<<<< MINE
        boolean     isUsingLockSafety = (lockPath != null);
        int         min = minItemsBeforeRefresh;
        for ( String itemNode : children )
=======
        final boolean   isUsingLockSafety = (lockPath != null);
        int             min = minItemsBeforeRefresh;
        for ( final String itemNode : children )
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_1ee1673_859a623/rev_1ee1673-859a623/curator-recipes/src/main/java/com/netflix/curator/framework/recipes/queue/DistributedQueue.java;<<<<<<< MINE
            if ( isUsingLockSafety )
            {
                processWithLockSafety(itemNode, ProcessType.NORMAL);
            }
            else
            {
                processNormally(itemNode, ProcessType.NORMAL);
            }
=======
            executor.execute
            (
                new Runnable()
                {
                    @Override
                    public void run()
                    {
                        try
                        {
                            if ( isUsingLockSafety )
                            {
                                processWithLockSafety(itemNode, ProcessType.NORMAL);
                            }
                            else
                            {
                                processNormally(itemNode, ProcessType.NORMAL);
                            }
                        }
                        catch ( Exception e )
                        {
                            log.error("Error processing message at " + itemNode, e);
                        }
                    }
                }
            );
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_1ee1673_859a623/rev_1ee1673-859a623/curator-recipes/src/test/java/com/netflix/curator/framework/recipes/queue/TestQueueSharder.java;<<<<<<< MINE
            timing.sleepABit();
=======
            timing.forWaiting().sleepABit();
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_1ee1673_859a623/rev_1ee1673-859a623/curator-recipes/src/test/java/com/netflix/curator/framework/recipes/queue/TestQueueSharder.java;<<<<<<< MINE

            timing.sleepABit(); // let queue clear
=======
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_1ee1673_859a623/rev_1ee1673-859a623/curator-recipes/src/test/java/com/netflix/curator/framework/recipes/queue/TestQueueSharder.java;<<<<<<< MINE
=======
            timing.sleepABit(); // let queue clear
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_1ee1673_859a623/rev_1ee1673-859a623/curator-recipes/src/test/java/com/netflix/curator/framework/recipes/queue/TestQueueSharder.java;<<<<<<< MINE
            timing.sleepABit();
=======
            timing.forWaiting().sleepABit();
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_1ee1673_859a623/rev_1ee1673-859a623/curator-recipes/src/test/java/com/netflix/curator/framework/recipes/queue/TestQueueSharder.java;<<<<<<< MINE
            timing.sleepABit();
=======
            timing.forWaiting().sleepABit();
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_1ee1673_859a623/rev_1ee1673-859a623/curator-recipes/src/test/java/com/netflix/curator/framework/recipes/queue/TestQueueSharder.java;<<<<<<< MINE
=======
            timing.sleepABit(); // let queues clear
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_b29bb89_8ab7c2d/rev_b29bb89-8ab7c2d/jodd-core/src/main/java/jodd/util/BCrypt.java;<<<<<<< MINE
		rs.append(Integer.toString(rounds));
		rs.append("$");
		rs.append(encode_base64(saltb, saltb.length));
		rs.append(encode_base64(hashed,
			bf_crypt_ciphertext.length * 4 - 1));
=======
		rs.append(rounds)
				.append("$")
				.append(encode_base64(saltb, saltb.length))
				.append(encode_base64(hashed,
						bf_crypt_ciphertext.length * 4 - 1));
>>>>>>> YOURS
/home/taes/taes/projects/jodd/revisions/rev_b29bb89_8ab7c2d/rev_b29bb89-8ab7c2d/jodd-core/src/main/java/jodd/util/BCrypt.java;<<<<<<< MINE
		rs.append(Integer.toString(log_rounds));
		rs.append("$");
		rs.append(encode_base64(rnd, rnd.length));
=======
		rs.append(log_rounds).append("$")
				.append(encode_base64(rnd, rnd.length));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/java/com/twitter/elephantbird/pig/store/LzoProtobufB64LinePigStorage.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.store;

import java.io.IOException;

import org.apache.commons.codec.binary.Base64;
import org.apache.pig.data.Tuple;

import com.google.protobuf.Message;
import com.google.protobuf.Message.Builder;
import com.twitter.elephantbird.pig.util.PigToProtobuf;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * Serializes Pig Tuples into Base-64 encoded, line-delimited protocol buffers.
 * The fields in the pig tuple must correspond exactly to the fields in the protobuf, as
 * no name-matching is performed (names of the tuple fields are not currently accessible to
 * a StoreFunc. It will be in 0.7, so something more flexible will be possible)
 *
 * @param <M> Protocol Buffer Message class being serialized
 */
public class LzoProtobufB64LinePigStorage<M extends Message> extends LzoBaseStoreFunc {

  private TypeRef<M> typeRef_;
  private Base64 base64_ = new Base64();
  Builder builder_;

  protected LzoProtobufB64LinePigStorage(){}

  public LzoProtobufB64LinePigStorage(String protoClassName) {
    TypeRef<M> typeRef = Protobufs.getTypeRef(protoClassName);
    setTypeRef(typeRef);
  }

  protected void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    builder_ =  Protobufs.getMessageBuilder(typeRef_.getRawClass());
  }

  public void putNext(Tuple f) throws IOException {
    if (f == null) return;
    os_.write(base64_.encode(PigToProtobuf.tupleToMessage(builder_, f).toByteArray()));
    os_.write("\n".getBytes("UTF-8"));
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/java/com/twitter/elephantbird/pig/store/LzoProtobufBlockPigStorage.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.store;

import java.io.IOException;

import org.apache.pig.data.Tuple;

import com.google.protobuf.Message;
import com.google.protobuf.Message.Builder;
import com.twitter.elephantbird.pig.util.PigToProtobuf;
import com.twitter.elephantbird.mapreduce.io.ProtobufBlockWriter;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;
import java.io.OutputStream;


/**
 * Serializes Pig Tuples into Block encodedprotocol buffers.
 * The fields in the pig tuple must correspond exactly to the fields in the protobuf, as
 * no name-matching is performed (names of the tuple fields are not currently accessible to
 * a StoreFunc. It will be in 0.7, so something more flexible will be possible)
 *
 * @param <M> Protocol Buffer Message class being serialized
 */
public class LzoProtobufBlockPigStorage<M extends Message> extends LzoBaseStoreFunc {

  private TypeRef<M> typeRef_;
  Builder builder_;
  protected ProtobufBlockWriter<M> writer_ = null;
  private int numRecordsPerBlock_ = 10000;

  protected LzoProtobufBlockPigStorage() {
  }

  public LzoProtobufBlockPigStorage(String protoClassName) {
    TypeRef<M> typeRef = Protobufs.getTypeRef(protoClassName);
    setTypeRef(typeRef);
  }

  @Override
  public void bindTo(OutputStream os) throws IOException {
		super.bindTo(os);
		writer_ = new ProtobufBlockWriter<M>(os_, typeRef_.getRawClass(), numRecordsPerBlock_);
  }

  protected void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    builder_ = Protobufs.getMessageBuilder(typeRef_.getRawClass());
  }

  @SuppressWarnings("unchecked")
  public void putNext(Tuple f) throws IOException {
    if (f == null) return;
	  writer_.write((M)PigToProtobuf.tupleToMessage(builder_, f));
  }

	@Override
	public void finish() throws IOException {
    if (writer_ != null) {
      writer_.close();
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/java/com/twitter/elephantbird/pig/util/PigToProtobuf.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;

import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.protobuf.ByteString;
import com.google.protobuf.Message;
import com.google.protobuf.Descriptors.FieldDescriptor;
import com.google.protobuf.Message.Builder;
import com.twitter.elephantbird.util.Protobufs;

/**
 * A class for turning Pig Tuples into codegen'd protos for custom Pig StoreFuncs.
 * @author Vikram Oberoi
 */
public class PigToProtobuf {
  private static final Logger LOG = LoggerFactory.getLogger(PigToProtobuf.class);

  public PigToProtobuf() {}

  @SuppressWarnings("unchecked")
  public static <M extends Message> M tupleToMessage(Class<M> protoClass, Tuple tuple) {
    Builder builder = Protobufs.getMessageBuilder(protoClass);
    return (M) tupleToMessage(builder, tuple);
  }

  /**
   * Turn a Tuple into a Message with the given type.
   * @param builder a builder for the Message type the tuple will be converted to
   * @param tuple the tuple
   * @return a message representing the given tuple
   */

  public static Message tupleToMessage(Builder builder, Tuple tuple) {
    List<FieldDescriptor> fieldDescriptors = builder.getDescriptorForType().getFields();

    if (tuple == null) {
      return  builder.build();
    }

    for (int i = 0; i < fieldDescriptors.size() && i < tuple.size(); i++) {
      Object tupleField = null;
      FieldDescriptor fieldDescriptor = fieldDescriptors.get(i);

      try {
        tupleField = tuple.get(i);
      } catch (ExecException e) {
        LOG.warn("Could not convert tuple field " + tupleField + " to field with descriptor " + fieldDescriptor);
        continue;
      }

      if (tupleField != null) {
        if (fieldDescriptor.isRepeated()) {
          // Repeated fields are set with Lists containing objects of the fields' Java type.
          builder.setField(fieldDescriptor, dataBagToRepeatedField(builder, fieldDescriptor, (DataBag)tupleField));
        } else {
          if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
            Builder nestedMessageBuilder = builder.newBuilderForField(fieldDescriptor);
            builder.setField(fieldDescriptor, tupleToMessage((Builder)nestedMessageBuilder, (Tuple)tupleField));
          } else {
            builder.setField(fieldDescriptor, tupleFieldToSingleField(fieldDescriptor, tupleField));
          }
        }
      }
    }

    return builder.build();
  }

  /**
   * Converts a DataBag into a List of objects with the type in the given FieldDescriptor. DataBags
   * don't map cleanly to repeated protobuf types, so each Tuple has to be unwrapped (by taking the
   * first element if the type is primitive or by converting the Tuple to a Message if the type is
   * MESSAGE), and the contents have to be appended to a List.
   * @param containingMessageBuilder a Message builder for the Message that contains this repeated field
   * @param fieldDescriptor a FieldDescriptor for this repeated field
   * @param bag the DataBag being serialized
   * @return a protobuf-friendly List of fieldDescriptor-type objects
   */
  private static List<Object> dataBagToRepeatedField(Builder containingMessageBuilder, FieldDescriptor fieldDescriptor, DataBag bag) {
    ArrayList<Object> bagContents = new ArrayList<Object>((int)bag.size());
    Iterator<Tuple> bagIter = bag.iterator();

    while (bagIter.hasNext()) {
      Tuple tuple = bagIter.next();
      if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
        Builder nestedMessageBuilder = containingMessageBuilder.newBuilderForField(fieldDescriptor);
        bagContents.add(tupleToMessage((Builder)nestedMessageBuilder, tuple));
      } else {
        try {
          bagContents.add(tupleFieldToSingleField(fieldDescriptor, tuple.get(0)));
        } catch (ExecException e) {
          LOG.warn("Could not add a value for repeated field with descriptor " + fieldDescriptor);
        }
      }
    }

    return bagContents;
  }

  /**
   * Converts a tupleField string to its corresponding protobuf enum type if necessary, otherwise
   * returns the tupleField as is.
   * @param fieldDescriptor the FieldDescriptor for the given tuple field
   * @param tupleField the tupleField being converted to a protobuf field
   * @return the protobuf type for the given tupleField. This will be the tupleField itself unless it's an enum, in which case this will return the enum type for the field.
   */
  private static Object tupleFieldToSingleField(FieldDescriptor fieldDescriptor, Object tupleField) {
    // type convertion should match with ProtobufToPig.getPigScriptDataType
    switch (fieldDescriptor.getType()) {
    case ENUM:
      // Convert tupleField to the enum value.
      return fieldDescriptor.getEnumType().findValueByName((String)tupleField);
    case BOOL:
      return Boolean.valueOf((Integer)tupleField != 0);
    case BYTES:
      return ByteString.copyFrom(((DataByteArray)tupleField).get());
    default:
      return tupleField;
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/java/com/twitter/elephantbird/pig/load/LzoThriftB64LinePigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import java.nio.charset.Charset;

import org.apache.commons.codec.binary.Base64;
import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.apache.thrift.TBase;
import org.apache.thrift.TException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.mapreduce.io.ThriftConverter;
import com.twitter.elephantbird.pig.util.ThriftToPig;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

public class LzoThriftB64LinePigLoader<M extends TBase<?, ?>> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoThriftB64LinePigLoader.class);

  private final TypeRef<M> typeRef_;
  private final ThriftConverter<M> converter_;
  private final Base64 base64_ = new Base64();
  private final ThriftToPig<M> thriftToPig_;

  private static final Charset UTF8 = Charset.forName("UTF-8");
  private static final byte RECORD_DELIMITER = (byte)'\n';

  private Pair<String, String> linesRead;
  private Pair<String, String> thriftStructsRead;
  private Pair<String, String> thriftErrors;

  public LzoThriftB64LinePigLoader(String thriftClassName) {
    typeRef_ = ThriftUtils.getTypeRef(thriftClassName);
    converter_ = ThriftConverter.newInstance(typeRef_);
    thriftToPig_ =  ThriftToPig.newInstance(typeRef_);

    String group = "LzoB64Lines of " + typeRef_.getRawClass().getName();
    linesRead = new Pair<String, String>(group, "Lines Read");
    thriftStructsRead = new Pair<String, String>(group, "Thrift Structs");
    thriftErrors = new Pair<String, String>(group, "Errors");

    setLoaderSpec(getClass(), new String[]{thriftClassName});
  }

  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // Since we are not block aligned we throw away the first record of each split and count on a different
    // instance to read it.  The only split this doesn't work for is the first.
    if (!atFirstRecord) {
      getNext();
    }
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }

  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    String line;
    Tuple t = null;
    while ((line = is_.readLine(UTF8, RECORD_DELIMITER)) != null) {
      incrCounter(linesRead, 1L);
      M value = converter_.fromBytes(base64_.decode(line.getBytes("UTF-8")));
      if (value != null) {
        try {
          t = thriftToPig_.getPigTuple(value);
          incrCounter(thriftStructsRead, 1L);
          break;
        } catch (TException e) {
          incrCounter(thriftErrors, 1L);
          LOG.warn("ThriftToTuple error :", e); // may be struct mismatch
        }
      }
    }

    return t;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return ThriftToPig.toSchema(typeRef_.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/java/com/twitter/elephantbird/pig/load/LzoThriftBlockPigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;

import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.apache.thrift.TBase;
import org.apache.thrift.TException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.mapreduce.io.ThriftBlockReader;
import com.twitter.elephantbird.pig.util.ThriftToPig;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;


public class LzoThriftBlockPigLoader<M extends TBase<?, ?>> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoThriftBlockPigLoader.class);

  private final TypeRef<M> typeRef_;
  private final ThriftToPig<M> thriftToPig_;
  private ThriftBlockReader<M> reader_;

  private Pair<String, String> thriftStructsRead;
  private Pair<String, String> thriftErrors;

  public LzoThriftBlockPigLoader(String thriftClassName) {
    typeRef_ = ThriftUtils.getTypeRef(thriftClassName);
    thriftToPig_ =  ThriftToPig.newInstance(typeRef_);

    String group = "LzoBlocks of " + typeRef_.getRawClass().getName();
    thriftStructsRead = new Pair<String, String>(group, "Thrift Structs Read");
    thriftErrors = new Pair<String, String>(group, "Errors");

    setLoaderSpec(getClass(), new String[]{thriftClassName});
  }

  @Override
  public void postBind() throws IOException {
    reader_ = new ThriftBlockReader<M>(is_, typeRef_);
  }

  @Override
  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // We want to explicitly not do any special syncing here, because the reader_
    // handles this automatically.
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }

  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    // If we are past the end of the file split, tell the reader not to read any more new blocks.
    // Then continue reading until the last of the reader's already-parsed values are used up.
    // The next split will start at the next sync point and no records will be missed.
    if (is_.getPosition() > end_) {
      reader_.markNoMoreNewBlocks();
    }

    M value;
    while ((value = reader_.readNext()) != null) {
      try {
        Tuple t = thriftToPig_.getPigTuple(value);
        incrCounter(thriftStructsRead, 1L);
        return t;
      } catch (TException e) {
        incrCounter(thriftErrors, 1L);
        LOG.warn("ThriftToTuple error :", e); // may be corrupt data.
        // try next
      }
    }
    return null;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return ThriftToPig.toSchema(typeRef_.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/java/com/twitter/elephantbird/pig/piggybank/ThriftToPig.java;<<<<<<< MINE
package com.twitter.elephantbird.pig.piggybank;

import java.lang.reflect.Field;
import java.nio.ByteBuffer;
import java.util.ArrayDeque;
import java.util.Deque;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import org.apache.pig.LoadFunc;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.BagFactory;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.DataType;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
import org.apache.thrift.TBase;
import org.apache.thrift.TEnum;
import org.apache.thrift.TException;
import org.apache.thrift.TFieldIdEnum;
import org.apache.thrift.meta_data.EnumMetaData;
import org.apache.thrift.meta_data.FieldMetaData;
import org.apache.thrift.meta_data.FieldValueMetaData;
import org.apache.thrift.meta_data.ListMetaData;
import org.apache.thrift.meta_data.MapMetaData;
import org.apache.thrift.meta_data.SetMetaData;
import org.apache.thrift.meta_data.StructMetaData;
import org.apache.thrift.protocol.TField;
import org.apache.thrift.protocol.TList;
import org.apache.thrift.protocol.TMap;
import org.apache.thrift.protocol.TMessage;
import org.apache.thrift.protocol.TProtocol;
import org.apache.thrift.protocol.TSet;
import org.apache.thrift.protocol.TStruct;
import org.apache.thrift.protocol.TType;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.collect.ImmutableMap;
import com.google.common.collect.Lists;
import com.google.common.collect.Maps;
import com.twitter.elephantbird.pig8.load.LzoThriftB64LinePigLoader;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

/**
 * <li> converts a Thrift struct to a Pig tuple
 * <li> utilities to provide schema for Pig loaders and Pig scripts
 */
public class ThriftToPig<M extends TBase<?, ?>> {
  private static final Logger LOG = LoggerFactory.getLogger(ThriftToPig.class);

  /* TODO :
   * 1. Add lazy deserialization like ProtobufTuple does. Not sure if it can be done
   *    efficiently for Thrift.
   * 2. Converting Enum to names (strings) is supported only in the common
   *    case where Enum is part of a struct. Enum used directly in containers
   *    (e.g. list<SomeEnum>) are still integers. The issue is that Thrift
   *    does not explicitly tell that it is writing an Enum. We need to
   *    deduce that from the context. In the case of Structs, we already
   *    maintain this contexts.
   *
   *    In order to support enums-to-strings correctly we need to maintain more
   *    state and we should always know exact context/recursion of Thrift
   *    struct's write() method.
   *
   *    This is certainly do-able. Once we keep track of serialization
   *    so closely, we not far from implementing our own generic write() method.
   *    implementing generic write method will let us deserialize thrift buffer
   *    directly to a Pig Tuple and there is no need to use a Thrift object
   *    as intermediate step. This will also let us support
   *    lazy-deserialization and projections efficiently since we direclty
   *    access the thrift buffer.
   */
  private static BagFactory bagFactory_ = BagFactory.getInstance();
  private static TupleFactory tupleFactory_  = TupleFactory.getInstance();

  private Class<? extends TBase<?, ?>> tClass_;
  private ThriftProtocol tProtocol_ = new ThriftProtocol();
  private Deque<PigContainer> containerStack_ = new ArrayDeque<PigContainer>();
  private PigContainer curContainer_;
  private Tuple curTuple_;

  // We want something that provides a generic interface for populating
  // Pig Tuples, Bags, and Maps. This does the trick.

  private abstract class PigContainer {
    StructDescriptor structDesc; // The current thrift struct being written
    FieldDescriptor curFieldDesc;
    public abstract Object getContents();
    public abstract void add(Object o) throws TException;

    /** set curFieldDesc if the container is is Thrift Struct. */
    public void setCurField(TField tField) throws TException {
      if (structDesc != null) {
        curFieldDesc = structDesc.fieldMap.get(tField.id);
        if (curFieldDesc == null) {
          throw new TException("Unexpected TField " + tField + " for " + tClass_.getName());
        }
      }
    }
  }

  private class TupleWrap extends PigContainer {

    private final Tuple t;

    public TupleWrap(int size) {
      t = tupleFactory_.newTuple(size);
    }

    @Override
    public Object getContents() { return t; }

    @Override
    public void add(Object o) throws TException {
      if (curFieldDesc == null) {
        throw new TException("Internal Error. curFieldDesc is not set");
      }
      if (curFieldDesc.enumMap != null && // map enum to string
          (o = curFieldDesc.enumMap.get(o)) == null) {
        throw new TException("cound not find Enum string");
      }
      try {
        t.set(curFieldDesc.tupleIdx, o);
       } catch (ExecException e) {
          throw new TException(e);
       }
    }
  }

  private class BagWrap extends PigContainer {
    List<Tuple> tuples;

    public BagWrap(int size) {
      tuples =  Lists.newArrayListWithCapacity(size);
    }

    @Override
    public void add(Object o) throws TException {
      // Pig bags contain tuples of objects, so we must wrap a tuple around
      // everything we get.
      if (o instanceof Tuple) {
        tuples.add((Tuple) o);
      } else {
        tuples.add(tupleFactory_.newTuple(o));
      }
    }

    @Override
    public Object getContents() {
      return bagFactory_.newDefaultBag(tuples);
    }
  }

  private class MapWrap extends PigContainer {
    private final Map<String, Object> map;
    String currKey = null;

    public MapWrap(int size) {
      map = new HashMap<String, Object>(size);
    }

    @Override
    public void add(Object o) throws TException {
      //we alternate between String keys and (converted) DataByteArray values.
      if (currKey == null) {
        try {
          currKey = (String) o;
        } catch (ClassCastException e) {
          throw new TException("Only String keys are allowed in maps.");
        }
      } else {
        map.put(currKey, o);
        currKey = null;
      }
    }

    @Override
    public Object getContents() {
      return map;
    }
  }


  private void pushContainer(PigContainer c) {
    containerStack_.addLast(c);
    curContainer_ = c;
  }

  private PigContainer popContainer() throws TException {
    PigContainer c = containerStack_.removeLast();
    curContainer_ = containerStack_.peekLast();
    if (curContainer_ == null) { // All done!
      curTuple_ = (Tuple) c.getContents();
    } else {
      curContainer_.add(c.getContents());
    }
    return c;
  }

  public static <M extends TBase<?, ?>> ThriftToPig<M> newInstance(Class<M> tClass) {
    return new ThriftToPig<M>(tClass);
  }

  public static <M extends TBase<?, ?>> ThriftToPig<M> newInstance(TypeRef<M> typeRef) {
    return new ThriftToPig<M>(typeRef.getRawClass());
  }

  public ThriftToPig(Class<M> tClass) {
    this.tClass_ = tClass;
    structMap = Maps.newHashMap();
    updateStructMap(tClass_);
    structMap = ImmutableMap.copyOf(structMap);
    reset();
  }

  /**
   * The protocol should be reset before each object that is serialized.
   * This is important since, the protocol itself can not reliably
   * realize if it at the beginning of a new object. It can not always
   * rely on the last object being correct written because of
   * any exceptions while processing previous object.
   */
  public void reset() {
    containerStack_.clear();
    curContainer_ = null;
    curTuple_ = null;
  }

  /**
   * Converts a thrift object to Pig tuple.
   * Throws TException in case of any errors.
   */
  public Tuple getPigTuple(M thriftObj) throws TException {
    reset();
    thriftObj.write(tProtocol_);
    if (curTuple_ != null) {
      return curTuple_;
    }
    // unexpected
    throw new TException("Internal error. tuple is not set");
  }

  /**
   * returns 'enum int -> enum name' mapping
   */
  static private Map<Integer, String> extractEnumMap(FieldValueMetaData field) {
    MetaData f = new MetaData(field);
    if (!f.isEnum()) {
      return null;
    }
    Map<Integer, String> map = Maps.newHashMap();
    for(TEnum e : f.getEnumClass().getEnumConstants()) {
      map.put(e.getValue(), e.toString());
    }
    return ImmutableMap.copyOf(map);
  }

  /**
   * holds relevant info for a field in a Thrift Struct including
   * index into tuple array.
   */
  private static class FieldDescriptor {
    TFieldIdEnum fieldEnum;
    int tupleIdx;
    Map<Integer, String> enumMap = null; // set for enums
  }

  /**
   * describes a Thrift struct. Contains following info :
   * <li> Thrift field descriptor map
   * <li> ...
   */
  private static class StructDescriptor {
    Map<Short, FieldDescriptor> fieldMap;

    public StructDescriptor(Class<? extends TBase<?, ?>> tClass) {
      fieldMap = Maps.newHashMap();
      int idx = 0;
      for (Entry<? extends TFieldIdEnum, FieldMetaData> e : FieldMetaData.getStructMetaDataMap(tClass).entrySet()) {
        FieldDescriptor desc = new FieldDescriptor();
        desc.fieldEnum = e.getKey();
        desc.tupleIdx = idx++;
        if (e.getValue().valueMetaData.type == TType.ENUM) {
          desc.enumMap = extractEnumMap(e.getValue().valueMetaData);
        }
        fieldMap.put(desc.fieldEnum.getThriftFieldId(), desc);
      }
      fieldMap = ImmutableMap.copyOf(fieldMap);
    }
  }

  private Map<TStruct, StructDescriptor> structMap;

  private void updateStructMap(Class<? extends TBase<?, ?>> tClass) {
    final TStruct tStruct = getStructDesc(tClass);

    if (structMap.get(tStruct) != null) {
      return;
    }

    StructDescriptor desc = new StructDescriptor(tClass);
    LOG.debug("adding struct descriptor for " + tClass.getName()
        + " with " + desc.fieldMap.size() + " fields");
    structMap.put(tStruct, desc);
    // recursively add any referenced classes.
    for (FieldMetaData field : FieldMetaData.getStructMetaDataMap(tClass).values()) {
      updateStructMap(field.valueMetaData);
    }
  }

  /**
   * Look for any class embedded in the in the container or struct fields
   * and update the struct map with them.
   */
  private void updateStructMap(FieldValueMetaData field) {
    MetaData f = new MetaData(field);

    if (f.isStruct()) {
      updateStructMap(f.getStructClass());
    }

    if (f.isList()) {
      updateStructMap(f.getListElem());
    }

    if (f.isMap()) {
      if (f.getMapKey().type != TType.STRING) {
        throw new IllegalArgumentException("Pig does not support maps with non-string keys "
            + "while initializing ThriftToPig for " + tClass_.getName());
      }
      updateStructMap(f.getMapKey());
      updateStructMap(f.getMapValue());
    }

    if (f.isSet()) {
      updateStructMap(f.getSetElem());
    }
  }

  private class ThriftProtocol extends TProtocol {

    ThriftProtocol() {
      super(null); // this protocol is not used for transport.
    }

    @Override
    public void writeBinary(ByteBuffer bin) throws TException {
      byte[] buf = new byte[bin.remaining()];
      bin.mark();
      bin.get(buf);
      bin.reset();
      curContainer_.add(new DataByteArray(buf));
      /* We could use DataByteArray(byte[], start, end) and avoid a
       * copy here.  But the constructor will make a (quite inefficient) copy.
       */
    }

    @Override
    public void writeBool(boolean b) throws TException {
      curContainer_.add(Integer.valueOf(b ? 1 : 0));
    }

    @Override
    public void writeByte(byte b) throws TException {
      curContainer_.add(Integer.valueOf(b));
    }

    @Override
    public void writeDouble(double dub) throws TException {
      curContainer_.add(Double.valueOf(dub));
    }

    @Override
    public void writeFieldBegin(TField field) throws TException {
      curContainer_.setCurField(field);
    }

    @Override
    public void writeFieldEnd() throws TException {
    }

    @Override
    public void writeFieldStop() throws TException {
    }

    @Override
    public void writeI16(short i16) throws TException {
      curContainer_.add(Integer.valueOf(i16));
    }

    @Override
    public void writeI32(int i32) throws TException {
      curContainer_.add(i32);
    }

    @Override
    public void writeI64(long i64) throws TException {
      curContainer_.add(i64);
    }

    @Override
    public void writeListBegin(TList list) throws TException {
      pushContainer(new BagWrap(list.size));
    }

    @Override
    public void writeListEnd() throws TException {
      popContainer();
    }

    @Override
    public void writeMapBegin(TMap map) throws TException {
      pushContainer(new MapWrap(map.size));
    }

    @Override
    public void writeMapEnd() throws TException {
      popContainer();
    }

    @Override
    public void writeSetBegin(TSet set) throws TException {
      pushContainer(new BagWrap(set.size));
    }

    @Override
    public void writeSetEnd() throws TException {
      popContainer();
    }

    @Override
    public void writeString(String str) throws TException {
      curContainer_.add(str);
    }

    @Override
    public void writeStructBegin(TStruct struct) throws TException {
      StructDescriptor desc = structMap.get(struct);
      if (desc == null) {
        throw new TException("Unexpected TStruct " + struct.name + " for " + tClass_.getName());
      }
      PigContainer c = new TupleWrap(desc.fieldMap.size());
      c.structDesc = desc;
      pushContainer(c);
    }

    @Override
    public void writeStructEnd() throws TException {
      popContainer();
    }

    @Override
    public void writeMessageBegin(TMessage message) throws TException {
      throw new TException("method not implemented.");
    }
    @Override
    public void writeMessageEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public ByteBuffer readBinary() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public boolean readBool() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public byte readByte() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public double readDouble() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TField readFieldBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readFieldEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public short readI16() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public int readI32() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public long readI64() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TList readListBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readListEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TMap readMapBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readMapEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TMessage readMessageBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readMessageEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TSet readSetBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readSetEnd() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public String readString() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public TStruct readStructBegin() throws TException {
      throw new TException("method not implemented.");
    }

    @Override
    public void readStructEnd() throws TException {
      throw new TException("method not implemented.");
    }
  }

  /**
   * A utility class to help with type checking of a ThriftField.
   * Avoids checking type and not-so-readable casting in many places.
   */
  static class MetaData {
    final FieldValueMetaData field;

    MetaData(FieldValueMetaData field) {
      this.field = field;
    }

    FieldValueMetaData getField() {
      return field;
    }

    // List
    boolean isList() {
      return field instanceof ListMetaData;
    }

    FieldValueMetaData getListElem() {
      return ((ListMetaData)field).elemMetaData;
    }

    // Enum
    boolean isEnum() {
      return field instanceof EnumMetaData;
    }

    Class<? extends TEnum> getEnumClass() {
      return ((EnumMetaData)field).enumClass;
    }

    // Map
    boolean isMap() {
      return field instanceof MapMetaData;
    }

    FieldValueMetaData getMapKey() {
      return ((MapMetaData)field).keyMetaData;
    }

    FieldValueMetaData getMapValue() {
      return ((MapMetaData)field).valueMetaData;
    }

    // Set
    boolean isSet() {
      return field instanceof SetMetaData;
    }

    FieldValueMetaData getSetElem() {
      return ((SetMetaData)field).elemMetaData;
    }

    // Struct
    boolean isStruct() {
      return field instanceof StructMetaData;
    }

    @SuppressWarnings("unchecked")
    Class<? extends TBase<?, ?>> getStructClass() {
      return (Class <? extends TBase<?, ?>>)((StructMetaData)field).structClass;
    }
  }

  /**
   * Returns Pig schema for the Thrift struct.
   */
  public static Schema toSchema(Class<? extends TBase<?, ?>> tClass) {
    Schema schema = new Schema();

    try {
      for (Entry<? extends TFieldIdEnum, FieldMetaData> e : FieldMetaData.getStructMetaDataMap(tClass).entrySet()) {
        FieldMetaData meta = e.getValue();
        FieldValueMetaData field = e.getValue().valueMetaData;
        MetaData fm = new MetaData(field);
        if (fm.isStruct()) {
          schema.add(new FieldSchema(meta.fieldName, toSchema(fm.getStructClass()), DataType.TUPLE));
        } else if (fm.isEnum()) { // enums in Structs are strings (enums in containers are not, yet)
          schema.add(new FieldSchema(meta.fieldName, null, DataType.CHARARRAY));
        } else {
          schema.add(singleFieldToFieldSchema(meta.fieldName, field));
        }
      }
    } catch (FrontendException t) {
      throw new RuntimeException(t);
    }

    return schema;
  }

  private static FieldSchema singleFieldToFieldSchema(String fieldName, FieldValueMetaData field) throws FrontendException {

    MetaData fm = new MetaData(field);

    switch (field.type) {
      case TType.LIST:
        return new FieldSchema(fieldName, singleFieldToTupleSchema(fieldName + "_tuple", fm.getListElem()), DataType.BAG);
      case TType.SET:
        return new FieldSchema(fieldName, singleFieldToTupleSchema(fieldName + "_tuple", fm.getSetElem()), DataType.BAG);
      case TType.MAP:
        // can not specify types for maps in Pig.
        return new FieldSchema(fieldName, null, DataType.MAP);
      default:
        return new FieldSchema(fieldName, null, getPigDataType(field));
    }
  }

  /**
   * Returns a schema with single tuple (for Pig bags).
   */
  private static Schema singleFieldToTupleSchema(String fieldName, FieldValueMetaData field) throws FrontendException {
    MetaData fm = new MetaData(field);
    FieldSchema fieldSchema = null;

    switch (field.type) {
      case TType.STRUCT:
        fieldSchema = new FieldSchema(fieldName, toSchema(fm.getStructClass()), DataType.TUPLE);
        break;
      case TType.LIST:
        fieldSchema = singleFieldToFieldSchema(fieldName, fm.getListElem());
        break;
      case TType.SET:
        fieldSchema = singleFieldToFieldSchema(fieldName, fm.getSetElem());
        break;
      default:
        fieldSchema = new FieldSchema(fieldName, null, getPigDataType(fm.getField()));
    }

    Schema schema = new Schema();
    schema.add(fieldSchema);
    return schema;
  }

  private static byte getPigDataType(FieldValueMetaData field) {
    switch (field.type) {
      case TType.BOOL:
      case TType.BYTE:
      case TType.I16:
      case TType.I32:
      case TType.ENUM: // will revisit this once Enums in containers are also strings.
        return DataType.INTEGER;
      case TType.I64:
        return DataType.LONG;
      case TType.STRING:
        return DataType.CHARARRAY;
      default:
        throw new IllegalArgumentException("Unexpected type where a simple type is expected : " + field.type);
    }
  }

  /**
   * Turn a Thrift Struct into a loading schema for a pig script.
   */
  public static String toPigScript(Class<? extends TBase<?, ?>> thriftClass,
                                   Class<? extends LoadFunc> pigLoader) {
    StringBuilder sb = new StringBuilder();
    /* we are commenting out explicit schema specification. The schema is
     * included mainly to help the readers of the pig script. Pig learns the
     * schema directly from the loader.
     * If explicit schema is not commented, we might have surprising results
     * when a Thrift class (possibly in control of another team) changes,
     * but the Pig script is not updated. Commenting it out work around this.
     */
    StringBuilder prefix = new StringBuilder("       --  ");
    sb.append("raw_data = load '$INPUT_FILES' using ")
      .append(pigLoader.getName())
      .append("('")
      .append(thriftClass.getName())
      .append("');\n")
      .append(prefix)
      .append("as ");
    prefix.append("   ");

    try {
      stringifySchema(sb, toSchema(thriftClass), DataType.TUPLE, prefix);
    } catch (FrontendException e) {
      throw new RuntimeException(e);
    }

    sb.append("\n");
    return sb.toString();
  }

  /**
   * Print formatted schema. This is a modified version of
   * {@link Schema#stringifySchema(StringBuilder, Schema, byte)}
   * with support for (indented) pretty printing.
   */
  // This is used for building up output string
  // type can only be BAG or TUPLE
  public static void stringifySchema(StringBuilder sb,
                                     Schema schema,
                                     byte type,
                                     StringBuilder prefix)
                                          throws FrontendException{
      // this is a modified version of {@link Schema#stringifySchema(StringBuilder, Schema, byte)}
      if (type == DataType.TUPLE) {
          sb.append("(") ;
      }
      else if (type == DataType.BAG) {
          sb.append("{") ;
      }

      prefix.append("  ");
      sb.append("\n").append(prefix);

      if (schema == null) {
          sb.append("null") ;
      }
      else {
          boolean isFirst = true ;
          for (int i=0; i< schema.size() ;i++) {

              if (!isFirst) {
                  sb.append(",\n").append(prefix);
              }
              else {
                  isFirst = false ;
              }

              FieldSchema fs = schema.getField(i) ;

              if(fs == null) {
                  sb.append("null");
                  continue;
              }

              if (fs.alias != null) {
                  sb.append(fs.alias);
                  sb.append(": ");
              }

              if (DataType.isAtomic(fs.type)) {
                  sb.append(DataType.findTypeName(fs.type)) ;
              }
              else if ( (fs.type == DataType.TUPLE) ||
                        (fs.type == DataType.BAG) ) {
                  // safety net
                  if (schema != fs.schema) {
                      stringifySchema(sb, fs.schema, fs.type, prefix) ;
                  }
                  else {
                      throw new AssertionError("Schema refers to itself "
                                               + "as inner schema") ;
                  }
              } else if (fs.type == DataType.MAP) {
                  sb.append(DataType.findTypeName(fs.type) + "[ ]") ;
              } else {
                  sb.append(DataType.findTypeName(fs.type)) ;
              }
          }
      }

      prefix.setLength(prefix.length()-2);
      sb.append("\n").append(prefix);

      if (type == DataType.TUPLE) {
          sb.append(")") ;
      }
      else if (type == DataType.BAG) {
          sb.append("}") ;
      }
  }

  private TStruct getStructDesc(Class<? extends TBase<?, ?>> tClass) {
    // hack to get hold of STRUCT_DESC of a thrift class:
    // Access 'private static final' field STRUCT_DESC using reflection.
    // Bad practice, but not sure if there is a better way.
    try {
      Field f = tClass.getDeclaredField("STRUCT_DESC");
      f.setAccessible(true);
      return (TStruct) f.get(null);
    } catch (Throwable t) {
      throw new RuntimeException(t);
    }
  }

  public static void main(String[] args) throws Exception {
    if (args.length > 0) {
      Class<? extends TBase<?, ?>> tClass = ThriftUtils.getTypeRef(args[0]).getRawClass();
      System.out.println(args[0] + " : " + toSchema(tClass).toString());
      System.out.println(toPigScript(tClass, LzoThriftB64LinePigLoader.class));
    }
  }
}=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/java/com/twitter/elephantbird/pig/piggybank/BytesToThriftTuple.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.piggybank;

import java.io.IOException;

import org.apache.pig.EvalFunc;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.thrift.TBase;
import org.apache.thrift.TDeserializer;
import org.apache.thrift.TException;
import org.apache.thrift.protocol.TBinaryProtocol;
import org.apache.thrift.transport.TMemoryBuffer;

import com.twitter.elephantbird.pig.util.ThriftToPig;
import com.twitter.elephantbird.util.TypeRef;

/**
 * This is an abstract UDF for converting serialized Thrift objects into Pig tuples.
 * To create a converter for your Thrift class <code>MyThriftClass</code>, you simply need to extend
 * <code>BytesToThriftTuple</code> with something like this:
 *<pre>
 * {@code
 * public class BytesToSimpleLocation extends BytesToThriftTuple<MyThriftClass> {
 *
 *   public BytesToSimpleLocation() {
 *     setTypeRef(new TypeRef<MyThriftClass>() {});
 *   }
 * }}
 *</pre>
 */
public abstract class BytesToThriftTuple<T extends TBase<?, ?>> extends EvalFunc<Tuple> {

  private final TDeserializer deserializer_ = new TDeserializer(new TBinaryProtocol.Factory());
  private ThriftToPig<T> thriftToTuple_;
  private TypeRef<T> typeRef_;

  /**
   * Set the type parameter so it doesn't get erased by Java.  Must be called by the constructor!
   *
   * @param typeRef
   */
  public void setTypeRef(TypeRef<T> typeRef) {
    typeRef_ = typeRef;
    thriftToTuple_ = ThriftToPig.newInstance(typeRef);
  }


  @Override
  public Tuple exec(org.apache.pig.data.Tuple input) throws IOException {
    if (input == null || input.size() < 1) return null;
    try {
      T tObj = typeRef_.safeNewInstance();
      DataByteArray dbarr = (DataByteArray) input.get(0);
      deserializer_.deserialize(tObj, dbarr.get());
      return thriftToTuple_.getPigTuple(tObj);
    } catch (IOException e) {
      log.warn("Caught exception "+e.getMessage());
      return null;
    } catch (TException e) {
      log.warn("Unable to deserialize Thrift object: "+e);
      return null;
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.piggybank;

import java.io.IOException;

import org.apache.pig.EvalFunc;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;

import com.google.protobuf.Message;
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
import com.twitter.elephantbird.pig.util.ProtobufTuple;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * The base class for a Pig UDF that takes as input a tuple containing a single element, the
 * bytes of a serialized protocol buffer as a DataByteArray.  It outputs the protobuf in
 * expanded form.  The specific protocol buffer is a template parameter, generally specified by a
 * codegen'd derived class. See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
 * Alternatly, full class name could be passed to the constructor in Pig:
 * <pre>
 *   DEFINE PersonProtobufBytesToTuple com.twitter.elephantbird.pig.piggybank.ProtobufBytesToTuple('com.twitter.elephantbird.proto.Person');
 *   persons = FOREACH protobufs GENERATE PersonProtobufBytesToTuple($0);
 * </pre>
 */
public class ProtobufBytesToTuple<M extends Message> extends EvalFunc<Tuple> {
  private TypeRef<M> typeRef_ = null;
  private ProtobufConverter<M> protoConverter_ = null;
  private final ProtobufToPig protoToPig_ = new ProtobufToPig();

  public ProtobufBytesToTuple() {}

  public ProtobufBytesToTuple(String protoClassName) {
    TypeRef<M> typeRef = Protobufs.getTypeRef(protoClassName);
    setTypeRef(typeRef);
  }

  /**
   * Set the type parameter so it doesn't get erased by Java. Must be called during
   * initialization.
   * @param typeRef
   */
  public void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    protoConverter_ = ProtobufConverter.newInstance(typeRef);
  }

  @Override
  public Tuple exec(Tuple input) throws IOException {
    if (input == null || input.size() < 1) return null;
    try {
      DataByteArray bytes = (DataByteArray) input.get(0);
      M value_ = protoConverter_.fromBytes(bytes.get());
      return new ProtobufTuple(value_);
    } catch (IOException e) {
      return null;
    }
  }

  @Override
  public Schema outputSchema(Schema input) {
    return protoToPig_.toSchema(Protobufs.getMessageDescriptor(typeRef_.getRawClass()));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/test/com/twitter/elephantbird/mapreduce/io/TestProtobufWritable.java;<<<<<<< MINE

import org.junit.Test;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/test/com/twitter/elephantbird/pig/piggybank/TestPigToProto.java;<<<<<<< MINE
import com.twitter.elephantbird.pig8.util.PigToProtobuf;
=======
import com.twitter.elephantbird.examples.proto.ThriftFixtures.OneOfEach;
import com.twitter.elephantbird.pig.util.PigToProtobuf;
import com.twitter.elephantbird.pig.util.ThriftToPig;
import com.twitter.elephantbird.util.ThriftToProto;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
        "1-0-35-27000-16777216-6000000000-3.141592653589793-JSON THIS! \"-"+ooe.zomg_unicode+"-0-base64-{(1),(2),(3)}-{(1),(2),(3)}-{(1),(2),(3)}",
        toTuple(ooe).toDelimitedString("-"));
=======
        "1-0-35-27000-16777216-6000000000-3.141592653589793-JSON THIS! \"-"+ooe.zomg_unicode+"-0-base64-{(1),(2),(3)}-{(1),(2),(3)}-{(1L),(2L),(3L)}",
        toTuple(type, ooe).toDelimitedString("-"));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
    assertEquals("(31337,I am a bonk... xor!)-(1,0,35,27000,16777216,6000000000,3.141592653589793,JSON THIS! \","+n.my_ooe.zomg_unicode+",0,base64,{(1),(2),(3)},{(1),(2),(3)},{(1),(2),(3)})",
        toTuple(n).toDelimitedString("-"));
=======
    assertEquals("(31337,I am a bonk... xor!)-(1,0,35,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \","+n.my_ooe.zomg_unicode+",0,base64,{(1),(2),(3)},{(1),(2),(3)},{(1L),(2L),(3L)})",
        toTuple(type, n).toDelimitedString("-"));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
    assertEquals("{(1,0,34,27000,16777216,6000000000,3.141592653589793,JSON THIS! \"," + ooe.zomg_unicode +
        ",0,base64,{(1),(2),(3)},{(1),(2),(3)},{(1),(2),(3)}),(1,0,35,27000,16777216,6000000000,3.141592653589793,JSON THIS! \"," +
        ooe.zomg_unicode + ",0,base64,{(1),(2),(3)},{(1),(2),(3)},{(1),(2),(3)})}-{({}),({(then a one, two),(three!),(FOUR!!)}),({(and a one),(and a two)})}-{zero={}, three={}, two={(1,Wait.),(2,What?)}}",
        (toTuple(hm).toDelimitedString("-")));
=======
    assertEquals("{(1,0,34,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \"," + ooe.zomg_unicode +
        ",0,base64,{(1),(2),(3)},{(1),(2),(3)},{(1L),(2L),(3L)}),(1,0,35,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \"," +
        ooe.zomg_unicode + ",0,base64,{(1),(2),(3)},{(1),(2),(3)},{(1L),(2L),(3L)})}-{({}),({(and a one),(and a two)}),({(then a one, two),(three!),(FOUR!!)})}-{zero={}, three={}, two={(1,Wait.),(2,What?)}}",
        (toTuple(type, hm).toDelimitedString("-")));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
        "1-0-35-27000-16777216-6000000000-3.141592653589793-JSON THIS! \"-"+ooe.zomg_unicode+"-0--{(1),(2),(3)}--{(1),(2),(3)}",
        toTuple(mostly_ooe).toDelimitedString("-"));
=======
        "1-0-35-27000-16777216-6000000000-3.141592653589793-JSON THIS! \"--0--{(1),(2),(3)}-{(1),(2),(3)}-{(1L),(2L),(3L)}",
        toTuple(type, mostly_ooe).toDelimitedString("-"));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_110e154_738e6ce/rev_110e154-738e6ce/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
    assertEquals("(31337,)-(1,0,35,27000,16777216,6000000000,3.141592653589793,JSON THIS! \","+n.my_ooe.zomg_unicode+",0,,{(1),(2),(3)},,{(1),(2),(3)})",
        toTuple(n2).toDelimitedString("-"));
=======
    assertEquals("(31337,)-(1,0,35,27000,16777216,6000000000L,3.141592653589793,JSON THIS! \",,0,,{(1),(2),(3)},{(1),(2),(3)},{(1L),(2L),(3L)})",
        toTuple(type, n2).toDelimitedString("-"));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_4ece7ba_811018f/rev_4ece7ba-811018f/src/java/com/twitter/elephantbird/pig/store/LzoProtobufBlockPigStorage.java;<<<<<<< MINE
  private Message msgObj; // for newBuilder().
=======
  private Builder builder_;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_4ece7ba_811018f/rev_4ece7ba-811018f/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
            // This a partition work around. still need to fix the case
=======
            // This a partial work around. still need to fix the case
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_cc1e4c7_f3518a2/rev_cc1e4c7-f3518a2/src/java/com/twitter/elephantbird/pig/store/LzoProtobufB64LinePigStorage.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.PigUtil;
=======
import com.twitter.elephantbird.util.Codecs;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/mapreduce/output/LzoProtobufB64LineOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.mapreduce.input.LzoProtobufBlockInputFormat;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/mapreduce/output/LzoBinaryB64LineRecordWriter.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapreduce.io.BinaryConverter;
import com.twitter.elephantbird.mapreduce.io.BinaryWritable;
import com.twitter.elephantbird.util.Codecs;
import com.twitter.elephantbird.util.Protobufs;

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/mapreduce/output/LzoBinaryB64LineRecordWriter.java;<<<<<<< MINE
  
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/mapreduce/io/BinaryBlockWriter.java;<<<<<<< MINE
/** 
=======
/**
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/mapreduce/io/BinaryBlockWriter.java;<<<<<<< MINE
    
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/store/LzoProtobufB64LinePigStorage.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.store;

import java.io.IOException;

import org.apache.commons.codec.binary.Base64;
import org.apache.pig.data.Tuple;
import org.omg.IOP.Codec;

import com.google.protobuf.Message;
import com.twitter.elephantbird.pig.util.PigToProtobuf;
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.util.Codecs;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * Serializes Pig Tuples into Base-64 encoded, line-delimited protocol buffers.
 * The fields in the pig tuple must correspond exactly to the fields in the protobuf, as
 * no name-matching is performed (names of the tuple fields are not currently accessible to
 * a StoreFunc. It will be in 0.7, so something more flexible will be possible)
 *
 * @param <M> Protocol Buffer Message class being serialized
 */
public class LzoProtobufB64LinePigStorage<M extends Message> extends LzoBaseStoreFunc {

  private TypeRef<M> typeRef_;
  private Base64 base64_ = Codecs.createStandardBase64();
  private Message msgObj; // for newBuilder()

  protected LzoProtobufB64LinePigStorage(){}

  public LzoProtobufB64LinePigStorage(String protoClassName) {
    TypeRef<M> typeRef = PigUtil.getProtobufTypeRef(protoClassName);
    setTypeRef(typeRef);
  }

  protected void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    msgObj =  Protobufs.getMessageBuilder(typeRef_.getRawClass()).build();
  }

  public void putNext(Tuple f) throws IOException {
    if (f == null) return;
    Message message = PigToProtobuf.tupleToMessage(msgObj.newBuilderForType(), f);
    os_.write(base64_.encode(message.toByteArray()));
    os_.write(Protobufs.NEWLINE_UTF8_BYTE);
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/store/LzoProtobufBlockPigStorage.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.store;

import java.io.IOException;

import org.apache.pig.data.Tuple;

import com.google.protobuf.Message;
import com.twitter.elephantbird.pig.util.PigToProtobuf;
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.mapreduce.io.ProtobufBlockWriter;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;
import java.io.OutputStream;


/**
 * Serializes Pig Tuples into Block encodedprotocol buffers.
 * The fields in the pig tuple must correspond exactly to the fields in the protobuf, as
 * no name-matching is performed (names of the tuple fields are not currently accessible to
 * a StoreFunc. It will be in 0.7, so something more flexible will be possible)
 *
 * @param <M> Protocol Buffer Message class being serialized
 */
public class LzoProtobufBlockPigStorage<M extends Message> extends LzoBaseStoreFunc {

  private TypeRef<M> typeRef_;
  private Message msgObj; // for newBuilder().
  protected ProtobufBlockWriter<M> writer_ = null;
  private int numRecordsPerBlock_ = 10000;

  protected LzoProtobufBlockPigStorage() {
  }

  public LzoProtobufBlockPigStorage(String protoClassName) {
    TypeRef<M> typeRef = PigUtil.getProtobufTypeRef(protoClassName);
    setTypeRef(typeRef);
  }

  @Override
  public void bindTo(OutputStream os) throws IOException {
		super.bindTo(os);
		writer_ = new ProtobufBlockWriter<M>(os_, typeRef_.getRawClass(), numRecordsPerBlock_);
  }

  protected void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    msgObj = Protobufs.getMessageBuilder(typeRef_.getRawClass()).build();
  }

  @SuppressWarnings("unchecked")
  public void putNext(Tuple f) throws IOException {
    if (f == null) return;
	  writer_.write((M)PigToProtobuf.tupleToMessage(msgObj.newBuilderForType(), f));
  }

	@Override
	public void finish() throws IOException {
    if (writer_ != null) {
      writer_.close();
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

import java.nio.ByteBuffer;
import java.util.Arrays;
import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
import org.apache.pig.LoadFunc;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.BagFactory;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.DataType;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
import org.apache.thrift.TBase;
import org.apache.thrift.protocol.TType;

import com.google.common.collect.Lists;
import com.twitter.elephantbird.pig.load.LzoThriftB64LinePigLoader;
import com.twitter.elephantbird.thrift.TStructDescriptor;
import com.twitter.elephantbird.thrift.TStructDescriptor.Field;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

/**
 * <li> converts a Thrift struct to a Pig tuple
 * <li> utilities to provide schema for Pig loaders and Pig scripts
 */
public class ThriftToPig<M extends TBase<?, ?>> {
  public static final Logger LOG = LogManager.getLogger(ThriftToPig.class);

  private static BagFactory bagFactory = BagFactory.getInstance();
  private static TupleFactory tupleFactory  = TupleFactory.getInstance();

  private TStructDescriptor structDesc;

  public static <M extends TBase<?, ?>> ThriftToPig<M> newInstance(Class<M> tClass) {
    return new ThriftToPig<M>(tClass);
  }

  public static <M extends TBase<?, ?>> ThriftToPig<M> newInstance(TypeRef<M> typeRef) {
    return new ThriftToPig<M>(typeRef.getRawClass());
  }

  public ThriftToPig(Class<M> tClass) {
    structDesc = TStructDescriptor.getInstance(tClass);
  }

  /**
   * Converts a thrift object to Pig tuple.
   * All the fields are deserialized.
   * It might be better to use getLazyTuple() if not all fields
   * are required.
   */
  public Tuple getPigTuple(M thriftObj) {
    return toTuple(structDesc, thriftObj);
  }

  /**
   * Similar to {@link #getPigTuple(TBase)}. This delays
   * serialization of tuple contents until they are requested.
   * @param thriftObj
   * @return
   */
  public Tuple getLazyTuple(M thriftObj) {
    return new LazyTuple(thriftObj);
  }

  @SuppressWarnings("unchecked")
  private static <T extends TBase>Tuple toTuple(TStructDescriptor tDesc, T tObj) {
    int size = tDesc.getFields().size();
    Tuple tuple = tupleFactory.newTuple(size);
    for (int i=0; i<size; i++) {
      Field field = tDesc.getFieldAt(i);
      Object value = tDesc.getFieldValue(i, tObj);
      try {
        tuple.set(i, toPigObject(field, value));
      } catch (ExecException e) { // not expected
        throw new RuntimeException(e);
      }
    }
    return tuple;
  }

  @SuppressWarnings("unchecked")
  private static Object toPigObject(Field field, Object value) {
    if (value == null) {
      return null;
    }

    switch (field.getType()) {
    case TType.BOOL:
      return Integer.valueOf((Boolean)value ? 1 : 0);
    case TType.BYTE :
      return Integer.valueOf((Byte)value);
    case TType.I16 :
      return Integer.valueOf((Short)value);
    case TType.STRING:
      return stringTypeToPig(value);
    case TType.STRUCT:
      return toTuple(field.gettStructDescriptor(), (TBase<?, ?>)value);
    case TType.MAP:
      return toPigMap(field, (Map<Object, Object>)value);
    case TType.SET:
      return toPigBag(field.getSetElemField(), (Collection<Object>)value);
    case TType.LIST:
      return toPigBag(field.getListElemField(), (Collection<Object>)value);
    case TType.ENUM:
      return value.toString();
    default:
      // standard types : I32, I64, DOUBLE, etc.
      return value;
    }
  }

  /**
   * TType.STRING is a mess in Thrift. It could be byte[], ByteBuffer,
   * or even a String!.
   */
  private static Object stringTypeToPig(Object value) {
    if (value instanceof String) {
      return value;
    }
    if (value instanceof byte[]) {
      byte[] buf = (byte[])value;
      return new DataByteArray(Arrays.copyOf(buf, buf.length));
    }
    if (value instanceof ByteBuffer) {
      ByteBuffer bin = (ByteBuffer)value;
      byte[] buf = new byte[bin.remaining()];
      bin.mark();
      bin.get(buf);
      bin.reset();
      return new DataByteArray(buf);
    }
    return null;
  }

  private static Map<String, Object> toPigMap(Field field, Map<Object, Object> map) {
    // PIG map's key always a String. just use toString() and hope
    // things would work out ok.
    HashMap<String, Object> out = new HashMap<String, Object>(map.size());
    Field valueField = field.getMapValueField();
    for(Entry<Object, Object> e : map.entrySet()) {
      Object prev = out.put(e.getKey().toString(),
                            toPigObject(valueField, e.getValue()));
      if (prev != null) {
        String msg = "Duplicate keys while converting to String while "
          + " processing map " + field.getName() + " (key type : "
          + field.getMapKeyField().getType() + " value type : "
          + field.getMapValueField().getType() + ")";
        LOG.warn(msg);
        throw new RuntimeException(msg);
      }
    }
    return out;
  }

  private static DataBag toPigBag(Field field, Collection<Object> values) {
    List<Tuple> tuples = Lists.newArrayListWithExpectedSize(values.size());
    for(Object value : values) {
      Object pValue = toPigObject(field, value);
      if (pValue instanceof Tuple) { // DataBag should contain Tuples
        tuples.add((Tuple)pValue);
      } else {
        tuples.add(tupleFactory.newTuple(pValue));
      }
    }
    return bagFactory.newDefaultBag(tuples);
  }

  @SuppressWarnings("serial")
  /**
   * Delays serialization of Thrift fields until they are requested.
   */
  private class LazyTuple extends AbstractLazyTuple {
    /* NOTE : This is only a partial optimization. The other part
     * is to avoid deserialization of the Thrift fields from the
     * binary buffer.
     *
     * Currently TDeserializer allows deserializing just one field,
     * psuedo-skipping over the fields before it.
     * But if we are going deserialize 5 fields out of 20, we will be
     * skipping over same set of fields multiple times. OTOH this might
     * still be better than a full deserialization.
     *
     * We need to write our own version of TBinaryProtocol that truly skips.
     * Even TDeserializer 'skips'/ignores only after deserializing fields.
     * (e.g. Strings, Integers, buffers etc).
     */
    private M tObject;

    LazyTuple(M tObject) {
      initRealTuple(structDesc.getFields().size());
      this.tObject = tObject;
    }

    @Override
    protected Object getObjectAt(int index) {
      Field field = structDesc.getFieldAt(index);
      return toPigObject(field, structDesc.getFieldValue(index, tObject));
    }
  }

  /**
   * Returns Pig schema for the Thrift struct.
   */
  public static Schema toSchema(Class<? extends TBase<?, ?>> tClass) {
    return toSchema(TStructDescriptor.getInstance(tClass));
  }
  public static Schema toSchema(TStructDescriptor tDesc ) {
    Schema schema = new Schema();

    try {
      for(Field field : tDesc.getFields()) {
        String fieldName = field.getName();
        if (field.isStruct()) {
          schema.add(new FieldSchema(fieldName, toSchema(field.gettStructDescriptor()), DataType.TUPLE));
        } else {
          schema.add(singleFieldToFieldSchema(fieldName, field));
        }
      }
    } catch (FrontendException t) {
      throw new RuntimeException(t);
    }

    return schema;
  }

  private static FieldSchema singleFieldToFieldSchema(String fieldName, Field field) throws FrontendException {
    switch (field.getType()) {
      case TType.LIST:
        return new FieldSchema(fieldName, singleFieldToTupleSchema(fieldName + "_tuple", field.getListElemField()), DataType.BAG);
      case TType.SET:
        return new FieldSchema(fieldName, singleFieldToTupleSchema(fieldName + "_tuple", field.getSetElemField()), DataType.BAG);
      case TType.MAP:
        // can not specify types for maps in Pig.
        if (field.getMapKeyField().getType() != TType.STRING) {
          LOG.warn("Using a map with non-string key for field " + field.getName()
              + ". while converting to PIG Tuple, toString() is used for the key."
              + " It could result in incorrect maps.");
        }
        return new FieldSchema(fieldName, null, DataType.MAP);
      default:
        return new FieldSchema(fieldName, null, getPigDataType(field));
    }
  }

  /**
   * Returns a schema with single tuple (for Pig bags).
   */
  private static Schema singleFieldToTupleSchema(String fieldName, Field field) throws FrontendException {

    FieldSchema fieldSchema = null;

    switch (field.getType()) {
      case TType.STRUCT:
        fieldSchema = new FieldSchema(fieldName, toSchema(field.gettStructDescriptor()), DataType.TUPLE);
        break;
      case TType.LIST:
        fieldSchema = singleFieldToFieldSchema(fieldName, field.getListElemField());
        break;
      case TType.SET:
        fieldSchema = singleFieldToFieldSchema(fieldName, field.getSetElemField());
        break;
      default:
        fieldSchema = new FieldSchema(fieldName, null, getPigDataType(field));
    }

    Schema schema = new Schema();
    schema.add(fieldSchema);
    return schema;
  }

  private static byte getPigDataType(Field field) {
    switch (field.getType()) {
      case TType.BOOL:
      case TType.BYTE:
      case TType.I16:
      case TType.I32:
        return DataType.INTEGER;
      case TType.ENUM:
        return DataType.CHARARRAY;
      case TType.I64:
        return DataType.LONG;
      case TType.DOUBLE:
        return DataType.DOUBLE;
      case TType.STRING:
        return field.isBuffer() ? DataType.BYTEARRAY : DataType.CHARARRAY;
      default:
        throw new IllegalArgumentException("Unexpected type where a simple type is expected : " + field.getType());
    }
  }

  /**
   * Turn a Thrift Struct into a loading schema for a pig script.
   */
  public static String toPigScript(Class<? extends TBase<?, ?>> thriftClass,
                                   Class<? extends LoadFunc> pigLoader) {
    StringBuilder sb = new StringBuilder();
    /* we are commenting out explicit schema specification. The schema is
     * included mainly to help the readers of the pig script. Pig learns the
     * schema directly from the loader.
     * If explicit schema is not commented, we might have surprising results
     * when a Thrift class (possibly in control of another team) changes,
     * but the Pig script is not updated. Commenting it out avoids this.
     */
    StringBuilder prefix = new StringBuilder("       --  ");
    sb.append("raw_data = load '$INPUT_FILES' using ")
      .append(pigLoader.getName())
      .append("('")
      .append(thriftClass.getName())
      .append("');\n")
      .append(prefix)
      .append("as ");
    prefix.append("   ");

    try {
      stringifySchema(sb, toSchema(thriftClass), DataType.TUPLE, prefix);
    } catch (FrontendException e) {
      throw new RuntimeException(e);
    }

    sb.append("\n");
    return sb.toString();
  }

  /**
   * Print formatted schema. This is a modified version of
   * {@link Schema#stringifySchema(StringBuilder, Schema, byte)}
   * with support for (indented) pretty printing.
   */
  // This is used for building up output string
  // type can only be BAG or TUPLE
  public static void stringifySchema(StringBuilder sb,
                                     Schema schema,
                                     byte type,
                                     StringBuilder prefix)
                                          throws FrontendException{
      // this is a modified version of {@link Schema#stringifySchema(StringBuilder, Schema, byte)}
      if (type == DataType.TUPLE) {
          sb.append("(") ;
      }
      else if (type == DataType.BAG) {
          sb.append("{") ;
      }

      prefix.append("  ");
      sb.append("\n").append(prefix);

      if (schema == null) {
          sb.append("null") ;
      }
      else {
          boolean isFirst = true ;
          for (int i=0; i< schema.size() ;i++) {

              if (!isFirst) {
                  sb.append(",\n").append(prefix);
              }
              else {
                  isFirst = false ;
              }

              FieldSchema fs = schema.getField(i) ;

              if(fs == null) {
                  sb.append("null");
                  continue;
              }

              if (fs.alias != null) {
                  sb.append(fs.alias);
                  sb.append(": ");
              }

              if (DataType.isAtomic(fs.type)) {
                  sb.append(DataType.findTypeName(fs.type)) ;
              }
              else if ( (fs.type == DataType.TUPLE) ||
                        (fs.type == DataType.BAG) ) {
                  // safety net
                  if (schema != fs.schema) {
                      stringifySchema(sb, fs.schema, fs.type, prefix) ;
                  }
                  else {
                      throw new AssertionError("Schema refers to itself "
                                               + "as inner schema") ;
                  }
              } else if (fs.type == DataType.MAP) {
                  sb.append(DataType.findTypeName(fs.type) + "[ ]") ;
              } else {
                  sb.append(DataType.findTypeName(fs.type)) ;
              }
          }
      }

      prefix.setLength(prefix.length()-2);
      sb.append("\n").append(prefix);

      if (type == DataType.TUPLE) {
          sb.append(")") ;
      }
      else if (type == DataType.BAG) {
          sb.append("}") ;
      }
  }

  public static void main(String[] args) throws Exception {
    if (args.length > 0) {
      Class<? extends TBase<?, ?>> tClass = ThriftUtils.getTypeRef(args[0]).getRawClass();
      System.out.println(args[0] + " : " + toSchema(tClass).toString());
      System.out.println(toPigScript(tClass, LzoThriftB64LinePigLoader.class));
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/util/ProtobufTuple.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

import java.util.List;

import com.google.protobuf.Message;
import com.google.protobuf.Descriptors.Descriptor;
import com.google.protobuf.Descriptors.FieldDescriptor;

@SuppressWarnings("serial")
/**
 * This class wraps a protocol buffer message and attempts to delay parsing until individual
 * fields are requested.
 */
public class ProtobufTuple extends AbstractLazyTuple {

  private final Message msg_;
  private final Descriptor descriptor_;
  private final List<FieldDescriptor> fieldDescriptors_;
  private final ProtobufToPig protoConv_;
  private final int protoSize_;

  public ProtobufTuple(Message msg) {
    msg_ = msg;
    descriptor_ = msg.getDescriptorForType();
    fieldDescriptors_ = descriptor_.getFields();
    protoSize_ = fieldDescriptors_.size();
    protoConv_ = new ProtobufToPig();
    initRealTuple(protoSize_);
  }

  protected Object getObjectAt(int idx) {
    FieldDescriptor fieldDescriptor = fieldDescriptors_.get(idx);
    Object fieldValue = msg_.getField(fieldDescriptor);
    if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
      return protoConv_.messageToTuple(fieldDescriptor, fieldValue);
    } else {
      return protoConv_.singleFieldToTuple(fieldDescriptor, fieldValue);
    }
  }

  @Override
  public long getMemorySize() {
    // The protobuf estimate is obviously inaccurate.
    return msg_.getSerializedSize() + realTuple.getMemorySize();
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/util/ProtobufToPig.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

import java.util.List;
import java.util.Map;

import com.google.common.collect.Lists;
import com.google.common.collect.Maps;
import com.google.protobuf.Descriptors.Descriptor;
import com.google.protobuf.Descriptors.EnumValueDescriptor;
import com.google.protobuf.Descriptors.FieldDescriptor;
import com.google.protobuf.ByteString;
import com.google.protobuf.Message;
import com.twitter.data.proto.Misc.CountedMap;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.BagFactory;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.DataType;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * A class for turning codegen'd protos into Pig Tuples and Schemas
 * for custom Pig LoadFuncs.
 * @author Kevin Weil
 */
public class ProtobufToPig {
  private static final Logger LOG = LoggerFactory.getLogger(ProtobufToPig.class);

  private static final TupleFactory tupleFactory_ = TupleFactory.getInstance();
  private static BagFactory bagFactory_ = BagFactory.getInstance();

  public enum CoercionLevel { kNoCoercion, kAllowCoercionToPigMaps }

  private final CoercionLevel coercionLevel_;

  public ProtobufToPig() {
    this(CoercionLevel.kAllowCoercionToPigMaps);
  }

  public ProtobufToPig(CoercionLevel coercionLevel) {
    coercionLevel_ = coercionLevel;
  }
  /**
   * Turn a generic message into a Tuple.  Individual fields that are enums
   * are converted into their string equivalents.  Fields that are not filled
   * out in the protobuf are set to null, unless there is a default field value in
   * which case that is used instead.
   * @param msg the protobuf message
   * @return a pig tuple representing the message.
   */
  public Tuple toTuple(Message msg) {
    if (msg == null) {
      // Pig tuples deal gracefully with nulls.
      // Also, we can be called with null here in recursive calls.
      return null;
    }

    Descriptor msgDescriptor = msg.getDescriptorForType();
    Tuple tuple = tupleFactory_.newTuple(msgDescriptor.getFields().size());
    int curField = 0;
    try {
      // Walk through all the possible fields in the message.
      for (FieldDescriptor fieldDescriptor : msgDescriptor.getFields()) {
        // Get the set value, or the default value, or null.
        Object fieldValue = getFieldValue(msg, fieldDescriptor);

        if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
          tuple.set(curField++, messageToTuple(fieldDescriptor, fieldValue));
        } else {
          tuple.set(curField++, singleFieldToTuple(fieldDescriptor, fieldValue));
        }
      }
    } catch (ExecException e) {
      LOG.warn("Could not convert msg " + msg + " to tuple", e);
    }

    return tuple;
  }

  /**
   * Translate a nested message to a tuple.  If the field is repeated, it walks the list and adds each to a bag.
   * Otherwise, it just adds the given one.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param fieldValue the object representing the value of this field, possibly null.
   * @return the object representing fieldValue in Pig -- either a bag or a tuple.
   */
  @SuppressWarnings("unchecked")
  protected Object messageToTuple(FieldDescriptor fieldDescriptor, Object fieldValue) {
    assert fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE : "messageToTuple called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      // The protobuf contract is that if the field is repeated, then the object returned is actually a List
      // of the underlying datatype, which in this case is a nested message.
      List<Message> messageList = (List<Message>) (fieldValue != null ? fieldValue : Lists.newArrayList());

      // Since protobufs do not have a map type, we use CountedMap to fake it.  Whenever the protobuf has a repeated CountedMap in it,
      // we can force the type into a pig map type.
      if (coercionLevel_ == CoercionLevel.kAllowCoercionToPigMaps &&
          fieldDescriptor.getMessageType().getName().equals(CountedMap.getDescriptor().getName())) {
        Map<Object, Long> map = Maps.newHashMap();
        for (Message m : messageList) {
          CountedMap cm = (CountedMap) m;
          final Long curCount = map.get(cm.getKey());
          map.put(cm.getKey(), (curCount == null ? 0L : curCount) + cm.getValue());
        }
        return map;
      } else {
        DataBag bag = bagFactory_.newDefaultBag();
        for (Message m : messageList) {
          bag.add(new ProtobufTuple(m));
        }
        return bag;
      }
    } else {
      return new ProtobufTuple((Message)fieldValue);
    }
  }

  /**
   * Translate a single field to a tuple.  If the field is repeated, it walks the list and adds each to a bag.
   * Otherwise, it just adds the given one.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param fieldValue the object representing the value of this field, possibly null.
   * @return the object representing fieldValue in Pig -- either a bag or a single field.
   * @throws ExecException if Pig decides to.  Shouldn't happen because we won't walk off the end of a tuple's field set.
   */
  @SuppressWarnings("unchecked")
  protected Object singleFieldToTuple(FieldDescriptor fieldDescriptor, Object fieldValue) {
    assert fieldDescriptor.getType() != FieldDescriptor.Type.MESSAGE : "messageToFieldSchema called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      // The protobuf contract is that if the field is repeated, then the object returned is actually a List
      // of the underlying datatype, which in this case is a "primitive" like int, float, String, etc.
      // We have to make a single-item tuple out of it to put it in the bag.
      DataBag bag = bagFactory_.newDefaultBag();
      List<Object> fieldValueList = (List<Object>) (fieldValue != null ? fieldValue : Lists.newArrayList());
      for (Object singleFieldValue : fieldValueList) {
        Object nonEnumFieldValue = coerceToPigTypes(fieldDescriptor, singleFieldValue);
        Tuple innerTuple = tupleFactory_.newTuple(1);
        try {
          innerTuple.set(0, nonEnumFieldValue);
        } catch (ExecException e) { // not expected
          throw new RuntimeException(e);
        }
        bag.add(innerTuple);
      }
      return bag;
    } else {
      return coerceToPigTypes(fieldDescriptor, fieldValue);
    }
  }

  /**
   * If the given field value is an enum, translate it to the enum's name as a string, since Pig cannot handle enums.
   * Also, if the given field value is a bool, translate it to 0 or 1 to avoid Pig bools, which can be sketchy.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param fieldValue the object representing the value of this field, possibly null.
   * @return the object, unless it was from an enum field, in which case we return the name of the enum field.
   */
  private Object coerceToPigTypes(FieldDescriptor fieldDescriptor, Object fieldValue) {
    if (fieldDescriptor.getType() == FieldDescriptor.Type.ENUM && fieldValue != null) {
      EnumValueDescriptor enumValueDescriptor = (EnumValueDescriptor)fieldValue;
      return enumValueDescriptor.getName();
    } else if (fieldDescriptor.getType() == FieldDescriptor.Type.BOOL && fieldValue != null) {
      Boolean boolValue = (Boolean)fieldValue;
      return new Integer(boolValue ? 1 : 0);
    } else if (fieldDescriptor.getType() == FieldDescriptor.Type.BYTES && fieldValue != null) {
      ByteString bsValue = (ByteString)fieldValue;
      return new DataByteArray(bsValue.toByteArray());
    }
    return fieldValue;
  }

  /**
   * A utility function for getting the value of a field in a protobuf message.  It first tries the
   * literal set value in the protobuf's field list.  If the value isn't set, and the field has a default
   * value, it uses that.  Otherwise, it returns null.
   * @param msg the protobuf message
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the value of the field, or null if none can be assigned.
   */
  protected Object getFieldValue(Message msg, FieldDescriptor fieldDescriptor) {
    Object o = null;
    Map<FieldDescriptor, Object> setFields = msg.getAllFields();
    if (setFields.containsKey(fieldDescriptor)) {
      o = setFields.get(fieldDescriptor);
    } else if (fieldDescriptor.hasDefaultValue()) {
      o = fieldDescriptor.getDefaultValue();
    }

    return o;
  }

  /**
   * Turn a generic message descriptor into a Schema.  Individual fields that are enums
   * are converted into their string equivalents.
   * @param msgDescriptor the descriptor for the given message type.
   * @return a pig schema representing the message.
   */
  public Schema toSchema(Descriptor msgDescriptor) {
    Schema schema = new Schema();

    try {
      // Walk through all the possible fields in the message.
      for (FieldDescriptor fieldDescriptor : msgDescriptor.getFields()) {
        if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
          schema.add(messageToFieldSchema(fieldDescriptor));
        } else {
          schema.add(singleFieldToFieldSchema(fieldDescriptor));
        }
      }
    } catch (FrontendException e) {
      LOG.warn("Could not convert descriptor " + msgDescriptor + " to schema", e);
    }

    return schema;
  }

  /**
   * Turn a nested message into a Schema object.  For repeated nested messages, it generates a schema for a bag of
   * tuples.  For non-repeated nested messages, it just generates a schema for the tuple itself.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the Schema for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private FieldSchema messageToFieldSchema(FieldDescriptor fieldDescriptor) throws FrontendException {
    assert fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE : "messageToFieldSchema called with field of type " + fieldDescriptor.getType();

    // Since protobufs do not have a map type, we use CountedMap to fake it.  Whenever the protobuf has a repeated CountedMap in it,
    // we can force the type into a pig map type.
    if (coercionLevel_ == CoercionLevel.kAllowCoercionToPigMaps &&
        fieldDescriptor.getMessageType().getName().equals(CountedMap.getDescriptor().getName()) && fieldDescriptor.isRepeated()) {
      return new FieldSchema(fieldDescriptor.getName(), null, DataType.MAP);
    }

    Schema innerSchema = toSchema(fieldDescriptor.getMessageType());

    if (fieldDescriptor.isRepeated()) {
      Schema tupleSchema = new Schema();
      tupleSchema.add(new FieldSchema(fieldDescriptor.getName() + "_tuple", innerSchema, DataType.TUPLE));
      return new FieldSchema(fieldDescriptor.getName(), tupleSchema, DataType.BAG);
    } else {
      return new FieldSchema(fieldDescriptor.getName(), innerSchema, DataType.TUPLE);
    }
  }

  /**
   * Turn a single field into a Schema object.  For repeated single fields, it generates a schema for a bag of single-item tuples.
   * For non-repeated fields, it just generates a standard field schema.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the Schema for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private FieldSchema singleFieldToFieldSchema(FieldDescriptor fieldDescriptor) throws FrontendException {
    assert fieldDescriptor.getType() != FieldDescriptor.Type.MESSAGE : "singleFieldToFieldSchema called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      Schema itemSchema = new Schema();
      itemSchema.add(new FieldSchema(fieldDescriptor.getName(), null, getPigDataType(fieldDescriptor)));
      Schema itemTupleSchema = new Schema();
      itemTupleSchema.add(new FieldSchema(fieldDescriptor.getName() + "_tuple", itemSchema, DataType.TUPLE));

      return new FieldSchema(fieldDescriptor.getName() + "_bag", itemTupleSchema, DataType.BAG);
    } else {
      return new FieldSchema(fieldDescriptor.getName(), null, getPigDataType(fieldDescriptor));
    }
  }

  /**
   * Translate between protobuf's datatype representation and Pig's datatype representation.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the byte representing the pig datatype for the given field type.
   */
  private byte getPigDataType(FieldDescriptor fieldDescriptor) {
    switch (fieldDescriptor.getType()) {
      case INT32:
      case UINT32:
      case SINT32:
      case FIXED32:
      case SFIXED32:
      case BOOL: // We convert booleans to ints for pig output.
        return DataType.INTEGER;
      case INT64:
      case UINT64:
      case SINT64:
      case FIXED64:
      case SFIXED64:
        return DataType.LONG;
      case FLOAT:
        return DataType.FLOAT;
      case DOUBLE:
        return DataType.DOUBLE;
      case STRING:
      case ENUM: // We convert enums to strings for pig output.
        return DataType.CHARARRAY;
      case BYTES:
        return DataType.BYTEARRAY;
      case MESSAGE:
        throw new IllegalArgumentException("getPigDataType called on field " + fieldDescriptor.getFullName() + " of type message.");
      default:
        throw new IllegalArgumentException("Unexpected field type. " + fieldDescriptor.toString() + " " + fieldDescriptor.getFullName() + " " + fieldDescriptor.getType());
    }
  }

  /**
   * Turn a generic message descriptor into a loading schema for a pig script.
   * @param msgDescriptor the descriptor for the given message type.
   * @param loaderClassName the fully qualified classname of the pig loader to use.  Not
   * passed a <code>Class<? extends LoadFunc></code> because in many situations that class
   * is being generated as well, and so doesn't exist in compiled form.
   * @return a pig schema representing the message.
   */
  public String toPigScript(Descriptor msgDescriptor, String loaderClassName) {
    StringBuffer sb = new StringBuffer();
    final int initialTabOffset = 3;

    sb.append("raw_data = load '$INPUT_FILES' using " + loaderClassName + "()").append("\n");
    sb.append(tabs(initialTabOffset)).append("as (").append("\n");
    sb.append(toPigScriptInternal(msgDescriptor, initialTabOffset));
    sb.append(tabs(initialTabOffset)).append(");").append("\n").append("\n");

    return sb.toString();
  }

  /**
   * Turn a generic message descriptor into a loading schema for a pig script.  Individual fields that are enums
   * are converted into their string equivalents.
   * @param msgDescriptor the descriptor for the given message type.
   * @param numTabs the tab depth at the current point in the recursion, for pretty printing.
   * @return a pig schema representing the message.
   */
  private StringBuffer toPigScriptInternal(Descriptor msgDescriptor, int numTabs) {
    StringBuffer sb = new StringBuffer();
    try {
      // Walk through all the possible fields in the message.
      for (FieldDescriptor fieldDescriptor : msgDescriptor.getFields()) {
        // We have to add a comma after every line EXCEPT for the last, or Pig gets mad.
        boolean isLast = (fieldDescriptor == msgDescriptor.getFields().get(msgDescriptor.getFields().size() - 1));
        if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
          sb.append(messageToPigScript(fieldDescriptor, numTabs + 1, isLast));
        } else {
          sb.append(singleFieldToPigScript(fieldDescriptor, numTabs + 1, isLast));
        }
      }
    } catch (FrontendException e) {
      LOG.warn("Could not convert descriptor " + msgDescriptor + " to pig script", e);
    }

    return sb;
  }

  /**
   * Turn a nested message into a pig script load string.  For repeated nested messages, it generates a string for a bag of
   * tuples.  For non-repeated nested messages, it just generates a string for the tuple itself.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param numTabs the tab depth at the current point in the recursion, for pretty printing.
   * @return the pig script load schema for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private StringBuffer messageToPigScript(FieldDescriptor fieldDescriptor, int numTabs, boolean isLast) throws FrontendException {
    assert fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE : "messageToPigScript called with field of type " + fieldDescriptor.getType();

    // Since protobufs do not have a map type, we use CountedMap to fake it.  Whenever the protobuf has a repeated CountedMap in it,
    // we force the type into a pig map type.
    if (coercionLevel_ == CoercionLevel.kAllowCoercionToPigMaps &&
        fieldDescriptor.getMessageType().getName().equals(CountedMap.getDescriptor().getName()) && fieldDescriptor.isRepeated()) {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName())
          .append(": map[]").append(isLast ? "" : ",").append("\n");
    }

    if (fieldDescriptor.isRepeated()) {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append(": bag {").append("\n")
          .append(tabs(numTabs + 1)).append(fieldDescriptor.getName()).append("_tuple: tuple (").append("\n")
          .append(toPigScriptInternal(fieldDescriptor.getMessageType(), numTabs + 2))
          .append(tabs(numTabs + 1)).append(")").append("\n")
          .append(tabs(numTabs)).append("}").append(isLast ? "" : ",").append("\n");
    } else {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append(": tuple (").append("\n")
          .append(toPigScriptInternal(fieldDescriptor.getMessageType(), numTabs + 1))
          .append(tabs(numTabs)).append(")").append(isLast ? "" : ",").append("\n");
    }
  }

  /**
   * Turn a single field into a pig script load string.  For repeated single fields, it generates a string for a bag of single-item tuples.
   * For non-repeated fields, it just generates a standard single-element string.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param numTabs the tab depth at the current point in the recursion, for pretty printing.
   * @return the pig script load string for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private StringBuffer singleFieldToPigScript(FieldDescriptor fieldDescriptor, int numTabs, boolean isLast) throws FrontendException {
    assert fieldDescriptor.getType() != FieldDescriptor.Type.MESSAGE : "singleFieldToPigScript called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append("_bag: bag {").append("\n")
          .append(tabs(numTabs + 1)).append(fieldDescriptor.getName()).append("_tuple: tuple (").append("\n")
          .append(tabs(numTabs + 2)).append(fieldDescriptor.getName()).append(": ").append(getPigScriptDataType(fieldDescriptor)).append("\n")
          .append(tabs(numTabs + 1)).append(")").append("\n")
          .append(tabs(numTabs)).append("}").append(isLast ? "" : ",").append("\n");
    } else {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append(": ")
          .append(getPigScriptDataType(fieldDescriptor)).append(isLast ? "" : ",").append("\n");
    }
  }

  /**
   * Translate between protobuf's datatype representation and Pig's datatype representation.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the byte representing the pig datatype for the given field type.
   */
  private String getPigScriptDataType(FieldDescriptor fieldDescriptor) {
    switch (fieldDescriptor.getType()) {
      case INT32:
      case UINT32:
      case SINT32:
      case FIXED32:
      case SFIXED32:
      case BOOL: // We convert booleans to ints for pig output.
        return "int";
      case INT64:
      case UINT64:
      case SINT64:
      case FIXED64:
      case SFIXED64:
        return "long";
      case FLOAT:
        return "float";
      case DOUBLE:
        return "double";
      case STRING:
      case ENUM: // We convert enums to strings for pig output.
        return "chararray";
      case BYTES:
        return "bytearray";
      case MESSAGE:
        throw new IllegalArgumentException("getPigScriptDataType called on field " + fieldDescriptor.getFullName() + " of type message.");
      default:
        throw new IllegalArgumentException("Unexpected field type. " + fieldDescriptor.toString() + " " + fieldDescriptor.getFullName() + " " + fieldDescriptor.getType());
    }
  }

  private StringBuffer tabs(int numTabs) {
    StringBuffer sb = new StringBuffer();
    for (int i = 0; i < numTabs; i++) {
      sb.append("  ");
    }
    return sb;
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/util/PigCounterHelper.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

import java.util.Map;

import com.google.common.collect.Maps;
import org.apache.hadoop.mapred.Reporter;
import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigHadoopLogger;
import org.apache.pig.impl.util.Pair;

/**
 * A helper class to deal with Hadoop counters in Pig.  They are stored within the singleton
 * PigHadoopLogger instance, but are null for some period of time at job startup, even after
 * Pig has been invoked.  This class buffers counters, trying each time to get a valid Reporter and flushing
 * stored counters each time it does.
 */
public class PigCounterHelper {
  private Map<Pair<String, String>, Long> counterStringMap_ = Maps.newHashMap();
  private Map<Enum<?>, Long> counterEnumMap_ = Maps.newHashMap();
  private PigHadoopLogger pigLogger_ = null;

  /**
   * Mocks the Reporter.incrCounter, but adds buffering.
   * See org.apache.hadoop.mapred.Reporter's incrCounter.
   */
  public void incrCounter(String group, String counter, long incr) {
    if (getReporter() != null) { // common case
      getReporter().incrCounter(group, counter, incr);
      if (counterStringMap_.size() > 0) {
        for (Map.Entry<Pair<String, String>, Long> entry : counterStringMap_.entrySet()) {
          getReporter().incrCounter(entry.getKey().first, entry.getKey().second, entry.getValue());
        }
        counterStringMap_.clear();
      }
    } else { // buffer the increments.
      Pair<String, String> key = new Pair<String, String>(group, counter);
      Long currentValue = counterStringMap_.get(key);
      counterStringMap_.put(key, (currentValue == null ? 0 : currentValue) + incr);
    }
  }

  /**
   * Mocks the Reporter.incrCounter, but adds buffering.
   * See org.apache.hadoop.mapred.Reporter's incrCounter.
   */
  public void incrCounter(Enum<?> key, long incr) {
    Reporter reporter = getReporter();
    if (reporter != null) {
      reporter.incrCounter(key, incr);
      if (counterEnumMap_.size() > 0) {
        for (Map.Entry<Enum<?>, Long> entry : counterEnumMap_.entrySet()) {
          getReporter().incrCounter(entry.getKey(), entry.getValue());
        }
        counterEnumMap_.clear();
      }
    } else { // buffer the increments
      Long currentValue = counterEnumMap_.get(key);
      counterEnumMap_.put(key, (currentValue == null ? 0 : currentValue) + incr);
    }
  }

  /**
   * Try for the Reporter object if it hasn't been initialized yet, otherwise just return it.
   * @return the job's reporter object, or null if it isn't retrievable yet.
   */
  private Reporter getReporter() {
    if (pigLogger_ == null) {
      pigLogger_ = PigHadoopLogger.getInstance();
    }
    return pigLogger_.getReporter();
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/load/LzoThriftB64LinePigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;

import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.thrift.TBase;

import com.twitter.elephantbird.mapreduce.io.BinaryConverter;
import com.twitter.elephantbird.mapreduce.io.ThriftConverter;
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.pig.util.ThriftToPig;
import com.twitter.elephantbird.util.TypeRef;

/**
 * Loader for LZO files with line-oriented base64 encoded Thrift objects.
 */
public class LzoThriftB64LinePigLoader<M extends TBase<?, ?>> extends LzoBinaryB64LinePigLoader {

  private final TypeRef<M> typeRef_;
  private ThriftConverter<M> converter_;
  private final ThriftToPig<M> thriftToPig_;

  public LzoThriftB64LinePigLoader(String thriftClassName) {
    typeRef_ = PigUtil.getThriftTypeRef(thriftClassName);
    converter_ = ThriftConverter.newInstance(typeRef_);
    thriftToPig_ =  ThriftToPig.newInstance(typeRef_);

    BinaryConverter<Tuple> tupleConverter = new BinaryConverter<Tuple>() {
      public Tuple fromBytes(byte[] messageBuffer) {
        M value = converter_.fromBytes(messageBuffer);
        if (value != null) {
          return thriftToPig_.getLazyTuple(value);
        }
        return null;
      }

      public byte[] toBytes(Tuple message) {
        throw new RuntimeException("not implemented");
      }
    };

    init(thriftClassName, tupleConverter);
    setLoaderSpec(getClass(), new String[]{thriftClassName});
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return ThriftToPig.toSchema(typeRef_.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/load/LzoThriftBlockPigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;

import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.apache.thrift.TBase;

import com.twitter.elephantbird.mapreduce.io.ThriftBlockReader;
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.pig.util.ThriftToPig;
import com.twitter.elephantbird.util.TypeRef;


public class LzoThriftBlockPigLoader<M extends TBase<?, ?>> extends LzoBaseLoadFunc {

  private final TypeRef<M> typeRef_;
  private final ThriftToPig<M> thriftToPig_;
  private ThriftBlockReader<M> reader_;

  private Pair<String, String> thriftStructsRead;

  public LzoThriftBlockPigLoader(String thriftClassName) {
    typeRef_ = PigUtil.getThriftTypeRef(thriftClassName);
    thriftToPig_ =  ThriftToPig.newInstance(typeRef_);

    String group = "LzoBlocks of " + typeRef_.getRawClass().getName();
    thriftStructsRead = new Pair<String, String>(group, "Thrift Structs Read");

    setLoaderSpec(getClass(), new String[]{thriftClassName});
  }

  @Override
  public void postBind() throws IOException {
    reader_ = new ThriftBlockReader<M>(is_, typeRef_);
  }

  @Override
  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // We want to explicitly not do any special syncing here, because the reader_
    // handles this automatically.
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }

  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    // If we are past the end of the file split, tell the reader not to read any more new blocks.
    // Then continue reading until the last of the reader's already-parsed values are used up.
    // The next split will start at the next sync point and no records will be missed.
    if (is_.getPosition() > end_) {
      reader_.markNoMoreNewBlocks();
    }

    M value;
    while ((value = reader_.readNext()) != null) {
      incrCounter(thriftStructsRead, 1L);
      return thriftToPig_.getLazyTuple(value);
    }
    return null;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return ThriftToPig.toSchema(typeRef_.getRawClass());
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;

import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.util.Pair;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.protobuf.Message;
import com.twitter.elephantbird.mapreduce.io.ProtobufBlockReader;
import com.twitter.elephantbird.mapreduce.io.ProtobufWritable;
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
import com.twitter.elephantbird.pig.util.ProtobufTuple;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;


public class LzoProtobufBlockPigLoader<M extends Message> extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufBlockPigLoader.class);

  private ProtobufBlockReader<M> reader_ = null;
  private ProtobufWritable<M> value_ = null;
  private TypeRef<M> typeRef_ = null;
  private final ProtobufToPig protoToPig_ = new ProtobufToPig();

  private Pair<String, String> protobufsRead;
  private Pair<String, String> protobufErrors;

  public LzoProtobufBlockPigLoader() {
    LOG.info("LzoProtobufBlockLoader zero-parameter creation");
  }

  public LzoProtobufBlockPigLoader(String protoClassName) {
    TypeRef<M> typeRef = PigUtil.getProtobufTypeRef(protoClassName);
    setTypeRef(typeRef);
    setLoaderSpec(getClass(), new String[]{protoClassName});
  }

  /**
   * Set the type parameter so it doesn't get erased by Java.  Must be called before getNext!
   *
   * @param typeRef
   */
  public void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    value_ = new ProtobufWritable<M>(typeRef_);
    String group = "LzoBlocks of " + typeRef_.getRawClass().getName();
    protobufsRead = new Pair<String, String>(group, "Protobufs Read");
    protobufErrors = new Pair<String, String>(group, "Errors");
  }

  @Override
  public void postBind() throws IOException {
    reader_ = new ProtobufBlockReader<M>(is_, typeRef_);
  }

  @Override
  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // We want to explicitly not do any special syncing here, because the reader_
    // handles this automatically.
  }

  @Override
  protected boolean verifyStream() throws IOException {
    return is_ != null;
  }


  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  public Tuple getNext() throws IOException {
    if (!verifyStream()) {
      return null;
    }

    // If we are past the end of the file split, tell the reader not to read any more new blocks.
    // Then continue reading until the last of the reader's already-parsed values are used up.
    // The next split will start at the next sync point and no records will be missed.
    if (is_.getPosition() > end_) {
      reader_.markNoMoreNewBlocks();
    }

    Tuple t = null;
    if (reader_.readProtobuf(value_)) {
      if (value_.get() == null) {
        incrCounter(protobufErrors, 1);
      }
      t = new ProtobufTuple(value_.get());
      incrCounter(protobufsRead, 1L);
    }
    return t;
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return protoToPig_.toSchema(Protobufs.getMessageDescriptor(typeRef_.getRawClass()));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import org.apache.pig.ExecType;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.protobuf.Message;
import com.twitter.elephantbird.mapreduce.io.BinaryConverter;
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
import com.twitter.elephantbird.pig.util.ProtobufTuple;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * This is the class for all base64 encoded, line-oriented protocol buffer based pig loaders.
 * Data is expected to be one base64 encoded serialized protocol buffer per line. The specific
 * protocol buffer is a template parameter, generally specified by a codegen'd derived class.
 * See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
 */

public class LzoProtobufB64LinePigLoader<M extends Message> extends LzoBinaryB64LinePigLoader {
  private static final Logger LOG = LoggerFactory.getLogger(LzoProtobufB64LinePigLoader.class);

  private TypeRef<M> typeRef_ = null;
  private ProtobufConverter<M> protoConverter_ = null;

  public LzoProtobufB64LinePigLoader() {
    LOG.info("LzoProtobufB64LineLoader zero-parameter creation");
  }

  public LzoProtobufB64LinePigLoader(String protoClassName) {
    TypeRef<M> typeRef = PigUtil.getProtobufTypeRef(protoClassName);
    setTypeRef(typeRef);
    setLoaderSpec(getClass(), new String[]{protoClassName});
  }

  /**
   * Set the type parameter so it doesn't get erased by Java.  Must be called before getNext!
   *
   * @param typeRef
   */
  public void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    protoConverter_ = ProtobufConverter.newInstance(typeRef);
    BinaryConverter<Tuple> converter = new BinaryConverter<Tuple>() {
      public Tuple fromBytes(byte[] messageBuffer) {
        Message message = protoConverter_.fromBytes(messageBuffer);
        if (message != null) {
          return new ProtobufTuple(message);
        }
        return null;
      }

      public byte[] toBytes(Tuple message) {
        throw new RuntimeException("not implemented");
      }
    };

    init(typeRef_.getRawClass().getName(), converter);
  }

  @Override
  public Schema determineSchema(String filename, ExecType execType, DataStorage store) throws IOException {
    return new ProtobufToPig().toSchema(Protobufs.getMessageDescriptor(typeRef_.getRawClass()));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/piggybank/ThriftBytesToTuple.java;<<<<<<< MINE
import com.twitter.elephantbird.pig8.util.ThriftToPig;
import com.twitter.elephantbird.util.ThriftUtils;
=======
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.pig.util.ThriftToPig;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/java/com/twitter/elephantbird/pig/piggybank/ProtobufBytesToTuple.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.piggybank;

import java.io.IOException;

import org.apache.pig.EvalFunc;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.logicalLayer.schema.Schema;

import com.google.protobuf.Message;
import com.twitter.elephantbird.mapreduce.io.ProtobufConverter;
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
import com.twitter.elephantbird.pig.util.ProtobufTuple;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * The base class for a Pig UDF that takes as input a tuple containing a single element, the
 * bytes of a serialized protocol buffer as a DataByteArray.  It outputs the protobuf in
 * expanded form.  The specific protocol buffer is a template parameter, generally specified by a
 * codegen'd derived class. See com.twitter.elephantbird.proto.HadoopProtoCodeGenerator.
 * Alternatly, full class name could be passed to the constructor in Pig:
 * <pre>
 *   DEFINE PersonProtobufBytesToTuple com.twitter.elephantbird.pig.piggybank.ProtobufBytesToTuple('com.twitter.elephantbird.proto.Person');
 *   persons = FOREACH protobufs GENERATE PersonProtobufBytesToTuple($0);
 * </pre>
 */
public class ProtobufBytesToTuple<M extends Message> extends EvalFunc<Tuple> {
  private TypeRef<M> typeRef_ = null;
  private ProtobufConverter<M> protoConverter_ = null;
  private final ProtobufToPig protoToPig_ = new ProtobufToPig();

  public ProtobufBytesToTuple() {}

  public ProtobufBytesToTuple(String protoClassName) {
    TypeRef<M> typeRef = PigUtil.getProtobufTypeRef(protoClassName);
    setTypeRef(typeRef);
  }

  /**
   * Set the type parameter so it doesn't get erased by Java. Must be called during
   * initialization.
   * @param typeRef
   */
  public void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    protoConverter_ = ProtobufConverter.newInstance(typeRef);
  }

  @Override
  public Tuple exec(Tuple input) throws IOException {
    if (input == null || input.size() < 1) return null;
    try {
      DataByteArray bytes = (DataByteArray) input.get(0);
      M value_ = protoConverter_.fromBytes(bytes.get());
      return new ProtobufTuple(value_);
    } catch (IOException e) {
      return null;
    }
  }

  @Override
  public Schema outputSchema(Schema input) {
    return protoToPig_.toSchema(Protobufs.getMessageDescriptor(typeRef_.getRawClass()));
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_27ceb0c_4353485/rev_27ceb0c-4353485/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
import com.twitter.elephantbird.pig8.util.ThriftToPig;
=======
import com.twitter.elephantbird.pig.util.PigToThrift;
import com.twitter.elephantbird.pig.util.ThriftToPig;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_a64b868_6e11c79/rev_a64b868-6e11c79/ribbon-core/src/main/java/com/netflix/client/AbstractLoadBalancerAwareClient.java;<<<<<<< MINE
     * Get the default port which is protocol specific if port is missing in the request URI.
=======
     * Get the default port from the vip address.
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_a64b868_6e11c79/rev_a64b868-6e11c79/ribbon-core/src/main/java/com/netflix/client/AbstractLoadBalancerAwareClient.java;<<<<<<< MINE
=======
     * @deprecated replaced by {@link #getDefaultPortFromScheme(String)}
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_a64b868_6e11c79/rev_a64b868-6e11c79/ribbon-core/src/main/java/com/netflix/client/AbstractLoadBalancerAwareClient.java;<<<<<<< MINE
=======
    
    
    /**
     * Get the default port of the target server given the scheme of vip address if it is available. 
     * Subclass should override it to provider protocol specific default port number if any.
     * 
     * @param scheme from the vip address. null if not present.
     * @return 80 if scheme is http, 443 if scheme is https, -1 else.
     */
    protected int getDefaultPortFromScheme(String scheme) {
        if (scheme == null) {
            return -1;
        }
        if (scheme.equals("http")) {
            return 80;
        } else if (scheme.equals("https")) {
            return 443;
        } else {
            return -1;
        }
    }

>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_a64b868_6e11c79/rev_a64b868-6e11c79/ribbon-core/src/main/java/com/netflix/client/AbstractLoadBalancerAwareClient.java;<<<<<<< MINE
        	port = getDefaultPort();
=======
        	port = getDefaultPortFromScheme(scheme);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_a64b868_6e11c79/rev_a64b868-6e11c79/ribbon-httpclient/src/main/java/com/netflix/niws/client/http/RestClient.java;<<<<<<< MINE
=======
	
	
    @Override
    protected int getDefaultPortFromScheme(String scheme) {        
        int port = super.getDefaultPortFromScheme(scheme);
        if (port < 0) {
            return 80;
        } else {
            return port;
        }
    }

>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/HttpProfiler.java;<<<<<<< MINE
=======
  HttpProfiler<Void> NONE = new HttpProfiler<Void>() {
    @Override public Void beforeCall() {
      return null;
    }
    @Override public void afterCall(RequestInformation requestInfo,
        long elapsedTime, int statusCode, Void beforeCallData) {
    }
  };

>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/Fetcher.java;<<<<<<< MINE
import com.google.inject.Inject;
import com.google.inject.Provider;
=======
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/Fetcher.java;<<<<<<< MINE
=======
import javax.inject.Inject;
import javax.inject.Provider;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
import com.google.inject.Inject;
=======
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
import com.google.inject.Provider;
import com.google.inject.Singleton;
import org.apache.http.HttpEntity;
import org.apache.http.HttpResponse;
import org.apache.http.client.HttpClient;
import org.apache.http.client.ResponseHandler;
import org.apache.http.client.methods.HttpEntityEnclosingRequestBase;
import org.apache.http.client.methods.HttpUriRequest;
import retrofit.core.Callback;
import retrofit.core.MainThread;

=======
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
import javax.inject.Inject;
import javax.inject.Provider;
import javax.inject.Singleton;
import org.apache.http.Header;
import org.apache.http.HttpEntity;
import org.apache.http.HttpResponse;
import org.apache.http.client.HttpClient;
import org.apache.http.client.ResponseHandler;
import org.apache.http.client.methods.HttpEntityEnclosingRequestBase;
import org.apache.http.client.methods.HttpUriRequest;
import retrofit.core.Callback;
import retrofit.core.MainThread;
=======
import javax.inject.Inject;
import javax.inject.Provider;
import javax.inject.Singleton;
import org.apache.http.HttpEntity;
import org.apache.http.HttpResponse;
import org.apache.http.client.HttpClient;
import org.apache.http.client.ResponseHandler;
import org.apache.http.client.methods.HttpEntityEnclosingRequestBase;
import org.apache.http.client.methods.HttpUriRequest;
import retrofit.core.Callback;
import retrofit.core.MainThread;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
  @Inject(optional = true) private HttpProfiler profiler;
=======
  @Inject private HttpProfiler profiler = HttpProfiler.NONE;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
=======
   * Returns a new instance of {@code type} that uses {@code restAdapter} to
   * convert Java method calls to Rest calls.
   */
  @SuppressWarnings("unchecked")
  public static <T> T create(RestAdapter restAdapter, Class<T> type) {
    RestAdapter.RestHandler handler = restAdapter.new RestHandler();
    return (T) Proxy.newProxyInstance(type.getClassLoader(), new Class<?>[]{type}, handler);
  }

  /**
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
  public static <T> Provider<T> createProvider(final Class<T> type) {
    return new Provider<T>() {
=======
  public static <T> com.google.inject.Provider<T> createProvider(final Class<T> type) {
    return new com.google.inject.Provider<T>() {
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE

      @SuppressWarnings("unchecked")
=======
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
        RestAdapter.RestHandler handler = restAdapter.new RestHandler();
        return (T) Proxy.newProxyInstance(type.getClassLoader(), new Class<?>[]{type}, handler);
=======
        return create(restAdapter, type);
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
        final ResponseHandler<Void> rh = (profiler == null) ? gsonResponseHandler
=======
        final ResponseHandler<Void> rh = (profiler == HttpProfiler.NONE)
            ? gsonResponseHandler
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/test/java/retrofit/http/FetcherTest.java;<<<<<<< MINE
import com.google.inject.Provider;
=======
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/test/java/retrofit/http/FetcherTest.java;<<<<<<< MINE
=======
import javax.inject.Provider;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/test/java/retrofit/http/RestAdapterTest.java;<<<<<<< MINE
=======
  private HttpProfiler mockProfiler;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/test/java/retrofit/http/RestAdapterTest.java;<<<<<<< MINE
=======
    mockProfiler   = createMock(HttpProfiler.class);
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_35b7257_838711b/rev_35b7257-838711b/http/src/test/java/retrofit/http/RestAdapterTest.java;<<<<<<< MINE
=======
            bind(HttpProfiler.class).toInstance(HttpProfiler.NONE);
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_9749e85_ff2918c/rev_9749e85-ff2918c/atlas-demo/AtlasDemo/buildSrc/src/main/java/com/taobao/android/builder/extension/AtlasExtension.java;<<<<<<< MINE

=======
import com.taobao.android.builder.extension.factory.MultiDexConfigFactory;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_9749e85_ff2918c/rev_9749e85-ff2918c/atlas-demo/AtlasDemo/buildSrc/src/main/java/com/taobao/android/builder/extension/AtlasExtension.java;<<<<<<< MINE

    public Logger getLogger() {
        return logger;
    }

    public Project getProject() {
        return project;
    }
=======

    public NamedDomainObjectContainer<MultiDexConfig> getMultiDexConfigs() {
        return multiDexConfigs;
    }

    public void setMultiDexConfigs(
        NamedDomainObjectContainer<MultiDexConfig> multiDexConfigs) {
        this.multiDexConfigs = multiDexConfigs;
    }
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_9749e85_ff2918c/rev_9749e85-ff2918c/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/extension/AtlasExtension.java;<<<<<<< MINE

=======
import com.taobao.android.builder.extension.factory.MultiDexConfigFactory;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_9749e85_ff2918c/rev_9749e85-ff2918c/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/extension/AtlasExtension.java;<<<<<<< MINE

    public Logger getLogger() {
        return logger;
    }

    public Project getProject() {
        return project;
    }
=======

    public NamedDomainObjectContainer<MultiDexConfig> getMultiDexConfigs() {
        return multiDexConfigs;
    }

    public void setMultiDexConfigs(
        NamedDomainObjectContainer<MultiDexConfig> multiDexConfigs) {
        this.multiDexConfigs = multiDexConfigs;
    }
>>>>>>> YOURS
/home/taes/taes/projects/archaius/revisions/rev_07ee5dc_bfb68e9/rev_07ee5dc-bfb68e9/archaius-core/src/main/java/com/netflix/config/DynamicSetProperty.java;<<<<<<< MINE
        
=======

    public static final String DEFAULT_DELIMITER = ",";

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ed6d50d_1f0c02e/rev_ed6d50d-1f0c02e/src/java/com/twitter/elephantbird/util/Codecs.java;<<<<<<< MINE
        
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ed6d50d_1f0c02e/rev_ed6d50d-1f0c02e/src/java/com/twitter/elephantbird/util/Codecs.java;<<<<<<< MINE
    
=======

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ed6d50d_1f0c02e/rev_ed6d50d-1f0c02e/src/java/com/twitter/elephantbird/util/Codecs.java;<<<<<<< MINE
     * Get a instance of standard base64 implementation from apache 
     * commons-codec library 
=======
     * Get a instance of standard base64 implementation from apache
     * commons-codec library
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ed6d50d_1f0c02e/rev_ed6d50d-1f0c02e/src/java/com/twitter/elephantbird/util/Codecs.java;<<<<<<< MINE
=======
      /* with constructor Base64() in commons-codec-1.4
       * encode() inserts a newline after every 76 characters.
       * Base64(0) disables that incompatibility.
       */
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ed6d50d_1f0c02e/rev_ed6d50d-1f0c02e/src/java/com/twitter/elephantbird/pig/store/LzoProtobufB64LinePigStorage.java;<<<<<<< MINE
import org.omg.IOP.Codec;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d48ed68_da570d2/rev_d48ed68-da570d2/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufBlockPigletGenerator.java;<<<<<<< MINE
import com.twitter.elephantbird.pig8.util.ProtobufToPig;
=======
import com.twitter.elephantbird.pig.load.LzoProtobufBlockPigLoader;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d48ed68_da570d2/rev_d48ed68-da570d2/src/java/com/twitter/elephantbird/proto/codegen/LzoProtobufB64LinePigletGenerator.java;<<<<<<< MINE
import com.twitter.elephantbird.pig8.util.ProtobufToPig;
=======
import com.twitter.elephantbird.pig.load.LzoProtobufB64LinePigLoader;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d48ed68_da570d2/rev_d48ed68-da570d2/src/java/com/twitter/elephantbird/pig/store/LzoProtobufB64LinePigStorage.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.store;

import java.io.IOException;

import org.apache.commons.codec.binary.Base64;
import org.apache.pig.data.Tuple;

import com.google.protobuf.Message;
import com.twitter.elephantbird.pig.util.PigToProtobuf;
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.util.Codecs;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * Serializes Pig Tuples into Base-64 encoded, line-delimited protocol buffers.
 * The fields in the pig tuple must correspond exactly to the fields in the protobuf, as
 * no name-matching is performed (names of the tuple fields are not currently accessible to
 * a StoreFunc. It will be in 0.7, so something more flexible will be possible)
 *
 * @param <M> Protocol Buffer Message class being serialized
 */
public class LzoProtobufB64LinePigStorage<M extends Message> extends LzoBaseStoreFunc {

  private TypeRef<M> typeRef_;
  private Base64 base64_ = Codecs.createStandardBase64();
  private Message msgObj; // for newBuilder()

  protected LzoProtobufB64LinePigStorage(){}

  public LzoProtobufB64LinePigStorage(String protoClassName) {
    TypeRef<M> typeRef = PigUtil.getProtobufTypeRef(protoClassName);
    setTypeRef(typeRef);
  }

  protected void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
    msgObj =  Protobufs.getMessageBuilder(typeRef_.getRawClass()).build();
  }

  public void putNext(Tuple f) throws IOException {
    if (f == null) return;
    Message message = PigToProtobuf.tupleToMessage(msgObj.newBuilderForType(), f);
    os_.write(base64_.encode(message.toByteArray()));
    os_.write(Protobufs.NEWLINE_UTF8_BYTE);
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d48ed68_da570d2/rev_d48ed68-da570d2/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

import java.nio.ByteBuffer;
import java.util.Arrays;
import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
import org.apache.pig.LoadFunc;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.BagFactory;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.DataType;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
import org.apache.thrift.TBase;
import org.apache.thrift.protocol.TType;

import com.google.common.collect.Lists;
import com.twitter.elephantbird.pig.load.LzoThriftB64LinePigLoader;
import com.twitter.elephantbird.thrift.TStructDescriptor;
import com.twitter.elephantbird.thrift.TStructDescriptor.Field;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

/**
 * <li> converts a Thrift struct to a Pig tuple
 * <li> utilities to provide schema for Pig loaders and Pig scripts
 */
public class ThriftToPig<M extends TBase<?, ?>> {
  public static final Logger LOG = LogManager.getLogger(ThriftToPig.class);

  private static BagFactory bagFactory = BagFactory.getInstance();
  private static TupleFactory tupleFactory  = TupleFactory.getInstance();

  private TStructDescriptor structDesc;

  public static <M extends TBase<?, ?>> ThriftToPig<M> newInstance(Class<M> tClass) {
    return new ThriftToPig<M>(tClass);
  }

  public static <M extends TBase<?, ?>> ThriftToPig<M> newInstance(TypeRef<M> typeRef) {
    return new ThriftToPig<M>(typeRef.getRawClass());
  }

  public ThriftToPig(Class<M> tClass) {
    structDesc = TStructDescriptor.getInstance(tClass);
  }

  /**
   * Converts a thrift object to Pig tuple.
   * All the fields are deserialized.
   * It might be better to use getLazyTuple() if not all fields
   * are required.
   */
  public Tuple getPigTuple(M thriftObj) {
    return toTuple(structDesc, thriftObj);
  }

  /**
   * Similar to {@link #getPigTuple(TBase)}. This delays
   * serialization of tuple contents until they are requested.
   * @param thriftObj
   * @return
   */
  public Tuple getLazyTuple(M thriftObj) {
    return new LazyTuple(thriftObj);
  }

  @SuppressWarnings("unchecked")
  private static <T extends TBase>Tuple toTuple(TStructDescriptor tDesc, T tObj) {
    int size = tDesc.getFields().size();
    Tuple tuple = tupleFactory.newTuple(size);
    for (int i=0; i<size; i++) {
      Field field = tDesc.getFieldAt(i);
      Object value = tDesc.getFieldValue(i, tObj);
      try {
        tuple.set(i, toPigObject(field, value));
      } catch (ExecException e) { // not expected
        throw new RuntimeException(e);
      }
    }
    return tuple;
  }

  @SuppressWarnings("unchecked")
  private static Object toPigObject(Field field, Object value) {
    if (value == null) {
      return null;
    }

    switch (field.getType()) {
    case TType.BOOL:
      return Integer.valueOf((Boolean)value ? 1 : 0);
    case TType.BYTE :
      return Integer.valueOf((Byte)value);
    case TType.I16 :
      return Integer.valueOf((Short)value);
    case TType.STRING:
      return stringTypeToPig(value);
    case TType.STRUCT:
      return toTuple(field.gettStructDescriptor(), (TBase<?, ?>)value);
    case TType.MAP:
      return toPigMap(field, (Map<Object, Object>)value);
    case TType.SET:
      return toPigBag(field.getSetElemField(), (Collection<Object>)value);
    case TType.LIST:
      return toPigBag(field.getListElemField(), (Collection<Object>)value);
    case TType.ENUM:
      return value.toString();
    default:
      // standard types : I32, I64, DOUBLE, etc.
      return value;
    }
  }

  /**
   * TType.STRING is a mess in Thrift. It could be byte[], ByteBuffer,
   * or even a String!.
   */
  private static Object stringTypeToPig(Object value) {
    if (value instanceof String) {
      return value;
    }
    if (value instanceof byte[]) {
      byte[] buf = (byte[])value;
      return new DataByteArray(Arrays.copyOf(buf, buf.length));
    }
    if (value instanceof ByteBuffer) {
      ByteBuffer bin = (ByteBuffer)value;
      byte[] buf = new byte[bin.remaining()];
      bin.mark();
      bin.get(buf);
      bin.reset();
      return new DataByteArray(buf);
    }
    return null;
  }

  private static Map<String, Object> toPigMap(Field field, Map<Object, Object> map) {
    // PIG map's key always a String. just use toString() and hope
    // things would work out ok.
    HashMap<String, Object> out = new HashMap<String, Object>(map.size());
    Field valueField = field.getMapValueField();
    for(Entry<Object, Object> e : map.entrySet()) {
      Object prev = out.put(e.getKey().toString(),
                            toPigObject(valueField, e.getValue()));
      if (prev != null) {
        String msg = "Duplicate keys while converting to String while "
          + " processing map " + field.getName() + " (key type : "
          + field.getMapKeyField().getType() + " value type : "
          + field.getMapValueField().getType() + ")";
        LOG.warn(msg);
        throw new RuntimeException(msg);
      }
    }
    return out;
  }

  private static DataBag toPigBag(Field field, Collection<Object> values) {
    List<Tuple> tuples = Lists.newArrayListWithExpectedSize(values.size());
    for(Object value : values) {
      Object pValue = toPigObject(field, value);
      if (pValue instanceof Tuple) { // DataBag should contain Tuples
        tuples.add((Tuple)pValue);
      } else {
        tuples.add(tupleFactory.newTuple(pValue));
      }
    }
    return bagFactory.newDefaultBag(tuples);
  }

  @SuppressWarnings("serial")
  /**
   * Delays serialization of Thrift fields until they are requested.
   */
  private class LazyTuple extends AbstractLazyTuple {
    /* NOTE : This is only a partial optimization. The other part
     * is to avoid deserialization of the Thrift fields from the
     * binary buffer.
     *
     * Currently TDeserializer allows deserializing just one field,
     * psuedo-skipping over the fields before it.
     * But if we are going deserialize 5 fields out of 20, we will be
     * skipping over same set of fields multiple times. OTOH this might
     * still be better than a full deserialization.
     *
     * We need to write our own version of TBinaryProtocol that truly skips.
     * Even TDeserializer 'skips'/ignores only after deserializing fields.
     * (e.g. Strings, Integers, buffers etc).
     */
    private M tObject;

    LazyTuple(M tObject) {
      initRealTuple(structDesc.getFields().size());
      this.tObject = tObject;
    }

    @Override
    protected Object getObjectAt(int index) {
      Field field = structDesc.getFieldAt(index);
      return toPigObject(field, structDesc.getFieldValue(index, tObject));
    }
  }

  /**
   * Returns Pig schema for the Thrift struct.
   */
  public static Schema toSchema(Class<? extends TBase<?, ?>> tClass) {
    return toSchema(TStructDescriptor.getInstance(tClass));
  }
  public static Schema toSchema(TStructDescriptor tDesc ) {
    Schema schema = new Schema();

    try {
      for(Field field : tDesc.getFields()) {
        String fieldName = field.getName();
        if (field.isStruct()) {
          schema.add(new FieldSchema(fieldName, toSchema(field.gettStructDescriptor()), DataType.TUPLE));
        } else {
          schema.add(singleFieldToFieldSchema(fieldName, field));
        }
      }
    } catch (FrontendException t) {
      throw new RuntimeException(t);
    }

    return schema;
  }

  private static FieldSchema singleFieldToFieldSchema(String fieldName, Field field) throws FrontendException {
    switch (field.getType()) {
      case TType.LIST:
        return new FieldSchema(fieldName, singleFieldToTupleSchema(fieldName + "_tuple", field.getListElemField()), DataType.BAG);
      case TType.SET:
        return new FieldSchema(fieldName, singleFieldToTupleSchema(fieldName + "_tuple", field.getSetElemField()), DataType.BAG);
      case TType.MAP:
        // can not specify types for maps in Pig.
        if (field.getMapKeyField().getType() != TType.STRING) {
          LOG.warn("Using a map with non-string key for field " + field.getName()
              + ". while converting to PIG Tuple, toString() is used for the key."
              + " It could result in incorrect maps.");
        }
        return new FieldSchema(fieldName, null, DataType.MAP);
      default:
        return new FieldSchema(fieldName, null, getPigDataType(field));
    }
  }

  /**
   * Returns a schema with single tuple (for Pig bags).
   */
  private static Schema singleFieldToTupleSchema(String fieldName, Field field) throws FrontendException {

    FieldSchema fieldSchema = null;

    switch (field.getType()) {
      case TType.STRUCT:
        // wrapping STRUCT in a FieldSchema makes it impossible to
        // access fields in PIG script (causes runtime error).
        return toSchema(field.gettStructDescriptor());
      case TType.LIST:
        fieldSchema = singleFieldToFieldSchema(fieldName, field.getListElemField());
        break;
      case TType.SET:
        fieldSchema = singleFieldToFieldSchema(fieldName, field.getSetElemField());
        break;
      default:
        fieldSchema = new FieldSchema(fieldName, null, getPigDataType(field));
    }

    Schema schema = new Schema();
    schema.add(fieldSchema);
    return schema;
  }

  private static byte getPigDataType(Field field) {
    switch (field.getType()) {
      case TType.BOOL:
      case TType.BYTE:
      case TType.I16:
      case TType.I32:
        return DataType.INTEGER;
      case TType.ENUM:
        return DataType.CHARARRAY;
      case TType.I64:
        return DataType.LONG;
      case TType.DOUBLE:
        return DataType.DOUBLE;
      case TType.STRING:
        return field.isBuffer() ? DataType.BYTEARRAY : DataType.CHARARRAY;
      default:
        throw new IllegalArgumentException("Unexpected type where a simple type is expected : " + field.getType());
    }
  }

  /**
   * Turn a Thrift Struct into a loading schema for a pig script.
   */
  public static String toPigScript(Class<? extends TBase<?, ?>> thriftClass,
                                   Class<? extends LoadFunc> pigLoader) {
    StringBuilder sb = new StringBuilder();
    /* we are commenting out explicit schema specification. The schema is
     * included mainly to help the readers of the pig script. Pig learns the
     * schema directly from the loader.
     * If explicit schema is not commented, we might have surprising results
     * when a Thrift class (possibly in control of another team) changes,
     * but the Pig script is not updated. Commenting it out avoids this.
     */
    StringBuilder prefix = new StringBuilder("       --  ");
    sb.append("raw_data = load '$INPUT_FILES' using ")
      .append(pigLoader.getName())
      .append("('")
      .append(thriftClass.getName())
      .append("');\n")
      .append(prefix)
      .append("as ");
    prefix.append("   ");

    try {
      stringifySchema(sb, toSchema(thriftClass), DataType.TUPLE, prefix);
    } catch (FrontendException e) {
      throw new RuntimeException(e);
    }

    sb.append("\n");
    return sb.toString();
  }

  /**
   * Print formatted schema. This is a modified version of
   * {@link Schema#stringifySchema(StringBuilder, Schema, byte)}
   * with support for (indented) pretty printing.
   */
  // This is used for building up output string
  // type can only be BAG or TUPLE
  public static void stringifySchema(StringBuilder sb,
                                     Schema schema,
                                     byte type,
                                     StringBuilder prefix)
                                          throws FrontendException{
      // this is a modified version of {@link Schema#stringifySchema(StringBuilder, Schema, byte)}
      if (type == DataType.TUPLE) {
          sb.append("(") ;
      }
      else if (type == DataType.BAG) {
          sb.append("{") ;
      }

      prefix.append("  ");
      sb.append("\n").append(prefix);

      if (schema == null) {
          sb.append("null") ;
      }
      else {
          boolean isFirst = true ;
          for (int i=0; i< schema.size() ;i++) {

              if (!isFirst) {
                  sb.append(",\n").append(prefix);
              }
              else {
                  isFirst = false ;
              }

              FieldSchema fs = schema.getField(i) ;

              if(fs == null) {
                  sb.append("null");
                  continue;
              }

              if (fs.alias != null) {
                  sb.append(fs.alias);
                  sb.append(": ");
              }

              if (DataType.isAtomic(fs.type)) {
                  sb.append(DataType.findTypeName(fs.type)) ;
              }
              else if ( (fs.type == DataType.TUPLE) ||
                        (fs.type == DataType.BAG) ) {
                  // safety net
                  if (schema != fs.schema) {
                      stringifySchema(sb, fs.schema, fs.type, prefix) ;
                  }
                  else {
                      throw new AssertionError("Schema refers to itself "
                                               + "as inner schema") ;
                  }
              } else if (fs.type == DataType.MAP) {
                  sb.append(DataType.findTypeName(fs.type) + "[ ]") ;
              } else {
                  sb.append(DataType.findTypeName(fs.type)) ;
              }
          }
      }

      prefix.setLength(prefix.length()-2);
      sb.append("\n").append(prefix);

      if (type == DataType.TUPLE) {
          sb.append(")") ;
      }
      else if (type == DataType.BAG) {
          sb.append("}") ;
      }
  }

  public static void main(String[] args) throws Exception {
    if (args.length > 0) {
      Class<? extends TBase<?, ?>> tClass = ThriftUtils.getTypeRef(args[0]).getRawClass();
      System.out.println(args[0] + " : " + toSchema(tClass).toString());
      System.out.println(toPigScript(tClass, LzoThriftB64LinePigLoader.class));
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d48ed68_da570d2/rev_d48ed68-da570d2/src/java/com/twitter/elephantbird/pig/util/ProtobufToPig.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

import java.util.List;
import java.util.Map;

import com.google.common.base.Joiner;
import com.google.common.collect.Lists;
import com.google.common.collect.Maps;
import com.google.protobuf.DescriptorProtos.DescriptorProto;
import com.google.protobuf.Descriptors.Descriptor;
import com.google.protobuf.Descriptors.EnumValueDescriptor;
import com.google.protobuf.Descriptors.FieldDescriptor;
import com.google.protobuf.ByteString;
import com.google.protobuf.Message;
import com.twitter.data.proto.Misc.CountedMap;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.BagFactory;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.DataType;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * A class for turning codegen'd protos into Pig Tuples and Schemas
 * for custom Pig LoadFuncs.
 * @author Kevin Weil
 */
public class ProtobufToPig {
  private static final Logger LOG = LoggerFactory.getLogger(ProtobufToPig.class);

  private static final TupleFactory tupleFactory_ = TupleFactory.getInstance();
  private static BagFactory bagFactory_ = BagFactory.getInstance();

  public enum CoercionLevel { kNoCoercion, kAllowCoercionToPigMaps }

  private final CoercionLevel coercionLevel_;

  public ProtobufToPig() {
    this(CoercionLevel.kAllowCoercionToPigMaps);
  }

  public ProtobufToPig(CoercionLevel coercionLevel) {
    coercionLevel_ = coercionLevel;
  }
  /**
   * Turn a generic message into a Tuple.  Individual fields that are enums
   * are converted into their string equivalents.  Fields that are not filled
   * out in the protobuf are set to null, unless there is a default field value in
   * which case that is used instead.
   * @param msg the protobuf message
   * @return a pig tuple representing the message.
   */
  public Tuple toTuple(Message msg) {
    if (msg == null) {
      // Pig tuples deal gracefully with nulls.
      // Also, we can be called with null here in recursive calls.
      return null;
    }

    Descriptor msgDescriptor = msg.getDescriptorForType();
    Tuple tuple = tupleFactory_.newTuple(msgDescriptor.getFields().size());
    int curField = 0;
    try {
      // Walk through all the possible fields in the message.
      for (FieldDescriptor fieldDescriptor : msgDescriptor.getFields()) {
        // Get the set value, or the default value, or null.
        Object fieldValue = getFieldValue(msg, fieldDescriptor);

        if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
          tuple.set(curField++, messageToTuple(fieldDescriptor, fieldValue));
        } else {
          tuple.set(curField++, singleFieldToTuple(fieldDescriptor, fieldValue));
        }
      }
    } catch (ExecException e) {
      LOG.warn("Could not convert msg " + msg + " to tuple", e);
    }

    return tuple;
  }

  /**
   * Translate a nested message to a tuple.  If the field is repeated, it walks the list and adds each to a bag.
   * Otherwise, it just adds the given one.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param fieldValue the object representing the value of this field, possibly null.
   * @return the object representing fieldValue in Pig -- either a bag or a tuple.
   */
  @SuppressWarnings("unchecked")
  protected Object messageToTuple(FieldDescriptor fieldDescriptor, Object fieldValue) {
    assert fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE : "messageToTuple called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      // The protobuf contract is that if the field is repeated, then the object returned is actually a List
      // of the underlying datatype, which in this case is a nested message.
      List<Message> messageList = (List<Message>) (fieldValue != null ? fieldValue : Lists.newArrayList());

      // Since protobufs do not have a map type, we use CountedMap to fake it.  Whenever the protobuf has a repeated CountedMap in it,
      // we can force the type into a pig map type.
      if (coercionLevel_ == CoercionLevel.kAllowCoercionToPigMaps &&
          fieldDescriptor.getMessageType().getName().equals(CountedMap.getDescriptor().getName())) {
        Map<Object, Long> map = Maps.newHashMap();
        for (Message m : messageList) {
          CountedMap cm = (CountedMap) m;
          final Long curCount = map.get(cm.getKey());
          map.put(cm.getKey(), (curCount == null ? 0L : curCount) + cm.getValue());
        }
        return map;
      } else {
        DataBag bag = bagFactory_.newDefaultBag();
        for (Message m : messageList) {
          bag.add(new ProtobufTuple(m));
        }
        return bag;
      }
    } else {
      return new ProtobufTuple((Message)fieldValue);
    }
  }

  /**
   * Translate a single field to a tuple.  If the field is repeated, it walks the list and adds each to a bag.
   * Otherwise, it just adds the given one.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param fieldValue the object representing the value of this field, possibly null.
   * @return the object representing fieldValue in Pig -- either a bag or a single field.
   * @throws ExecException if Pig decides to.  Shouldn't happen because we won't walk off the end of a tuple's field set.
   */
  @SuppressWarnings("unchecked")
  protected Object singleFieldToTuple(FieldDescriptor fieldDescriptor, Object fieldValue) {
    assert fieldDescriptor.getType() != FieldDescriptor.Type.MESSAGE : "messageToFieldSchema called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      // The protobuf contract is that if the field is repeated, then the object returned is actually a List
      // of the underlying datatype, which in this case is a "primitive" like int, float, String, etc.
      // We have to make a single-item tuple out of it to put it in the bag.
      DataBag bag = bagFactory_.newDefaultBag();
      List<Object> fieldValueList = (List<Object>) (fieldValue != null ? fieldValue : Lists.newArrayList());
      for (Object singleFieldValue : fieldValueList) {
        Object nonEnumFieldValue = coerceToPigTypes(fieldDescriptor, singleFieldValue);
        Tuple innerTuple = tupleFactory_.newTuple(1);
        try {
          innerTuple.set(0, nonEnumFieldValue);
        } catch (ExecException e) { // not expected
          throw new RuntimeException(e);
        }
        bag.add(innerTuple);
      }
      return bag;
    } else {
      return coerceToPigTypes(fieldDescriptor, fieldValue);
    }
  }

  /**
   * If the given field value is an enum, translate it to the enum's name as a string, since Pig cannot handle enums.
   * Also, if the given field value is a bool, translate it to 0 or 1 to avoid Pig bools, which can be sketchy.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param fieldValue the object representing the value of this field, possibly null.
   * @return the object, unless it was from an enum field, in which case we return the name of the enum field.
   */
  private Object coerceToPigTypes(FieldDescriptor fieldDescriptor, Object fieldValue) {
    if (fieldDescriptor.getType() == FieldDescriptor.Type.ENUM && fieldValue != null) {
      EnumValueDescriptor enumValueDescriptor = (EnumValueDescriptor)fieldValue;
      return enumValueDescriptor.getName();
    } else if (fieldDescriptor.getType() == FieldDescriptor.Type.BOOL && fieldValue != null) {
      Boolean boolValue = (Boolean)fieldValue;
      return new Integer(boolValue ? 1 : 0);
    } else if (fieldDescriptor.getType() == FieldDescriptor.Type.BYTES && fieldValue != null) {
      ByteString bsValue = (ByteString)fieldValue;
      return new DataByteArray(bsValue.toByteArray());
    }
    return fieldValue;
  }

  /**
   * A utility function for getting the value of a field in a protobuf message.  It first tries the
   * literal set value in the protobuf's field list.  If the value isn't set, and the field has a default
   * value, it uses that.  Otherwise, it returns null.
   * @param msg the protobuf message
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the value of the field, or null if none can be assigned.
   */
  protected Object getFieldValue(Message msg, FieldDescriptor fieldDescriptor) {
    Object o = null;
    Map<FieldDescriptor, Object> setFields = msg.getAllFields();
    if (setFields.containsKey(fieldDescriptor)) {
      o = setFields.get(fieldDescriptor);
    } else if (fieldDescriptor.hasDefaultValue()) {
      o = fieldDescriptor.getDefaultValue();
    }

    return o;
  }

  /**
   * Turn a generic message descriptor into a Schema.  Individual fields that are enums
   * are converted into their string equivalents.
   * @param msgDescriptor the descriptor for the given message type.
   * @return a pig schema representing the message.
   */
  public Schema toSchema(Descriptor msgDescriptor) {
    Schema schema = new Schema();

    try {
      // Walk through all the possible fields in the message.
      for (FieldDescriptor fieldDescriptor : msgDescriptor.getFields()) {
        if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
          schema.add(messageToFieldSchema(fieldDescriptor));
        } else {
          schema.add(singleFieldToFieldSchema(fieldDescriptor));
        }
      }
    } catch (FrontendException e) {
      LOG.warn("Could not convert descriptor " + msgDescriptor + " to schema", e);
    }

    return schema;
  }

  /**
   * Turn a nested message into a Schema object.  For repeated nested messages, it generates a schema for a bag of
   * tuples.  For non-repeated nested messages, it just generates a schema for the tuple itself.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the Schema for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private FieldSchema messageToFieldSchema(FieldDescriptor fieldDescriptor) throws FrontendException {
    assert fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE : "messageToFieldSchema called with field of type " + fieldDescriptor.getType();

    // Since protobufs do not have a map type, we use CountedMap to fake it.  Whenever the protobuf has a repeated CountedMap in it,
    // we can force the type into a pig map type.
    if (coercionLevel_ == CoercionLevel.kAllowCoercionToPigMaps &&
        fieldDescriptor.getMessageType().getName().equals(CountedMap.getDescriptor().getName()) && fieldDescriptor.isRepeated()) {
      return new FieldSchema(fieldDescriptor.getName(), null, DataType.MAP);
    }

    Schema innerSchema = toSchema(fieldDescriptor.getMessageType());

    if (fieldDescriptor.isRepeated()) {
      Schema tupleSchema = new Schema();
      tupleSchema.add(new FieldSchema(fieldDescriptor.getName() + "_tuple", innerSchema, DataType.TUPLE));
      return new FieldSchema(fieldDescriptor.getName(), tupleSchema, DataType.BAG);
    } else {
      return new FieldSchema(fieldDescriptor.getName(), innerSchema, DataType.TUPLE);
    }
  }

  /**
   * Turn a single field into a Schema object.  For repeated single fields, it generates a schema for a bag of single-item tuples.
   * For non-repeated fields, it just generates a standard field schema.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the Schema for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private FieldSchema singleFieldToFieldSchema(FieldDescriptor fieldDescriptor) throws FrontendException {
    assert fieldDescriptor.getType() != FieldDescriptor.Type.MESSAGE : "singleFieldToFieldSchema called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      Schema itemSchema = new Schema();
      itemSchema.add(new FieldSchema(fieldDescriptor.getName(), null, getPigDataType(fieldDescriptor)));
      Schema itemTupleSchema = new Schema();
      itemTupleSchema.add(new FieldSchema(fieldDescriptor.getName() + "_tuple", itemSchema, DataType.TUPLE));

      return new FieldSchema(fieldDescriptor.getName() + "_bag", itemTupleSchema, DataType.BAG);
    } else {
      return new FieldSchema(fieldDescriptor.getName(), null, getPigDataType(fieldDescriptor));
    }
  }

  /**
   * Translate between protobuf's datatype representation and Pig's datatype representation.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the byte representing the pig datatype for the given field type.
   */
  private byte getPigDataType(FieldDescriptor fieldDescriptor) {
    switch (fieldDescriptor.getType()) {
      case INT32:
      case UINT32:
      case SINT32:
      case FIXED32:
      case SFIXED32:
      case BOOL: // We convert booleans to ints for pig output.
        return DataType.INTEGER;
      case INT64:
      case UINT64:
      case SINT64:
      case FIXED64:
      case SFIXED64:
        return DataType.LONG;
      case FLOAT:
        return DataType.FLOAT;
      case DOUBLE:
        return DataType.DOUBLE;
      case STRING:
      case ENUM: // We convert enums to strings for pig output.
        return DataType.CHARARRAY;
      case BYTES:
        return DataType.BYTEARRAY;
      case MESSAGE:
        throw new IllegalArgumentException("getPigDataType called on field " + fieldDescriptor.getFullName() + " of type message.");
      default:
        throw new IllegalArgumentException("Unexpected field type. " + fieldDescriptor.toString() + " " + fieldDescriptor.getFullName() + " " + fieldDescriptor.getType());
    }
  }

  /**
   * Turn a generic message descriptor into a loading schema for a pig script.
   * @param msgDescriptor the descriptor for the given message type.
   * @param loaderClassName the fully qualified classname of the pig loader to use.  Not
   * passed a <code>Class<? extends LoadFunc></code> because in many situations that class
   * is being generated as well, and so doesn't exist in compiled form.
   * @return a pig script that can load the given message.
   */
  public String toPigScript(Descriptor msgDescriptor, String loaderClassName) {
    StringBuffer sb = new StringBuffer();
    final int initialTabOffset = 3;

    sb.append("raw_data = load '$INPUT_FILES' using " + loaderClassName + "()").append("\n");
    sb.append(tabs(initialTabOffset)).append("as (").append("\n");
    sb.append(toPigScriptInternal(msgDescriptor, initialTabOffset));
    sb.append(tabs(initialTabOffset)).append(");").append("\n").append("\n");

    return sb.toString();
  }

  /**
   * Same as toPigScript(Descriptor, String) but allows parameters for the loader.
   *
   * @param msgDescriptor
   * @param loaderClassName
   * @param params
   * @return a pig script that can load the given message.
   */
  public String toPigScript(Descriptor msgDescriptor, String loaderClassName, String... params) {
    StringBuffer sb = new StringBuffer();
    final int initialTabOffset = 3;

    sb.append("raw_data = load '$INPUT_FILES' using ")
    .append(loaderClassName)
    .append("(");
    String paramString = "";
    if (params.length > 0) {
      paramString = "'" + Joiner.on(",'").join(params) + "'";
    }
    sb.append(paramString).append(")").append("\n");
    sb.append("/**\n");
    sb.append(tabs(initialTabOffset)).append("as (").append("\n");
    sb.append(toPigScriptInternal(msgDescriptor, initialTabOffset));
    sb.append(tabs(initialTabOffset)).append(")").append("\n").append("\n");
    sb.append("**/\n;\n");
    return sb.toString();
  }

  /**
   * Turn a generic message descriptor into a loading schema for a pig script.  Individual fields that are enums
   * are converted into their string equivalents.
   * @param msgDescriptor the descriptor for the given message type.
   * @param numTabs the tab depth at the current point in the recursion, for pretty printing.
   * @return a pig schema representing the message.
   */
  private StringBuffer toPigScriptInternal(Descriptor msgDescriptor, int numTabs) {
    StringBuffer sb = new StringBuffer();
    try {
      // Walk through all the possible fields in the message.
      for (FieldDescriptor fieldDescriptor : msgDescriptor.getFields()) {
        // We have to add a comma after every line EXCEPT for the last, or Pig gets mad.
        boolean isLast = (fieldDescriptor == msgDescriptor.getFields().get(msgDescriptor.getFields().size() - 1));
        if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
          sb.append(messageToPigScript(fieldDescriptor, numTabs + 1, isLast));
        } else {
          sb.append(singleFieldToPigScript(fieldDescriptor, numTabs + 1, isLast));
        }
      }
    } catch (FrontendException e) {
      LOG.warn("Could not convert descriptor " + msgDescriptor + " to pig script", e);
    }

    return sb;
  }

  /**
   * Turn a nested message into a pig script load string.  For repeated nested messages, it generates a string for a bag of
   * tuples.  For non-repeated nested messages, it just generates a string for the tuple itself.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param numTabs the tab depth at the current point in the recursion, for pretty printing.
   * @return the pig script load schema for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private StringBuffer messageToPigScript(FieldDescriptor fieldDescriptor, int numTabs, boolean isLast) throws FrontendException {
    assert fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE : "messageToPigScript called with field of type " + fieldDescriptor.getType();

    // Since protobufs do not have a map type, we use CountedMap to fake it.  Whenever the protobuf has a repeated CountedMap in it,
    // we force the type into a pig map type.
    if (coercionLevel_ == CoercionLevel.kAllowCoercionToPigMaps &&
        fieldDescriptor.getMessageType().getName().equals(CountedMap.getDescriptor().getName()) && fieldDescriptor.isRepeated()) {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName())
          .append(": map[]").append(isLast ? "" : ",").append("\n");
    }

    if (fieldDescriptor.isRepeated()) {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append(": bag {").append("\n")
          .append(tabs(numTabs + 1)).append(fieldDescriptor.getName()).append("_tuple: tuple (").append("\n")
          .append(toPigScriptInternal(fieldDescriptor.getMessageType(), numTabs + 2))
          .append(tabs(numTabs + 1)).append(")").append("\n")
          .append(tabs(numTabs)).append("}").append(isLast ? "" : ",").append("\n");
    } else {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append(": tuple (").append("\n")
          .append(toPigScriptInternal(fieldDescriptor.getMessageType(), numTabs + 1))
          .append(tabs(numTabs)).append(")").append(isLast ? "" : ",").append("\n");
    }
  }

  /**
   * Turn a single field into a pig script load string.  For repeated single fields, it generates a string for a bag of single-item tuples.
   * For non-repeated fields, it just generates a standard single-element string.
   * @param fieldDescriptor the descriptor object for the given field.
   * @param numTabs the tab depth at the current point in the recursion, for pretty printing.
   * @return the pig script load string for the nested message.
   * @throws FrontendException if Pig decides to.
   */
  private StringBuffer singleFieldToPigScript(FieldDescriptor fieldDescriptor, int numTabs, boolean isLast) throws FrontendException {
    assert fieldDescriptor.getType() != FieldDescriptor.Type.MESSAGE : "singleFieldToPigScript called with field of type " + fieldDescriptor.getType();

    if (fieldDescriptor.isRepeated()) {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append("_bag: bag {").append("\n")
          .append(tabs(numTabs + 1)).append(fieldDescriptor.getName()).append("_tuple: tuple (").append("\n")
          .append(tabs(numTabs + 2)).append(fieldDescriptor.getName()).append(": ").append(getPigScriptDataType(fieldDescriptor)).append("\n")
          .append(tabs(numTabs + 1)).append(")").append("\n")
          .append(tabs(numTabs)).append("}").append(isLast ? "" : ",").append("\n");
    } else {
      return new StringBuffer().append(tabs(numTabs)).append(fieldDescriptor.getName()).append(": ")
          .append(getPigScriptDataType(fieldDescriptor)).append(isLast ? "" : ",").append("\n");
    }
  }

  /**
   * Translate between protobuf's datatype representation and Pig's datatype representation.
   * @param fieldDescriptor the descriptor object for the given field.
   * @return the byte representing the pig datatype for the given field type.
   */
  private String getPigScriptDataType(FieldDescriptor fieldDescriptor) {
    switch (fieldDescriptor.getType()) {
      case INT32:
      case UINT32:
      case SINT32:
      case FIXED32:
      case SFIXED32:
      case BOOL: // We convert booleans to ints for pig output.
        return "int";
      case INT64:
      case UINT64:
      case SINT64:
      case FIXED64:
      case SFIXED64:
        return "long";
      case FLOAT:
        return "float";
      case DOUBLE:
        return "double";
      case STRING:
      case ENUM: // We convert enums to strings for pig output.
        return "chararray";
      case BYTES:
        return "bytearray";
      case MESSAGE:
        throw new IllegalArgumentException("getPigScriptDataType called on field " + fieldDescriptor.getFullName() + " of type message.");
      default:
        throw new IllegalArgumentException("Unexpected field type. " + fieldDescriptor.toString() + " " + fieldDescriptor.getFullName() + " " + fieldDescriptor.getType());
    }
  }

  private StringBuffer tabs(int numTabs) {
    StringBuffer sb = new StringBuffer();
    for (int i = 0; i < numTabs; i++) {
      sb.append("  ");
    }
    return sb;
  }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_06b2d1f_53cd9d2/rev_06b2d1f-53cd9d2/atlas-demo/AtlasDemo/buildSrc/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.diff;

import java.io.File;
import java.io.IOException;
import java.util.Collection;
import java.util.Set;
import java.util.UUID;

import com.taobao.android.builder.tools.MD5Util;
import com.taobao.android.builder.tools.zip.ZipUtils;
import org.apache.commons.io.FileUtils;
import org.apache.commons.io.filefilter.TrueFileFilter;

/**
 * Created by wuzhong on 2016/9/30.
 */
public class DiffResExtractor {

    /**
     * assets : ç´æ¥éè¿æ¯è¾apk
     * res : éè¿diffResFiles ï¼ åå»apk éªè¯
     *
     * @param diffResFiles
     * @param currentApk
     * @param baseApk
     * @param fullResDir
     * @param destDir
     * @throws IOException
     */
    public static void extractDiff(Set<String> diffResFiles, File currentApk, File baseApk, File fullResDir,
                                   File destDir) throws IOException {

        if (!currentApk.exists() || !baseApk.exists() || !fullResDir.exists()) {
            return;
        }

        FileUtils.deleteDirectory(destDir);
        destDir.mkdirs();

        File tmpFolder = new File(destDir.getParentFile(), "tmp-diffRes");
        FileUtils.deleteDirectory(tmpFolder);
        tmpFolder.mkdirs();

        File apkDir = new File(tmpFolder, "newApkDir");
        File baseApkDir = new File(tmpFolder, "baseApkDir");

        ZipUtils.unzip(currentApk, apkDir.getAbsolutePath());
        ZipUtils.unzip(baseApk, baseApkDir.getAbsolutePath());

        //compare res and assets
        Collection<File> files = FileUtils.listFiles(apkDir, TrueFileFilter.INSTANCE, TrueFileFilter.INSTANCE);

        int basePathLength = apkDir.getAbsolutePath().length();

        //List<String> diffResPath = new ArrayList<String>();

        //è®¡ç®assets
        for (File file : files) {

            String relativePath = file.getAbsolutePath().substring(basePathLength);

            if (!relativePath.startsWith("/assets/")) {
                continue;
            }

            File baseFile = new File(baseApkDir, relativePath);
            if (!baseFile.exists() || !MD5Util.getFileMD5(file).equals(MD5Util.getFileMD5(baseFile))) {
                FileUtils.copyFile(file, new File(destDir, relativePath));
            }

        }

        //è®¡ç®res
        for (String diffFile : diffResFiles) {

            File baseFile = new File(baseApkDir, diffFile);
            File currentFile = new File(apkDir, diffFile);

            if (baseFile.exists() && currentFile.exists() && MD5Util.getFileMD5(baseFile).equals(
                MD5Util.getFileMD5(currentFile))) {
                continue;
            }

            //copy file
            File rawFile = new File(fullResDir, diffFile);
            if (rawFile.exists()) {
                FileUtils.copyFile(rawFile, new File(destDir, diffFile));
            }

        }

        //å¿é¡»çæresource.arsc
        File resDir = new File(destDir, "res");
        if (!resDir.exists()) {
            File valuesDir = new File(resDir, "values");
            FileUtils.forceMkdir(valuesDir);
            File stringsFile = new File(valuesDir, "strings.xml");
            UUID uuid = UUID.randomUUID();
            FileUtils.writeStringToFile(stringsFile, String.format(
                "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<resources>\n    <string "
                    + "name=\"%s\">%s</string>\n</resources>\n",
                uuid, uuid), "UTF-8", false);

        }

        //final Pattern densityOnlyPattern = Pattern.compile("[a-zA-Z]+-[a-zA-Z]+dpi");
        //if (resDir.exists()) {
        //    File[] resDirs = resDir.listFiles();
        //    if (resDirs != null) {
        //        for (File file : resDirs) {
        //            Matcher m = densityOnlyPattern.matcher(file.getName());
        //            if (m.matches()) {
        //                FileUtils.moveDirectory(file, new File(file.getAbsolutePath() + "-v4"));
        //            }
        //        }
        //    }
        //}

    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_a504c52_dd98861/rev_a504c52-dd98861/atlas-core/src/main/java/android/taobao/atlas/framework/bundlestorage/BundleArchive.java;<<<<<<< MINE
=======
import android.util.Log;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_a504c52_dd98861/rev_a504c52-dd98861/atlas-core/src/main/java/android/taobao/atlas/framework/bundlestorage/BundleArchive.java;<<<<<<< MINE
        if (RuntimeVariables.sCurrentProcessName.equals(RuntimeVariables.androidApplication.getPackageName())) {
=======
        if (RuntimeVariables.sCurrentProcessName.equals(RuntimeVariables.androidApplication.getPackageName()) && !Framework.updateHappend) {
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_a504c52_dd98861/rev_a504c52-dd98861/atlas-core/src/main/java/android/taobao/atlas/framework/bundlestorage/BundleArchive.java;<<<<<<< MINE
    public synchronized void purge(String uniqueTag, final long dexPatchVersion) {
=======
    public synchronized void purge(final String uniqueTag, final long dexPatchVersion) {
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_a504c52_dd98861/rev_a504c52-dd98861/atlas-core/src/main/java/android/taobao/atlas/framework/bundlestorage/BundleArchive.java;<<<<<<< MINE
                }else if(dexPatchVersion<=0){
                    if(System.currentTimeMillis()-dir.lastModified()>30*1000) {
                        return true;
                    }
=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_a504c52_dd98861/rev_a504c52-dd98861/atlas-core/src/main/java/android/taobao/atlas/framework/bundlestorage/BundleArchive.java;<<<<<<< MINE
=======
                Log.e("BundleArchive","purge "+bundleDir +" : "+dir.getName());
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_a504c52_dd98861/rev_a504c52-dd98861/atlas-core/src/main/java/android/taobao/atlas/framework/BundleClassLoader.java;<<<<<<< MINE
                    impl.startBundle();
                    clazz = ((BundleClassLoader) impl.getClassLoader()).loadOwnClass(classname);
                    if(clazz!=null){
                        return clazz;
=======
                    if(impl!=null) {
                        impl.startBundle();
                        clazz = ((BundleClassLoader) impl.getClassLoader()).loadOwnClass(classname);
                        if (clazz != null) {
                            return clazz;
                        }
                    }else{
                        Log.e("BundleClassLoader",String.format("%s is not success installed by %s",""+dependencyBundle,location));
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_a504c52_dd98861/rev_a504c52-dd98861/atlas-core/src/main/java/android/taobao/atlas/bundleInfo/BundleListing.java;<<<<<<< MINE
//            if(bundlesListForInstall.contains(location)){
//                return;
//            }
=======
            findBundleTransitivelyInternal(location,bundlesListForInstall,location);
        }

        private void findBundleTransitivelyInternal(String location,List<String> bundlesListForInstall,final String root){
//            //ææ­å¾ªç¯ä¾èµ
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_a504c52_dd98861/rev_a504c52-dd98861/atlas-core/src/main/java/android/taobao/atlas/bundleInfo/BundleListing.java;<<<<<<< MINE
                bundlesListForInstall.remove(location);
                bundlesListForInstall.add(0,location);
=======
                if(!location.equals(root)) {
                    bundlesListForInstall.remove(location);
                    bundlesListForInstall.add(0, location);
                }
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_a504c52_dd98861/rev_a504c52-dd98861/atlas-core/src/main/java/android/taobao/atlas/bundleInfo/BundleListing.java;<<<<<<< MINE
                        findBundleTransitively(dependepcy,bundlesListForInstall);
=======
                        findBundleTransitivelyInternal(dependepcy,bundlesListForInstall,root);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_f06548b_513c57a/rev_f06548b-513c57a/src/java/com/twitter/elephantbird/pig/load/LzoSlice.java;<<<<<<< MINE
package com.twitter.elephantbird.pig.load;

import java.io.IOException;
import java.util.Arrays;
import java.util.HashSet;
import java.util.Set;

import com.twitter.elephantbird.pig.util.LzoBufferedPositionedInputStream;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.BlockLocation;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.io.compress.CompressionCodecFactory;
import org.apache.hadoop.io.compress.CompressionInputStream;
import org.apache.pig.FuncSpec;
import org.apache.pig.Slice;
import org.apache.pig.backend.datastorage.DataStorage;
import org.apache.pig.backend.datastorage.SeekableInputStream;
import org.apache.pig.backend.datastorage.SeekableInputStream.FLAGS;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.PigContext;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * This class implements the Pig Slice interface, meaning it both represents an input split
 * and begins processing on a mapper by binding a loader to each input split.
 */
public class LzoSlice implements Slice {
  private static final Logger LOG = LoggerFactory.getLogger(LzoSlice.class);

  // Generated by Eclipse.
  private static final long serialVersionUID = 4921280606900935966L;

  private final String filename_;
  private long start_;
  private long length_;
  private CompressionInputStream is_;
  private SeekableInputStream fsis_;
  private LzoBaseLoadFunc loader_;
  private FuncSpec loadFuncSpec_;

  /**
   * Construct a slice with the given specifications.
   * @param filename the filename from which the block comes.
   * @param start the byte offset of the start of the block.  If this is zero, it's necessary to read the
   *        file header before real data reading starts.  If this is nonzero, it's assumed to be at the beginning
   *        of an LZO block boundary, otherwise decompression will fail.
   * @param length the length of the block.
   * @param loadFuncSpec the spec for invoking the loader function.
   */
  public LzoSlice(String filename, long start, long length, FuncSpec loadFuncSpec) {
    LOG.debug("LzoSlice::LzoSlice, file = " + filename + ", start = " + start + ", length = " + length);
    filename_ = filename;
    start_ = start;
    length_ = length;
    loadFuncSpec_ = loadFuncSpec;
  }

  public void close() throws IOException {
    if (is_ != null) {
      is_.close();
    }
  }

  public long getStart() {
    return start_;
  }

  public long getLength() {
    return length_;
  }

  /*
   * return the filename being operated on
   */
  public String getFilename() {
    return filename_;
  }

  /**
   * Return the set of servers which contain any blocks of the given file.
   */
  public String[] getLocations() {
    try {
      FileSystem fs = FileSystem.get(new Configuration());
      Set<String> locations = new HashSet<String>();

      FileStatus status = fs.getFileStatus(new Path(filename_));
      BlockLocation[] b = fs.getFileBlockLocations(status, getStart(), getLength());
      for (int i = 0; i < b.length; i++) {
        locations.addAll(Arrays.asList(b[i].getHosts()));
      }
      return locations.toArray(new String[locations.size()]);
    } catch (IOException e) {
      LOG.error("Caught exception: " + e);
      return null;
    }
  }

  public long getPos() throws IOException {
    return fsis_.tell();
  }

  public float getProgress() throws IOException {
    float progress = getPos() - start_;
    float finish = getLength();
    return progress / finish;
  }

  /**
   * Set up the slice by creating the compressed input stream around the given Hadoop file input stream.
   * @param store the Pig storage object.
   */
  public void init(DataStorage store) throws IOException {

    LOG.info("LzoSlice::LzoSlice, file = " + filename_ + ", start = " + start_ + ", length = " + length_);

    fsis_ = store.asElement(store.getActiveContainer(), filename_).sopen();

    CompressionCodecFactory compressionCodecs = new CompressionCodecFactory(new Configuration());
    final CompressionCodec codec = compressionCodecs.getCodec(new Path(filename_));
    is_ = codec.createInputStream(fsis_, codec.createDecompressor());
    // At this point, is_ will already be a nonzero number of bytes into the file, because
    // the Lzop codec reads the header upon opening the stream.
    boolean beginsAtHeader = false;
    if (start_ != 0) {
      // If start_ is nonzero, seek there to begin reading, using SEEK_SET per above.
      fsis_.seek(start_, FLAGS.SEEK_SET);
    } else {
      // If start_ is zero, then it's actually at the header offset. Adjust based on this.
      start_ = fsis_.tell();
      length_ -= start_;
      beginsAtHeader = true;
    }

    LOG.info("Creating constructor for class " + loadFuncSpec_);
    // Use instantiateFuncFromSpec to maintain the arguments passed in from the Pig script.
    loader_ = (LzoBaseLoadFunc) PigContext.instantiateFuncFromSpec(loadFuncSpec_);
    loader_.setBeginsAtHeader(beginsAtHeader);
    // Wrap Pig's BufferedPositionedInputStream with our own, which gives positions based on the number
    // of compressed bytes read rather than the number of uncompressed bytes read.
    loader_.bindTo(filename_, new LzoBufferedPositionedInputStream(is_, start_), start_, start_ + length_);
  }

  /**
   * Get the next tuple by delegating to the loader.
   * @param tuple the tuple to be filled out
   * @return true if the load should continue, i.e. if the tuple was filled out this round.
   */
  public boolean next(Tuple tuple) throws IOException {
    // Delegate to the loader.
    Tuple t = loader_.getNext();
    if (t == null) {
      return false;
    }
    tuple.reference(t);
    return true;
  }


}=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_f06548b_513c57a/rev_f06548b-513c57a/src/java/com/twitter/elephantbird/pig/load/LzoJsonLoader.java;<<<<<<< MINE
  public LzoJsonLoader() {
    LOG.debug("LzoJsonLoader creation");
  }

  public void skipToNextSyncPoint(boolean atFirstRecord) throws IOException {
    // Since we are not block aligned we throw away the first record of each split and count on a different
    // instance to read it.  The only split this doesn't work for is the first.
    if (!atFirstRecord) {
      getNext();
    }
  }
=======
  public LzoJsonLoader() {}
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_f06548b_513c57a/rev_f06548b-513c57a/src/java/com/twitter/elephantbird/pig/load/LzoJsonLoader.java;<<<<<<< MINE

=======

  @Override
  public void setLocation(String location, Job job)
  throws IOException {
	  FileInputFormat.setInputPaths(job, location);
  }

>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/aapt/src/main/java/com/taobao/android/AaptLib.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android;

/**
 * Created by wuzhong on 2017/6/11.
 */
public class AaptLib {
}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/proguard/AtlasProguardConstants.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package proguard;

/**
 * Created by wuzhong on 2017/5/13.
 */
public class AtlasProguardConstants extends ConfigurationConstants {

    public static final String INOUT_CFG = "inout_config.cfg";

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/android/build/gradle/internal/api/AwbTransform.java;<<<<<<< MINE
=======
import java.io.File;
import java.util.List;
import java.util.Map;

>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/android/build/gradle/internal/api/AwbTransform.java;<<<<<<< MINE
import java.io.File;
import java.util.List;
import java.util.Map;

=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/extension/MultiDexConfig.java;<<<<<<< MINE
=======
    @Config(title = "é¢å¤ç¬¬ä¸ä¸ªdexç±»åè¡¨", message = "èªå®ä¹éè¦æ¾å°ç¬¬ä¸ä¸ªdexä¸­çå¥å£ç±»", order = 3, group = "atlas")
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/extension/MultiDexConfig.java;<<<<<<< MINE
=======
    /**
     * dex çååä¸ªæ°ï¼ 0 è¡¨ç¤ºä¸è¿è¡éå¶ï¼ä¸å2æ¬¡merge
     */
    @Config(title = "dexçä¸ªæ°", message = "0è¡¨ç¤ºæ éå¶", order = 1, group = "atlas")
    private int dexCount;

    @Config(title = "dexåéçè§å", message = "a,b;c,d", order = 2, group = "atlas")
    private String dexSplitRules;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/extension/MultiDexConfig.java;<<<<<<< MINE
=======

    public int getDexCount() {
        return dexCount;
    }

    public void setDexCount(int dexCount) {
        this.dexCount = dexCount;
    }

    public String getDexSplitRules() {
        return dexSplitRules;
    }

    public void setDexSplitRules(String dexSplitRules) {
        this.dexSplitRules = dexSplitRules;
    }
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/manager/AtlasAppTaskManager.java;<<<<<<< MINE
=======
                }

                try {
                    hookFastDex(appVariantContext);
                    hookFastMultiDex(appVariantContext);
                } catch (Exception e) {
                    throw new GradleException(e.getMessage(), e);
                }

                for (final BaseVariantOutputData vod : baseVariantOutputDataList) {
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/manager/AtlasAppTaskManager.java;<<<<<<< MINE
                try {
                    hookFastMultiDex(appVariantContext);
                } catch (Exception e) {
                    throw new GradleException(e.getMessage(), e);
                }

=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/manager/AtlasAppTaskManager.java;<<<<<<< MINE
=======
                if (appVariantContext.getBuildType().getDexConfig()!= null && appVariantContext.getBuildType().getDexConfig().isUseMyDex()){
                    dexOptions.getAdditionalParameters().add("--useMyDex");
                }
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/manager/AtlasAppTaskManager.java;<<<<<<< MINE
=======

    //å³é­æç³»ç»çproguardtransform
    private void hookFastDex(AppVariantContext appVariantContext) throws Exception {

        if (appVariantContext.getAtlasExtension().getTBuildConfig().isFastProguard()) {

            List<TransformTask> list = TransformManager.findTransformTaskByTransformType(appVariantContext,
                                                                                         DexTransform.class);
            for (TransformTask transformTask : list) {

                DefaultDexOptions dexOptions = (DefaultDexOptions)ReflectUtils.getField(transformTask.getTransform(),
                                                                                        "dexOptions");
                dexOptions.setPreDexLibraries(false);
            }
        }
    }

>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/app/merge/MergeManifestAwbsConfigAction.java;<<<<<<< MINE
                                                "/manifests-awb/full/" +
=======
                                                "/awb-manifests/full/" +
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffApkBuildTask.java;<<<<<<< MINE
=======
import java.io.File;
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.Callable;
import java.util.zip.ZipEntry;

>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffApkBuildTask.java;<<<<<<< MINE
import java.io.File;
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.Callable;
import java.util.zip.ZipEntry;

=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffApkBuildTask.java;<<<<<<< MINE
            return scope.getTaskName("Create", "TPatchDiffApk");
=======
            return scope.getTaskName("createTPatchDiffApk");
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/bundleinfo/BundleItemRunner.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.bundleinfo;

/**
 * Created by wuzhong on 2017/5/15.
 */
public interface BundleItemRunner {

    public void execute(BundleItem bundleItem);

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/FileNameUtils.java;<<<<<<< MINE
=======
    public static String getUniqueFileName(String name, String type) {
        String outFileName = name.replace(".jar","") + "_" + type;
        if (outFileNames.contains(outFileName)) {
            outFileName = outFileName + index.incrementAndGet();
        }
        outFileNames.add(outFileName);
        return outFileName;
    }

>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/cache/FileLockUtils.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.cache;

import java.io.File;
import java.io.RandomAccessFile;
import java.nio.channels.FileLock;

import org.gradle.api.GradleException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * Created by wuzhong on 2017/5/14.
 */
public class FileLockUtils {

    private static Logger log = LoggerFactory.getLogger(FileLockUtils.class);

    public static boolean lock(File file, Runnable runnable) {
        try {

            File lockFile = file;
            if (lockFile.isDirectory()) {
                lockFile = new File(lockFile, ".atlaslock");
            }
            RandomAccessFile randomAccessFile;
            FileLock fileLock ;
            try {
                randomAccessFile = new RandomAccessFile(lockFile, "rw");
                fileLock = randomAccessFile.getChannel().tryLock();
            } catch (Exception e) {
                throw new GradleException(e.getMessage(),e);
            }
            if (fileLock != null) {
                File finalLockFile = lockFile;
                Runtime.getRuntime().addShutdownHook(new Thread() {
                    @Override
                    public void run() {
                        try {
                            fileLock.release();
                            randomAccessFile.close();
                            finalLockFile.delete();
                        } catch (Exception e) {
                            log.error("Unable to remove lock file: " + file.getAbsolutePath(), e);
                        }
                    }
                });

                runnable.run();

                lockFile.delete();
                return true;
            }

        } finally {

        }
        return false;
    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/cache/SimpleLocalCache.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.cache;

import java.io.File;
import java.io.IOException;

import org.apache.commons.io.FileUtils;
import org.apache.commons.lang.StringUtils;
import org.jetbrains.annotations.NotNull;

/**
 * Created by wuzhong on 2017/6/8.
 */
public class SimpleLocalCache implements Cache {

    //java.io.tmpdir
    static File cacheDir;

    static {
        cacheDir = new File(System.getProperty("user.home"), ".mtl-plugin/cache");
        cacheDir.mkdirs();
    }

    @Override
    public void cacheFile(String type, String key, File file) throws FileCacheException {
        if (StringUtils.isEmpty(key)) {
            throw new FileCacheException("cache key is empty ");
        }
        File cacheFile = getLocalCacheFile(type, key);
        if (cacheFile.exists()) {
            throw new FileCacheException("file cache alerady exist:" + cacheFile.getAbsolutePath());
        }

        try {

            cacheFile.getParentFile().mkdirs();

            if (file.isFile()) {
                FileUtils.copyFile(file, cacheFile);
            } else {

                cacheFile.mkdirs();

                FileLockUtils.lock(cacheFile, new Runnable() {
                    @Override
                    public void run() {
                        try {
                            FileUtils.copyDirectory(file, cacheFile);
                        } catch (Throwable e) {
                            try {
                                FileUtils.forceDelete(cacheFile);
                            } catch (IOException e1) {
                                e1.printStackTrace();
                            }
                            throw new RuntimeException(e.getMessage(), e);
                        }
                    }
                });
            }
        } catch (Throwable e) {
            throw new FileCacheException(e.getMessage(), e);
        }

    }

    @Override
    public boolean fetchFile(String type, String key, File localFile, boolean folder) throws FileCacheException {

        if (StringUtils.isEmpty(key)) {
            throw new FileCacheException("cache key is empty ");
        }

        File cacheFile = getLocalCacheFile(type, key);

        try {
            if (cacheFile.exists() && cacheFile.length() > 0) {
                if (cacheFile.isDirectory()) {
                    FileUtils.copyDirectory(cacheFile, localFile);
                } else {
                    FileUtils.copyFile(cacheFile, localFile);
                }
            }
        } catch (IOException e) {
            throw new FileCacheException(e.getMessage(), e);
        }

        return true;
    }

    @NotNull
    public File getLocalCacheFile(String type, String key) {
        return new File(cacheDir, type + "/" + key);
    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/cache/SimpleNetworkCache.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.cache;

import java.io.File;
import java.io.IOException;

import com.taobao.android.builder.tools.zip.BetterZip;

/**
 * Created by wuzhong on 2017/6/8.
 */
public class SimpleNetworkCache implements Cache{

    private NetworkProtocol networkProtocol;

    public SimpleNetworkCache(NetworkProtocol networkProtocol) {
        this.networkProtocol = networkProtocol;
    }

    @Override
    public void cacheFile(String type, String key, File file) throws FileCacheException {

        File toUploadFile = file;
        if (file.isDirectory()){
            toUploadFile = new File(file.getParentFile(),toUploadFile.getName()+"_tmp.zip");
            try {
                BetterZip.zipDirectory(file,toUploadFile);
            } catch (IOException e) {
                throw new FileCacheException(e.getMessage(),e);
            }
        }

        try {
            if (!networkProtocol.uploadFile(type + "/" + key, toUploadFile)) {
                throw new FileCacheException("upload file failed");
            }
        }finally {
            //å é¤æä»¶å¤¹
            if(toUploadFile.getName().endsWith("_tmp.zip")){
                toUploadFile.delete();
            }
        }
    }

    @Override
    public boolean fetchFile(String type, String key, File localFile, boolean folder) throws FileCacheException {

        boolean succss = networkProtocol.downloadFile(type + "/" + key, localFile);

        if (!succss){
            return false;
        }

        if (folder){

            //è§£åæä»¶
            File current = new File(localFile.getAbsolutePath());
            File zipFile = new File(localFile.getParentFile(),localFile.getName()+"_tmp.zip");
            localFile.renameTo(zipFile);

            try {
                BetterZip.unzipDirectory(zipFile,current);
                zipFile.delete();
            } catch (IOException e) {
                throw new FileCacheException(e.getMessage(),e);
            }

        }

        return true;

    }

    @Override
    public File getLocalCacheFile(String type, String key) {
        return null;
    }


    public static interface NetworkProtocol {

        boolean downloadFile(String key, File localFile);

        boolean uploadFile(String key, File file);

    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/cache/FileCacheCenter.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.cache;

import java.io.File;
import java.io.IOException;

import com.taobao.android.builder.tools.log.FileLogger;
import org.apache.commons.io.FileUtils;

/**
 * Created by wuzhong on 2017/6/8.
 *
 * ç»ä¸æä»¶ç¼å­ä¸­å¿
 */
public class FileCacheCenter {

    public static final boolean BUILD_CACHE_ENABLED = true;
    private static FileLogger logger = FileLogger.getInstance("filecache");

    public static Cache networkCache;
    public static Cache localCache = new SimpleLocalCache();

    /**
     * ç¼å­æä»¶æèæä»¶å¤¹
     *
     * @param type
     * @param key
     * @param file
     * @throws FileCacheException
     */
    public static void cacheFile(String type, String key, File file, boolean remote) throws FileCacheException {

        if (!BUILD_CACHE_ENABLED){
            return;
        }

        localCache.cacheFile(type, key, file);

        logger.log(type + "." + key + " cache " + file.getAbsolutePath() + " to local success");

        if (null != networkCache && remote) {
            networkCache.cacheFile(type, key, file);
            logger.log(type + "." + key + " cache " + file.getAbsolutePath() + " to network success");
        }

    }

    /**
     * æ¥è¯¢æä»¶ï¼å¦ææ¬å°æä»¶ä¸å­å¨ï¼å°è¯ä»äºç«¯è¯»åç¼å­
     *
     * @param type
     * @param key
     * @param folder
     * @return
     * @throws FileCacheException
     */
    public static File queryFile(String type, String key, boolean folder, boolean remote) throws FileCacheException {

        if (!BUILD_CACHE_ENABLED){
            return null;
        }

        File localCacheFile = localCache.getLocalCacheFile(type, key);
        if (localCacheFile.exists()) {

            if (folder != localCacheFile.isDirectory()) {
                try {
                    FileUtils.forceDelete(localCacheFile);
                } catch (IOException e) {
                    e.printStackTrace();
                }
                throw new FileCacheException("local dir is folder " + folder);
            }

            logger.log(type + "." + key + " query local cache  " + localCacheFile.getAbsolutePath() + " success");
            return localCacheFile;
        }else {
            logger.log(type + "." + key + " miss local cache  " + localCacheFile.getAbsolutePath());
        }

        if (null == networkCache || !remote) {
            return localCacheFile;
        }

        try {

            boolean success = networkCache.fetchFile(type, key, localCacheFile, folder);

            logger.log(type + "." + key + " fetch remote cache  " + localCacheFile.getAbsolutePath() + success);

            if (success) {
                return localCacheFile;
            }

        } catch (Throwable e) {

            logger.log(type + "." + key + " fetch remote cache  " + localCacheFile.getAbsolutePath() + " exception");
            e.printStackTrace();
        }

        logger.log(type + "." + key + " get cache file failed  " + localCacheFile.getAbsolutePath());
        try {
            FileUtils.forceDelete(localCacheFile);
        } catch (IOException e) {
            e.printStackTrace();
        }
        return localCacheFile;

    }


    public static void fetchFile(String type, String key, boolean folder, boolean remote, File dest) throws FileCacheException {

        if (!BUILD_CACHE_ENABLED){
            return;
        }

        File cacheFile = queryFile(type,key,folder,remote);

        if (null != cacheFile && cacheFile.exists()){

            try {
                if (cacheFile.isFile()) {
                    FileUtils.copyFile(cacheFile, dest);
                } else {
                    FileUtils.copyDirectory(cacheFile, dest);
                }
                logger.log(type + "." + key + " fech  file success  " + dest.getAbsolutePath());
            }catch (Throwable e){
                throw new FileCacheException(e.getMessage(),e);
            }

        }


    }


}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/cache/Cache.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.cache;

import java.io.File;
import java.io.IOException;

/**
 * Created by wuzhong on 2017/6/8.
 */
public interface Cache {

    /**
     * å­ç¼å­
     *
     * @param type
     * @param key
     * @param file
     * @return
     */
    public void cacheFile(String type, String key, File file) throws FileCacheException;

    /**
     * è¯»åç¼å­
     *
     * @param type
     * @param key
     * @param localFile
     * @return
     * @throws IOException
     */
    public boolean fetchFile(String type, String key, File localFile, boolean folder) throws FileCacheException;


    public File getLocalCacheFile(String type, String key);

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/cache/FileCacheException.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.cache;

/**
 * Created by wuzhong on 2017/6/8.
 */
public class FileCacheException extends Exception {

    public FileCacheException(String message) {
        super(message);
    }

    public FileCacheException(String message, Throwable cause) {
        super(message, cause);
    }

    public FileCacheException(Throwable cause) {
        super(cause);
    }

    public FileCacheException(String message, Throwable cause, boolean enableSuppression, boolean writableStackTrace) {
        super(message, cause, enableSuppression, writableStackTrace);
    }
}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/log/LogOutputListener.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.log;

import org.gradle.BuildListener;
import org.gradle.BuildResult;
import org.gradle.api.Project;
import org.gradle.api.initialization.Settings;
import org.gradle.api.invocation.Gradle;

/**
 * Created by wuzhong on 2017/6/8.
 */
public class LogOutputListener {

    public static void addListener(Project project) {

        FileLogger.project = project.getRootProject();

        project.getGradle().addListener(new BuildListener() {
            @Override
            public void buildStarted(Gradle gradle) {
            }

            @Override
            public void settingsEvaluated(Settings settings) {

            }

            @Override
            public void projectsLoaded(Gradle gradle) {

            }

            @Override
            public void projectsEvaluated(Gradle gradle) {

            }

            @Override
            public void buildFinished(BuildResult buildResult) {
                FileLogger.shutDown(project);
            }
        });

    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/Profiler.java;<<<<<<< MINE
=======
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/Profiler.java;<<<<<<< MINE
=======

    public static Logger sLogger = LoggerFactory.getLogger(Profiler.class);

>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/multidex/FileComparator.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.multidex;

import java.io.File;
import java.util.Comparator;

/**
 * Created by wuzhong on 2017/5/31.
 */
public class FileComparator implements Comparator<File> {

    @Override
    public int compare(File o1, File o2) {
        if (o1.getAbsolutePath().contains("fastmaindex")) {
            return 1;
        } else if (o2.getAbsolutePath().contains("fastmaindex")) {
            return -1;
        }
        return (int)(o2.length() - o1.length());
    }
}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/proguard/dump/AbstractClasslVisitor.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.proguard.dump;

import proguard.classfile.Clazz;
import proguard.classfile.LibraryClass;
import proguard.classfile.LibraryField;
import proguard.classfile.LibraryMethod;
import proguard.classfile.ProgramClass;
import proguard.classfile.ProgramField;
import proguard.classfile.ProgramMethod;
import proguard.classfile.constant.ClassConstant;
import proguard.classfile.constant.DoubleConstant;
import proguard.classfile.constant.FieldrefConstant;
import proguard.classfile.constant.FloatConstant;
import proguard.classfile.constant.IntegerConstant;
import proguard.classfile.constant.InterfaceMethodrefConstant;
import proguard.classfile.constant.InvokeDynamicConstant;
import proguard.classfile.constant.LongConstant;
import proguard.classfile.constant.MethodHandleConstant;
import proguard.classfile.constant.MethodTypeConstant;
import proguard.classfile.constant.MethodrefConstant;
import proguard.classfile.constant.NameAndTypeConstant;
import proguard.classfile.constant.StringConstant;
import proguard.classfile.constant.Utf8Constant;
import proguard.classfile.constant.visitor.ConstantVisitor;
import proguard.classfile.util.SimplifiedVisitor;
import proguard.classfile.visitor.ClassVisitor;
import proguard.classfile.visitor.MemberVisitor;

/**
 * Created by wuzhong on 2017/5/12.
 */
public class AbstractClasslVisitor extends SimplifiedVisitor implements ConstantVisitor, MemberVisitor, ClassVisitor {

    @Override
    public void visitProgramClass(ProgramClass programClass) {
        programClass.constantPoolEntriesAccept(this);
    }

    @Override
    public void visitLibraryClass(LibraryClass libraryClass) {
    }

    @Override
    public void visitIntegerConstant(Clazz clazz, IntegerConstant integerConstant) {

    }

    @Override
    public void visitLongConstant(Clazz clazz, LongConstant longConstant) {

    }

    @Override
    public void visitFloatConstant(Clazz clazz, FloatConstant floatConstant) {

    }

    @Override
    public void visitDoubleConstant(Clazz clazz, DoubleConstant doubleConstant) {

    }

    @Override
    public void visitStringConstant(Clazz clazz, StringConstant stringConstant) {

    }

    @Override
    public void visitUtf8Constant(Clazz clazz, Utf8Constant utf8Constant) {

    }

    @Override
    public void visitInvokeDynamicConstant(Clazz clazz, InvokeDynamicConstant invokeDynamicConstant) {

    }

    @Override
    public void visitMethodHandleConstant(Clazz clazz, MethodHandleConstant methodHandleConstant) {

    }

    @Override
    public void visitFieldrefConstant(Clazz clazz, FieldrefConstant fieldrefConstant) {
    }

    @Override
    public void visitInterfaceMethodrefConstant(Clazz clazz, InterfaceMethodrefConstant interfaceMethodrefConstant) {

    }

    @Override
    public void visitMethodrefConstant(Clazz clazz, MethodrefConstant methodrefConstant) {
    }

    @Override
    public void visitClassConstant(Clazz clazz, ClassConstant classConstant) {

    }

    @Override
    public void visitMethodTypeConstant(Clazz clazz, MethodTypeConstant methodTypeConstant) {

    }

    @Override
    public void visitNameAndTypeConstant(Clazz clazz, NameAndTypeConstant nameAndTypeConstant) {

    }

    @Override
    public void visitProgramField(ProgramClass programClass, ProgramField programField) {
    }

    @Override
    public void visitProgramMethod(ProgramClass programClass, ProgramMethod programMethod) {
    }

    @Override
    public void visitLibraryField(LibraryClass libraryClass, LibraryField libraryField) {
    }

    @Override
    public void visitLibraryMethod(LibraryClass libraryClass, LibraryMethod libraryMethod) {
    }

    public void println(String message) {
        System.out.println(message);
    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/proguard/dump/BundleProguardDumper.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.proguard.dump;

import java.util.Map;
import java.util.Set;

import com.taobao.android.builder.tools.proguard.dump.utils.ReflectUtils;
import proguard.ProGuard;
import proguard.classfile.ClassPool;

/**
 * Created by wuzhong on 2017/6/2.
 */
public class BundleProguardDumper {

    public static Map<String, ClazzRefInfo> dump(ProGuard proGuard, Set<String> defaultClasses) throws Exception {

        ClassPool classPool = (ClassPool)ReflectUtils.getField(proGuard, "programClassPool");
        ClassPool libClassPool = (ClassPool)ReflectUtils.getField(proGuard, "libraryClassPool");

        VisitorDTO visitorDTO = new VisitorDTO(defaultClasses, classPool, libClassPool);

        classPool.classesAccept(new ClassStructVisitor(visitorDTO));
        classPool.classesAccept(new ClassDetailVisitor(visitorDTO));
        visitorDTO.addSuperRefInfo();

        return visitorDTO.clazzRefInfoMap;
    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/proguard/dump/ClassDetailVisitor.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.proguard.dump;

import proguard.classfile.Clazz;
import proguard.classfile.LibraryClass;
import proguard.classfile.LibraryMethod;
import proguard.classfile.Method;
import proguard.classfile.ProgramClass;
import proguard.classfile.ProgramMember;
import proguard.classfile.ProgramMethod;
import proguard.classfile.attribute.Attribute;
import proguard.classfile.attribute.CodeAttribute;
import proguard.classfile.attribute.visitor.AttributeVisitor;
import proguard.classfile.constant.FieldrefConstant;
import proguard.classfile.constant.InterfaceMethodrefConstant;
import proguard.classfile.constant.MethodrefConstant;
import proguard.classfile.instruction.ConstantInstruction;
import proguard.classfile.instruction.Instruction;
import proguard.classfile.instruction.visitor.InstructionVisitor;

/**
 * Created by wuzhong on 2017/5/12.
 */
public class ClassDetailVisitor extends AbstractClasslVisitor implements AttributeVisitor, InstructionVisitor {

    private VisitorDTO visitorDTO;

    public ClassDetailVisitor(VisitorDTO visitorDTO) {
        this.visitorDTO = visitorDTO;
    }

    //class çé¡ºåºä¸ç¡®å®æå¾å¤§çé®é¢
    @Override
    public void visitProgramClass(ProgramClass programClass) {
        programClass.constantPoolEntriesAccept(this);

        programClass.methodsAccept(this);
    }

    //@Override
    //public void visitMethodrefConstant(Clazz clazz, MethodrefConstant methodrefConstant) {
    //
    //    String clazzName = clazz.getClassName(methodrefConstant.u2classIndex);
    //    ClazzRefInfo clazzRefInfo = visitorDTO.getClazzRefInfo(clazzName);
    //
    //    String methodName = clazz.getName(methodrefConstant.u2nameAndTypeIndex);
    //    if (null != clazzRefInfo) {
    //        clazzRefInfo.getMethods().add(methodName);
    //    }
    //
    //}

    @Override
    public void visitProgramMethod(ProgramClass programClass, ProgramMethod programMethod) {
        visitMember(programClass, programMethod);
    }

    private void visitMember(ProgramClass programClass, ProgramMember programMember) {
        if (programMember.u2attributesCount > 0) {
            //println("Class member attributes (count = " + programMember.u2attributesCount + "):");
            programMember.attributesAccept(programClass, this);
        }
    }

    @Override
    public void visitAnyInstruction(Clazz clazz, Method method, CodeAttribute codeAttribute, int offset,
                                    Instruction instruction) {
        //println(instruction.toString(offset));
    }

    @Override
    public void visitAnyAttribute(Clazz clazz, Attribute attribute) {
        //super.visitAnyAttribute(clazz, attribute);

        //System.out.println(">>>>>>");

    }

    @Override
    public void visitCodeAttribute(Clazz clazz, Method method, CodeAttribute codeAttribute) {

        //println("visitCodeAttribute >>>>>");

        codeAttribute.instructionsAccept(clazz, method, this);
    }

    @Override
    public void visitConstantInstruction(Clazz clazz, Method method, CodeAttribute codeAttribute, int offset,
                                         ConstantInstruction constantInstruction) {
        //println("visitConstantInstruction >>>" + constantInstruction.toString(offset));

        //indent();
        clazz.constantPoolEntryAccept(constantInstruction.constantIndex, this);
        //outdent();
    }

    @Override
    public void visitMethodrefConstant(Clazz clazz, MethodrefConstant methodrefConstant) {

        //println("visitMethodrefConstant Methodref [" +
        //            clazz.getClassName(methodrefConstant.u2classIndex) + "." +
        //            clazz.getName(methodrefConstant.u2nameAndTypeIndex) + " " +
        //            clazz.getType(methodrefConstant.u2nameAndTypeIndex) + "]");

        addMethod(clazz.getClassName(methodrefConstant.u2classIndex),
                  clazz.getName(methodrefConstant.u2nameAndTypeIndex),
                  clazz.getType(methodrefConstant.u2nameAndTypeIndex), false);

    }

    @Override
    public void visitInterfaceMethodrefConstant(Clazz clazz, InterfaceMethodrefConstant interfaceMethodrefConstant) {
        //println("visitInterfaceMethodrefConstant InterfaceMethodref [" +
        //            clazz.getClassName(interfaceMethodrefConstant.u2classIndex) + "." +
        //            clazz.getName(interfaceMethodrefConstant.u2nameAndTypeIndex) + " " +
        //            clazz.getType(interfaceMethodrefConstant.u2nameAndTypeIndex) + "]");

        addMethod(clazz.getClassName(interfaceMethodrefConstant.u2classIndex),
                  clazz.getName(interfaceMethodrefConstant.u2nameAndTypeIndex),
                  clazz.getType(interfaceMethodrefConstant.u2nameAndTypeIndex), true);

    }

    @Override
    public void visitFieldrefConstant(Clazz clazz, FieldrefConstant fieldrefConstant) {

        //println("visitFieldrefConstant Methodref [" +
        //            clazz.getClassName(fieldrefConstant.u2classIndex) + "." +
        //            clazz.getName(fieldrefConstant.u2nameAndTypeIndex) + " " +
        //            clazz.getType(fieldrefConstant.u2nameAndTypeIndex) + "]");

        addField(clazz.getClassName(fieldrefConstant.u2classIndex),
                 clazz.getName(fieldrefConstant.u2nameAndTypeIndex));

    }

    private void addMethod(String name, String method, String args, boolean interfaceClazz) {
        //println("addMethod " + name + "." + method);

        ClazzRefInfo clazzRefInfo = visitorDTO.getClazzRefInfo(name);
        if (null != clazzRefInfo) {

            if (interfaceClazz) {
                clazzRefInfo.setNeedExtend(true);
            }

            //keep it interface
            LibraryClass libraryClass = (LibraryClass)visitorDTO.libraryClassPool.getClass(clazzRefInfo.getClazzName());
            //å¤æ­æ¯å¦è½å½ä¸­superç±»
            if (null != libraryClass) {

                ClazzRefInfo superRefInfo = getSuperClazzRef(libraryClass, method, args);
                if (null != superRefInfo){
                    superRefInfo.getMethods().add(method);
                }

            }

            //clazzRefInfo.getMethods().add(method);

        }

    }

    private ClazzRefInfo getSuperClazzRef(LibraryClass libraryClass, String methodName, String args) {
        if (null == libraryClass || !visitorDTO.isLibClazz(libraryClass.getName())) {
            return null;
        }
        for (LibraryMethod method : libraryClass.methods) {
            if (method.name.equals(methodName) && method.descriptor.equals(args)) {
                ClazzRefInfo clazzRefInfo = visitorDTO.getClazzRefInfoByName(libraryClass.getName());
                return clazzRefInfo;
            }
        }

        Clazz clazz = libraryClass.getSuperClass();
        ClazzRefInfo clazzRefInfo = getClazzRefInfoBySuper(methodName, args, clazz);
        if (clazzRefInfo != null) {
            return clazzRefInfo;
        }
        for (int i = 0; i < libraryClass.getInterfaceCount(); i++) {
            ClazzRefInfo clazzRefInfo1 = getClazzRefInfoBySuper(methodName, args, libraryClass.getInterface(i));
            if (clazzRefInfo1 != null) {
                return clazzRefInfo1;
            }
        }
        return null;
    }

    private ClazzRefInfo getClazzRefInfoBySuper(String methodName, String args, Clazz clazz) {
        if (null != clazz && visitorDTO.isLibClazz(clazz.getName())) {
            return getSuperClazzRef((LibraryClass)clazz, methodName, args);
        }
        return null;
    }

    private void addField(String name, String field) {

        //println("addField " + name + "." + field);

        ClazzRefInfo clazzRefInfo = visitorDTO.getClazzRefInfo(name);
        if (null != clazzRefInfo) {
            clazzRefInfo.getFields().add(field);
        }

    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/proguard/dump/utils/ReflectUtils.java;<<<<<<< MINE
=======
package com.taobao.android.builder.tools.proguard.dump.utils;

import java.lang.reflect.Field;

public class ReflectUtils {

    public static Object getField(Object obj, String fieldName) throws Exception {
        Field t = obj.getClass().getDeclaredField(fieldName);
        t.setAccessible(true);
        return t.get(obj);
    }
}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/proguard/dump/ClassStructVisitor.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.proguard.dump;

import com.taobao.android.builder.tools.proguard.dump.VisitorDTO.ClassStruct;
import com.taobao.android.builder.tools.proguard.dump.VisitorDTO.LibraryClazzInfo;
import org.apache.commons.lang.StringUtils;
import proguard.classfile.Clazz;
import proguard.classfile.LibraryClass;
import proguard.classfile.ProgramClass;
import proguard.classfile.ProgramField;
import proguard.classfile.ProgramMethod;
import proguard.classfile.visitor.ClassVisitor;

/**
 * Created by wuzhong on 2017/5/12.
 *
 * æ¥æ¾ææç±»çç¶å­å³ç³»ï¼ æ¯ å½åç±» -> root library class
 */
public class ClassStructVisitor extends AbstractClasslVisitor implements ClassVisitor {

    private VisitorDTO visitorDTO;

    public ClassStructVisitor(VisitorDTO visitorDTO) {
        this.visitorDTO = visitorDTO;
    }

    //class çé¡ºåºä¸ç¡®å®æå¾å¤§çé®é¢
    @Override
    public void visitProgramClass(ProgramClass programClass) {

        addSuperClass(programClass);

        for (int i = 0; i < programClass.getInterfaceCount(); i++) {
            addInterface(programClass, i);
        }

        programClass.methodsAccept(this);

        programClass.fieldsAccept(this);

    }

    private void addInterface(ProgramClass programClass, int i) {
        String interfaceClazz = programClass.getInterfaceName(i);
        //ç®åå¤ç
        if (visitorDTO.isLibClazz(interfaceClazz)) {
            ClassStruct classStruct = getOrCreateClassStruct(programClass);
            classStruct.libInterfaces.add(interfaceClazz);

            //add super interface to keep
            addSuperInterfaces(interfaceClazz, classStruct);

        }
    }

    private void addSuperInterfaces(String interfaceClazz, ClassStruct classStruct) {
        LibraryClass libraryClass = (LibraryClass)visitorDTO.libraryClassPool.getClass(interfaceClazz);
        if (null == libraryClass){
            return;
        }
        for (int index = 0; index < libraryClass.getInterfaceCount(); index++) {
            Clazz superInter = libraryClass.getInterface(index);
            if (null != superInter && visitorDTO.isLibClazz(superInter.getName())) {
                classStruct.libInterfaces.add(superInter.getName());

                //åè¿­ä»£
                addSuperInterfaces(superInter.getName(), classStruct);

            }
        }
    }

    private ClassStruct getOrCreateClassStruct(ProgramClass programClass) {
        ClassStruct classStruct = visitorDTO.classStructMap.get(programClass.getName());
        if (null == classStruct) {
            classStruct = new ClassStruct();
            visitorDTO.classStructMap.put(programClass.getName(), classStruct);
        }
        return classStruct;
    }

    private void addSuperClass(ProgramClass programClass) {
        String superName = visitorDTO.findRootLibClazz(programClass);
        if (StringUtils.isEmpty(superName)) {
            return;
        }
        ClassStruct classStruct = getOrCreateClassStruct(programClass);
        classStruct.superClazzName = superName;
    }

    @Override
    public void visitProgramField(ProgramClass programClass, ProgramField programField) {
        LibraryClazzInfo libraryClazzInfo = getOrCreateLibraryClazzInfo(programClass);
        if (null != libraryClazzInfo) {
            libraryClazzInfo.appFields.add(programField.getName(programClass));
        }
    }

    @Override
    public void visitProgramMethod(ProgramClass programClass, ProgramMethod programMethod) {
        LibraryClazzInfo libraryClazzInfo = getOrCreateLibraryClazzInfo(programClass);
        if (null != libraryClazzInfo) {
            libraryClazzInfo.appMethods.add(programMethod.getName(programClass));
        }
    }

    private LibraryClazzInfo getOrCreateLibraryClazzInfo(ProgramClass programClass) {

        return visitorDTO.getLibraryClazzInfo(programClass.getName());

    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/proguard/domain/Result.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.android.builder.tools.proguard.domain;

import java.io.File;

/**
 * Created by wuzhong on 2017/5/14.
 */
public class Result {

    public boolean success ;

    public String key;

    public File cacheDir;

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/proguard/KeepOnlyConfigurationParser.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */
package com.taobao.android.builder.tools.proguard;

import java.io.File;
import java.io.IOException;
import java.io.LineNumberReader;
import java.io.StringReader;
import java.net.URL;
import java.util.ArrayList;
import java.util.List;
import java.util.Properties;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import proguard.ArgumentWordReader;
import proguard.AtlasProguardConstants;
import proguard.ClassPath;
import proguard.ClassPathEntry;
import proguard.ClassSpecification;
import proguard.Configuration;
import proguard.ConfigurationParser;
import proguard.FileWordReader;
import proguard.KeepClassSpecification;
import proguard.LineWordReader;
import proguard.MemberSpecification;
import proguard.ParseException;
import proguard.WordReader;
import proguard.classfile.ClassConstants;
import proguard.classfile.JavaConstants;
import proguard.classfile.util.ClassUtil;
import proguard.util.ListUtil;

/**
 * This class parses ProGuard configurations. Configurations can be read from an
 * array of arguments or from a configuration file or URL. External references
 * in file names ('<...>') can be resolved against a given set of properties.
 *
 * @author Eric Lafortune
 */
public class KeepOnlyConfigurationParser {
    private static Logger sLogger = LoggerFactory.getLogger(KeepOnlyConfigurationParser.class);

    private final WordReader reader;
    private final Properties properties;

    private String nextWord;
    private String lastComments;

    private String filePath;

    /**
     * Creates a new ConfigurationParser for the given String arguments and
     * the given Properties.
     */
    public KeepOnlyConfigurationParser(String[] args,
                                       Properties properties) throws IOException {
        this(args, null, properties);
    }

    /**
     * Creates a new ConfigurationParser for the given String arguments,
     * with the given base directory and the given Properties.
     */
    public KeepOnlyConfigurationParser(String[] args,
                                       File baseDir,
                                       Properties properties) throws IOException {
        this(new ArgumentWordReader(args, baseDir), properties);
    }

    /**
     * Creates a new ConfigurationParser for the given lines,
     * with the given base directory and the given Properties.
     */
    public KeepOnlyConfigurationParser(String lines,
                                       String description,
                                       File baseDir,
                                       Properties properties) throws IOException {
        this(new LineWordReader(new LineNumberReader(new StringReader(lines)),
                                description,
                                baseDir),
             properties);
    }

    /**
     * Creates a new ConfigurationParser for the given file, with the system
     * Properties.
     *
     * @deprecated Temporary code for backward compatibility in Obclipse.
     */
    public KeepOnlyConfigurationParser(File file) throws IOException {
        this(file, System.getProperties());
    }

    /**
     * Creates a new ConfigurationParser for the given file and the given
     * Properties.
     */
    public KeepOnlyConfigurationParser(File file,
                                       Properties properties) throws IOException {
        this(new FileWordReader(file), properties);
        this.filePath = file.getAbsolutePath();
    }

    /**
     * Creates a new ConfigurationParser for the given URL and the given
     * Properties.
     */
    public KeepOnlyConfigurationParser(URL url,
                                       Properties properties) throws IOException {
        this(new FileWordReader(url), properties);
    }

    /**
     * Creates a new ConfigurationParser for the given word reader and the
     * given Properties.
     */
    public KeepOnlyConfigurationParser(WordReader reader,
                                       Properties properties) throws IOException {
        this.reader = reader;
        this.properties = properties;

        readNextWord();
    }

    /**
     * Parses and returns the configuration.
     *
     * @param configuration the configuration that is updated as a side-effect.
     * @throws ParseException if the any of the configuration settings contains
     * a syntax error.
     * @throws IOException if an IO error occurs while reading a configuration.
     */
    public void parse(Configuration configuration)
        throws ParseException, IOException {
        while (nextWord != null) {
            lastComments = reader.lastComments();

            // First include directives.
            if (AtlasProguardConstants.AT_DIRECTIVE.startsWith(nextWord) ||
                AtlasProguardConstants.INCLUDE_DIRECTIVE.startsWith(nextWord)) {
                configuration.lastModified = parseIncludeArgument(configuration.lastModified);
            } else if (AtlasProguardConstants.BASE_DIRECTORY_DIRECTIVE.startsWith(nextWord)) {
                parseBaseDirectoryArgument();
            }

            // Then configuration options with or without arguments.
            else if (AtlasProguardConstants.INJARS_OPTION.startsWith(nextWord)) {
                configuration.programJars = parseClassPathArgument(configuration.programJars, false);
            } else if (AtlasProguardConstants.OUTJARS_OPTION.startsWith(nextWord)) {
                configuration.programJars = parseClassPathArgument(configuration.programJars, true);
            }
            //else if (AtlasProguardConstants.LIBRARYJARS_OPTION                               .startsWith
            // (nextWord)) configuration.libraryJars                      = parseClassPathArgument(configuration
            // .libraryJars, false);
            //else if (AtlasProguardConstants.RESOURCEJARS_OPTION                              .startsWith
            // (nextWord)) throw new ParseException("The '-resourcejars' option is no longer supported. Please
            // use the '-injars' option for all input");
            //else if (AtlasProguardConstants.SKIP_NON_PUBLIC_LIBRARY_CLASSES_OPTION           .startsWith
            // (nextWord)) configuration.skipNonPublicLibraryClasses      = parseNoArgument(true);
            //else if (AtlasProguardConstants.DONT_SKIP_NON_PUBLIC_LIBRARY_CLASSES_OPTION      .startsWith
            // (nextWord)) configuration.skipNonPublicLibraryClasses      = parseNoArgument(false);
            //else if (AtlasProguardConstants.DONT_SKIP_NON_PUBLIC_LIBRARY_CLASS_MEMBERS_OPTION.startsWith
            // (nextWord)) configuration.skipNonPublicLibraryClassMembers = parseNoArgument(false);
            //else if (AtlasProguardConstants.TARGET_OPTION                                    .startsWith
            // (nextWord)) configuration.targetClassVersion               = parseClassVersion();
            //else if (AtlasProguardConstants.FORCE_PROCESSING_OPTION                          .startsWith
            // (nextWord)) configuration.lastModified                     = parseNoArgument(Long.MAX_VALUE);

            else if (AtlasProguardConstants.KEEP_OPTION.startsWith(nextWord)) {
                configuration.keep = parseKeepClassSpecificationArguments(configuration.keep, true, false, false);
            } else if (AtlasProguardConstants.KEEP_CLASS_MEMBERS_OPTION.startsWith(nextWord)) {
                configuration.keep = parseKeepClassSpecificationArguments(configuration.keep, false, false, false);
            } else if (AtlasProguardConstants.KEEP_CLASSES_WITH_MEMBERS_OPTION.startsWith(nextWord)) {
                configuration.keep = parseKeepClassSpecificationArguments(configuration.keep, false, true, false);
            } else if (AtlasProguardConstants.KEEP_NAMES_OPTION.startsWith(nextWord)) {
                configuration.keep = parseKeepClassSpecificationArguments(configuration.keep, true, false, true);
            } else if (AtlasProguardConstants.KEEP_CLASS_MEMBER_NAMES_OPTION.startsWith(nextWord)) {
                configuration.keep = parseKeepClassSpecificationArguments(configuration.keep, false, false, true);
            } else if (AtlasProguardConstants.KEEP_CLASSES_WITH_MEMBER_NAMES_OPTION.startsWith(nextWord)) {
                configuration.keep = parseKeepClassSpecificationArguments(configuration.keep, false, true, true);
            }
            //else if (AtlasProguardConstants.PRINT_SEEDS_OPTION                               .startsWith
            // (nextWord)) configuration.printSeeds                       = parseOptionalFile();

            // After '-keep'.
            else if (AtlasProguardConstants.KEEP_DIRECTORIES_OPTION.startsWith(nextWord)) {
                configuration.keepDirectories = parseCommaSeparatedList("directory name", true, true, false, true,
                                                                        false, true, false, false,
                                                                        configuration.keepDirectories);
            }

            //else if (AtlasProguardConstants.DONT_SHRINK_OPTION                               .startsWith
            // (nextWord)) configuration.shrink                           = parseNoArgument(false);
            //else if (AtlasProguardConstants.PRINT_USAGE_OPTION                               .startsWith
            // (nextWord)) configuration.printUsage                       = parseOptionalFile();
            //else if (AtlasProguardConstants.WHY_ARE_YOU_KEEPING_OPTION                       .startsWith
            // (nextWord)) configuration.whyAreYouKeeping                 = parseClassSpecificationArguments
            // (configuration.whyAreYouKeeping);

            //else if (AtlasProguardConstants.DONT_OPTIMIZE_OPTION                             .startsWith
            // (nextWord)) configuration.optimize                         = parseNoArgument(false);
            //else if (AtlasProguardConstants.OPTIMIZATION_PASSES                              .startsWith
            // (nextWord)) configuration.optimizationPasses               = parseIntegerArgument();
            //else if (AtlasProguardConstants.OPTIMIZATIONS                                    .startsWith
            // (nextWord)) configuration.optimizations                    = parseCommaSeparatedList("optimization
            // name", true, false, false, false, false, false, false, false, configuration.optimizations);
            //else if (AtlasProguardConstants.ASSUME_NO_SIDE_EFFECTS_OPTION                    .startsWith
            // (nextWord)) configuration.assumeNoSideEffects              = parseClassSpecificationArguments
            // (configuration.assumeNoSideEffects);
            //else if (AtlasProguardConstants.ALLOW_ACCESS_MODIFICATION_OPTION                 .startsWith
            // (nextWord)) configuration.allowAccessModification          = parseNoArgument(true);
            //else if (AtlasProguardConstants.MERGE_INTERFACES_AGGRESSIVELY_OPTION             .startsWith
            // (nextWord)) configuration.mergeInterfacesAggressively      = parseNoArgument(true);

            //else if (AtlasProguardConstants.DONT_OBFUSCATE_OPTION                            .startsWith
            // (nextWord)) configuration.obfuscate                        = parseNoArgument(false);
            //else if (AtlasProguardConstants.PRINT_MAPPING_OPTION                             .startsWith
            // (nextWord)) configuration.printMapping                     = parseOptionalFile();
            //else if (AtlasProguardConstants.APPLY_MAPPING_OPTION                             .startsWith
            // (nextWord)) configuration.applyMapping                     = parseFile();
            //else if (AtlasProguardConstants.OBFUSCATION_DICTIONARY_OPTION                    .startsWith
            // (nextWord)) configuration.obfuscationDictionary            = parseFile();
            //else if (AtlasProguardConstants.CLASS_OBFUSCATION_DICTIONARY_OPTION              .startsWith
            // (nextWord)) configuration.classObfuscationDictionary       = parseFile();
            //else if (AtlasProguardConstants.PACKAGE_OBFUSCATION_DICTIONARY_OPTION            .startsWith
            // (nextWord)) configuration.packageObfuscationDictionary     = parseFile();
            //else if (AtlasProguardConstants.OVERLOAD_AGGRESSIVELY_OPTION                     .startsWith
            // (nextWord)) configuration.overloadAggressively             = parseNoArgument(true);
            //else if (AtlasProguardConstants.USE_UNIQUE_CLASS_MEMBER_NAMES_OPTION             .startsWith
            // (nextWord)) configuration.useUniqueClassMemberNames        = parseNoArgument(true);
            //else if (AtlasProguardConstants.DONT_USE_MIXED_CASE_CLASS_NAMES_OPTION           .startsWith
            // (nextWord)) configuration.useMixedCaseClassNames           = parseNoArgument(false);
            else if (AtlasProguardConstants.KEEP_PACKAGE_NAMES_OPTION.startsWith(nextWord)) {
                configuration.keepPackageNames = parseCommaSeparatedList("package name", true, true, false, false, true,
                                                                         false, true, false,
                                                                         configuration.keepPackageNames);
            }
            //else if (AtlasProguardConstants.FLATTEN_PACKAGE_HIERARCHY_OPTION                 .startsWith
            // (nextWord)) configuration.flattenPackageHierarchy          = ClassUtil.internalClassName
            // (parseOptionalArgument());
            //else if (AtlasProguardConstants.REPACKAGE_CLASSES_OPTION                         .startsWith
            // (nextWord)) configuration.repackageClasses                 = ClassUtil.internalClassName
            // (parseOptionalArgument());
            //else if (AtlasProguardConstants.DEFAULT_PACKAGE_OPTION                           .startsWith
            // (nextWord)) configuration.repackageClasses                 = ClassUtil.internalClassName
            // (parseOptionalArgument());
            else if (AtlasProguardConstants.KEEP_ATTRIBUTES_OPTION.startsWith(nextWord)) {
                configuration.keepAttributes = parseCommaSeparatedList("attribute name", true, true, false, false, true,
                                                                       false, false, false,
                                                                       configuration.keepAttributes);
            } else if (AtlasProguardConstants.KEEP_PARAMETER_NAMES_OPTION.startsWith(nextWord)) {
                configuration.keepParameterNames = parseNoArgument(true);
            }
            //else if (AtlasProguardConstants.RENAME_SOURCE_FILE_ATTRIBUTE_OPTION              .startsWith
            // (nextWord)) configuration.newSourceFileAttribute           = parseOptionalArgument();
            //else if (AtlasProguardConstants.ADAPT_CLASS_STRINGS_OPTION                       .startsWith
            // (nextWord)) configuration.adaptClassStrings                = parseCommaSeparatedList("class name",
            // true, true, false, false, true, false, true, false, configuration.adaptClassStrings);
            //else if (AtlasProguardConstants.ADAPT_RESOURCE_FILE_NAMES_OPTION                 .startsWith
            // (nextWord)) configuration.adaptResourceFileNames           = parseCommaSeparatedList("resource
            // file name", true, true, false, true, false, false, false, false, configuration
            // .adaptResourceFileNames);
            //else if (AtlasProguardConstants.ADAPT_RESOURCE_FILE_CONTENTS_OPTION              .startsWith
            // (nextWord)) configuration.adaptResourceFileContents        = parseCommaSeparatedList("resource
            // file name", true, true, false, true, false, false, false, false, configuration
            // .adaptResourceFileContents);

            //else if (AtlasProguardConstants.DONT_PREVERIFY_OPTION                            .startsWith
            // (nextWord)) configuration.preverify                        = parseNoArgument(false);
            //else if (AtlasProguardConstants.MICRO_EDITION_OPTION                             .startsWith
            // (nextWord)) configuration.microEdition                     = parseNoArgument(true);

            //else if (AtlasProguardConstants.VERBOSE_OPTION                                   .startsWith
            // (nextWord)) configuration.verbose                          = parseNoArgument(true);
            //else if (AtlasProguardConstants.DONT_NOTE_OPTION                                 .startsWith
            // (nextWord)) configuration.note                             = parseCommaSeparatedList("class name",
            // true, true, false, false, true, false, true, false, configuration.note);
            else if (AtlasProguardConstants.DONT_WARN_OPTION.startsWith(nextWord)) {
                configuration.warn = parseCommaSeparatedList("class name", true, true, false, false, true, false, true,
                                                             false, configuration.warn);
            }
            //else if (AtlasProguardConstants.IGNORE_WARNINGS_OPTION                           .startsWith
            // (nextWord)) configuration.ignoreWarnings                   = parseNoArgument(true);
            //else if (AtlasProguardConstants.PRINT_CONFIGURATION_OPTION                       .startsWith
            // (nextWord)) configuration.printConfiguration               = parseOptionalFile();
            //else if (AtlasProguardConstants.DUMP_OPTION                                      .startsWith
            // (nextWord)) configuration.dump                             = parseOptionalFile();
            else {
                //throw new GradleException("Unsupport option in library " + reader.locationDescription());
                sLogger.error("Unsupport option " + reader.locationDescription());
                readNextWord(false);
            }
        }
    }

    /**
     * Closes the configuration.
     *
     * @throws IOException if an IO error occurs while closing the configuration.
     */
    public void close() throws IOException {
        if (reader != null) {
            reader.close();
        }
    }

    private long parseIncludeArgument(long lastModified) throws ParseException, IOException {
        // Read the configuration file name.
        readNextWord("configuration file name", true, false);

        File file = file(nextWord);
        reader.includeWordReader(new FileWordReader(file));

        readNextWord();

        return Math.max(lastModified, file.lastModified());
    }

    private void parseBaseDirectoryArgument() throws ParseException, IOException {
        // Read the base directory name.
        readNextWord("base directory name", true, false);

        reader.setBaseDir(file(nextWord));

        readNextWord();
    }

    private ClassPath parseClassPathArgument(ClassPath classPath,
                                             boolean isOutput)
        throws ParseException, IOException {
        // Create a new List if necessary.
        if (classPath == null) {
            classPath = new ClassPath();
        }

        while (true) {
            // Read the next jar name.
            readNextWord("jar or directory name", true, false);

            // Create a new class path entry.
            ClassPathEntry entry = new ClassPathEntry(file(nextWord), isOutput);

            // Read the opening parenthesis or the separator, if any.
            readNextWord();

            // Read the optional filters.
            if (!configurationEnd() &&
                AtlasProguardConstants.OPEN_ARGUMENTS_KEYWORD.equals(nextWord)) {
                // Read all filters in an array.
                List[] filters = new List[7];

                int counter = 0;
                do {
                    // Read the filter.
                    filters[counter++] =
                        parseCommaSeparatedList("filter", true, true, true, true, false, true, false, false, null);
                }
                while (counter < filters.length &&
                    AtlasProguardConstants.SEPARATOR_KEYWORD.equals(nextWord));

                // Make sure there is a closing parenthesis.
                if (!AtlasProguardConstants.CLOSE_ARGUMENTS_KEYWORD.equals(nextWord)) {
                    throw new ParseException(
                        "Expecting separating '" + AtlasProguardConstants.ARGUMENT_SEPARATOR_KEYWORD +
                            "' or '" + AtlasProguardConstants.SEPARATOR_KEYWORD +
                            "', or closing '" + AtlasProguardConstants.CLOSE_ARGUMENTS_KEYWORD +
                            "' before " + reader.locationDescription());
                }

                // Set all filters from the array on the entry.
                entry.setFilter(filters[--counter]);
                if (counter > 0) {
                    entry.setJarFilter(filters[--counter]);
                    if (counter > 0) {
                        entry.setWarFilter(filters[--counter]);
                        if (counter > 0) {
                            entry.setEarFilter(filters[--counter]);
                            if (counter > 0) {
                                entry.setZipFilter(filters[--counter]);
                                if (counter > 0) {
                                    // For backward compatibility, the apk
                                    // filter comes second in the list.
                                    entry.setApkFilter(filters[--counter]);
                                    if (counter > 0) {
                                        // For backward compatibility, the aar
                                        // filter comes first in the list.
                                        entry.setAarFilter(filters[--counter]);
                                    }
                                }
                            }
                        }
                    }
                }

                // Read the separator, if any.
                readNextWord();
            }

            // Add the entry to the list.
            classPath.add(entry);

            if (configurationEnd()) {
                return classPath;
            }

            if (!nextWord.equals(AtlasProguardConstants.JAR_SEPARATOR_KEYWORD)) {
                throw new ParseException(
                    "Expecting class path separator '" + AtlasProguardConstants.JAR_SEPARATOR_KEYWORD +
                        "' before " + reader.locationDescription());
            }
        }
    }

    private int parseClassVersion()
        throws ParseException, IOException {
        // Read the obligatory target.
        readNextWord("java version");

        int classVersion = ClassUtil.internalClassVersion(nextWord);
        if (classVersion == 0) {
            throw new ParseException("Unsupported java version " + reader.locationDescription());
        }

        readNextWord();

        return classVersion;
    }

    private int parseIntegerArgument()
        throws ParseException, IOException {
        try {
            // Read the obligatory integer.
            readNextWord("integer");

            int integer = Integer.parseInt(nextWord);

            readNextWord();

            return integer;
        } catch (NumberFormatException e) {
            throw new ParseException("Expecting integer argument instead of '" + nextWord +
                                         "' before " + reader.locationDescription());
        }
    }

    private File parseFile()
        throws ParseException, IOException {
        // Read the obligatory file name.
        readNextWord("file name", true, false);

        // Make sure the file is properly resolved.
        File file = file(nextWord);

        readNextWord();

        return file;
    }

    private File parseOptionalFile()
        throws ParseException, IOException {
        // Read the optional file name.
        readNextWord(true);

        // Didn't the user specify a file name?
        if (configurationEnd()) {
            return Configuration.STD_OUT;
        }

        // Make sure the file is properly resolved.
        File file = file(nextWord);

        readNextWord();

        return file;
    }

    private String parseOptionalArgument() throws IOException {
        // Read the optional argument.
        readNextWord();

        // Didn't the user specify an argument?
        if (configurationEnd()) {
            return "";
        }

        String argument = nextWord;

        readNextWord();

        return argument;
    }

    private boolean parseNoArgument(boolean value) throws IOException {
        readNextWord();

        return value;
    }

    private long parseNoArgument(long value) throws IOException {
        readNextWord();

        return value;
    }

    private List parseKeepClassSpecificationArguments(List keepClassSpecifications,
                                                      boolean markClasses,
                                                      boolean markConditionally,
                                                      boolean allowShrinking)
        throws ParseException, IOException {
        // Create a new List if necessary.
        if (keepClassSpecifications == null) {
            keepClassSpecifications = new ArrayList();
        }

        boolean markDescriptorClasses = false;
        //boolean allowShrinking        = false;
        boolean allowOptimization = false;
        boolean allowObfuscation = false;

        // Read the keep modifiers.
        while (true) {
            readNextWord("keyword '" + AtlasProguardConstants.CLASS_KEYWORD +
                             "', '" + JavaConstants.ACC_INTERFACE +
                             "', or '" + JavaConstants.ACC_ENUM + "'",
                         false, true);

            if (!AtlasProguardConstants.ARGUMENT_SEPARATOR_KEYWORD.equals(nextWord)) {
                // Not a comma. Stop parsing the keep modifiers.
                break;
            }

            readNextWord("keyword '" + AtlasProguardConstants.ALLOW_SHRINKING_SUBOPTION +
                             "', '" + AtlasProguardConstants.ALLOW_OPTIMIZATION_SUBOPTION +
                             "', or '" + AtlasProguardConstants.ALLOW_OBFUSCATION_SUBOPTION + "'");

            if (AtlasProguardConstants.INCLUDE_DESCRIPTOR_CLASSES_SUBOPTION.startsWith(nextWord)) {
                markDescriptorClasses = true;
            } else if (AtlasProguardConstants.ALLOW_SHRINKING_SUBOPTION.startsWith(nextWord)) {
                allowShrinking = true;
            } else if (AtlasProguardConstants.ALLOW_OPTIMIZATION_SUBOPTION.startsWith(nextWord)) {
                allowOptimization = true;
            } else if (AtlasProguardConstants.ALLOW_OBFUSCATION_SUBOPTION.startsWith(nextWord)) {
                allowObfuscation = true;
            } else {
                throw new ParseException(
                    "Expecting keyword '" + AtlasProguardConstants.INCLUDE_DESCRIPTOR_CLASSES_SUBOPTION +
                        "', '" + AtlasProguardConstants.ALLOW_SHRINKING_SUBOPTION +
                        "', '" + AtlasProguardConstants.ALLOW_OPTIMIZATION_SUBOPTION +
                        "', or '" + AtlasProguardConstants.ALLOW_OBFUSCATION_SUBOPTION +
                        "' before " + reader.locationDescription());
            }
        }

        // Read the class configuration.
        ClassSpecification classSpecification =
            parseClassSpecificationArguments();

        // Create and add the keep configuration.
        keepClassSpecifications.add(new KeepClassSpecification(markClasses,
                                                               markConditionally,
                                                               markDescriptorClasses,
                                                               allowShrinking,
                                                               allowOptimization,
                                                               allowObfuscation,
                                                               classSpecification));
        return keepClassSpecifications;
    }

    private List parseClassSpecificationArguments(List classSpecifications)
        throws ParseException, IOException {
        // Create a new List if necessary.
        if (classSpecifications == null) {
            classSpecifications = new ArrayList();
        }

        // Read and add the class configuration.
        readNextWord("keyword '" + AtlasProguardConstants.CLASS_KEYWORD +
                         "', '" + JavaConstants.ACC_INTERFACE +
                         "', or '" + JavaConstants.ACC_ENUM + "'",
                     false, true);

        classSpecifications.add(parseClassSpecificationArguments());

        return classSpecifications;
    }

    /**
     * Parses and returns a class specification.
     *
     * @throws ParseException if the class specification contains a syntax error.
     * @throws IOException if an IO error occurs while reading the class
     * specification.
     */
    public ClassSpecification parseClassSpecificationArguments()
        throws ParseException, IOException {
        // Clear the annotation type.
        String annotationType = null;

        // Clear the class access modifiers.
        int requiredSetClassAccessFlags = 0;
        int requiredUnsetClassAccessFlags = 0;

        // Parse the class annotations and access modifiers until the class keyword.
        while (!AtlasProguardConstants.CLASS_KEYWORD.equals(nextWord)) {
            // Strip the negating sign, if any.
            boolean negated =
                nextWord.startsWith(AtlasProguardConstants.NEGATOR_KEYWORD);

            String strippedWord = negated ?
                nextWord.substring(1) :
                nextWord;

            // Parse the class access modifiers.
            int accessFlag =
                strippedWord.equals(JavaConstants.ACC_PUBLIC) ? ClassConstants.ACC_PUBLIC :
                    strippedWord.equals(JavaConstants.ACC_FINAL) ? ClassConstants.ACC_FINAL :
                        strippedWord.equals(JavaConstants.ACC_INTERFACE) ? ClassConstants.ACC_INTERFACE :
                            strippedWord.equals(JavaConstants.ACC_ABSTRACT) ? ClassConstants.ACC_ABSTRACT :
                                strippedWord.equals(JavaConstants.ACC_SYNTHETIC) ? ClassConstants.ACC_SYNTHETIC :
                                    strippedWord.equals(JavaConstants.ACC_ANNOTATION) ? ClassConstants.ACC_ANNOTATTION :
                                        strippedWord.equals(JavaConstants.ACC_ENUM) ? ClassConstants.ACC_ENUM :
                                            unknownAccessFlag();

            // Is it an annotation modifier?
            if (accessFlag == ClassConstants.ACC_ANNOTATTION) {
                // Already read the next word.
                readNextWord("annotation type or keyword '" + JavaConstants.ACC_INTERFACE + "'",
                             false, false);

                // Is the next word actually an annotation type?
                if (!nextWord.equals(JavaConstants.ACC_INTERFACE) &&
                    !nextWord.equals(JavaConstants.ACC_ENUM) &&
                    !nextWord.equals(AtlasProguardConstants.CLASS_KEYWORD)) {
                    // Parse the annotation type.
                    annotationType =
                        ListUtil.commaSeparatedString(
                            parseCommaSeparatedList("annotation type",
                                                    false, false, false, false, true, false, false, true, null), false);

                    // Continue parsing the access modifier that we just read
                    // in the next cycle.
                    continue;
                }

                // Otherwise just handle the annotation modifier.
            }

            if (!negated) {
                requiredSetClassAccessFlags |= accessFlag;
            } else {
                requiredUnsetClassAccessFlags |= accessFlag;
            }

            if ((requiredSetClassAccessFlags &
                requiredUnsetClassAccessFlags) != 0) {
                throw new ParseException("Conflicting class access modifiers for '" + strippedWord +
                                             "' before " + reader.locationDescription());
            }

            if (strippedWord.equals(JavaConstants.ACC_INTERFACE) ||
                strippedWord.equals(JavaConstants.ACC_ENUM) ||
                strippedWord.equals(AtlasProguardConstants.CLASS_KEYWORD)) {
                // The interface or enum keyword. Stop parsing the class flags.
                break;
            }

            // Should we read the next word?
            if (accessFlag != ClassConstants.ACC_ANNOTATTION) {
                readNextWord("keyword '" + AtlasProguardConstants.CLASS_KEYWORD +
                                 "', '" + JavaConstants.ACC_INTERFACE +
                                 "', or '" + JavaConstants.ACC_ENUM + "'",
                             false, true);
            }
        }

        // Parse the class name part.
        String externalClassName =
            ListUtil.commaSeparatedString(
                parseCommaSeparatedList("class name or interface name",
                                        true, false, false, false, true, false, false, false, null), false);

        // For backward compatibility, allow a single "*" wildcard to match any
        // class.
        String className = AtlasProguardConstants.ANY_CLASS_KEYWORD.equals(externalClassName) ?
            null :
            ClassUtil.internalClassName(externalClassName);

        // Clear the annotation type and the class name of the extends part.
        String extendsAnnotationType = null;
        String extendsClassName = null;

        if (!configurationEnd()) {
            // Parse 'implements ...' or 'extends ...' part, if any.
            if (AtlasProguardConstants.IMPLEMENTS_KEYWORD.equals(nextWord) ||
                AtlasProguardConstants.EXTENDS_KEYWORD.equals(nextWord)) {
                readNextWord("class name or interface name", false, true);

                // Parse the annotation type, if any.
                if (AtlasProguardConstants.ANNOTATION_KEYWORD.equals(nextWord)) {
                    extendsAnnotationType =
                        ListUtil.commaSeparatedString(
                            parseCommaSeparatedList("annotation type",
                                                    true, false, false, false, true, false, false, true, null), false);
                }

                String externalExtendsClassName =
                    ListUtil.commaSeparatedString(
                        parseCommaSeparatedList("class name or interface name",
                                                false, false, false, false, true, false, false, false, null), false);

                extendsClassName = AtlasProguardConstants.ANY_CLASS_KEYWORD.equals(externalExtendsClassName) ?
                    null :
                    ClassUtil.internalClassName(externalExtendsClassName);
            }
        }

        // Create the basic class specification.
        ClassSpecification classSpecification =
            new ClassSpecification(lastComments,
                                   requiredSetClassAccessFlags,
                                   requiredUnsetClassAccessFlags,
                                   annotationType,
                                   className,
                                   extendsAnnotationType,
                                   extendsClassName);

        // Now add any class members to this class specification.
        if (!configurationEnd()) {
            // Check the class member opening part.
            if (!AtlasProguardConstants.OPEN_KEYWORD.equals(nextWord)) {
                throw new ParseException("Expecting opening '" + AtlasProguardConstants.OPEN_KEYWORD +
                                             "' at " + reader.locationDescription());
            }

            // Parse all class members.
            while (true) {
                readNextWord("class member description" +
                                 " or closing '" + AtlasProguardConstants.CLOSE_KEYWORD + "'",
                             false, true);

                if (nextWord.equals(AtlasProguardConstants.CLOSE_KEYWORD)) {
                    // The closing brace. Stop parsing the class members.
                    readNextWord();

                    break;
                }

                parseMemberSpecificationArguments(externalClassName,
                                                  classSpecification);
            }
        }

        return classSpecification;
    }

    private void parseMemberSpecificationArguments(String externalClassName,
                                                   ClassSpecification classSpecification)
        throws ParseException, IOException {
        // Clear the annotation name.
        String annotationType = null;

        // Parse the class member access modifiers, if any.
        int requiredSetMemberAccessFlags = 0;
        int requiredUnsetMemberAccessFlags = 0;

        while (!configurationEnd(true)) {
            // Parse the annotation type, if any.
            if (AtlasProguardConstants.ANNOTATION_KEYWORD.equals(nextWord)) {
                annotationType =
                    ListUtil.commaSeparatedString(
                        parseCommaSeparatedList("annotation type",
                                                true, false, false, false, true, false, false, true, null), false);
                continue;
            }

            String strippedWord = nextWord.startsWith("!") ?
                nextWord.substring(1) :
                nextWord;

            // Parse the class member access modifiers.
            int accessFlag =
                strippedWord.equals(JavaConstants.ACC_PUBLIC) ? ClassConstants.ACC_PUBLIC :
                    strippedWord.equals(JavaConstants.ACC_PRIVATE) ? ClassConstants.ACC_PRIVATE :
                        strippedWord.equals(JavaConstants.ACC_PROTECTED) ? ClassConstants.ACC_PROTECTED :
                            strippedWord.equals(JavaConstants.ACC_STATIC) ? ClassConstants.ACC_STATIC :
                                strippedWord.equals(JavaConstants.ACC_FINAL) ? ClassConstants.ACC_FINAL :
                                    strippedWord.equals(JavaConstants.ACC_SYNCHRONIZED)
                                        ? ClassConstants.ACC_SYNCHRONIZED :
                                        strippedWord.equals(JavaConstants.ACC_VOLATILE) ? ClassConstants.ACC_VOLATILE :
                                            strippedWord.equals(JavaConstants.ACC_TRANSIENT)
                                                ? ClassConstants.ACC_TRANSIENT :
                                                strippedWord.equals(JavaConstants.ACC_BRIDGE)
                                                    ? ClassConstants.ACC_BRIDGE :
                                                    strippedWord.equals(JavaConstants.ACC_VARARGS)
                                                        ? ClassConstants.ACC_VARARGS :
                                                        strippedWord.equals(JavaConstants.ACC_NATIVE)
                                                            ? ClassConstants.ACC_NATIVE :
                                                            strippedWord.equals(JavaConstants.ACC_ABSTRACT)
                                                                ? ClassConstants.ACC_ABSTRACT :
                                                                strippedWord.equals(JavaConstants.ACC_STRICT)
                                                                    ? ClassConstants.ACC_STRICT :
                                                                    strippedWord.equals(JavaConstants.ACC_SYNTHETIC)
                                                                        ? ClassConstants.ACC_SYNTHETIC :
                                                                        0;
            if (accessFlag == 0) {
                // Not a class member access modifier. Stop parsing them.
                break;
            }

            if (strippedWord.equals(nextWord)) {
                requiredSetMemberAccessFlags |= accessFlag;
            } else {
                requiredUnsetMemberAccessFlags |= accessFlag;
            }

            // Make sure the user doesn't try to set and unset the same
            // access flags simultaneously.
            if ((requiredSetMemberAccessFlags &
                requiredUnsetMemberAccessFlags) != 0) {
                throw new ParseException("Conflicting class member access modifiers for " +
                                             reader.locationDescription());
            }

            readNextWord("class member description");
        }

        // Parse the class member type and name part.

        // Did we get a special wildcard?
        if (AtlasProguardConstants.ANY_CLASS_MEMBER_KEYWORD.equals(nextWord) ||
            AtlasProguardConstants.ANY_FIELD_KEYWORD.equals(nextWord) ||
            AtlasProguardConstants.ANY_METHOD_KEYWORD.equals(nextWord)) {
            // Act according to the type of wildcard..
            if (AtlasProguardConstants.ANY_CLASS_MEMBER_KEYWORD.equals(nextWord)) {
                checkFieldAccessFlags(requiredSetMemberAccessFlags,
                                      requiredUnsetMemberAccessFlags);
                checkMethodAccessFlags(requiredSetMemberAccessFlags,
                                       requiredUnsetMemberAccessFlags);

                classSpecification.addField(
                    new MemberSpecification(requiredSetMemberAccessFlags,
                                            requiredUnsetMemberAccessFlags,
                                            annotationType,
                                            null,
                                            null));
                classSpecification.addMethod(
                    new MemberSpecification(requiredSetMemberAccessFlags,
                                            requiredUnsetMemberAccessFlags,
                                            annotationType,
                                            null,
                                            null));
            } else if (AtlasProguardConstants.ANY_FIELD_KEYWORD.equals(nextWord)) {
                checkFieldAccessFlags(requiredSetMemberAccessFlags,
                                      requiredUnsetMemberAccessFlags);

                classSpecification.addField(
                    new MemberSpecification(requiredSetMemberAccessFlags,
                                            requiredUnsetMemberAccessFlags,
                                            annotationType,
                                            null,
                                            null));
            } else if (AtlasProguardConstants.ANY_METHOD_KEYWORD.equals(nextWord)) {
                checkMethodAccessFlags(requiredSetMemberAccessFlags,
                                       requiredUnsetMemberAccessFlags);

                classSpecification.addMethod(
                    new MemberSpecification(requiredSetMemberAccessFlags,
                                            requiredUnsetMemberAccessFlags,
                                            annotationType,
                                            null,
                                            null));
            }

            // We still have to read the closing separator.
            readNextWord("separator '" + AtlasProguardConstants.SEPARATOR_KEYWORD + "'");

            if (!AtlasProguardConstants.SEPARATOR_KEYWORD.equals(nextWord)) {
                throw new ParseException("Expecting separator '" + AtlasProguardConstants.SEPARATOR_KEYWORD +
                                             "' before " + reader.locationDescription());
            }
        } else {
            // Make sure we have a proper type.
            checkJavaIdentifier("java type");
            String type = nextWord;

            readNextWord("class member name");
            String name = nextWord;

            // Did we get just one word before the opening parenthesis?
            if (AtlasProguardConstants.OPEN_ARGUMENTS_KEYWORD.equals(name)) {
                // This must be a constructor then.
                // Make sure the type is a proper constructor name.
                if (!(type.equals(ClassConstants.METHOD_NAME_INIT) ||
                    type.equals(externalClassName) ||
                    type.equals(ClassUtil.externalShortClassName(externalClassName)))) {
                    throw new ParseException("Expecting type and name " +
                                                 "instead of just '" + type +
                                                 "' before " + reader.locationDescription());
                }

                // Assign the fixed constructor type and name.
                type = JavaConstants.TYPE_VOID;
                name = ClassConstants.METHOD_NAME_INIT;
            } else {
                // It's not a constructor.
                // Make sure we have a proper name.
                checkJavaIdentifier("class member name");

                // Read the opening parenthesis or the separating
                // semi-colon.
                readNextWord("opening '" + AtlasProguardConstants.OPEN_ARGUMENTS_KEYWORD +
                                 "' or separator '" + AtlasProguardConstants.SEPARATOR_KEYWORD + "'");
            }

            // Are we looking at a field, a method, or something else?
            if (AtlasProguardConstants.SEPARATOR_KEYWORD.equals(nextWord)) {
                // It's a field.
                checkFieldAccessFlags(requiredSetMemberAccessFlags,
                                      requiredUnsetMemberAccessFlags);

                // We already have a field descriptor.
                String descriptor = ClassUtil.internalType(type);

                // Add the field.
                classSpecification.addField(
                    new MemberSpecification(requiredSetMemberAccessFlags,
                                            requiredUnsetMemberAccessFlags,
                                            annotationType,
                                            name,
                                            descriptor));
            } else if (AtlasProguardConstants.OPEN_ARGUMENTS_KEYWORD.equals(nextWord)) {
                // It's a method.
                checkMethodAccessFlags(requiredSetMemberAccessFlags,
                                       requiredUnsetMemberAccessFlags);

                // Parse the method arguments.
                String descriptor =
                    ClassUtil.internalMethodDescriptor(type,
                                                       parseCommaSeparatedList("argument", true, true, true, false,
                                                                               true, false, false, false, null));

                if (!AtlasProguardConstants.CLOSE_ARGUMENTS_KEYWORD.equals(nextWord)) {
                    throw new ParseException(
                        "Expecting separating '" + AtlasProguardConstants.ARGUMENT_SEPARATOR_KEYWORD +
                            "' or closing '" + AtlasProguardConstants.CLOSE_ARGUMENTS_KEYWORD +
                            "' before " + reader.locationDescription());
                }

                // Read the separator after the closing parenthesis.
                readNextWord("separator '" + AtlasProguardConstants.SEPARATOR_KEYWORD + "'");

                if (!AtlasProguardConstants.SEPARATOR_KEYWORD.equals(nextWord)) {
                    throw new ParseException("Expecting separator '" + AtlasProguardConstants.SEPARATOR_KEYWORD +
                                                 "' before " + reader.locationDescription());
                }

                // Add the method.
                classSpecification.addMethod(
                    new MemberSpecification(requiredSetMemberAccessFlags,
                                            requiredUnsetMemberAccessFlags,
                                            annotationType,
                                            name,
                                            descriptor));
            } else {
                // It doesn't look like a field or a method.
                throw new ParseException("Expecting opening '" + AtlasProguardConstants.OPEN_ARGUMENTS_KEYWORD +
                                             "' or separator '" + AtlasProguardConstants.SEPARATOR_KEYWORD +
                                             "' before " + reader.locationDescription());
            }
        }
    }

    /**
     * Reads a comma-separated list of java identifiers or of file names.
     * Examples of invocation arguments:
     * ("directory name", true,  true,  false, true,  false, true,  false, false, ...)
     * ("optimization",   true,  false, false, false, false, false, false, false, ...)
     * ("package name",   true,  true,  false, false, true,  false, true,  false, ...)
     * ("attribute name", true,  true,  false, false, true,  false, false, false, ...)
     * ("class name",     true,  true,  false, false, true,  false, true,  false, ...)
     * ("resource file",  true,  true,  false, true,  false, false, false, false, ...)
     * ("resource file",  true,  true,  false, true,  false, false, false, false, ...)
     * ("class name",     true,  true,  false, false, true,  false, true,  false, ...)
     * ("class name",     true,  true,  false, false, true,  false, true,  false, ...)
     * ("filter",         true,  true,  true,  true,  false, true,  false, false, ...)
     * ("annotation ",    false, false, false, false, true,  false, false, true,  ...)
     * ("class name ",    true,  false, false, false, true,  false, false, false, ...)
     * ("annotation ",    true,  false, false, false, true,  false, false, true,  ...)
     * ("class name ",    false, false, false, false, true,  false, false, false, ...)
     * ("annotation ",    true,  false, false, false, true,  false, false, true,  ...)
     * ("argument",       true,  true,  true,  false, true,  false, false, false, ...)
     */
    private List parseCommaSeparatedList(String expectedDescription,
                                         boolean readFirstWord,
                                         boolean allowEmptyList,
                                         boolean expectClosingParenthesis,
                                         boolean isFileName,
                                         boolean checkJavaIdentifiers,
                                         boolean replaceSystemProperties,
                                         boolean replaceExternalClassNames,
                                         boolean replaceExternalTypes,
                                         List list)
        throws ParseException, IOException {
        if (list == null) {
            list = new ArrayList();
        }

        if (readFirstWord) {
            if (!allowEmptyList) {
                // Read the first list entry.
                readNextWord(expectedDescription, isFileName, false);
            } else if (expectClosingParenthesis) {
                // Read the first list entry.
                readNextWord(expectedDescription, isFileName, false);

                // Return if the entry is actually empty (an empty file name or
                // a closing parenthesis).
                if (nextWord.length() == 0) {
                    // Read the closing parenthesis
                    readNextWord("closing '" + AtlasProguardConstants.CLOSE_ARGUMENTS_KEYWORD +
                                     "'");

                    return list;
                } else if (nextWord.equals(AtlasProguardConstants.CLOSE_ARGUMENTS_KEYWORD)) {
                    return list;
                }
            } else {
                // Read the first list entry, if there is any.
                readNextWord(isFileName);

                // Check if the list is empty.
                if (configurationEnd()) {
                    return list;
                }
            }
        }

        while (true) {
            if (checkJavaIdentifiers) {
                checkJavaIdentifier("java type");
            }

            if (replaceSystemProperties) {
                nextWord = replaceSystemProperties(nextWord);
            }

            if (replaceExternalClassNames) {
                nextWord = ClassUtil.internalClassName(nextWord);
            }

            if (replaceExternalTypes) {
                nextWord = ClassUtil.internalType(nextWord);
            }

            list.add(nextWord);

            if (expectClosingParenthesis) {
                // Read a comma (or a closing parenthesis, or a different word).
                readNextWord("separating '" + AtlasProguardConstants.ARGUMENT_SEPARATOR_KEYWORD +
                                 "' or closing '" + AtlasProguardConstants.CLOSE_ARGUMENTS_KEYWORD +
                                 "'");
            } else {
                // Read a comma (or a different word).
                readNextWord();
            }

            if (!AtlasProguardConstants.ARGUMENT_SEPARATOR_KEYWORD.equals(nextWord)) {
                return list;
            }

            // Read the next list entry.
            readNextWord(expectedDescription, isFileName, false);
        }
    }

    /**
     * Throws a ParseException for an unexpected keyword.
     */
    private int unknownAccessFlag() throws ParseException {
        throw new ParseException("Unexpected keyword " + reader.locationDescription());
    }

    /**
     * Creates a properly resolved File, based on the given word.
     */
    private File file(String word) throws ParseException {
        String fileName = replaceSystemProperties(word);
        File file = new File(fileName);

        // Try to get an absolute file.
        if (!file.isAbsolute()) {
            file = new File(reader.getBaseDir(), fileName);
        }

        return file;
    }

    /**
     * Replaces any properties in the given word by their values.
     * For instance, the substring "<java.home>" is replaced by its value.
     */
    private String replaceSystemProperties(String word) throws ParseException {
        int fromIndex = 0;
        while (true) {
            fromIndex = word.indexOf(AtlasProguardConstants.OPEN_SYSTEM_PROPERTY, fromIndex);
            if (fromIndex < 0) {
                break;
            }

            int toIndex = word.indexOf(AtlasProguardConstants.CLOSE_SYSTEM_PROPERTY, fromIndex + 1);
            if (toIndex < 0) {
                break;
            }

            String propertyName = word.substring(fromIndex + 1, toIndex);
            String propertyValue = properties.getProperty(propertyName);
            if (propertyValue == null) {
                throw new ParseException("Value of system property '" + propertyName +
                                             "' is undefined in " + reader.locationDescription());
            }

            word = word.substring(0, fromIndex) + propertyValue + word.substring(toIndex + 1);

            fromIndex += propertyValue.length();
        }

        return word;
    }

    /**
     * Reads the next word of the configuration in the 'nextWord' field,
     * throwing an exception if there is no next word.
     */
    private void readNextWord(String expectedDescription)
        throws ParseException, IOException {
        readNextWord(expectedDescription, false, false);
    }

    /**
     * Reads the next word of the configuration in the 'nextWord' field,
     * throwing an exception if there is no next word.
     */
    private void readNextWord(String expectedDescription,
                              boolean isFileName,
                              boolean expectingAtCharacter)
        throws ParseException, IOException {
        readNextWord(isFileName);
        if (configurationEnd(expectingAtCharacter)) {
            throw new ParseException("Expecting " + expectedDescription +
                                         " before " + reader.locationDescription());
        }
    }

    /**
     * Reads the next word of the configuration in the 'nextWord' field.
     */
    private void readNextWord() throws IOException {
        readNextWord(false);
    }

    /**
     * Reads the next word of the configuration in the 'nextWord' field.
     */
    private void readNextWord(boolean isFileName) throws IOException {
        nextWord = reader.nextWord(isFileName);
    }

    /**
     * Returns whether the end of the configuration has been reached.
     */
    private boolean configurationEnd() {
        return configurationEnd(false);
    }

    /**
     * Returns whether the end of the configuration has been reached.
     */
    private boolean configurationEnd(boolean expectingAtCharacter) {
        return nextWord == null ||
            nextWord.startsWith(AtlasProguardConstants.OPTION_PREFIX) ||
            (!expectingAtCharacter &&
                nextWord.equals(AtlasProguardConstants.AT_DIRECTIVE));
    }

    /**
     * Checks whether the given word is a valid Java identifier and throws
     * a ParseException if it isn't. Wildcard characters are accepted.
     */
    private void checkJavaIdentifier(String expectedDescription)
        throws ParseException {
        if (!isJavaIdentifier(nextWord)) {
            throw new ParseException("Expecting " + expectedDescription +
                                         " before " + reader.locationDescription());
        }
    }

    /**
     * Returns whether the given word is a valid Java identifier.
     * Wildcard characters are accepted.
     */
    private boolean isJavaIdentifier(String aWord) {
        if (aWord.length() == 0) {
            return false;
        }

        for (int index = 0; index < aWord.length(); index++) {
            char c = aWord.charAt(index);
            if (!(Character.isJavaIdentifierPart(c) ||
                c == '.' ||
                c == '[' ||
                c == ']' ||
                c == '<' ||
                c == '>' ||
                c == '-' ||
                c == '!' ||
                c == '*' ||
                c == '?' ||
                c == '%')) {
                return false;
            }
        }

        return true;
    }

    /**
     * Checks whether the given access flags are valid field access flags,
     * throwing a ParseException if they aren't.
     */
    private void checkFieldAccessFlags(int requiredSetMemberAccessFlags,
                                       int requiredUnsetMemberAccessFlags)
        throws ParseException {
        if (((requiredSetMemberAccessFlags |
            requiredUnsetMemberAccessFlags) &
            ~ClassConstants.VALID_ACC_FIELD) != 0) {
            throw new ParseException("Invalid method access modifier for field before " +
                                         reader.locationDescription());
        }
    }

    /**
     * Checks whether the given access flags are valid method access flags,
     * throwing a ParseException if they aren't.
     */
    private void checkMethodAccessFlags(int requiredSetMemberAccessFlags,
                                        int requiredUnsetMemberAccessFlags)
        throws ParseException {
        if (((requiredSetMemberAccessFlags |
            requiredUnsetMemberAccessFlags) &
            ~ClassConstants.VALID_ACC_METHOD) != 0) {
            throw new ParseException("Invalid field access modifier for method before " +
                                         reader.locationDescription());
        }
    }

    /**
     * A main method for testing configuration parsing.
     */
    public static void main(String[] args) {
        try {
            ConfigurationParser parser =
                new ConfigurationParser(args, System.getProperties());

            try {
                parser.parse(new Configuration());
            } catch (ParseException ex) {
                ex.printStackTrace();
            } finally {
                parser.close();
            }
        } catch (IOException ex) {
            ex.printStackTrace();
        }
    }
}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/test/java/proguard/KeepOnlyConfigurationParserTest.java;<<<<<<< MINE
=======
import com.taobao.android.builder.tools.proguard.KeepOnlyConfigurationParser;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/test/java/com/taobao/atlas/LogTest.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.atlas;

import org.apache.log4j.Logger;
import org.junit.Test;

/**
 * Created by wuzhong on 2017/5/14.
 */
public class LogTest {

    //static final Logger debugLog = LoggerFactory.getLogger("debugLogger");

    static Logger sLogger = Logger.getLogger("debugLogger");

    @Test
    public void test() throws InterruptedException {

        //debugLog.log(Level., "hello");
        //PropertyConfigurator.configure("log4j.properties");

        System.out.println(123);

        for (int i = 0 ; i < 1000; i++){
            sLogger.info(i);
        }

        sLogger.info("123");

        sLogger.error("12312");

        Thread.sleep(1000);
    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/test/java/com/taobao/atlas/cache/FileLockTest.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.atlas.cache;

import java.io.File;

import com.taobao.android.builder.tools.cache.FileLockUtils;
import org.junit.Test;

/**
 * Created by wuzhong on 2017/5/16.
 */
public class FileLockTest {

    @Test
    public void test(){

        File dir = new File("build/test/lock");
        System.out.println(dir.getAbsolutePath());

        dir.mkdirs();

        FileLockUtils.lock(dir, new Runnable() {
            @Override
            public void run() {
                System.out.println("1111");

                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }

            }
        });

        FileLockUtils.lock(dir, new Runnable() {
            @Override
            public void run() {
                System.out.println("2222");

                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }

            }
        });


    }

}>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_8d5a4e8_cc2b800/rev_8d5a4e8-cc2b800/atlas-gradle-plugin/atlas-plugin/src/test/java/com/taobao/atlas/dex/FastDexMergeTest.java;<<<<<<< MINE
=======
/*
 *
 *
 *
 *                                   Apache License
 *                             Version 2.0, January 2004
 *                          http://www.apache.org/licenses/
 *
 *     TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *     1. Definitions.
 *
 *        "License" shall mean the terms and conditions for use, reproduction,
 *        and distribution as defined by Sections 1 through 9 of this document.
 *
 *        "Licensor" shall mean the copyright owner or entity authorized by
 *        the copyright owner that is granting the License.
 *
 *        "Legal Entity" shall mean the union of the acting entity and all
 *        other entities that control, are controlled by, or are under common
 *        control with that entity. For the purposes of this definition,
 *        "control" means (i) the power, direct or indirect, to cause the
 *        direction or management of such entity, whether by contract or
 *        otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *        outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *        "You" (or "Your") shall mean an individual or Legal Entity
 *        exercising permissions granted by this License.
 *
 *        "Source" form shall mean the preferred form for making modifications,
 *        including but not limited to software source code, documentation
 *        source, and configuration files.
 *
 *        "Object" form shall mean any form resulting from mechanical
 *        transformation or translation of a Source form, including but
 *        not limited to compiled object code, generated documentation,
 *        and conversions to other media types.
 *
 *        "Work" shall mean the work of authorship, whether in Source or
 *        Object form, made available under the License, as indicated by a
 *        copyright notice that is included in or attached to the work
 *        (an example is provided in the Appendix below).
 *
 *        "Derivative Works" shall mean any work, whether in Source or Object
 *        form, that is based on (or derived from) the Work and for which the
 *        editorial revisions, annotations, elaborations, or other modifications
 *        represent, as a whole, an original work of authorship. For the purposes
 *        of this License, Derivative Works shall not include works that remain
 *        separable from, or merely link (or bind by name) to the interfaces of,
 *        the Work and Derivative Works thereof.
 *
 *        "Contribution" shall mean any work of authorship, including
 *        the original version of the Work and any modifications or additions
 *        to that Work or Derivative Works thereof, that is intentionally
 *        submitted to Licensor for inclusion in the Work by the copyright owner
 *        or by an individual or Legal Entity authorized to submit on behalf of
 *        the copyright owner. For the purposes of this definition, "submitted"
 *        means any form of electronic, verbal, or written communication sent
 *        to the Licensor or its representatives, including but not limited to
 *        communication on electronic mailing lists, source code control systems,
 *        and issue tracking systems that are managed by, or on behalf of, the
 *        Licensor for the purpose of discussing and improving the Work, but
 *        excluding communication that is conspicuously marked or otherwise
 *        designated in writing by the copyright owner as "Not a Contribution."
 *
 *        "Contributor" shall mean Licensor and any individual or Legal Entity
 *        on behalf of whom a Contribution has been received by Licensor and
 *        subsequently incorporated within the Work.
 *
 *     2. Grant of Copyright License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        copyright license to reproduce, prepare Derivative Works of,
 *        publicly display, publicly perform, sublicense, and distribute the
 *        Work and such Derivative Works in Source or Object form.
 *
 *     3. Grant of Patent License. Subject to the terms and conditions of
 *        this License, each Contributor hereby grants to You a perpetual,
 *        worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *        (except as stated in this section) patent license to make, have made,
 *        use, offer to sell, sell, import, and otherwise transfer the Work,
 *        where such license applies only to those patent claims licensable
 *        by such Contributor that are necessarily infringed by their
 *        Contribution(s) alone or by combination of their Contribution(s)
 *        with the Work to which such Contribution(s) was submitted. If You
 *        institute patent litigation against any entity (including a
 *        cross-claim or counterclaim in a lawsuit) alleging that the Work
 *        or a Contribution incorporated within the Work constitutes direct
 *        or contributory patent infringement, then any patent licenses
 *        granted to You under this License for that Work shall terminate
 *        as of the date such litigation is filed.
 *
 *     4. Redistribution. You may reproduce and distribute copies of the
 *        Work or Derivative Works thereof in any medium, with or without
 *        modifications, and in Source or Object form, provided that You
 *        meet the following conditions:
 *
 *        (a) You must give any other recipients of the Work or
 *            Derivative Works a copy of this License; and
 *
 *        (b) You must cause any modified files to carry prominent notices
 *            stating that You changed the files; and
 *
 *        (c) You must retain, in the Source form of any Derivative Works
 *            that You distribute, all copyright, patent, trademark, and
 *            attribution notices from the Source form of the Work,
 *            excluding those notices that do not pertain to any part of
 *            the Derivative Works; and
 *
 *        (d) If the Work includes a "NOTICE" text file as part of its
 *            distribution, then any Derivative Works that You distribute must
 *            include a readable copy of the attribution notices contained
 *            within such NOTICE file, excluding those notices that do not
 *            pertain to any part of the Derivative Works, in at least one
 *            of the following places: within a NOTICE text file distributed
 *            as part of the Derivative Works; within the Source form or
 *            documentation, if provided along with the Derivative Works; or,
 *            within a display generated by the Derivative Works, if and
 *            wherever such third-party notices normally appear. The contents
 *            of the NOTICE file are for informational purposes only and
 *            do not modify the License. You may add Your own attribution
 *            notices within Derivative Works that You distribute, alongside
 *            or as an addendum to the NOTICE text from the Work, provided
 *            that such additional attribution notices cannot be construed
 *            as modifying the License.
 *
 *        You may add Your own copyright statement to Your modifications and
 *        may provide additional or different license terms and conditions
 *        for use, reproduction, or distribution of Your modifications, or
 *        for any such Derivative Works as a whole, provided Your use,
 *        reproduction, and distribution of the Work otherwise complies with
 *        the conditions stated in this License.
 *
 *     5. Submission of Contributions. Unless You explicitly state otherwise,
 *        any Contribution intentionally submitted for inclusion in the Work
 *        by You to the Licensor shall be under the terms and conditions of
 *        this License, without any additional terms or conditions.
 *        Notwithstanding the above, nothing herein shall supersede or modify
 *        the terms of any separate license agreement you may have executed
 *        with Licensor regarding such Contributions.
 *
 *     6. Trademarks. This License does not grant permission to use the trade
 *        names, trademarks, service marks, or product names of the Licensor,
 *        except as required for reasonable and customary use in describing the
 *        origin of the Work and reproducing the content of the NOTICE file.
 *
 *     7. Disclaimer of Warranty. Unless required by applicable law or
 *        agreed to in writing, Licensor provides the Work (and each
 *        Contributor provides its Contributions) on an "AS IS" BASIS,
 *        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *        implied, including, without limitation, any warranties or conditions
 *        of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *        PARTICULAR PURPOSE. You are solely responsible for determining the
 *        appropriateness of using or redistributing the Work and assume any
 *        risks associated with Your exercise of permissions under this License.
 *
 *     8. Limitation of Liability. In no event and under no legal theory,
 *        whether in tort (including negligence), contract, or otherwise,
 *        unless required by applicable law (such as deliberate and grossly
 *        negligent acts) or agreed to in writing, shall any Contributor be
 *        liable to You for damages, including any direct, indirect, special,
 *        incidental, or consequential damages of any character arising as a
 *        result of this License or out of the use or inability to use the
 *        Work (including but not limited to damages for loss of goodwill,
 *        work stoppage, computer failure or malfunction, or any and all
 *        other commercial damages or losses), even if such Contributor
 *        has been advised of the possibility of such damages.
 *
 *     9. Accepting Warranty or Additional Liability. While redistributing
 *        the Work or Derivative Works thereof, You may choose to offer,
 *        and charge a fee for, acceptance of support, warranty, indemnity,
 *        or other liability obligations and/or rights consistent with this
 *        License. However, in accepting such obligations, You may act only
 *        on Your own behalf and on Your sole responsibility, not on behalf
 *        of any other Contributor, and only if You agree to indemnify,
 *        defend, and hold each Contributor harmless for any liability
 *        incurred by, or claims asserted against, such Contributor by reason
 *        of your accepting any such warranty or additional liability.
 *
 *     END OF TERMS AND CONDITIONS
 *
 *     APPENDIX: How to apply the Apache License to your work.
 *
 *        To apply the Apache License to your work, attach the following
 *        boilerplate notice, with the fields enclosed by brackets "[]"
 *        replaced with your own identifying information. (Don't include
 *        the brackets!)  The text should be enclosed in the appropriate
 *        comment syntax for the file format. We also recommend that a
 *        file or class name and description of purpose be included on the
 *        same "printed page" as the copyright notice for easier
 *        identification within third-party archives.
 *
 *     Copyright 2016 Alibaba Group
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 *
 */

package com.taobao.atlas.dex;

import java.io.File;
import java.io.IOException;
import java.util.Collection;
import java.util.List;

import com.taobao.android.builder.extension.MultiDexConfig;
import com.taobao.android.builder.tools.multidex.DexGroup;
import com.taobao.android.builder.tools.multidex.DexMerger;
import org.apache.commons.io.FileUtils;
import org.junit.Test;

/**
 * Created by wuzhong on 2017/5/19.
 */
public class FastDexMergeTest {

    @Test
    public void test() throws IOException {

        //String dir
        //    = "/Users/wuzhong/workspace/ali_android/cainiao/guoguo_android/guoguo_app/build/intermediates/transforms"
        //    + "/dex/debug/folders/1000/1f/main";

        String dir = "/Users/wuzhong/Downloads/alipay";

        //String dir = "/Users/wuzhong/Downloads/guoguo";
        Collection<File> files = FileUtils.listFiles(new File(dir), new String[] {"dex"}, true);

        //testA(files);
        //
        //testB(files);

        testC(files);

    }

    private void testA(Collection<File> files) throws IOException {
        MultiDexConfig multiDexConfig = new MultiDexConfig("debug");
        DexMerger dexMerger = new DexMerger(multiDexConfig, files);
        List<DexGroup> dexDtos = dexMerger.group();
        //System.out.println(JSON.toJSONString(dexDtos,true));
        System.out.println(dexDtos.size());
        System.out.println(dexMerger.dexList.size());
    }

    private void testB(Collection<File> files) throws IOException {
        MultiDexConfig multiDexConfig = new MultiDexConfig("debug");
        multiDexConfig.setDexCount(3);
        DexMerger dexMerger = new DexMerger(multiDexConfig, files);
        List<DexGroup> dexDtos = dexMerger.group();
        //System.out.println(JSON.toJSONString(dexDtos,true));
        System.out.println(dexDtos.size());
        System.out.println(dexMerger.dexList.size());
    }

    private void testC(Collection<File> files) throws IOException {
        MultiDexConfig multiDexConfig = new MultiDexConfig("debug");
        //multiDexConfig.setDexSplitRules("a12312,123213;c123123,d123123;ee123123");
        //multiDexConfig.setDexCount(3);
        DexMerger dexMerger = new DexMerger(multiDexConfig, files);
        List<DexGroup> dexDtos = dexMerger.group();
        System.out.println(dexDtos.size());
        System.out.println(dexMerger.dexList.size());
        FileUtils.deleteDirectory(new File("/Users/wuzhong/Downloads/dex"));
        new File("/Users/wuzhong/Downloads/dex").mkdirs();
        dexMerger.executeMerge(new File("/Users/wuzhong/Downloads/dex"),dexDtos);
    }

}>>>>>>> YOURS
/home/taes/taes/projects/archaius/revisions/rev_f720103_8e7f408/rev_f720103-8e7f408/archaius-core/src/main/java/com/netflix/config/DerivedStringProperty.java;<<<<<<< MINE
=======
/*
 *
 *  Copyright 2012 Netflix, Inc.
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 */
package com.netflix.config;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.concurrent.atomic.AtomicReference;

/**
 * Derives a complex value from a {@link DynamicStringProperty}.
 *
 * @author mhawthorne
 */
public abstract class DerivedStringProperty<D> {

    private static final Logger log = LoggerFactory.getLogger(DerivedStringProperty.class);

    private final DynamicStringProperty delegate;

    /**
     * Holds derived value, which may be null.
     */
    private final AtomicReference<D> derived = new AtomicReference<D>(null);

    public DerivedStringProperty(String name, String defaultValue) {
        delegate = DynamicPropertyFactory.getInstance().getStringProperty(name, defaultValue);
        deriveAndSet();
        delegate.addCallback(new Runnable() {
            public void run() {
                propertyChangedInternal();
            }
        });
    }

    /**
     * Fetches derived value.
     */
    public D get() {
        return derived.get();
    }

    /**
     * Invoked when property is updated with a new value.  Should return the new derived value, which may be null.
     */
    protected abstract D derive(String value);

    /**
     * {@link com.netflix.config.PropertyWrapper#propertyChanged()}
     */
    protected void propertyChanged() {}

    void propertyChangedInternal() {
        deriveAndSet();
        propertyChanged();
    }

    private void deriveAndSet() {
         try {
            derived.set(derive(this.delegate.get()));
        } catch (Exception e) {
            log.error("error when deriving initial value", e);
        }
    }

}>>>>>>> YOURS
/home/taes/taes/projects/archaius/revisions/rev_f720103_8e7f408/rev_f720103-8e7f408/archaius-core/src/test/java/com/netflix/config/DerivedStringPropertyTest.java;<<<<<<< MINE
=======
/*
 *
 *  Copyright 2012 Netflix, Inc.
 *
 *     Licensed under the Apache License, Version 2.0 (the "License");
 *     you may not use this file except in compliance with the License.
 *     You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *     Unless required by applicable law or agreed to in writing, software
 *     distributed under the License is distributed on an "AS IS" BASIS,
 *     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *     See the License for the specific language governing permissions and
 *     limitations under the License.
 *
 */
package com.netflix.config;

import org.junit.Test;

import java.util.concurrent.atomic.AtomicBoolean;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;

public class DerivedStringPropertyTest {

    @Test
    public void testPropertyChanged() {
        final AtomicBoolean derived = new AtomicBoolean(false);

        final String defaultVal = "hi";
        DerivedStringProperty p = new DerivedStringProperty("com.netflix.hello", defaultVal) {
            @Override
            protected Object derive(String value) {
                derived.set(true);
                return String.format("%s/derived", value);
            }
        };

//        p.propertyChanged();
        p.propertyChangedInternal();
        assertTrue("derive() was not called", derived.get());
        assertEquals(String.format("%s/derived", defaultVal), p.get());
    }

    @Test
    public void testPropertyChangedWhenDeriveThrowsException() {
        final String defaultVal = "hi";
        DerivedStringProperty p = new DerivedStringProperty("com.netflix.hello", defaultVal) {
            @Override
            protected Object derive(String value) {
                throw new RuntimeException("oops");
            }
        };

        p.propertyChangedInternal();
        assertEquals(null, p.get());
    }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_50ad2a6_c42b56e/rev_50ad2a6-c42b56e/src/java/com/twitter/elephantbird/mapreduce/input/LzoInputFormat.java;<<<<<<< MINE
  private final Map<Path, LzoIndex> indexes_ = new HashMap<Path, LzoIndex>();

  private final PathFilter hiddenPathFilter = new PathFilter() {
    // avoid hidden files and directories.
    @Override
    public boolean accept(Path path) {
      String name = path.getName();
      return !name.startsWith(".") &&
             !name.startsWith("_");
    }
  };

=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-core/src/main/java/com/netflix/client/config/CommonClientConfigKey.java;<<<<<<< MINE
import javax.annotation.Nullable;
=======
    AppName("AppName"),
    Version("Version"),
    Port("Port"),
    SecurePort("SecurePort"),
    ForceClientPortConfiguration("ForceClientPortConfiguration"), // use client defined port regardless of server advert
    VipAddress("VipAddress"),
    DeploymentContextBasedVipAddresses("DeploymentContextBasedVipAddresses"),
    MaxAutoRetries("MaxAutoRetries"),
    MaxAutoRetriesNextServer("MaxAutoRetriesNextServer"),
    OkToRetryOnAllOperations("OkToRetryOnAllOperations"),
    RequestSpecificRetryOn("RequestSpecificRetryOn"),
    ReceiveBuffferSize("ReceiveBuffferSize"),
    EnablePrimeConnections("EnablePrimeConnections"),
    PrimeConnectionsClassName("PrimeConnectionsClassName"),
    MaxRetriesPerServerPrimeConnection("MaxRetriesPerServerPrimeConnection"),
    MaxTotalTimeToPrimeConnections("MaxTotalTimeToPrimeConnections"),
    MinPrimeConnectionsRatio("MinPrimeConnectionsRatio"),
    PrimeConnectionsURI("PrimeConnectionsURI"),
    PoolMaxThreads("PoolMaxThreads"),
    PoolMinThreads("PoolMinThreads"),
    PoolKeepAliveTime("PoolKeepAliveTime"),
    PoolKeepAliveTimeUnits("PoolKeepAliveTimeUnits"),
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-core/src/main/java/com/netflix/client/LoadBalancerContext.java;<<<<<<< MINE
=======
import java.net.URLEncoder;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-core/src/main/java/com/netflix/client/LoadBalancerContext.java;<<<<<<< MINE
=======
import com.google.common.base.Strings;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-core/src/main/java/com/netflix/client/LoadBalancerContext.java;<<<<<<< MINE
=======
            if (isURIEncoded(theUrl)) {
                StringBuilder sb = new StringBuilder();
                sb.append(newURI.getScheme())
                  .append("://")
                  .append(newURI.getRawAuthority())
                  .append(theUrl.getRawPath());
                if (!Strings.isNullOrEmpty(theUrl.getRawQuery())) {
                    sb.append("?").append(theUrl.getRawQuery());
                }
                if (!Strings.isNullOrEmpty(theUrl.getRawFragment())) {
                    sb.append("#").append(theUrl.getRawFragment());
                }
                newURI = new URI(sb.toString());
            }
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-core/src/main/java/com/netflix/client/LoadBalancerContext.java;<<<<<<< MINE
=======
    private boolean isURIEncoded(URI uri) {
        String original = uri.toString();
        try {
            return !URLEncoder.encode(original, "UTF-8").equals(original);
        } catch (Exception e) {
            return false;
        }
    }
    
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-core/src/test/java/com/netflix/client/LoadBalancerContextTest.java;<<<<<<< MINE
=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.client;

import static org.junit.Assert.*;

import java.net.URLEncoder;

import org.junit.Test;

import com.netflix.client.http.HttpRequest;
import com.netflix.client.http.HttpResponse;
import com.netflix.loadbalancer.BaseLoadBalancer;
import com.netflix.loadbalancer.Server;

public class LoadBalancerContextTest {

    static BaseLoadBalancer lb = new BaseLoadBalancer() {

        @Override
        public Server chooseServer(Object key) {
            return new Server("www.example.com:8080");
        }
    };
    
    
    private MyLoadBalancerContext context;
    
    public LoadBalancerContextTest() {
        context = new MyLoadBalancerContext();
        context.setLoadBalancer(lb);
    }
    
    @Test
    public void testComputeFinalUriWithLoadBalancer() throws ClientException {
        HttpRequest request = HttpRequest.newBuilder().uri("/test?abc=xyz").build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals("http://www.example.com:8080/test?abc=xyz", newRequest.getUri().toString());
    }
    
    @Test
    public void testEncodedPath() throws ClientException {
        String uri = "http://localhost:8080/resources/abc%2Fxyz";
        HttpRequest request = HttpRequest.newBuilder().uri(uri).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals(uri, newRequest.getUri().toString());
    }
    
    @Test
    public void testEncodedPathAndHostChange() throws ClientException {
        String uri = "/abc%2Fxyz";
        HttpRequest request = HttpRequest.newBuilder().uri(uri).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals("http://www.example.com:8080" + uri, newRequest.getUri().toString());
    }

    
    @Test
    public void testEncodedQuery() throws Exception {
        String uri = "http://localhost:8080/resources/abc?";
        String queryString = "name=" + URLEncoder.encode("Ã©Æ&=*%!@#$%^&*()", "UTF-8");   
        HttpRequest request = HttpRequest.newBuilder().uri(uri + queryString).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals(uri + queryString, newRequest.getUri().toString());        
    }
}

class MyLoadBalancerContext extends LoadBalancerContext<HttpRequest, HttpResponse> {
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
	protected static final String EXECUTE_TRACER = "NFHttpClient__EXECUTE_REQ";
=======
	protected static final String EXECUTE_TRACER = "HttpClient-ExecuteTimer";
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
		init(DefaultClientConfigImpl.getClientConfigWithDefaultValues());
=======
		init(DefaultClientConfigImpl.getClientConfigWithDefaultValues(), false);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
		init(DefaultClientConfigImpl.getClientConfigWithDefaultValues());
=======
		init(DefaultClientConfigImpl.getClientConfigWithDefaultValues(), false);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
		super(new MonitoredConnectionManager(name));
		this.name = name;
		init(DefaultClientConfigImpl.getClientConfigWithDefaultValues());
=======
	    this(name, DefaultClientConfigImpl.getClientConfigWithDefaultValues(), true);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
=======
        this(name, config, true);
    }

    protected NFHttpClient(String name, IClientConfig config, boolean registerMonitor) {
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
        init(config);
=======
        init(config, registerMonitor);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE

=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
	void init(IClientConfig config) {
=======
	void init(IClientConfig config, boolean registerMonitor) {
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
	    tracer = Monitors.newTimer(EXECUTE_TRACER, TimeUnit.MILLISECONDS);
        Monitors.registerObject(name, this);
=======
	    tracer = Monitors.newTimer(EXECUTE_TRACER + "-" + name, TimeUnit.MILLISECONDS);
	    if (registerMonitor) {
            Monitors.registerObject(name, this);
	    }
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
	@Monitor(name = "connPoolCleaner", type = DataSourceType.INFORMATIONAL)
=======
	@Monitor(name = "HttpClient-ConnPoolCleaner", type = DataSourceType.INFORMATIONAL)
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
	@Monitor(name = "connIdleEvictTimeMilliSeconds", type = DataSourceType.INFORMATIONAL)
=======
	@Monitor(name = "HttpClient-ConnIdleEvictTimeMilliSeconds", type = DataSourceType.INFORMATIONAL)
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
	@Monitor(name="connectionsInPool", type = DataSourceType.GAUGE)    
=======
	@Monitor(name="HttpClient-ConnectionsInPool", type = DataSourceType.GAUGE)    
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
	@Monitor(name = "maxTotalConnections", type = DataSourceType.INFORMATIONAL)
=======
	@Monitor(name = "HttpClient-MaxTotalConnections", type = DataSourceType.INFORMATIONAL)
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
	@Monitor(name = "maxConnectionsPerHost", type = DataSourceType.INFORMATIONAL)
=======
	@Monitor(name = "HttpClient-MaxConnectionsPerHost", type = DataSourceType.INFORMATIONAL)
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
	@Monitor(name = "numRetries", type = DataSourceType.INFORMATIONAL)
=======
	@Monitor(name = "HttpClient-NumRetries", type = DataSourceType.INFORMATIONAL)
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClient.java;<<<<<<< MINE
	@Monitor(name = "sleepTimeFactorMs", type = DataSourceType.INFORMATIONAL)
=======
	@Monitor(name = "HttpClient-SleepTimeFactorMs", type = DataSourceType.INFORMATIONAL)
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClientFactory.java;<<<<<<< MINE
*
* Copyright 2013 Netflix, Inc.
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
* http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*
*/
=======
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClientFactory.java;<<<<<<< MINE
        			client = new NFHttpClient(name, config);
=======
        			client = new NFHttpClient(name, config, registerMonitor);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClientFactory.java;<<<<<<< MINE
        			if (registerMonitor) {
        			    Monitors.registerObject("HttpClient_" + name, client);
        			}
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_1c246b4_f841ad0/rev_1c246b4-f841ad0/ribbon-httpclient/src/main/java/com/netflix/http4/NFHttpClientFactory.java;<<<<<<< MINE
	        Monitors.unregisterObject("HttpClient_" + name, c);
=======
	        Monitors.unregisterObject(name, c);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/mapreduce/input/LzoInputFormat.java;<<<<<<< MINE
import java.util.HashMap;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/mapreduce/input/LzoInputFormat.java;<<<<<<< MINE
import java.util.Map;

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/mapreduce/input/LzoInputFormat.java;<<<<<<< MINE
  private final Map<Path, LzoIndex> indexes_ = new HashMap<Path, LzoIndex>();

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/mapreduce/input/LzoInputFormat.java;<<<<<<< MINE
    // To help split the files at LZO boundaries, walk the list of lzo files and, if they
    // have an associated index file, save that for later.
    for (FileStatus result : results) {
      LzoIndex index = LzoIndex.readIndex(result.getPath().getFileSystem(job.getConfiguration()), result.getPath());
      indexes_.put(result.getPath(), index);
    }

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/mapreduce/input/LzoRecordReader.java;<<<<<<< MINE
      throw new IOException("No codec for file " + file + " not found, cannot run");
=======
      throw new IOException("No codec for file " + file + " found, cannot run");
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/store/LzoPigStorage.java;<<<<<<< MINE
package com.twitter.elephantbird.pig.store;

import java.io.DataOutputStream;
import java.io.IOException;

import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.InputFormat;
import org.apache.hadoop.mapreduce.OutputFormat;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.pig.builtin.PigStorage;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.util.StorageUtil;

import com.twitter.elephantbird.mapreduce.input.LzoTextInputFormat;
import com.twitter.elephantbird.mapreduce.output.LzoOutputFormat;

/**
 * A wrapper for {@link PigStorage} to enable LZO compression.
 * LzoTextInputFormat is used for loading since PigStorage
 * can not split lzo files.
 * LzoTextOutputFormat is used for storage so that lzo index files
 * can be written at the same time.
 *
 * This is similar to:
 * <pre>
 *   set output.compression.enabled true;
 *   set output.compression.codec com.hadoop.compression.lzo.LzopCodec;
 *   store/load ... using PigStorage();
 * </pre>
 */
public class LzoPigStorage extends PigStorage {

  private String delimiter = null; // temporary for outpupt format

  public LzoPigStorage() {
    super();
  }

  public LzoPigStorage(String delimiter) {
    super(delimiter);
  }

  @Override
  public InputFormat<LongWritable, Text> getInputFormat() {
    // PigStorage can handle lzo files, but cannot split them.
    return new LzoTextInputFormat();
  }

  @Override
  public OutputFormat<NullWritable, Tuple> getOutputFormat() {
    // LzoOutputFormat can write lzo index file.
    // LzoTextInputFormat can't be used here.
    return new TupleOutputFormat(delimiter);
  }

  // This is a temporary work around for PigStorage since
  // it writes a Tuple to outputformat rather than Text.
  // This may change soon and we can use LzoTextOutputFormat directly.
  protected static class TupleOutputFormat extends LzoOutputFormat<NullWritable, Tuple> {

    private byte fieldDel;

    public TupleOutputFormat(String delimiter) {
      this.fieldDel = delimiter == null ? (byte)'\t' : StorageUtil.parseFieldDel(delimiter);
    }

    @Override
    public RecordWriter<NullWritable, Tuple> getRecordWriter(
        TaskAttemptContext job) throws IOException, InterruptedException {
      final DataOutputStream out = getOutputStream(job);

      return new RecordWriter<NullWritable, Tuple>() {
        public void close(TaskAttemptContext context) throws IOException,
                                                      InterruptedException {
          out.close();
        }

        public void write(NullWritable key, Tuple value) throws IOException,
                                                         InterruptedException {
          int sz = value.size();
          for (int i = 0; i < sz; i++) {
              StorageUtil.putField(out, value.get(i));
              if (i != sz - 1) {
                  out.writeByte(fieldDel);
              }
          }
          out.write('\n');
        }
      };
    }
  }
}=======
package com.twitter.elephantbird.pig.store;

import java.io.IOException;

import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.InputFormat;
import org.apache.hadoop.mapreduce.Job;
import org.apache.pig.builtin.PigStorage;
import com.hadoop.compression.lzo.LzopCodec;
import com.twitter.elephantbird.mapreduce.input.LzoTextInputFormat;

/**
 * A wrapper for {@link PigStorage} to enable LZO compression.
 * LzoTextInputFormat is used for loading since PigStorage
 * can not split lzo files.
 *
 * This is similar to:
 * <pre>
 *   set output.compression.enabled true;
 *   set output.compression.codec com.hadoop.compression.lzo.LzopCodec;
 *   storage alias using PigStorage();
 * </pre>
 */
public class LzoPigStorage extends PigStorage {

  public LzoPigStorage() {
    super();
  }

  public LzoPigStorage(String delimiter) {
    super(delimiter);
  }

  @Override
  public InputFormat<LongWritable, Text> getInputFormat() {
    // PigStorage can handle lzo files, but cannot split them.
    return new LzoTextInputFormat();
  }

  @Override
  public void setStoreLocation(String location, Job job) throws IOException {
    // looks like each context gets different job. modifying conf here
    // does not affect subsequent store statements in the script.
    job.getConfiguration().set("output.compression.enabled", "true");
    job.getConfiguration().set("output.compression.codec", LzopCodec.class.getName());
    super.setStoreLocation(location, job);
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/store/Bz2PigStorage.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.store;

import java.io.IOException;

import org.apache.hadoop.io.compress.BZip2Codec;
import org.apache.hadoop.mapreduce.Job;
import org.apache.pig.builtin.PigStorage;

/**
 * Enables bzip2 compression for storage.<br>
 * This is similar to:
 * <pre>
 *   set output.compression.enabled true;
 *   set output.compression.codec org.apache.hadoop.io.compress.BZip2Codec;
 *   storage alias using PigStorage();
 * </pre>
 */
public class Bz2PigStorage extends PigStorage {
  // Ideally, PigStorage it self should take more options like compression
  // codec etc.
  public Bz2PigStorage() {
    super();
  }

  public Bz2PigStorage(String delimiter) {
    super(delimiter);
  }

  @Override
  public void setStoreLocation(String location, Job job) throws IOException {
    job.getConfiguration().set("output.compression.enabled", "true");
    job.getConfiguration().set("output.compression.codec", BZip2Codec.class.getName());
    super.setStoreLocation(location, job);
  }

}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/store/LzoTokenizedStorage.java;<<<<<<< MINE
import java.io.IOException;
import java.nio.charset.Charset;
import java.util.Iterator;
import java.util.Map;

import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.WritableComparable;
import org.apache.hadoop.mapreduce.OutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.DataType;
import org.apache.pig.data.Tuple;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.pig.util.PigTokenHelper;

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/store/LzoTokenizedStorage.java;<<<<<<< MINE
 * A storage class to store the ouput of each tuple in a delimited file
 * like PigStorage, but LZO compressed.
=======
 * @deprecated use {@link LzoPigStorage} instead
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/store/LzoTokenizedStorage.java;<<<<<<< MINE
public class LzoTokenizedStorage extends LzoBaseStoreFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoTokenizedStorage.class);
=======
@Deprecated
public class LzoTokenizedStorage extends LzoPigStorage {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/store/LzoTokenizedStorage.java;<<<<<<< MINE
  private final char recordDel_ = PigTokenHelper.DEFAULT_RECORD_DELIMITER;
  private byte fieldDel_ = PigTokenHelper.DEFAULT_FIELD_DELIMITER;
=======
  public LzoTokenizedStorage() {
    super();
  }
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/store/LzoTokenizedStorage.java;<<<<<<< MINE
  /**
   * Constructs a Pig storage object that uses the specified character as a field delimiter.
   *
   * @param delimiter the single byte character that is used to separate fields.
   *        Examples are ':', '\t', or '\u0001'.
   */
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/store/LzoTokenizedStorage.java;<<<<<<< MINE
    LOG.info("LzoTokenizedStorage with given delimiter [" + delimiter + "]");
    fieldDel_ = PigTokenHelper.evaluateDelimiter(delimiter);
  }

  /**
   * Write the tuple out by writing its fields one at a time, separated by the delimiter.
   * @param tuple the tuple to write.
   */

  @Override
  public void putNext(Tuple tuple) throws IOException {
    // Must convert integer fields to string, and then to bytes.
    // Otherwise a DataOutputStream will convert directly from integer to bytes, rather
    // than using the string representation.
    int numElts = tuple.size();
    StringBuilder sb = new StringBuilder();
    for (int i = 0; i < numElts; i++) {
      Object field;
      try {
        field = tuple.get(i);
      } catch (ExecException ee) {
        throw ee;
      }
      sb.append(fieldToString(field));

      if (i == numElts - 1) {
        // Last field in tuple.
        sb.append(recordDel_);
      } else {
        sb.append(fieldDel_);
      }
    }

    Text text = new Text(sb.toString());
    try {
        writer.write(NullWritable.get(), text);
    } catch (InterruptedException e) {
        throw new IOException(e);
    }

=======
    super(delimiter);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/store/LzoTokenizedStorage.java;<<<<<<< MINE

  /**
   * Put an individual field in the tuple.
   * @param field the object to store.
   */
  @SuppressWarnings("unchecked")
  private String fieldToString(Object field) throws IOException {
    switch (DataType.findType(field)) {
    case DataType.NULL:
      return "";
    case DataType.BYTEARRAY: {
      byte[] b = ((DataByteArray)field).get();
      return String.valueOf(b);
    }
    case DataType.MAP:
      StringBuilder mapBuilder = new StringBuilder();
      boolean mapHasNext = false;
      Map<String, Object> m = (Map<String, Object>)field;
      mapBuilder.append(PigTokenHelper.MAP_BEGIN);
      for(String s: m.keySet()) {
        if(mapHasNext) {
          mapBuilder.append(fieldDel_);
        } else {
          mapHasNext = true;
        }
        mapBuilder.append(fieldToString(s));
        mapBuilder.append(PigTokenHelper.MAP_KV);
        mapBuilder.append(fieldToString(m.get(s)));
      }
      mapBuilder.append(PigTokenHelper.MAP_END);
      return mapBuilder.toString();

    case DataType.TUPLE:
      boolean tupleHasNext = false;
      Tuple t = (Tuple)field;
      StringBuilder tupleBuilder = new StringBuilder();
      tupleBuilder.append(PigTokenHelper.TUPLE_BEGIN);
      for(int i = 0; i < t.size(); ++i) {
        if(tupleHasNext) {
          tupleBuilder.append(fieldDel_);
        } else {
          tupleHasNext = true;
        }
        try {
          tupleBuilder.append(fieldToString(t.get(i)));
        } catch (ExecException ee) {
          throw ee;
        }
      }
      tupleBuilder.append(PigTokenHelper.TUPLE_END);
      return tupleBuilder.toString();

    case DataType.BAG:
      boolean bagHasNext = false;
      StringBuilder bagBuilder = new StringBuilder();
      bagBuilder.append(PigTokenHelper.BAG_BEGIN);
      Iterator<Tuple> tupleIter = ((DataBag)field).iterator();
      while(tupleIter.hasNext()) {
        if(bagHasNext) {
          bagBuilder.append(fieldDel_);
        } else {
          bagHasNext = true;
        }
        bagBuilder.append(fieldToString(tupleIter.next()));
      }
      bagBuilder.append(PigTokenHelper.BAG_END);
      return bagBuilder.toString();

    default:
      return field.toString();
   }
  }

  /**
   * Two LzoTokenizedStorage functions are equal if their delimiters are.
   */
  @Override
  public boolean equals(Object obj) {
    if (obj instanceof LzoTokenizedStorage) {
      LzoTokenizedStorage other = (LzoTokenizedStorage)obj;
      return fieldDel_ == other.fieldDel_;
    }
    return false;
  }

  @SuppressWarnings("rawtypes")
  @Override
  public OutputFormat getOutputFormat() {
      return new TextOutputFormat<WritableComparable, Text>();
  }

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTokenizedLoader.java;<<<<<<< MINE
import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.util.ArrayList;

import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.InputFormat;
import org.apache.pig.PigException;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.mapreduce.input.LzoTextInputFormat;
import com.twitter.elephantbird.pig.util.PigTokenHelper;
=======
import com.twitter.elephantbird.pig.store.LzoPigStorage;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTokenizedLoader.java;<<<<<<< MINE
 * A load function that parses a line of input into fields using a delimiter to set the fields. The
 * delimiter is given as a single character, \t, or \x___ or slash u___.
=======
 * Same as {@link LzoPigStorage}.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTokenizedLoader.java;<<<<<<< MINE
public class LzoTokenizedLoader extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoTokenizedLoader.class);
  private static final TupleFactory tupleFactory_ = TupleFactory.getInstance();
=======
public class LzoTokenizedLoader extends LzoPigStorage {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTokenizedLoader.java;<<<<<<< MINE
  private final ByteArrayOutputStream buffer_ = new ByteArrayOutputStream(4096);
  private final byte recordDel_ = PigTokenHelper.DEFAULT_RECORD_DELIMITER;
  private byte fieldDel_ = PigTokenHelper.DEFAULT_FIELD_DELIMITER;
  private ArrayList<Object> protoTuple_ = null;
  private Byte prevByte_ = null;
=======
  public LzoTokenizedLoader() {
    super();
  }
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTokenizedLoader.java;<<<<<<< MINE
  /**
   * Constructs a Pig loader that uses specified character as a field delimiter.
   *
   * @param delimiter the single byte character that is used to separate fields.
   *        examples are ':', '\t', or '\u0001'
   */
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTokenizedLoader.java;<<<<<<< MINE
    LOG.info("LzoTokenizedLoader with given delimiter [" + delimiter + "]");
    if (delimiter.length() > 1) {
      LOG.error("Delimiter is not a single character. Cannot construct LzoTokenizedLoader.");
      throw new IllegalArgumentException();
    }
    // Store the constructor args so that individual slicers can recreate them.
    fieldDel_ = PigTokenHelper.evaluateDelimiter(delimiter);
=======
    super(delimiter);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTokenizedLoader.java;<<<<<<< MINE

  /**
   * Break the next line into a delimited set of fields.  Note that this can and
   * does result in tuples with different numbers of fields, which is tracked by
   * a counter.
   */
  @Override
  public Tuple getNext() throws IOException {
    if (reader_ == null) {
      return null;
    }

    try {
      if(!reader_.nextKeyValue()) {
        return null;
      }
    } catch (InterruptedException e) {
      int errCode = 6018;
      String errMsg = "Error while reading input";
      throw new ExecException(errMsg, errCode,
          PigException.REMOTE_ENVIRONMENT, e);
    }

    Tuple t = null;
    buffer_.reset();
    try {
      Text line = (Text)reader_.getCurrentValue();
      if (line != null) {
        String lineStr = line.toString();
        int len = lineStr.length();
        for (int i= 0;i<len;i++) {
          int b = lineStr.charAt(i);
          prevByte_ = (byte)b;
          if (prevByte_ == fieldDel_) {
            readField();
          } else if (prevByte_ == recordDel_) {
            readField();
            t =  tupleFactory_.newTupleNoCopy(protoTuple_);
            protoTuple_ = null;
            break;
          } else if (b == -1) {
            // hit end of file
            break;
          } else {
            buffer_.write(b);
          }
        }
        readField();
        t =  tupleFactory_.newTupleNoCopy(protoTuple_);
        protoTuple_ = null;
      }
    } catch (InterruptedException e) {
      int errCode = 6018;
      String errMsg = "Error while reading input";
      throw new ExecException(errMsg, errCode,
          PigException.REMOTE_ENVIRONMENT, e);
    }

    if (t != null) {
      // Increment the per-tuple-size counters.
      incrCounter(getClass().getName(), getCounterName(t.size()), 1L);
    }

    return t;
  }




  public Tuple getSampledTuple() throws IOException {
    if(prevByte_ == null || prevByte_ == recordDel_) {
      // prevByte = null when this is called for the first time, in that case bindTo would have already
      // called getNext() if it was required.
      return getNext();
    } else {
      // We are in middle of record. So, we skip this and return the next one.
      getNext();
      return getNext();
    }
  }

  /**
   * Construct a field from the input buffer, which at this point should be
   * pointing at a single token.
   */
  private void readField() {
    if (protoTuple_ == null) {
      protoTuple_ = new ArrayList<Object>();
    }

    if (buffer_.size() == 0) {
      // NULL value
      protoTuple_.add(null);
    } else {
      byte[] array = buffer_.toByteArray();

      if (array.length == 0) {
        protoTuple_.add(null);
      } else {
        protoTuple_.add(new DataByteArray(array));
      }
    }
    buffer_.reset();
  }

  /**
   * An internal helper function to get a counter name.
   * @param i the number of fields
   */
  private String getCounterName(Integer i) {
    return "Tuples with " + i + " fields";
  }

  /**
   * LzoTokenizedLoaders are determined by their field delimiter.
   */
  @Override
  public boolean equals(Object obj) {
    if (obj instanceof LzoTokenizedLoader) {
      LzoTokenizedLoader other = (LzoTokenizedLoader)obj;
      return fieldDel_ == other.fieldDel_;
    }
    return false;
  }

  @Override
  public InputFormat getInputFormat() {
    return new LzoTextInputFormat();
  }

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTextLoader.java;<<<<<<< MINE
import java.io.IOException;

import org.apache.hadoop.mapreduce.InputFormat;
import org.apache.pig.PigException;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.mapreduce.input.LzoTextInputFormat;
=======
import com.twitter.elephantbird.pig.store.LzoPigStorage;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTextLoader.java;<<<<<<< MINE
public class LzoTextLoader extends LzoBaseLoadFunc {
  private static final Logger LOG = LoggerFactory.getLogger(LzoTextLoader.class);

  private static final TupleFactory tupleFactory_ = TupleFactory.getInstance();
  protected enum LzoTextLoaderCounters { LinesRead }
=======
public class LzoTextLoader extends LzoPigStorage {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTextLoader.java;<<<<<<< MINE
=======
    super("\n");
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_ad562ae_130cfc6/rev_ad562ae-130cfc6/src/java/com/twitter/elephantbird/pig/load/LzoTextLoader.java;<<<<<<< MINE

  /**
   * Return every non-null line as a single-element tuple to Pig.
   */
  @Override
  public Tuple getNext() throws IOException {
	  if (reader_ == null) {
		  return null;
	  }
	  Tuple t = null;
	  try {
	    if ( reader_.nextKeyValue()) {
	      Object line = reader_.getCurrentValue();
	      if (line != null) {
	        incrCounter(LzoTextLoaderCounters.LinesRead, 1L);
	        t = tupleFactory_.newTuple(new DataByteArray(line.toString().getBytes()));
	      }
	    }
	  } catch (InterruptedException e) {
		  int errCode = 6018;
		  String errMsg = "Error while reading input";
		  throw new ExecException(errMsg, errCode,
				  PigException.REMOTE_ENVIRONMENT, e);
	  }
	  return t;
  }

  @Override
  public InputFormat getInputFormat() {
	  return new LzoTextInputFormat();
  }

=======
>>>>>>> YOURS
/home/taes/taes/projects/archaius/revisions/rev_61eb7f8_8b0dddc/rev_61eb7f8-8b0dddc/archaius-core/src/main/java/com/netflix/config/DeploymentContext.java;<<<<<<< MINE
        serverId("@serverId"), stack("@stack"), region("@region");
=======
        serverId("@serverId"), stack("@stack"), region("@region"), zone("@zone");
>>>>>>> YOURS
/home/taes/taes/projects/archaius/revisions/rev_61eb7f8_8b0dddc/rev_61eb7f8-8b0dddc/archaius-core/src/main/java/com/netflix/config/ConfigurationBasedDeploymentContext.java;<<<<<<< MINE
=======
    @Override
    public String getValue(ContextKey key) {   
        String value = getValueFromConfig("archaius.deployment." + key.toString());
        if (value != null) {
            return value;
        } else {
            return super.getValue(key);
        }
    }

>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_98ae4ea_9a79e22/rev_98ae4ea-9a79e22/atlas-core/src/main/java/android/taobao/atlas/startup/patch/KernalBundle.java;<<<<<<< MINE
=======
                    File internalDebugBundleDir = new File(new File(application.getFilesDir(), "debug_storage"), KERNAL_BUNDLE_NAME);
                    internalDebugBundleDir.mkdirs();
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_98ae4ea_9a79e22/rev_98ae4ea-9a79e22/atlas-core/src/main/java/android/taobao/atlas/startup/patch/KernalBundle.java;<<<<<<< MINE
                            new File(patchFile.getParent(),"patch.dex").getAbsolutePath(),0,true) ;
=======
                            new File(internalDebugBundleDir,"patch.dex").getAbsolutePath(),0,true) ;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_7620032_42c3e4c/rev_7620032-42c3e4c/ribbon-core/src/main/java/com/netflix/client/LoadBalancerContext.java;<<<<<<< MINE
=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.client;

import java.net.URI;
import java.net.URISyntaxException;
import java.net.URLEncoder;
import java.util.Collection;
import java.util.concurrent.TimeUnit;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.base.Strings;
import com.netflix.client.config.CommonClientConfigKey;
import com.netflix.client.config.DefaultClientConfigImpl;
import com.netflix.client.config.IClientConfig;
import com.netflix.loadbalancer.AbstractLoadBalancer;
import com.netflix.loadbalancer.ILoadBalancer;
import com.netflix.loadbalancer.LoadBalancerStats;
import com.netflix.loadbalancer.Server;
import com.netflix.loadbalancer.ServerStats;
import com.netflix.servo.monitor.Monitors;
import com.netflix.servo.monitor.Timer;
import com.netflix.util.Pair;

/**
 * A class contains APIs intended to be used be load balancing client which is subclass of this class.
 * 
 * @author awang
 *
 * @param <T> Type of the request
 * @param <S> Type of the response
 */
public abstract class LoadBalancerContext<T extends ClientRequest, S extends IResponse> implements IClientConfigAware {
    private static final Logger logger = LoggerFactory.getLogger(LoadBalancerContext.class);

    protected String clientName = "default";          

    protected String vipAddresses;
    
    protected int maxAutoRetriesNextServer = DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES_NEXT_SERVER;
    protected int maxAutoRetries = DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES;

    protected LoadBalancerErrorHandler<? super T, ? super S> errorHandler = new DefaultLoadBalancerErrorHandler<ClientRequest, IResponse>();


    boolean okToRetryOnAllOperations = DefaultClientConfigImpl.DEFAULT_OK_TO_RETRY_ON_ALL_OPERATIONS.booleanValue();
        
    private ILoadBalancer lb;
    
    private volatile Timer tracer;

    public LoadBalancerContext() {
    }

    /**
     * Delegate to {@link #initWithNiwsConfig(IClientConfig)}
     * @param clientConfig
     */
    public LoadBalancerContext(IClientConfig clientConfig) {
        initWithNiwsConfig(clientConfig);        
    }

    /**
     * Set necessary parameters from client configuration and register with Servo monitors.
     */
    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
        if (clientConfig == null) {
            return;    
        }
        clientName = clientConfig.getClientName();
        if (clientName == null) {
            clientName = "default";
        }
        vipAddresses = clientConfig.resolveDeploymentContextbasedVipAddresses();
        maxAutoRetries = clientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetries, DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES);
        maxAutoRetriesNextServer = clientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetriesNextServer,maxAutoRetriesNextServer);
        
       okToRetryOnAllOperations = clientConfig.getPropertyAsBoolean(CommonClientConfigKey.OkToRetryOnAllOperations, okToRetryOnAllOperations);
       tracer = getExecuteTracer();

       Monitors.registerObject("Client_" + clientName, this);
    }

    protected Timer getExecuteTracer() {
        if (tracer == null) {
            synchronized(this) {
                if (tracer == null) {
                    tracer = Monitors.newTimer(clientName + "_OperationTimer", TimeUnit.MILLISECONDS);                    
                }
            }
        } 
        return tracer;        
    }
    
    public String getClientName() {
        return clientName;
    }
        
    public ILoadBalancer getLoadBalancer() {
        return lb;    
    }
        
    public void setLoadBalancer(ILoadBalancer lb) {
        this.lb = lb;
    }

    public int getMaxAutoRetriesNextServer() {
        return maxAutoRetriesNextServer;
    }

    public void setMaxAutoRetriesNextServer(int maxAutoRetriesNextServer) {
        this.maxAutoRetriesNextServer = maxAutoRetriesNextServer;
    }

    public int getMaxAutoRetries() {
        return maxAutoRetries;
    }

    public void setMaxAutoRetries(int maxAutoRetries) {
        this.maxAutoRetries = maxAutoRetries;
    }

    protected Throwable getDeepestCause(Throwable e) {
        if(e != null) {
            int infiniteLoopPreventionCounter = 10;
            while (e.getCause() != null && infiniteLoopPreventionCounter > 0) {
                infiniteLoopPreventionCounter--;
                e = e.getCause();
            }
        }
        return e;
    }

    private boolean isPresentAsCause(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor) {
        return isPresentAsCauseHelper(throwableToSearchIn, throwableToSearchFor) != null;
    }

    static Throwable isPresentAsCauseHelper(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor) {
        int infiniteLoopPreventionCounter = 10;
        while (throwableToSearchIn != null && infiniteLoopPreventionCounter > 0) {
            infiniteLoopPreventionCounter--;
            if (throwableToSearchIn.getClass().isAssignableFrom(
                    throwableToSearchFor)) {
                return throwableToSearchIn;
            } else {
                throwableToSearchIn = throwableToSearchIn.getCause();
            }
        }
        return null;
    }
    
    /**
     * Test if certain exception classes exist as a cause in a Throwable 
     */
    public static boolean isPresentAsCause(Throwable throwableToSearchIn,
            Collection<Class<? extends Throwable>> throwableToSearchFor) {
        int infiniteLoopPreventionCounter = 10;
        while (throwableToSearchIn != null && infiniteLoopPreventionCounter > 0) {
            infiniteLoopPreventionCounter--;
            for (Class<? extends Throwable> c: throwableToSearchFor) {
                if (throwableToSearchIn.getClass().isAssignableFrom(c)) {
                    return true;
                }
            }
            throwableToSearchIn = throwableToSearchIn.getCause();
        }
        return false;
    }

    protected ClientException generateNIWSException(String uri, Throwable e){
        ClientException niwsClientException;
        if (isPresentAsCause(e, java.net.SocketTimeoutException.class)) {
            niwsClientException = generateTimeoutNIWSException(uri, e);
        }else if (e.getCause() instanceof java.net.UnknownHostException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.UNKNOWN_HOST_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e.getCause() instanceof java.net.ConnectException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.CONNECT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e.getCause() instanceof java.net.NoRouteToHostException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.NO_ROUTE_TO_HOST_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e instanceof ClientException){
            niwsClientException = (ClientException)e;
        }else {
            niwsClientException = new ClientException(
                ClientException.ErrorType.GENERAL,
                "Unable to execute RestClient request for URI:" + uri,
                e);
        }
        return niwsClientException;
    }

    private boolean isPresentAsCause(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor, String messageSubStringToSearchFor) {
        Throwable throwableFound = isPresentAsCauseHelper(throwableToSearchIn, throwableToSearchFor);
        if(throwableFound != null) {
            return throwableFound.getMessage().contains(messageSubStringToSearchFor);
        }
        return false;
    }
    private ClientException generateTimeoutNIWSException(String uri, Throwable e){
        ClientException niwsClientException;
        if (isPresentAsCause(e, java.net.SocketTimeoutException.class,
                "Read timed out")) {
            niwsClientException = new ClientException(
                    ClientException.ErrorType.READ_TIMEOUT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri + ":"
                            + getDeepestCause(e).getMessage(), e);
        } else {
            niwsClientException = new ClientException(
                    ClientException.ErrorType.SOCKET_TIMEOUT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri + ":"
                            + getDeepestCause(e).getMessage(), e);
        }
        return niwsClientException;
    }

    /**
     * This is called after a response is received or an exception is thrown from the client
     * to update related stats.  
     */
    protected void noteRequestCompletion(ServerStats stats, ClientRequest request, IResponse response, Throwable e, long responseTime) {        
        try {
            if (stats != null) {
                stats.decrementActiveRequestsCount();
                stats.incrementNumRequests();
                stats.noteResponseTime(responseTime);
                if (response != null) {
                    stats.clearSuccessiveConnectionFailureCount();                    
                }
            }            
        } catch (Throwable ex) {
            logger.error("Unexpected exception", ex);
        }            
    }
       
    /**
     * This is usually called just before client execute a request.
     */
    protected void noteOpenConnection(ServerStats serverStats, ClientRequest request) {
        if (serverStats == null) {
            return;
        }
        try {
            serverStats.incrementActiveRequestsCount();
        } catch (Throwable e) {
            logger.info("Unable to note Server Stats:", e);
        }
    }

      
    /**
     * Derive scheme and port from a partial URI. For example, for HTTP based client, the URI with 
     * only path "/" should return "http" and 80, whereas the URI constructed with scheme "https" and
     * path "/" should return
     * "https" and 443. This method is called by {@link #computeFinalUriWithLoadBalancer(ClientRequest)}
     * to get the complete executable URI.
     * 
     */
    protected Pair<String, Integer> deriveSchemeAndPortFromPartialUri(T request) {
        URI theUrl = request.getUri();
        boolean isSecure = false;
        String scheme = theUrl.getScheme();
        if (scheme != null) {
            isSecure =  scheme.equalsIgnoreCase("https");
        }
        int port = theUrl.getPort();
        if (port < 0 && !isSecure){
            port = 80;
        } else if (port < 0 && isSecure){
            port = 443;
        }
        if (scheme == null){
            if (isSecure) {
                scheme = "https";
            } else {
                scheme = "http";
            }
        }
        return new Pair<String, Integer>(scheme, port);
    }
    
    /**
     * Get the default port of the target server given the scheme of vip address if it is available. 
     * Subclass should override it to provider protocol specific default port number if any.
     * 
     * @param scheme from the vip address. null if not present.
     * @return 80 if scheme is http, 443 if scheme is https, -1 else.
     */
    protected int getDefaultPortFromScheme(String scheme) {
        if (scheme == null) {
            return -1;
        }
        if (scheme.equals("http")) {
            return 80;
        } else if (scheme.equals("https")) {
            return 443;
        } else {
            return -1;
        }
    }

        
    /**
     * Derive the host and port from virtual address if virtual address is indeed contains the actual host 
     * and port of the server. This is the final resort to compute the final URI in {@link #computeFinalUriWithLoadBalancer(ClientRequest)}
     * if there is no load balancer available and the request URI is incomplete. Sub classes can override this method
     * to be more accurate or throws ClientException if it does not want to support virtual address to be the
     * same as physical server address.
     * <p>
     *  The virtual address is used by certain load balancers to filter the servers of the same function 
     *  to form the server pool. 
     *  
     */
    protected  Pair<String, Integer> deriveHostAndPortFromVipAddress(String vipAddress) 
            throws URISyntaxException, ClientException {
        Pair<String, Integer> hostAndPort = new Pair<String, Integer>(null, -1);
        URI uri = new URI(vipAddress);
        String scheme = uri.getScheme();
        if (scheme == null) {
            uri = new URI("http://" + vipAddress);
        }
        String host = uri.getHost();
        if (host == null) {
            throw new ClientException("Unable to derive host/port from vip address " + vipAddress);
        }
        int port = uri.getPort();
        if (port < 0) {
            port = getDefaultPortFromScheme(scheme);
        }
        if (port < 0) {
            throw new ClientException("Unable to derive host/port from vip address " + vipAddress);
        }
        hostAndPort.setFirst(host);
        hostAndPort.setSecond(port);
        return hostAndPort;
    }
    
    private boolean isVipRecognized(String vipEmbeddedInUri) {
        if (vipEmbeddedInUri == null) {
            return false;
        }
        if (vipAddresses == null) {
            return false;
        }
        String[] addresses = vipAddresses.split(",");
        for (String address: addresses) {
            if (vipEmbeddedInUri.equalsIgnoreCase(address.trim())) {
                return true;
            }
        }
        return false;
    }
    
    /**
     * Compute the final URI from a partial URI in the request. The following steps are performed:
     * 
     * <li> if host is missing and there is a load balancer, get the host/port from server chosen from load balancer
     * <li> if host is missing and there is no load balancer, try to derive host/port from virtual address set with the client
     * <li> if host is present and the authority part of the URI is a virtual address set for the client, 
     * and there is a load balancer, get the host/port from server chosen from load balancer
     * <li> if host is present but none of the above applies, interpret the host as the actual physical address
     * <li> if host is missing but none of the above applies, throws ClientException
     * 
     * @param original Original URI passed from caller
     * @return new request with the final URI  
     */
    @SuppressWarnings("unchecked")
    protected T computeFinalUriWithLoadBalancer(T original) throws ClientException{
        URI theUrl = original.getUri();

        if (theUrl == null){
            throw new ClientException(ClientException.ErrorType.GENERAL, "NULL URL passed in");
        }

        String host = theUrl.getHost();
        Pair<String, Integer> schemeAndPort = deriveSchemeAndPortFromPartialUri(original);
        String scheme = schemeAndPort.first();
        int port = schemeAndPort.second();
        // Various Supported Cases
        // The loadbalancer to use and the instances it has is based on how it was registered
        // In each of these cases, the client might come in using Full Url or Partial URL
        ILoadBalancer lb = getLoadBalancer();
        Object loadBalancerKey = original.getLoadBalancerKey();
        if (host == null){
            // Partial URL Case
            // well we have to just get the right instances from lb - or we fall back
            if (lb != null){
                Server svc = lb.chooseServer(loadBalancerKey);
                if (svc == null){
                    throw new ClientException(ClientException.ErrorType.GENERAL,
                            "LoadBalancer returned null Server for :"
                            + clientName);
                }
                host = svc.getHost();
                port = svc.getPort();

                if (host == null){
                    throw new ClientException(ClientException.ErrorType.GENERAL,
                            "Invalid Server for :" + svc);
                }
                if (logger.isDebugEnabled()){
                    logger.debug(clientName + " using LB returned Server:" + svc + "for request:" + theUrl);
                }
            } else {
                // No Full URL - and we dont have a LoadBalancer registered to
                // obtain a server
                // if we have a vipAddress that came with the registration, we
                // can use that else we
                // bail out
                if (vipAddresses != null && vipAddresses.contains(",")) {
                    throw new ClientException(
                            ClientException.ErrorType.GENERAL,
                            this.clientName
                                    + "Partial URI of ("
                                    + theUrl
                                    + ") has been sent in to RestClient (with no LB) to be executed."
                                    + " Also, there are multiple vipAddresses and hence RestClient cant pick"
                                    + "one vipAddress to complete this partial uri");
                } else if (vipAddresses != null) {
                    try {
                        Pair<String,Integer> hostAndPort = deriveHostAndPortFromVipAddress(vipAddresses);
                        host = hostAndPort.first();
                        port = hostAndPort.second();
                    } catch (URISyntaxException e) {
                        throw new ClientException(
                                ClientException.ErrorType.GENERAL,
                                this.clientName
                                        + "Partial URI of ("
                                        + theUrl
                                        + ") has been sent in to RestClient (with no LB) to be executed."
                                        + " Also, the configured/registered vipAddress is unparseable (to determine host and port)");
                    }
                }else{
                    throw new ClientException(
                            ClientException.ErrorType.GENERAL,
                            this.clientName
                                    + " has no LoadBalancer registered and passed in a partial URL request (with no host:port)."
                                    + " Also has no vipAddress registered");
                }
            }
        } else {
            // Full URL Case
            // This could either be a vipAddress or a hostAndPort or a real DNS
            // if vipAddress or hostAndPort, we just have to consult the loadbalancer
            // but if it does not return a server, we should just proceed anyways
            // and assume its a DNS
            // For restClients registered using a vipAddress AND executing a request
            // by passing in the full URL (including host and port), we should only
            // consult lb IFF the URL passed is registered as vipAddress in Discovery
            boolean shouldInterpretAsVip = false;

            if (lb != null) {
                shouldInterpretAsVip = isVipRecognized(original.getUri().getAuthority());
            }
            if (shouldInterpretAsVip) {
                Server svc = lb.chooseServer(loadBalancerKey);
                if (svc != null){
                    host = svc.getHost();
                    port = svc.getPort();
                    if (host == null){
                        throw new ClientException(ClientException.ErrorType.GENERAL,
                                "Invalid Server for :" + svc);
                    }
                    if (logger.isDebugEnabled()){
                        logger.debug("using LB returned Server:" + svc + "for request:" + theUrl);
                    }
                }else{
                    // just fall back as real DNS
                    if (logger.isDebugEnabled()){
                        logger.debug(host + ":" + port + " assumed to be a valid VIP address or exists in the DNS");
                    }
                }
            } else {
             // consult LB to obtain vipAddress backed instance given full URL
                //Full URL execute request - where url!=vipAddress
               if (logger.isDebugEnabled()){
                   logger.debug("Using full URL passed in by caller (not using LB/Discovery):" + theUrl);
               }
            }
        }
        // end of creating final URL
        if (host == null){
            throw new ClientException(ClientException.ErrorType.GENERAL,"Request contains no HOST to talk to");
        }
        // just verify that at this point we have a full URL

        try {
            StringBuilder sb = new StringBuilder();
            sb.append(scheme).append("://");
            if (!Strings.isNullOrEmpty(theUrl.getRawUserInfo())) {
                sb.append(theUrl.getRawUserInfo()).append("@");
            }
            sb.append(host);
            if (port >= 0) {
                sb.append(":").append(port);
            }
            sb.append(theUrl.getRawPath());
            if (!Strings.isNullOrEmpty(theUrl.getRawQuery())) {
                sb.append("?").append(theUrl.getRawQuery());
            }
            if (!Strings.isNullOrEmpty(theUrl.getRawFragment())) {
                sb.append("#").append(theUrl.getRawFragment());
            }
            URI newURI = new URI(sb.toString());
            return (T) original.replaceUri(newURI);            
        } catch (URISyntaxException e) {
            throw new ClientException(ClientException.ErrorType.GENERAL, e.getMessage());
        }
    }
    
    protected boolean isRetriable(T request) {
        if (request.isRetriable()) {
            return true;            
        } else {
            boolean retryOkayOnOperation = okToRetryOnAllOperations;
            IClientConfig overriddenClientConfig = request.getOverrideConfig();
            if (overriddenClientConfig != null) {
                retryOkayOnOperation = overriddenClientConfig.getPropertyAsBoolean(CommonClientConfigKey.RequestSpecificRetryOn, okToRetryOnAllOperations);
            }
            return retryOkayOnOperation;
        }
    }
    
    protected int getRetriesNextServer(IClientConfig overriddenClientConfig) {
        int numRetries = maxAutoRetriesNextServer;
        if (overriddenClientConfig != null) {
            numRetries = overriddenClientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetriesNextServer, maxAutoRetriesNextServer);
        }
        return numRetries;
    }
    
    public final ServerStats getServerStats(Server server) {
        ServerStats serverStats = null;
        ILoadBalancer lb = this.getLoadBalancer();
        if (lb instanceof AbstractLoadBalancer){
            LoadBalancerStats lbStats = ((AbstractLoadBalancer) lb).getLoadBalancerStats();
            serverStats = lbStats.getSingleServerStat(server);
        }
        return serverStats;

    }

    protected int getNumberRetriesOnSameServer(IClientConfig overriddenClientConfig) {
        int numRetries =  maxAutoRetries;
        if (overriddenClientConfig!=null){
            try {
                numRetries = overriddenClientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetries, maxAutoRetries);
            } catch (Exception e) {
                logger.warn("Invalid maxRetries requested for RestClient:" + this.clientName);
            }
        }
        return numRetries;
    }
    
    protected boolean handleSameServerRetry(URI uri, int currentRetryCount, int maxRetries, Throwable e) {
        if (currentRetryCount > maxRetries) {
            return false;
        }
        logger.debug("Exception while executing request which is deemed retry-able, retrying ..., SAME Server Retry Attempt#: {}, URI: {}",  
                currentRetryCount, uri);
        return true;
    }

    public final LoadBalancerErrorHandler<? super T, ? super S> getErrorHandler() {
        return errorHandler;
    }

    public final void setErrorHandler(
            LoadBalancerErrorHandler<? super T, ? super S> errorHandler) {
        this.errorHandler = errorHandler;
    }

    public final boolean isOkToRetryOnAllOperations() {
        return okToRetryOnAllOperations;
    }

    public final void setOkToRetryOnAllOperations(boolean okToRetryOnAllOperations) {
        this.okToRetryOnAllOperations = okToRetryOnAllOperations;
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_7620032_42c3e4c/rev_7620032-42c3e4c/ribbon-core/src/main/java/com/netflix/loadbalancer/BaseLoadBalancer.java;<<<<<<< MINE
=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.loadbalancer;

import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.Timer;
import java.util.TimerTask;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.collect.ImmutableList;
import com.netflix.client.ClientFactory;
import com.netflix.client.IClientConfigAware;
import com.netflix.client.PrimeConnections;
import com.netflix.client.config.CommonClientConfigKey;
import com.netflix.client.config.IClientConfig;
import com.netflix.servo.annotations.DataSourceType;
import com.netflix.servo.annotations.Monitor;
import com.netflix.servo.monitor.Counter;
import com.netflix.servo.monitor.Monitors;
import com.netflix.util.concurrent.ShutdownEnabledTimer;

/**
 * A basic implementation of the load balancer where an arbitrary list of
 * servers can be set as the server pool. A ping can be set to determine the
 * liveness of a server. Internally, this class maintains an "all" server list
 * and an "up" server list and use them depending on what the caller asks for.
 * 
 * @author stonse
 * 
 */
public class BaseLoadBalancer extends AbstractLoadBalancer implements
        PrimeConnections.PrimeConnectionListener, IClientConfigAware {

    private static Logger logger = LoggerFactory
            .getLogger(BaseLoadBalancer.class);
    private final static IRule DEFAULT_RULE = new RoundRobinRule();
    private static final String DEFAULT_NAME = "default";
    private static final String PREFIX = "LoadBalancer_";

    protected IRule rule = DEFAULT_RULE;

    protected IPing ping = null;

    @Monitor(name = PREFIX + "AllServerList", type = DataSourceType.INFORMATIONAL)
    protected volatile List<Server> allServerList = Collections
            .synchronizedList(new ArrayList<Server>());
    @Monitor(name = PREFIX + "UpServerList", type = DataSourceType.INFORMATIONAL)
    protected volatile List<Server> upServerList = Collections
            .synchronizedList(new ArrayList<Server>());

    protected ReadWriteLock allServerLock = new ReentrantReadWriteLock();
    protected ReadWriteLock upServerLock = new ReentrantReadWriteLock();

    protected String name = DEFAULT_NAME;

    protected Timer lbTimer = null;
    protected int pingIntervalSeconds = 10;
    protected int maxTotalPingTimeSeconds = 5;
    protected Comparator<Server> serverComparator = new ServerComparator();

    protected AtomicBoolean pingInProgress = new AtomicBoolean(false);

    protected LoadBalancerStats lbStats;

    private volatile Counter counter;

    private PrimeConnections primeConnections;

    private volatile boolean enablePrimingConnections = false;
    
    private IClientConfig config;
    
    private List<ServerListChangeListener> changeListeners = new CopyOnWriteArrayList<ServerListChangeListener>();

    /**
     * Default constructor which sets name as "default", sets null ping, and
     * {@link RoundRobinRule} as the rule.
     * <p>
     * This constructor is mainly used by {@link ClientFactory}. Calling this
     * constructor must be followed by calling {@link #init()} or
     * {@link #initWithNiwsConfig(IClientConfig)} to complete initialization.
     * This constructor is provided for reflection. When constructing
     * programatically, it is recommended to use other constructors.
     */
    public BaseLoadBalancer() {
        this.name = DEFAULT_NAME;
        this.ping = null;
        setRule(DEFAULT_RULE);
        setupPingTask();
        lbStats = new LoadBalancerStats(DEFAULT_NAME);
        counter = createCounter();
    }

    public BaseLoadBalancer(String lbName, IRule rule, LoadBalancerStats lbStats) {
        this(lbName, rule, lbStats, null);
    }

    public BaseLoadBalancer(IPing ping, IRule rule) {
        this(DEFAULT_NAME, rule, new LoadBalancerStats(DEFAULT_NAME), ping);
    }

    public BaseLoadBalancer(String name, IRule rule, LoadBalancerStats stats,
            IPing ping) {
        if (logger.isDebugEnabled()) {
            logger.debug("LoadBalancer:  initialized");
        }
        this.name = name;
        this.ping = ping;
        setRule(rule);
        setupPingTask();
        lbStats = stats;
        counter = createCounter();
        init();
    }

    public BaseLoadBalancer(IClientConfig config) {
        initWithNiwsConfig(config);
    }

    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
    	this.config = clientConfig;
        String clientName = clientConfig.getClientName();
        String ruleClassName = (String) clientConfig
                .getProperty(CommonClientConfigKey.NFLoadBalancerRuleClassName);
        String pingClassName = (String) clientConfig
                .getProperty(CommonClientConfigKey.NFLoadBalancerPingClassName);

        IRule rule;
        IPing ping;
        try {
            rule = (IRule) ClientFactory.instantiateInstanceWithClientConfig(
                    ruleClassName, clientConfig);
            ping = (IPing) ClientFactory.instantiateInstanceWithClientConfig(
                    pingClassName, clientConfig);
        } catch (Exception e) {
            throw new RuntimeException("Error initializing load balancer", e);
        }

        this.name = clientName;
        int pingIntervalTime = Integer.parseInt(""
                + clientConfig.getProperty(
                        CommonClientConfigKey.NFLoadBalancerPingInterval,
                        Integer.parseInt("30")));
        int maxTotalPingTime = Integer.parseInt(""
                + clientConfig.getProperty(
                        CommonClientConfigKey.NFLoadBalancerMaxTotalPingTime,
                        Integer.parseInt("2")));

        setPingInterval(pingIntervalTime);
        setMaxTotalPingTime(maxTotalPingTime);

        // cross associate with each other
        // i.e. Rule,Ping meet your container LB
        // LB, these are your Ping and Rule guys ...
        setRule(rule);
        setPing(ping);
        setLoadBalancerStats(new LoadBalancerStats(clientName));
        rule.setLoadBalancer(this);
        if (ping instanceof AbstractLoadBalancerPing) {
            ((AbstractLoadBalancerPing) ping).setLoadBalancer(this);
        }
        logger.info("Client:" + name + " instantiated a LoadBalancer:"
                + toString());
        boolean enablePrimeConnections = false;

        if (clientConfig
                .getProperty(CommonClientConfigKey.EnablePrimeConnections) != null) {
            Boolean bEnablePrimeConnections = Boolean.valueOf(""
                    + clientConfig.getProperty(
                            CommonClientConfigKey.EnablePrimeConnections,
                            "false"));
            enablePrimeConnections = bEnablePrimeConnections.booleanValue();
        }

        if (enablePrimeConnections) {
            this.setEnablePrimingConnections(true);
            PrimeConnections primeConnections = new PrimeConnections(
                    this.getName(), clientConfig);
            this.setPrimeConnections(primeConnections);
        }
        init();
    }

    public void addServerListChangeListener(ServerListChangeListener listener) {
        changeListeners.add(listener);
    }
    
    public void removeServerListChangeListener(ServerListChangeListener listener) {
        changeListeners.remove(listener);
    }

    public IClientConfig getClientConfig() {
    	return config;
    }
    
    private boolean canSkipPing() {
        if (ping == null
                || ping.getClass().getName().equals(DummyPing.class.getName())) {
            // default ping, no need to set up timer
            return true;
        } else {
            return false;
        }
    }

    private void setupPingTask() {
        if (canSkipPing()) {
            return;
        }
        if (lbTimer != null) {
            lbTimer.cancel();
        }
        lbTimer = new ShutdownEnabledTimer("NFLoadBalancer-PingTimer-" + name,
                true);
        lbTimer.schedule(new PingTask(), 0, pingIntervalSeconds * 1000);
        forceQuickPing();
    }

    /**
     * Set the name for the load balancer. This should not be called since name
     * should be immutable after initialization. Calling this method does not
     * guarantee that all other data structures that depend on this name will be
     * changed accordingly.
     */
    void setName(String name) {
        // and register
        this.name = name;
        if (lbStats == null) {
            lbStats = new LoadBalancerStats(name);
        } else {
            lbStats.setName(name);
        }
    }

    public String getName() {
        return name;
    }

    @Override
    public LoadBalancerStats getLoadBalancerStats() {
        return lbStats;
    }

    public void setLoadBalancerStats(LoadBalancerStats lbStats) {
        this.lbStats = lbStats;
    }

    public Lock lockAllServerList(boolean write) {
        Lock aproposLock = write ? allServerLock.writeLock() : allServerLock
                .readLock();
        aproposLock.lock();
        return aproposLock;
    }

    public Lock lockUpServerList(boolean write) {
        Lock aproposLock = write ? upServerLock.writeLock() : upServerLock
                .readLock();
        aproposLock.lock();
        return aproposLock;
    }

    public void setPingInterval(int pingIntervalSeconds) {
        if (pingIntervalSeconds < 1) {
            return;
        }

        this.pingIntervalSeconds = pingIntervalSeconds;
        if (logger.isDebugEnabled()) {
            logger.debug("LoadBalancer:  pingIntervalSeconds set to "
                    + this.pingIntervalSeconds);
        }
        setupPingTask(); // since ping data changed
    }

    public int getPingInterval() {
        return pingIntervalSeconds;
    }

    /*
     * Maximum time allowed for the ping cycle
     */
    public void setMaxTotalPingTime(int maxTotalPingTimeSeconds) {
        if (maxTotalPingTimeSeconds < 1) {
            return;
        }
        this.maxTotalPingTimeSeconds = maxTotalPingTimeSeconds;
        if (logger.isDebugEnabled()) {
            logger.debug("LoadBalancer: maxTotalPingTime set to "
                    + this.maxTotalPingTimeSeconds);
        }

    }

    public int getMaxTotalPingTime() {
        return maxTotalPingTimeSeconds;
    }

    public IPing getPing() {
        return ping;
    }

    public IRule getRule() {
        return rule;
    }

    public boolean isPingInProgress() {
        return pingInProgress.get();
    }

    /* Specify the object which is used to send pings. */

    public void setPing(IPing ping) {
        if (ping != null) {
            if (!ping.equals(this.ping)) {
                this.ping = ping;
                setupPingTask(); // since ping data changed
            }
        } else {
            this.ping = null;
            // cancel the timer task
            lbTimer.cancel();
        }
    }

    /* Ignore null rules */

    public void setRule(IRule rule) {
        if (rule != null) {
            this.rule = rule;
        } else {
            /* default rule */
            this.rule = new RoundRobinRule();
        }
        if (this.rule.getLoadBalancer() != this) {
            this.rule.setLoadBalancer(this);
        }
    }

    /**
     * get the count of servers.
     * 
     * @param onlyAvailable
     *            if true, return only up servers.
     */
    public int getServerCount(boolean onlyAvailable) {
        if (onlyAvailable) {
            return upServerList.size();
        } else {
            return allServerList.size();
        }
    }

    /**
     * Add a server to the 'allServer' list; does not verify uniqueness, so you
     * could give a server a greater share by adding it more than once.
     */
    public void addServer(Server newServer) {
        if (newServer != null) {
            try {
                ArrayList<Server> newList = new ArrayList<Server>();

                newList.addAll(allServerList);
                newList.add(newServer);
                setServersList(newList);
            } catch (Exception e) {
                logger.error("Exception while adding a newServer", e);
            }
        }
    }

    /**
     * Add a list of servers to the 'allServer' list; does not verify
     * uniqueness, so you could give a server a greater share by adding it more
     * than once
     */
    @Override
    public void addServers(List<Server> newServers) {
        if (newServers != null && newServers.size() > 0) {
            try {
                ArrayList<Server> newList = new ArrayList<Server>();
                newList.addAll(allServerList);
                newList.addAll(newServers);
                setServersList(newList);
            } catch (Exception e) {
                logger.error("Exception while adding Servers", e);
            }
        }
    }

    /*
     * Add a list of servers to the 'allServer' list; does not verify
     * uniqueness, so you could give a server a greater share by adding it more
     * than once USED by Test Cases only for legacy reason. DO NOT USE!!
     */
    void addServers(Object[] newServers) {
        if ((newServers != null) && (newServers.length > 0)) {

            try {
                ArrayList<Server> newList = new ArrayList<Server>();
                newList.addAll(allServerList);

                for (Object server : newServers) {
                    if (server != null) {
                        if (server instanceof String) {
                            server = new Server((String) server);
                        }
                        if (server instanceof Server) {
                            newList.add((Server) server);
                        }
                    }
                }
                setServersList(newList);
            } catch (Exception e) {
                logger.error("Exception while adding Servers", e);
            }
        }
    }

    /**
     * Set the list of servers used as the server pool. This overrides existing
     * server list.
     */
    public void setServersList(List lsrv) {
        Lock writeLock = allServerLock.writeLock();
        if (logger.isDebugEnabled()) {
            logger.debug("LoadBalancer:  clearing server list (SET op)");
        }
        ArrayList<Server> newServers = new ArrayList<Server>();
        writeLock.lock();
        try {
            ArrayList<Server> allServers = new ArrayList<Server>();
            for (Object server : lsrv) {
                if (server == null) {
                    continue;
                }

                if (server instanceof String) {
                    server = new Server((String) server);
                }

                if (server instanceof Server) {
                    if (logger.isDebugEnabled()) {
                        logger.debug("LoadBalancer:  addServer ["
                                + ((Server) server).getId() + "]");
                    }
                    allServers.add((Server) server);
                } else {
                    throw new IllegalArgumentException(
                            "Type String or Server expected, instead found:"
                                    + server.getClass());
                }

            }
            boolean listChanged = false;
            if (!allServerList.equals(allServers)) {
                listChanged = true;
                if (changeListeners != null && changeListeners.size() > 0) {
                   List<Server> oldList = ImmutableList.copyOf(allServerList);
                   List<Server> newList = ImmutableList.copyOf(allServers);                   
                   for (ServerListChangeListener l: changeListeners) {
                       try {
                           l.serverListChanged(oldList, newList);
                       } catch (Throwable e) {
                           logger.error("Error invoking server list change listener", e);
                       }
                   }
                }
            }
            if (isEnablePrimingConnections()) {
                for (Server server : allServers) {
                    if (!allServerList.contains(server)) {
                        server.setReadyToServe(false);
                        newServers.add((Server) server);
                    }
                }
                if (primeConnections != null) {
                    primeConnections.primeConnectionsAsync(newServers, this);
                }
            }
            // This will reset readyToServe flag to true on all servers
            // regardless whether
            // previous priming connections are success or not
            allServerList = allServers;
            if (canSkipPing()) {
                for (Server s : allServerList) {
                    s.setAlive(true);
                }
                upServerList = allServerList;
            } else if (listChanged) {
                forceQuickPing();
            }
        } finally {
            writeLock.unlock();
        }
    }

    /* List in string form. SETS, does not add. */
    void setServers(String srvString) {
        if (srvString != null) {

            try {
                String[] serverArr = srvString.split(",");
                ArrayList<Server> newList = new ArrayList<Server>();

                for (String serverString : serverArr) {
                    if (serverString != null) {
                        serverString = serverString.trim();
                        if (serverString.length() > 0) {
                            Server svr = new Server(serverString);
                            newList.add(svr);
                        }
                    }
                }
                setServersList(newList);
            } catch (Exception e) {
                logger.error("Exception while adding Servers", e);
            }
        }
    }

    /**
     * return the server
     * 
     * @param index
     * @param availableOnly
     */
    public Server getServerByIndex(int index, boolean availableOnly) {
        try {
            return (availableOnly ? upServerList.get(index) : allServerList
                    .get(index));
        } catch (Exception e) {
            return null;
        }
    }

    @Override
    public List<Server> getServerList(boolean availableOnly) {
        return (availableOnly ? Collections.unmodifiableList(upServerList) : 
        	Collections.unmodifiableList(allServerList));
    }

    @Override
    public List<Server> getServerList(ServerGroup serverGroup) {
        switch (serverGroup) {
        case ALL:
            return allServerList;
        case STATUS_UP:
            return upServerList;
        case STATUS_NOT_UP:
            ArrayList<Server> notAvailableServers = new ArrayList<Server>(
                    allServerList);
            ArrayList<Server> upServers = new ArrayList<Server>(upServerList);
            notAvailableServers.removeAll(upServers);
            return notAvailableServers;
        }
        return new ArrayList<Server>();
    }

    public void cancelPingTask() {
        if (lbTimer != null) {
            lbTimer.cancel();
        }
    }

    /**
     * TimerTask that keeps runs every X seconds to check the status of each
     * server/node in the Server List
     * 
     * @author stonse
     * 
     */
    class PingTask extends TimerTask {
        public void run() {
            Pinger ping = new Pinger();
            try {
                ping.runPinger();
            } catch (Throwable t) {
                logger.error("Throwable caught while running extends for "
                        + name, t);
            }
        }
    }

    /**
     * Class that contains the mechanism to "ping" all the instances
     * 
     * @author stonse
     *
     */
    class Pinger {

        public void runPinger() {

            if (pingInProgress.get()) {
                return; // Ping in progress - nothing to do
            } else {
                pingInProgress.set(true);
            }

            // we are "in" - we get to Ping

            Object[] allServers = null;
            boolean[] results = null;

            Lock allLock = null;
            Lock upLock = null;

            try {
                /*
                 * The readLock should be free unless an addServer operation is
                 * going on...
                 */
                allLock = allServerLock.readLock();
                allLock.lock();
                allServers = allServerList.toArray();
                allLock.unlock();

                int numCandidates = allServers.length;
                results = new boolean[numCandidates];

                if (logger.isDebugEnabled()) {
                    logger.debug("LoadBalancer:  PingTask executing ["
                            + numCandidates + "] servers configured");
                }

                for (int i = 0; i < numCandidates; i++) {
                    results[i] = false; /* Default answer is DEAD. */
                    try {
                        // NOTE: IFF we were doing a real ping
                        // assuming we had a large set of servers (say 15)
                        // the logic below will run them serially
                        // hence taking 15 times the amount of time it takes
                        // to ping each server
                        // A better method would be to put this in an executor
                        // pool
                        // But, at the time of this writing, we dont REALLY
                        // use a Real Ping (its mostly in memory eureka call)
                        // hence we can afford to simplify this design and run
                        // this
                        // serially
                        if (ping != null) {
                            results[i] = ping.isAlive((Server) allServers[i]);
                        }
                    } catch (Throwable t) {
                        logger.error("Exception while pinging Server:"
                                + allServers[i], t);
                    }
                }

                ArrayList<Server> newUpList = new ArrayList<Server>();

                for (int i = 0; i < numCandidates; i++) {
                    boolean isAlive = results[i];
                    Server svr = (Server) allServers[i];
                    boolean oldIsAlive = svr.isAlive();

                    svr.setAlive(isAlive);

                    if (oldIsAlive != isAlive && logger.isDebugEnabled()) {
                        logger.debug("LoadBalancer:  Server [" + svr.getId()
                                + "] status changed to "
                                + (isAlive ? "ALIVE" : "DEAD"));
                    }

                    if (isAlive) {
                        newUpList.add(svr);
                    }
                }
                // System.out.println(count + " servers alive");
                upLock = upServerLock.writeLock();
                upLock.lock();
                upServerList = newUpList;
                upLock.unlock();
            } catch (Throwable t) {
                logger.error("Throwable caught while running the Pinger-"
                        + name, t);
            } finally {
                pingInProgress.set(false);
            }
        }
    }

    private final Counter createCounter() {
        return Monitors.newCounter("LoadBalancer_ChooseServer");
    }

    /*
     * Get the alive server dedicated to key
     * 
     * @return the dedicated server
     */
    public Server chooseServer(Object key) {
        if (counter == null) {
            counter = createCounter();
        }
        counter.increment();
        if (rule == null) {
            return null;
        } else {
            try {
                return rule.choose(key);
            } catch (Throwable t) {
                return null;
            }
        }
    }

    /* Returns either null, or "server:port/servlet" */
    public String choose(Object key) {
        if (rule == null) {
            return null;
        } else {
            try {
                Server svr = rule.choose(key);
                return ((svr == null) ? null : svr.getId());
            } catch (Throwable t) {
                return null;
            }
        }
    }

    public void markServerDown(Server server) {
        if (server == null) {
            return;
        }

        if (!server.isAlive()) {
            return;
        }

        logger.error("LoadBalancer:  markServerDown called on ["
                + server.getId() + "]");
        server.setAlive(false);
        // forceQuickPing();
    }

    public void markServerDown(String id) {
        boolean triggered = false;

        id = Server.normalizeId(id);

        if (id == null) {
            return;
        }

        Lock writeLock = upServerLock.writeLock();

        try {

            for (Server svr : upServerList) {
                if (svr.isAlive() && (svr.getId().equals(id))) {
                    triggered = true;
                    svr.setAlive(false);
                }
            }

            if (triggered) {
                logger.error("LoadBalancer:  markServerDown called on [" + id
                        + "]");
            }

        } finally {
            try {
                writeLock.unlock();
            } catch (Exception e) { // NOPMD
            }
        }
    }

    /*
     * Force an immediate ping, if we're not currently pinging and don't have a
     * quick-ping already scheduled.
     */
    public void forceQuickPing() {
        if (canSkipPing()) {
            return;
        }
        if (logger.isDebugEnabled()) {
            logger.debug("LoadBalancer:  forceQuickPing invoked");
        }
        Pinger ping = new Pinger();
        try {
            ping.runPinger();
        } catch (Throwable t) {
            logger.error("Throwable caught while running forceQuickPing() for "
                    + name, t);
        }
    }

    public String toString() {
        StringBuilder sb = new StringBuilder();
        sb.append("{NFLoadBalancer:name=").append(this.getName())
                .append(",current list of Servers=").append(this.allServerList)
                .append(",Load balancer stats=")
                .append(this.lbStats.toString()).append("}");
        return sb.toString();
    }

    /**
     * Register with monitors and start priming connections if it is set.
     */
    protected void init() {
        Monitors.registerObject("LoadBalancer_" + name, this);
        // register the rule as it contains metric for available servers count
        Monitors.registerObject("Rule_" + name, this.getRule());
        if (enablePrimingConnections && primeConnections != null) {
            primeConnections.primeConnections(getServerList(true));
        }
    }

    public final PrimeConnections getPrimeConnections() {
        return primeConnections;
    }

    public final void setPrimeConnections(PrimeConnections primeConnections) {
        this.primeConnections = primeConnections;
    }

    @Override
    public void primeCompleted(Server s, Throwable lastException) {
        s.setReadyToServe(true);
    }

    public boolean isEnablePrimingConnections() {
        return enablePrimingConnections;
    }

    public final void setEnablePrimingConnections(
            boolean enablePrimingConnections) {
        this.enablePrimingConnections = enablePrimingConnections;
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_7620032_42c3e4c/rev_7620032-42c3e4c/ribbon-core/src/main/java/com/netflix/loadbalancer/DynamicServerListLoadBalancer.java;<<<<<<< MINE
=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.loadbalancer;

import java.util.Date;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.ScheduledThreadPoolExecutor;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicLong;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.netflix.client.ClientFactory;
import com.netflix.client.config.CommonClientConfigKey;
import com.netflix.client.config.DefaultClientConfigImpl;
import com.netflix.client.config.IClientConfig;
import com.netflix.config.DynamicIntProperty;
import com.netflix.config.DynamicProperty;
import com.netflix.servo.annotations.DataSourceType;
import com.netflix.servo.annotations.Monitor;
import com.google.common.annotations.VisibleForTesting;
import com.google.common.util.concurrent.ThreadFactoryBuilder;

/**
 * A LoadBalancer that has the capabilities to obtain the candidate list of
 * servers using a dynamic source. i.e. The list of servers can potentially be
 * changed at Runtime. It also contains facilities wherein the list of servers
 * can be passed through a Filter criteria to filter out servers that do not
 * meet the desired criteria.
 * 
 * @author stonse
 * 
 */
public class DynamicServerListLoadBalancer<T extends Server> extends
        BaseLoadBalancer {
    private static final Logger LOGGER = LoggerFactory
            .getLogger(DynamicServerListLoadBalancer.class);

    boolean isSecure = false;
    boolean useTunnel = false;
    private static Thread _shutdownThread;

    // to keep track of modification of server lists
    protected AtomicBoolean serverListUpdateInProgress = new AtomicBoolean(
            false);

    private static long LISTOFSERVERS_CACHE_UPDATE_DELAY = 1000; // msecs;
    private static long LISTOFSERVERS_CACHE_REPEAT_INTERVAL = 30 * 1000; // msecs;
                                                                         // //
                                                                         // every
                                                                         // 30
                                                                         // secs

    private static ScheduledThreadPoolExecutor _serverListRefreshExecutor = null;

    private long refeshIntervalMills = LISTOFSERVERS_CACHE_REPEAT_INTERVAL;

    volatile ServerList<T> serverListImpl;

    volatile ServerListFilter<T> filter;
    
    private AtomicLong lastUpdated = new AtomicLong(System.currentTimeMillis());
    
    protected volatile boolean serverRefreshEnabled = false;
    private final static String CORE_THREAD = "DynamicServerListLoadBalancer.ThreadPoolSize";
    private final static DynamicIntProperty poolSizeProp = new DynamicIntProperty(CORE_THREAD, 2);
    
    private volatile ScheduledFuture<?> scheduledFuture;

    static {
        int coreSize = poolSizeProp.get();
        ThreadFactory factory = (new ThreadFactoryBuilder()).setDaemon(true).build();
        _serverListRefreshExecutor = new ScheduledThreadPoolExecutor(coreSize, factory);
        poolSizeProp.addCallback(new Runnable() {
            @Override
            public void run() {
                _serverListRefreshExecutor.setCorePoolSize(poolSizeProp.get());
            }
        
        });
        _shutdownThread = new Thread(new Runnable() {
            public void run() {
                LOGGER.info("Shutting down the Executor Pool for DynamicServerListLoadBalancer");
                shutdownExecutorPool();
            }
        });
        Runtime.getRuntime().addShutdownHook(_shutdownThread);
    }
    
    public DynamicServerListLoadBalancer() {
        super();
    }

    public DynamicServerListLoadBalancer(IClientConfig niwsClientConfig) {
        initWithNiwsConfig(niwsClientConfig);
    }

    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
        try {
            super.initWithNiwsConfig(clientConfig);
            String niwsServerListClassName = clientConfig.getProperty(
                    CommonClientConfigKey.NIWSServerListClassName,
                    DefaultClientConfigImpl.DEFAULT_SEVER_LIST_CLASS)
                    .toString();

            ServerList<T> niwsServerListImpl = (ServerList<T>) ClientFactory
                    .instantiateInstanceWithClientConfig(
                            niwsServerListClassName, clientConfig);
            this.serverListImpl = niwsServerListImpl;

            if (niwsServerListImpl instanceof AbstractServerList) {
                AbstractServerListFilter<T> niwsFilter = ((AbstractServerList) niwsServerListImpl)
                        .getFilterImpl(clientConfig);
                niwsFilter.setLoadBalancerStats(getLoadBalancerStats());
                this.filter = niwsFilter;
            }

            refeshIntervalMills = Integer.valueOf(clientConfig.getProperty(
                    CommonClientConfigKey.ServerListRefreshInterval,
                    LISTOFSERVERS_CACHE_REPEAT_INTERVAL).toString());

            boolean primeConnection = this.isEnablePrimingConnections();
            // turn this off to avoid duplicated asynchronous priming done in BaseLoadBalancer.setServerList()
            this.setEnablePrimingConnections(false);
            enableAndInitLearnNewServersFeature();

            updateListOfServers();
            if (primeConnection && this.getPrimeConnections() != null) {
                this.getPrimeConnections()
                        .primeConnections(getServerList(true));
            }
            this.setEnablePrimingConnections(primeConnection);

        } catch (Exception e) {
            throw new RuntimeException(
                    "Exception while initializing NIWSDiscoveryLoadBalancer:"
                            + clientConfig.getClientName()
                            + ", niwsClientConfig:" + clientConfig, e);
        }
    }

    @Override
    public void setServersList(List lsrv) {
        super.setServersList(lsrv);
        List<T> serverList = (List<T>) lsrv;
        Map<String, List<Server>> serversInZones = new HashMap<String, List<Server>>();
        for (Server server : serverList) {
            // make sure ServerStats is created to avoid creating them on hot
            // path
            getLoadBalancerStats().getSingleServerStat(server);
            String zone = server.getZone();
            if (zone != null) {
                zone = zone.toLowerCase();
                List<Server> servers = serversInZones.get(zone);
                if (servers == null) {
                    servers = new ArrayList<Server>();
                    serversInZones.put(zone, servers);
                }
                servers.add(server);
            }
        }
        setServerListForZones(serversInZones);
    }

    protected void setServerListForZones(
            Map<String, List<Server>> zoneServersMap) {
        LOGGER.debug("Setting server list for zones: {}", zoneServersMap);
        getLoadBalancerStats().updateZoneServerMapping(zoneServersMap);
    }

    public ServerList<T> getServerListImpl() {
        return serverListImpl;
    }

    public void setServerListImpl(ServerList<T> niwsServerList) {
        this.serverListImpl = niwsServerList;
    }

    @Override
    public void setPing(IPing ping) {
        this.ping = ping;
    }

    public ServerListFilter<T> getFilter() {
        return filter;
    }

    public void setFilter(ServerListFilter<T> filter) {
        this.filter = filter;
    }

    @Override
    /**
     * Makes no sense to ping an inmemory disc client
     * 
     */
    public void forceQuickPing() {
        // no-op
    }

    /**
     * Feature that lets us add new instances (from AMIs) to the list of
     * existing servers that the LB will use Call this method if you want this
     * feature enabled
     */
    public void enableAndInitLearnNewServersFeature() {
        keepServerListUpdated();
        serverRefreshEnabled = true;
    }

    private String getIdentifier() {
        return this.getClientConfig().getClientName();
    }

    private void keepServerListUpdated() {
        scheduledFuture = _serverListRefreshExecutor.scheduleAtFixedRate(
                new ServerListRefreshExecutorThread(),
                LISTOFSERVERS_CACHE_UPDATE_DELAY, refeshIntervalMills,
                TimeUnit.MILLISECONDS);
    }

    private static void shutdownExecutorPool() {
        if (_serverListRefreshExecutor != null) {
            _serverListRefreshExecutor.shutdown();

            if (_shutdownThread != null) {
                try {
                    Runtime.getRuntime().removeShutdownHook(_shutdownThread);
                } catch (IllegalStateException ise) { // NOPMD
                    // this can happen if we're in the middle of a real
                    // shutdown,
                    // and that's 'ok'
                }
            }

        }
    }

    public void stopServerListRefreshing() {
        serverRefreshEnabled = false;
        if (scheduledFuture != null) {
            scheduledFuture.cancel(true);
        }
    }
    
    /**
     * Class that updates the list of Servers This is based on the method used
     * by the client * Appropriate Filters are applied before coming up with the
     * right set of servers
     * 
     * @author stonse
     * 
     */
    class ServerListRefreshExecutorThread implements Runnable {

        public void run() {
            if (!serverRefreshEnabled) {
                return;
            }
            try {
                updateListOfServers();

            } catch (Throwable e) {
                LOGGER.error(
                        "Exception while updating List of Servers obtained from Discovery client",
                        e);
                // e.printStackTrace();
            }
        }

    }

    @VisibleForTesting
    public void updateListOfServers() {
        List<T> servers = new ArrayList<T>();
        if (serverListImpl != null) {
            servers = serverListImpl.getUpdatedListOfServers();
            LOGGER.debug("List of Servers for {} obtained from Discovery client: {}",
                    getIdentifier(), servers);

            if (filter != null) {
                servers = filter.getFilteredListOfServers(servers);
                LOGGER.debug("Filtered List of Servers for {} obtained from Discovery client: {}",
                        getIdentifier(), servers);
            }
        }
        lastUpdated.set(System.currentTimeMillis());
        updateAllServerList(servers);
    }

    /**
     * Update the AllServer list in the LoadBalancer if necessary and enabled
     * 
     * @param ls
     */
    protected void updateAllServerList(List<T> ls) {
        // other threads might be doing this - in which case, we pass
        if (!serverListUpdateInProgress.get()) {
            serverListUpdateInProgress.set(true);
            for (T s : ls) {
                s.setAlive(true); // set so that clients can start using these
                                  // servers right away instead
                // of having to wait out the ping cycle.
            }
            setServersList(ls);
            super.forceQuickPing();
            serverListUpdateInProgress.set(false);
        }
    }

    @Monitor(name="NumUpdateCyclesMissed", type=DataSourceType.GAUGE)
    public int getNumberMissedCycles() {
        if (!serverRefreshEnabled) {
            return 0;
        }
        return (int) ((int) (System.currentTimeMillis() - lastUpdated.get()) / refeshIntervalMills);
    }
    
    @Monitor(name="LastUpdated", type=DataSourceType.INFORMATIONAL)
    public String getLastUpdate() {
        return new Date(lastUpdated.get()).toString();
    }
    
    @Monitor(name="NumThreads", type=DataSourceType.GAUGE) 
    public int getCoreThreads() {
        if (_serverListRefreshExecutor != null) {
            return _serverListRefreshExecutor.getCorePoolSize();
        } else {
            return 0;
        }
    }
    
    public String toString() {
        StringBuilder sb = new StringBuilder("DynamicServerListLoadBalancer:");
        sb.append(super.toString());
        sb.append("ServerList:" + String.valueOf(serverListImpl));
        return sb.toString();
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_7620032_42c3e4c/rev_7620032-42c3e4c/ribbon-core/src/test/java/com/netflix/client/LoadBalancerContextTest.java;<<<<<<< MINE
=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.client;

import static org.junit.Assert.*;

import java.net.URLEncoder;

import org.junit.Test;

import com.netflix.client.http.HttpRequest;
import com.netflix.client.http.HttpResponse;
import com.netflix.loadbalancer.BaseLoadBalancer;
import com.netflix.loadbalancer.Server;

public class LoadBalancerContextTest {

    static BaseLoadBalancer lb = new BaseLoadBalancer() {

        @Override
        public Server chooseServer(Object key) {
            return new Server("www.example.com:8080");
        }
    };
    
    
    private MyLoadBalancerContext context;
    
    public LoadBalancerContextTest() {
        context = new MyLoadBalancerContext();
        context.setLoadBalancer(lb);
    }
    
    @Test
    public void testComputeFinalUriWithLoadBalancer() throws ClientException {
        HttpRequest request = HttpRequest.newBuilder().uri("/test?abc=xyz").build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals("http://www.example.com:8080/test?abc=xyz", newRequest.getUri().toString());
    }
    
    @Test
    public void testEncodedPath() throws ClientException {
        String uri = "http://localhost:8080/resources/abc%2Fxyz";
        HttpRequest request = HttpRequest.newBuilder().uri(uri).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals(uri, newRequest.getUri().toString());
    }
    
    @Test
    public void testPreservesUserInfo() throws ClientException {
        // %3A == ":" -- ensure user info is not decoded
        String uri = "http://us%3Aer:pass@localhost:8080?foo=bar";
        HttpRequest request = HttpRequest.newBuilder().uri(uri).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals(uri, newRequest.getUri().toString());
    }
    
    @Test
    public void testQueryWithoutPath() throws ClientException {
        String uri = "?foo=bar";
        HttpRequest request = HttpRequest.newBuilder().uri(uri).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals("http://www.example.com:8080?foo=bar", newRequest.getUri().toString());
    }
    
    @Test
    public void testEncodedPathAndHostChange() throws ClientException {
        String uri = "/abc%2Fxyz";
        HttpRequest request = HttpRequest.newBuilder().uri(uri).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals("http://www.example.com:8080" + uri, newRequest.getUri().toString());
    }

    
    @Test
    public void testEncodedQuery() throws Exception {
        String uri = "http://localhost:8080/resources/abc?";
        String queryString = "name=" + URLEncoder.encode("Ã©Æ&=*%!@#$%^&*()", "UTF-8");   
        HttpRequest request = HttpRequest.newBuilder().uri(uri + queryString).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals(uri + queryString, newRequest.getUri().toString());        
    }
}

class MyLoadBalancerContext extends LoadBalancerContext<HttpRequest, HttpResponse> {
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_7620032_42c3e4c/rev_7620032-42c3e4c/ribbon-httpclient/src/test/java/com/netflix/niws/client/http/RestClientTest.java;<<<<<<< MINE
=======
import com.netflix.client.config.CommonClientConfigKey;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_7620032_42c3e4c/rev_7620032-42c3e4c/ribbon-httpclient/src/test/java/com/netflix/niws/client/http/RestClientTest.java;<<<<<<< MINE
=======
        ConfigurationManager.getConfigInstance().setProperty("allservices.ribbon." + CommonClientConfigKey.ReadTimeout, "10000");
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_7620032_42c3e4c/rev_7620032-42c3e4c/ribbon-httpclient/src/test/java/com/netflix/niws/client/http/RestClientTest.java;<<<<<<< MINE
        Server[] servers = new Server[]{new Server("www.google.com", 80), new Server("www.yahoo.com", 80), new Server("www.microsoft.com", 80)};
=======
        Server[] servers = new Server[]{new Server("www.google.com", 80)};
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_7620032_42c3e4c/rev_7620032-42c3e4c/ribbon-httpclient/src/test/java/com/netflix/niws/client/http/RestClientTest.java;<<<<<<< MINE
        expected.add(new URI("http://www.microsoft.com:80/"));
        expected.add(new URI("http://www.yahoo.com:80/"));
=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/extension/MultiDexConfig.java;<<<<<<< MINE
    private Set<String> mainDexWhiteList = Sets.newHashSet();

=======
    @Config(title = "ä¸è¿å¥ç¬¬ä¸ä¸ªdexçé»åååè¡¨", message = "a", order = 2, group = "atlas")
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/extension/MultiDexConfig.java;<<<<<<< MINE
    public Set<String> getMainDexWhiteList() {
        return mainDexWhiteList;
    }

    public void setMainDexWhiteList(Set<String> mainDexWhiteList) {
        this.mainDexWhiteList = mainDexWhiteList;
    }

=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
        AaptPackageProcessBuilder aaptPackageCommandBuilder = new AaptPackageProcessBuilder(
            miniManifest,
            aaptOptions).setAssetsFolder(assetsFolder)
=======
        AaptPackageProcessBuilder aaptPackageCommandBuilder = new AaptPackageProcessBuilder(miniManifest,
                                                                                            aaptOptions).setAssetsFolder(
            assetsFolder)
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
        ProcessOutputHandler processOutputHandler = new ParsingProcessOutputHandler(new ToolOutputParser(
            new AaptOutputParser(),
            getILogger()), new MergingLogRewriter(mergingLog, builder.getErrorReporter()));
=======
        ProcessOutputHandler processOutputHandler
            = new ParsingProcessOutputHandler(new ToolOutputParser(new AaptOutputParser(), getILogger()),
                                              new MergingLogRewriter(mergingLog, builder.getErrorReporter()));
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
        private AppVariantContext appVariantContext;
=======
        private final AppVariantContext appVariantContext;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
        public ConfigAction(AppVariantContext appVariantContext,
                            BaseVariantOutputData baseVariantOutputData) {
=======
        public ConfigAction(AppVariantContext appVariantContext, BaseVariantOutputData baseVariantOutputData) {
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
            if (variantData.getSplitHandlingPolicy() ==
                SplitHandlingPolicy.RELEASE_21_AND_AFTER_POLICY) {
=======
            if (variantData.getSplitHandlingPolicy() == SplitHandlingPolicy.RELEASE_21_AND_AFTER_POLICY) {
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
            processDiffResources.mergeBlameLogFolder = scope.getVariantScope()
                .getResourceBlameLogDir();
            processDiffResources.pseudoLocalesEnabled = config.getBuildType()
                .isPseudoLocalesEnabled();
=======
            processDiffResources.mergeBlameLogFolder = scope.getVariantScope().getResourceBlameLogDir();
            processDiffResources.pseudoLocalesEnabled = config.getBuildType().isPseudoLocalesEnabled();
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
                    return new File(appVariantContext.apContext.getApExploredFolder(),  "AndroidManifest.xml");
=======
                    return new File(appVariantContext.apContext.getApExploredFolder(), "AndroidManifest.xml");
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
            ConventionMappingHelper.map(processDiffResources,
                                        "aaptOptions",
                                        new Callable<AaptOptions>() {
                                            @Override
                                            public AaptOptions call() throws Exception {
                                                //è®¾ç½®aaptåæ°
                                                AaptOptions aaptOptions = scope.getGlobalScope()
                                                    .getExtension()
                                                    .getAaptOptions();
                                                if (null == aaptOptions.getAdditionalParameters() ||
                                                    !aaptOptions.getAdditionalParameters()
                                                        .contains("-B")) {

                                                    PatchConfig patchConfig = appVariantContext.getBuildType()
                                                        .getPatchConfig();
                                                    if (patchConfig == null ||
                                                        !(patchConfig.isCreateAPatch() ||
                                                            patchConfig.isCreateTPatch())) {
                                                        return aaptOptions;
                                                    }

                                                    AaptOptions cloneAaptOptions = new AaptOptions();
                                                    try {
                                                        BeanUtils.copyProperties(cloneAaptOptions,
                                                                                 aaptOptions);
                                                    } catch (Throwable e) {
                                                        throw new StopExecutionException(e.getMessage());
                                                    }
                                                    aaptOptions = cloneAaptOptions;

                                                    List<String> additionParameters = aaptOptions
                                                        .getAdditionalParameters();
                                                    if (null == additionParameters) {
                                                        additionParameters = new ArrayList<String>();
                                                    }
                                                    additionParameters.add("-B");
                                                    additionParameters.add(appVariantContext.apContext
                                                                               .getBaseApk()
                                                                               .getAbsolutePath());
                                                }
                                                return aaptOptions;
                                            }
                                        });

            ConventionMappingHelper.map(processDiffResources,
                                        "resourceConfigs",
                                        new Callable<Collection<String>>() {
                                            @Override
                                            public Collection<String> call() throws Exception {
                                                Collection<String> resConfigs = config.getMergedFlavor()
                                                    .getResourceConfigurations();
                                                if (resConfigs.size() == 1 &&
                                                    Iterators.getOnlyElement(resConfigs.iterator())
                                                        .equals("auto")) {
                                                    if (scope.getGlobalScope()
                                                        .getAndroidBuilder()
                                                        .getTargetInfo()
                                                        .getBuildTools()
                                                        .getRevision()
                                                        .getMajor() >= 21) {
                                                        return variantData.discoverListOfResourceConfigsNotDensities();
                                                    } else {
                                                        return variantData.discoverListOfResourceConfigs();
                                                    }
                                                }
                                                return config.getMergedFlavor()
                                                    .getResourceConfigurations();
                                            }
                                        });

            ConventionMappingHelper.map(processDiffResources,
                                        "preferredDensity",
                                        new Callable<String>() {
                                            @Override
                                            @Nullable
                                            public String call() throws Exception {
                                                String variantFilter = variantOutputData.getMainOutputFile()
                                                    .getFilter(com.android.build.OutputFile.DENSITY);
                                                if (variantFilter != null) {
                                                    return variantFilter;
                                                }
                                                return AndroidGradleOptions.getBuildTargetDensity(
                                                    scope.getGlobalScope().getProject());
                                            }
                                        });
=======
            ConventionMappingHelper.map(processDiffResources, "aaptOptions", new Callable<AaptOptions>() {
                @Override
                public AaptOptions call() throws Exception {
                    //è®¾ç½®aaptåæ°
                    AaptOptions aaptOptions = scope.getGlobalScope().getExtension().getAaptOptions();
                    if (null == aaptOptions.getAdditionalParameters() || !aaptOptions.getAdditionalParameters()
                        .contains("-B")) {

                        PatchConfig patchConfig = appVariantContext.getBuildType().getPatchConfig();
                        if (patchConfig == null || !(patchConfig.isCreateAPatch() || patchConfig.isCreateTPatch())) {
                            return aaptOptions;
                        }

                        AaptOptions cloneAaptOptions = new AaptOptions();
                        try {
                            BeanUtils.copyProperties(cloneAaptOptions, aaptOptions);
                        } catch (Throwable e) {
                            throw new StopExecutionException(e.getMessage());
                        }
                        aaptOptions = cloneAaptOptions;

                        List<String> additionParameters = aaptOptions.getAdditionalParameters();
                        if (null == additionParameters) {
                            additionParameters = new ArrayList<String>();
                        }
                        additionParameters.add("-B");
                        additionParameters.add(appVariantContext.apContext.getBaseApk().getAbsolutePath());
                    }
                    return aaptOptions;
                }
            });

            ConventionMappingHelper.map(processDiffResources, "resourceConfigs", new Callable<Collection<String>>() {
                @Override
                public Collection<String> call() throws Exception {
                    Collection<String> resConfigs = config.getMergedFlavor().getResourceConfigurations();
                    if (resConfigs.size() == 1 && Iterators.getOnlyElement(resConfigs.iterator()).equals("auto")) {
                        if (scope.getGlobalScope()
                            .getAndroidBuilder()
                            .getTargetInfo()
                            .getBuildTools()
                            .getRevision()
                            .getMajor() >= 21) {
                            return variantData.discoverListOfResourceConfigsNotDensities();
                        } else {
                            return variantData.discoverListOfResourceConfigs();
                        }
                    }
                    return config.getMergedFlavor().getResourceConfigurations();
                }
            });

            ConventionMappingHelper.map(processDiffResources, "preferredDensity", new Callable<String>() {
                @Override
                @Nullable
                public String call() throws Exception {
                    String variantFilter = variantOutputData.getMainOutputFile()
                        .getFilter(com.android.build.OutputFile.DENSITY);
                    if (variantFilter != null) {
                        return variantFilter;
                    }
                    return AndroidGradleOptions.getBuildTargetDensity(scope.getGlobalScope().getProject());
                }
            });
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
                    File baseApkFileList = new File(appVariantContext.apContext.getApExploredFolder(),
                                                    APK_FILE_LIST);
=======
                    File baseApkFileList = new File(appVariantContext.apContext.getApExploredFolder(), APK_FILE_LIST);
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
                                              "tpatch" +
                                                  File.separator +
                                                  config.getFullName() +
                                                  File.separator +
                                                  "raw-res");
=======
                                              "tpatch"
                                                  + File.separator
                                                  + config.getFullName()
                                                  + File.separator
                                                  + "raw-res");
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
                                            "tpatch" +
                                                File.separator +
                                                config.getFullName() +
                                                File.separator +
                                                "diff-res");
=======
                                            "tpatch"
                                                + File.separator
                                                + config.getFullName()
                                                + File.separator
                                                + "diff-res");
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
                    ApkFileList baseApkFiles = JSON.parseObject(FileUtils.readFileToString(
                        baseApkFileList), ApkFileList.class);
=======
                    ApkFileList baseApkFiles = JSON.parseObject(FileUtils.readFileToString(baseApkFileList),
                                                                ApkFileList.class);
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
                    FileUtils.copyDirectory(scope.getVariantScope().getFinalResourcesDir(),
                                            new File(rawResDir, "res"));
                    FileUtils.copyDirectory(variantData.mergeAssetsTask.getOutputDir(),
                                            new File(rawResDir, "assets"));
=======
                    FileUtils.copyDirectory(scope.getVariantScope().getFinalResourcesDir(), new File(rawResDir, "res"));
                    FileUtils.copyDirectory(variantData.mergeAssetsTask.getOutputDir(), new File(rawResDir, "assets"));
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
                    DiffResExtractor.extractDiff(diffFiles,
=======
                    DiffResExtractor.extractDiff(appVariantContext,
                                                 diffFiles,
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tasks/tpatch/TPatchDiffResAPBuildTask.java;<<<<<<< MINE
                                                 diffDir);
=======
                                                 diffDir,
                                                 patchConfig.isFullResValues());
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/xml/XmlHelper.java;<<<<<<< MINE
=======
import java.util.List;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/xml/XmlHelper.java;<<<<<<< MINE
=======
import org.dom4j.Element;
import org.dom4j.Node;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/xml/XmlHelper.java;<<<<<<< MINE
    public static void saveFile(Document document,
                                OutputFormat format,
                                File file) throws IOException {
=======
    public static void saveFile(Document document, OutputFormat format, File file) throws IOException {
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/xml/XmlHelper.java;<<<<<<< MINE
=======
    public static void removeStringValue(File file, String key) throws IOException, DocumentException {

        if (!file.exists()) {
            return;
        }

        Document document = XmlHelper.readXml(file);// è¯»åXMLæä»¶
        Element root = document.getRootElement();// å¾å°æ ¹èç¹
        List<? extends Node> nodes = root.selectNodes("//string");
        for (Node node : nodes) {
            Element element = (Element)node;
            String name = element.attributeValue("name");
            if (key.equals(name)) {
                element.getParent().remove(element);
                break;
            }
        }
        // sLogger.warn("[resxmlediter] add " + key + " to " + file.getAbsolutePath());
        XmlHelper.saveDocument(document, file);
    }
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
=======
import java.util.regex.Matcher;
import java.util.regex.Pattern;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
=======
import com.android.build.gradle.internal.api.AppVariantContext;
import com.taobao.android.builder.AtlasBuildContext;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
=======
import groovy.lang.Closure;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
=======
import org.gradle.api.file.CopySpec;

import static com.taobao.android.builder.tools.xml.XmlHelper.removeStringValue;
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
=======
     * @param appVariantContext
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
    public static void extractDiff(Set<String> diffResFiles, File currentApk, File baseApk, File fullResDir,
                                   File destDir) throws IOException {
=======
    public static void extractDiff(AppVariantContext appVariantContext, Set<String> diffResFiles, File currentApk,
                                   File baseApk, File fullResDir, File destDir, boolean fullValues) throws IOException {
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE

=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
            if (baseFile.exists() && currentFile.exists() && MD5Util.getFileMD5(baseFile).equals(
                MD5Util.getFileMD5(currentFile))) {
=======
            if (baseFile.exists() && currentFile.exists() && MD5Util.getFileMD5(baseFile).equals(MD5Util.getFileMD5(
                currentFile))) {
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE

=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
        //å¿é¡»çæresource.arsc
=======
        // //å¿é¡»çæresource.arsc
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
        if (!resDir.exists()) {
            File valuesDir = new File(resDir, "values");
            FileUtils.forceMkdir(valuesDir);
            File stringsFile = new File(valuesDir, "strings.xml");
            UUID uuid = UUID.randomUUID();
            FileUtils.writeStringToFile(stringsFile, String.format(
                "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<resources>\n    <string "
                    + "name=\"%s\">%s</string>\n</resources>\n",
                uuid, uuid), "UTF-8", false);
=======
        File valuesDir = new File(resDir, "values");
        FileUtils.forceMkdir(valuesDir);
        if (fullValues) {
            appVariantContext.getProject().copy(new Closure(DiffResExtractor.class) {
                public Object doCall(CopySpec cs) {
                    cs.from(fullResDir);
                    cs.into(destDir);
                    cs.include("res/values*/**");

                    return cs;
                }
            });

            // FileUtils.copyFile(new File(fullResDir, "res/values/values.xml"),
            //                    new File(destDir, "res/values/values.xml"));
        } else {
            if (!resDir.exists()) {
                File stringsFile = new File(valuesDir, "strings.xml");
                UUID uuid = UUID.randomUUID();
                FileUtils.writeStringToFile(stringsFile,
                                            String.format(
                                                "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<resources>\n    <string "
                                                    + "name=\"%s\">%s</string>\n</resources>\n",
                                                uuid,
                                                uuid),
                                            "UTF-8",
                                            false);
            }
        }
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
        //è®¾ç½®values.xml
        File valuesXml = new File(resDir, "values/values.xml");
        try {
            removeStringValue(valuesXml, "ttid");
        } catch (Exception e) {
            throw new RuntimeException(e);
=======
        //è®¾ç½®values.xml
        File valuesXml = new File(resDir, "values/values.xml");
        AtlasBuildContext.sBuilderAdapter.apkInjectInfoCreator.injectTpatchValuesRes(appVariantContext, valuesXml);
        try {
            removeStringValue(valuesXml, "config_channel");
            removeStringValue(valuesXml, "ttid");
            removeStringValue(valuesXml, "config_channel");
        } catch (Exception e) {
            throw new RuntimeException(e);
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE
        //final Pattern densityOnlyPattern = Pattern.compile("[a-zA-Z]+-[a-zA-Z]+dpi");
        //if (resDir.exists()) {
        //    File[] resDirs = resDir.listFiles();
        //    if (resDirs != null) {
        //        for (File file : resDirs) {
        //            Matcher m = densityOnlyPattern.matcher(file.getName());
        //            if (m.matches()) {
        //                FileUtils.moveDirectory(file, new File(file.getAbsolutePath() + "-v4"));
        //            }
        //        }
        //    }
        //}

=======
        final Pattern densityOnlyPattern = Pattern.compile("[a-zA-Z]+-[a-zA-Z]+dpi");
        if (resDir.exists()) {
            File[] resDirs = resDir.listFiles();
            if (resDirs != null) {
                for (File file : resDirs) {
                    Matcher m = densityOnlyPattern.matcher(file.getName());
                    if (m.matches()) {
                        FileUtils.moveDirectory(file, new File(file.getAbsolutePath() + "-v3"));
                    }
                }
            }
        }
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/diff/DiffResExtractor.java;<<<<<<< MINE

=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/sign/AndroidSigner.java;<<<<<<< MINE
=======
import java.io.File;
import java.io.IOException;
import java.util.Map;

>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/sign/AndroidSigner.java;<<<<<<< MINE
import java.io.File;
import java.io.IOException;

=======
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_4e151bd_ffb0907/rev_4e151bd-ffb0907/atlas-gradle-plugin/atlas-plugin/src/main/java/com/taobao/android/builder/tools/sign/AndroidSigner.java;<<<<<<< MINE
=======
    public boolean signFile(File inFile, File outFile, DefaultSigningConfig signingConfig, Map params) throws IOException,
                                                                                                       SigningException {
        return signFile(inFile,outFile,signingConfig);
    }

>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/serialization/SerializationFactory.java;<<<<<<< MINE
package com.netflix.serialization;

import com.google.common.base.Optional;


public interface SerializationFactory<K extends Object> {
    public Optional<Deserializer> getDeserializer(K key);  
    public Optional<Serializer> getSerializer(K key);
}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.serialization;

import com.google.common.base.Optional;


public interface SerializationFactory<K> {
    public Optional<Deserializer> getDeserializer(K key);  
    public Optional<Serializer> getSerializer(K key);
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/serialization/ContentTypeBasedSerializerKey.java;<<<<<<< MINE
package com.netflix.serialization;

import com.google.common.reflect.TypeToken;

public class ContentTypeBasedSerializerKey {
    private final String contentType;
    private final TypeToken<?> typeToken;
    private final Class<?> classType;
    
    public ContentTypeBasedSerializerKey(String contentType, Class<?> classType) {
        super();
        this.contentType = contentType;
        this.typeToken = TypeToken.of(classType);
        this.classType = classType;
    }
    
    public ContentTypeBasedSerializerKey(String contentType, TypeToken<?> typeToken) {
        super();
        this.contentType = contentType;
        this.typeToken = typeToken;
        this.classType = typeToken.getClass();
    }


    public final String getContentType() {
        return contentType;
    }

    public final Class<?> getClassType() {
        return classType;
    }
    
    public final TypeToken<?> getTypeToken() {
        return typeToken;
    }
    
    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result
                + ((classType == null) ? 0 : classType.hashCode());
        result = prime * result
                + ((contentType == null) ? 0 : contentType.hashCode());
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj)
            return true;
        if (obj == null)
            return false;
        if (getClass() != obj.getClass())
            return false;
        ContentTypeBasedSerializerKey other = (ContentTypeBasedSerializerKey) obj;
        if (classType == null) {
            if (other.classType != null)
                return false;
        } else if (!classType.equals(other.classType))
            return false;
        if (contentType == null) {
            if (other.contentType != null)
                return false;
        } else if (!contentType.equals(other.contentType))
            return false;
        return true;
    }

    @Override
    public String toString() {
        return "DefaultSerializerKey [contentType=" + contentType
                + ", classType=" + classType + "]";
    }
    
    
    
}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.serialization;

import com.google.common.reflect.TypeToken;

public class ContentTypeBasedSerializerKey {
    private final String contentType;
    private final TypeToken<?> typeToken;
    private final Class<?> classType;
    
    public ContentTypeBasedSerializerKey(String contentType, Class<?> classType) {
        super();
        this.contentType = contentType;
        this.typeToken = TypeToken.of(classType);
        this.classType = classType;
    }
    
    public ContentTypeBasedSerializerKey(String contentType, TypeToken<?> typeToken) {
        super();
        this.contentType = contentType;
        this.typeToken = typeToken;
        this.classType = typeToken.getClass();
    }


    public final String getContentType() {
        return contentType;
    }

    public final Class<?> getClassType() {
        return classType;
    }
    
    public final TypeToken<?> getTypeToken() {
        return typeToken;
    }
    
    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result
                + ((classType == null) ? 0 : classType.hashCode());
        result = prime * result
                + ((contentType == null) ? 0 : contentType.hashCode());
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj)
            return true;
        if (obj == null)
            return false;
        if (getClass() != obj.getClass())
            return false;
        ContentTypeBasedSerializerKey other = (ContentTypeBasedSerializerKey) obj;
        if (classType == null) {
            if (other.classType != null)
                return false;
        } else if (!classType.equals(other.classType))
            return false;
        if (contentType == null) {
            if (other.contentType != null)
                return false;
        } else if (!contentType.equals(other.contentType))
            return false;
        return true;
    }

    @Override
    public String toString() {
        return "DefaultSerializerKey [contentType=" + contentType
                + ", classType=" + classType + "]";
    }
    
    
    
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/serialization/JacksonSerializationFactory.java;<<<<<<< MINE
package com.netflix.serialization;

import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.lang.reflect.Type;

import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.type.TypeReference;

import com.google.common.base.Optional;
import com.google.common.reflect.TypeToken;

public class JacksonSerializationFactory implements SerializationFactory<ContentTypeBasedSerializerKey>{

    private static final JsonCodec instance = new JsonCodec();
    @Override
    public Optional<Deserializer> getDeserializer(ContentTypeBasedSerializerKey key) {
        if (key.getContentType().equalsIgnoreCase("application/json")) {
            return Optional.<Deserializer>of(instance);
        }
        return Optional.absent();
    }

    @Override
    public Optional<Serializer> getSerializer(ContentTypeBasedSerializerKey key) {
        if (key.getContentType().equalsIgnoreCase("application/json")) {
            return Optional.<Serializer>of(instance);
        }
        return Optional.absent();
    }

}

class JsonCodec implements Serializer, Deserializer {
    private ObjectMapper mapper = new ObjectMapper();
    
    @Override
    public <T> T deserialize(byte[] content, Class<T> type) throws IOException {
        return mapper.readValue(content, type);
    }

    @Override
    public byte[] serialize(Object object) throws IOException {
        return mapper.writeValueAsBytes(object);
    }

    @Override
    public <T> T deserialize(InputStream in, Class<T> type) throws IOException {
        return mapper.readValue(in, type);
    }

    @Override
    public void serialize(OutputStream out, Object object) throws IOException {
        mapper.writeValue(out, object);
    }

    @Override
    public <T> T deserialize(byte[] content, TypeToken<T> type)
            throws IOException {
        return mapper.readValue(content, new TypeTokenBasedReference<T>(type));
    }

    @Override
    public <T> T deserialize(InputStream in, TypeToken<T> type)
            throws IOException {
        return mapper.readValue(in, new TypeTokenBasedReference<T>(type));
    }
}

class TypeTokenBasedReference<T> extends TypeReference<T> {
    
    final Type type;
    public TypeTokenBasedReference(TypeToken<T> typeToken) {
        type = typeToken.getType();    
        
    }

    @Override
    public Type getType() {
        return type;
    }
}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.serialization;

import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.lang.reflect.Type;

import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.type.TypeReference;

import com.google.common.base.Optional;
import com.google.common.reflect.TypeToken;

public class JacksonSerializationFactory implements SerializationFactory<ContentTypeBasedSerializerKey>{

    private static final JsonCodec instance = new JsonCodec();
    @Override
    public Optional<Deserializer> getDeserializer(ContentTypeBasedSerializerKey key) {
        if (key.getContentType().equalsIgnoreCase("application/json")) {
            return Optional.<Deserializer>of(instance);
        }
        return Optional.absent();
    }

    @Override
    public Optional<Serializer> getSerializer(ContentTypeBasedSerializerKey key) {
        if (key.getContentType().equalsIgnoreCase("application/json")) {
            return Optional.<Serializer>of(instance);
        }
        return Optional.absent();
    }

}

class JsonCodec implements Serializer, Deserializer {
    private final ObjectMapper mapper = new ObjectMapper();

    @Override
    public <T> T deserialize(InputStream in, TypeToken<T> type)
            throws IOException {
        return mapper.readValue(in, new TypeTokenBasedReference<T>(type));
    }
    
    @Override
    public void serialize(OutputStream out, Object object) throws IOException {
        mapper.writeValue(out, object);
    }
}

class TypeTokenBasedReference<T> extends TypeReference<T> {
    
    final Type type;
    public TypeTokenBasedReference(TypeToken<T> typeToken) {
        type = typeToken.getType();    
        
    }

    @Override
    public Type getType() {
        return type;
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/serialization/Deserializer.java;<<<<<<< MINE
package com.netflix.serialization;

import java.io.IOException;
import java.io.InputStream;

import com.google.common.reflect.TypeToken;

public interface Deserializer {
    public <T> T deserialize(byte[] content, Class<T> type) throws IOException;
    
    public <T> T deserialize(InputStream in, Class<T> type) throws IOException;
    
    public <T> T deserialize(byte[] content, TypeToken<T> typeToken) throws IOException;
    
    public <T> T deserialize(InputStream in, TypeToken<T> type) throws IOException;    


}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.serialization;

import java.io.IOException;
import java.io.InputStream;

import com.google.common.reflect.TypeToken;

public interface Deserializer {
    public <T> T deserialize(InputStream in, TypeToken<T> type) throws IOException;    
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/serialization/Serializer.java;<<<<<<< MINE
package com.netflix.serialization;

import java.io.IOException;
import java.io.OutputStream;

public interface Serializer {
    public byte[] serialize(Object object) throws IOException;
    
    public void serialize(OutputStream out, Object object) throws IOException;    

}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.serialization;

import java.io.IOException;
import java.io.OutputStream;

public interface Serializer {
    public void serialize(OutputStream out, Object object) throws IOException;    
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/AbstractLoadBalancerAwareClient.java;<<<<<<< MINE

    protected String clientName = "default";          
    
    protected String vipAddresses;
    
    protected int maxAutoRetriesNextServer = DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES_NEXT_SERVER;
    protected int maxAutoRetries = DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES;


    boolean okToRetryOnAllOperations = DefaultClientConfigImpl.DEFAULT_OK_TO_RETRY_ON_ALL_OPERATIONS.booleanValue();
        
    private ILoadBalancer lb;
    protected volatile Timer tracer;

    
    public AbstractLoadBalancerAwareClient() {  
    }
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/AbstractLoadBalancerAwareClient.java;<<<<<<< MINE
    public final String getClientName() {
        return clientName;
    }
        
    public ILoadBalancer getLoadBalancer() {
        return lb;    
    }
        
    public void setLoadBalancer(ILoadBalancer lb) {
        this.lb = lb;
    }

    public final int getMaxAutoRetriesNextServer() {
        return maxAutoRetriesNextServer;
    }

    public final void setMaxAutoRetriesNextServer(int maxAutoRetriesNextServer) {
        this.maxAutoRetriesNextServer = maxAutoRetriesNextServer;
    }

    public final int getMaxAutoRetries() {
        return maxAutoRetries;
    }

    public final void setMaxAutoRetries(int maxAutoRetries) {
        this.maxAutoRetries = maxAutoRetries;
    }

    protected Throwable getDeepestCause(Throwable e) {
        if(e != null) {
            int infiniteLoopPreventionCounter = 10;
            while (e.getCause() != null && infiniteLoopPreventionCounter > 0) {
                infiniteLoopPreventionCounter--;
                e = e.getCause();
            }
        }
        return e;
    }

=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/AbstractLoadBalancerAwareClient.java;<<<<<<< MINE
    protected abstract boolean isCircuitBreakerException(Exception e);
=======
    protected abstract boolean isCircuitBreakerException(Throwable e);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/AbstractLoadBalancerAwareClient.java;<<<<<<< MINE
    protected abstract boolean isRetriableException(Exception e);
=======
    protected abstract boolean isRetriableException(Throwable e);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/AbstractLoadBalancerAwareClient.java;<<<<<<< MINE
    private boolean isPresentAsCause(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor) {
        return isPresentAsCauseHelper(throwableToSearchIn, throwableToSearchFor) != null;
    }

    private Throwable isPresentAsCauseHelper(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor) {
        int infiniteLoopPreventionCounter = 10;
        while (throwableToSearchIn != null && infiniteLoopPreventionCounter > 0) {
            infiniteLoopPreventionCounter--;
            if (throwableToSearchIn.getClass().isAssignableFrom(
                    throwableToSearchFor)) {
                return throwableToSearchIn;
            } else {
                throwableToSearchIn = throwableToSearchIn.getCause();
            }
        }
        return null;
    }

    protected ClientException generateNIWSException(String uri, Throwable e){
        ClientException niwsClientException;
        if (isPresentAsCause(e, java.net.SocketTimeoutException.class)) {
            niwsClientException = generateTimeoutNIWSException(uri, e);
        }else if (e.getCause() instanceof java.net.UnknownHostException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.UNKNOWN_HOST_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e.getCause() instanceof java.net.ConnectException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.CONNECT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e.getCause() instanceof java.net.NoRouteToHostException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.NO_ROUTE_TO_HOST_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e instanceof ClientException){
            niwsClientException = (ClientException)e;
        }else {
            niwsClientException = new ClientException(
                ClientException.ErrorType.GENERAL,
                "Unable to execute RestClient request for URI:" + uri,
                e);
        }
        return niwsClientException;
    }

    private boolean isPresentAsCause(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor, String messageSubStringToSearchFor) {
        Throwable throwableFound = isPresentAsCauseHelper(throwableToSearchIn, throwableToSearchFor);
        if(throwableFound != null) {
            return throwableFound.getMessage().contains(messageSubStringToSearchFor);
        }
        return false;
    }
    private ClientException generateTimeoutNIWSException(String uri, Throwable e){
        ClientException niwsClientException;
        if (isPresentAsCause(e, java.net.SocketTimeoutException.class,
                "Read timed out")) {
            niwsClientException = new ClientException(
                    ClientException.ErrorType.READ_TIMEOUT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri + ":"
                            + getDeepestCause(e).getMessage(), e);
        } else {
            niwsClientException = new ClientException(
                    ClientException.ErrorType.SOCKET_TIMEOUT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri + ":"
                            + getDeepestCause(e).getMessage(), e);
        }
        return niwsClientException;
    }

    protected int handleRetry(String uri, int retries, int numRetries,
            Exception e) throws ClientException {
        retries++;

        if (retries > numRetries) {
            throw new ClientException(ClientException.ErrorType.NUMBEROF_RETRIES_EXEEDED,
                    "NUMBEROFRETRIESEXEEDED :" + numRetries + " retries, while making a RestClient call for:" + uri,
                    e !=null? e: new RuntimeException());
        }
        logger.error("Exception while executing request which is deemed retry-able, retrying ..., SAME Server Retry Attempt#:" +
                retries +
                ", URI:" +
                uri);
        try {
            Thread.sleep((int) Math.pow(2.0, retries) * 100); 
        } catch (InterruptedException ex) {
        }
        return retries;
    }

    /**
     * This is called after a response is received or an exception is thrown from the {@link #execute(ClientRequest)}
     * to update related stats.  
     */
    protected void noteRequestCompletion(ServerStats stats, S task, IResponse response, Throwable e, long responseTime) {        
        try {
            if (stats != null) {
                stats.decrementActiveRequestsCount();
                stats.incrementNumRequests();
                stats.noteResponseTime(responseTime);
                if (response != null) {
                    stats.clearSuccessiveConnectionFailureCount();                    
                }
            }            
        } catch (Throwable ex) {
            logger.error("Unexpected exception", ex);
        }            
    }
       
    /**
     * Called just before {@link #execute(ClientRequest)} call.
     */
    protected void noteOpenConnection(ServerStats serverStats, S task) {
        if (serverStats == null) {
            return;
        }
        try {
            serverStats.incrementActiveRequestsCount();
        } catch (Throwable e) {
            logger.info("Unable to note Server Stats:", e);
        }
    }

=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/config/CommonClientConfigKey.java;<<<<<<< MINE
    RulePredicateClasses("RulePredicateClasses"),
    
    // serialization
    SerializationFactoryClassName("SerializationClassName");

=======
    RulePredicateClasses("RulePredicateClasses"),
    
    // serialization
    DefaultSerializationFactoryClassName("DefaultSerializationClassName");

>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/config/IClientConfig.java;<<<<<<< MINE
=======
	
	public int getPropertyAsInteger(IClientConfigKey key, int defaultValue);

    public String getPropertyAsString(IClientConfigKey key, String defaultValue);
    
    public boolean getPropertyAsBoolean(IClientConfigKey key, boolean defaultValue);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/config/DefaultClientConfigImpl.java;<<<<<<< MINE
=======
	
	public static DefaultClientConfigImpl getClientConfigWithDefaultValues() {
	    DefaultClientConfigImpl config = new DefaultClientConfigImpl();
	    config.loadDefaultValues();
	    return config;
	}

>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/config/DefaultClientConfigImpl.java;<<<<<<< MINE
		DefaultClientConfigImpl config = new DefaultClientConfigImpl(nameSpace);
		config.loadProperties(clientName);
=======
	    DefaultClientConfigImpl config = new DefaultClientConfigImpl(nameSpace);
	    config.loadProperties(clientName);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/config/DefaultClientConfigImpl.java;<<<<<<< MINE
=======

    @Override
    public int getPropertyAsInteger(IClientConfigKey key, int defaultValue) {
        Object rawValue = getProperty(key);
        if (rawValue != null) {
            try {
                return Integer.parseInt(String.valueOf(rawValue));
            } catch (NumberFormatException e) {
                return defaultValue;
            }
        }
        return defaultValue;
        
    }

    @Override
    public String getPropertyAsString(IClientConfigKey key, String defaultValue) {
        Object rawValue = getProperty(key);
        if (rawValue != null) {
            return String.valueOf(rawValue);
        }
        return defaultValue;
    }

    @Override
    public boolean getPropertyAsBoolean(IClientConfigKey key,
            boolean defaultValue) {
        Object rawValue = getProperty(key);
        if (rawValue != null) {
            try {
                return Boolean.valueOf(String.valueOf(rawValue));
            } catch (NumberFormatException e) {
                return defaultValue;
            }
        }
        return defaultValue;
    }
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/AsyncClient.java;<<<<<<< MINE
package com.netflix.client;

public interface AsyncClient<Request extends ClientRequest, Response extends ResponseWithTypedEntity> {
    public void execute(Request request, ResponseCallback<Response> callback) throws ClientException;

}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.client;

import java.nio.ByteBuffer;
import java.util.concurrent.Future;

import com.netflix.serialization.ContentTypeBasedSerializerKey;
import com.netflix.serialization.Deserializer;
import com.netflix.serialization.Serializer;

/**
 * Interface for asynchronous communication client with streaming capability.
 * 
 * @author awang
 *
 * @param <T> Request type
 * @param <S> Response type
 * @param <U> Type of storage used for delivering partial content, for example, {@link ByteBuffer}
 * @param <V> Type of key to find {@link Serializer} and {@link Deserializer} for the content. For example, for HTTP communication,
 *            the key type is {@link ContentTypeBasedSerializerKey}
 */
public interface AsyncClient<T extends ClientRequest, S extends IResponse, U, V> extends ResponseBufferingAsyncClient<T, S, V> {
    /**
     * Asynchronously execute a request.
     * 
     * @param request Request to execute
     * @param decooder Decoder to decode objects from the native stream 
     * @param callback Callback to be invoked when execution completes or fails
     * @return Future of the response
     * @param <E> Type of object to be decoded from the stream
     * 
     * @throws ClientException if exception happens before the actual asynchronous execution happens, for example, an error to serialize 
     *         the entity
     */
    public <E> Future<S> execute(T request, StreamDecoder<E, U> decooder, ResponseCallback<S, E> callback) throws ClientException;
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/LoadBalancerContext.java;<<<<<<< MINE
package com.netflix.client;

import java.net.URI;
import java.net.URISyntaxException;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.netflix.client.config.CommonClientConfigKey;
import com.netflix.client.config.DefaultClientConfigImpl;
import com.netflix.client.config.IClientConfig;
import com.netflix.loadbalancer.AbstractLoadBalancer;
import com.netflix.loadbalancer.AvailabilityFilteringRule;
import com.netflix.loadbalancer.ILoadBalancer;
import com.netflix.loadbalancer.LoadBalancerStats;
import com.netflix.loadbalancer.Server;
import com.netflix.loadbalancer.ServerStats;
import com.netflix.util.Pair;

public abstract class LoadBalancerContext implements IClientConfigAware {
    private static final Logger logger = LoggerFactory.getLogger(LoadBalancerContext.class);

    protected String clientName = "default";          

    protected String vipAddresses;
    
    protected int maxAutoRetriesNextServer = DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES_NEXT_SERVER;
    protected int maxAutoRetries = DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES;


    boolean okToRetryOnAllOperations = DefaultClientConfigImpl.DEFAULT_OK_TO_RETRY_ON_ALL_OPERATIONS.booleanValue();
        
    private ILoadBalancer lb;

    
    /**
     * Set necessary parameters from client configuration and register with Servo monitors.
     */
    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
        if (clientConfig == null) {
            return;    
        }
        clientName = clientConfig.getClientName();
        if (clientName == null) {
            clientName = "default";
        }
        vipAddresses = clientConfig.resolveDeploymentContextbasedVipAddresses();
        maxAutoRetries = clientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetries, DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES);
        maxAutoRetriesNextServer = clientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetriesNextServer,maxAutoRetriesNextServer);
        
       okToRetryOnAllOperations = clientConfig.getPropertyAsBoolean(CommonClientConfigKey.OkToRetryOnAllOperations, okToRetryOnAllOperations);
    }
    
    /**
     * Delegate to {@link #initWithNiwsConfig(IClientConfig)}
     * @param clientConfig
     */
    public LoadBalancerContext(IClientConfig clientConfig) {
        initWithNiwsConfig(clientConfig);        
    }
    
    public LoadBalancerContext() {
        // TODO Auto-generated constructor stub
    }

    public final String getClientName() {
        return clientName;
    }
        
    public ILoadBalancer getLoadBalancer() {
        return lb;    
    }
        
    public void setLoadBalancer(ILoadBalancer lb) {
        this.lb = lb;
    }

    public final int getMaxAutoRetriesNextServer() {
        return maxAutoRetriesNextServer;
    }

    public final void setMaxAutoRetriesNextServer(int maxAutoRetriesNextServer) {
        this.maxAutoRetriesNextServer = maxAutoRetriesNextServer;
    }

    public final int getMaxAutoRetries() {
        return maxAutoRetries;
    }

    public final void setMaxAutoRetries(int maxAutoRetries) {
        this.maxAutoRetries = maxAutoRetries;
    }

    protected Throwable getDeepestCause(Throwable e) {
        if(e != null) {
            int infiniteLoopPreventionCounter = 10;
            while (e.getCause() != null && infiniteLoopPreventionCounter > 0) {
                infiniteLoopPreventionCounter--;
                e = e.getCause();
            }
        }
        return e;
    }

    /**
     * Determine if an exception should contribute to circuit breaker trip. If such exceptions happen consecutively
     * on a server, it will be deemed as circuit breaker tripped and enter into a time out when it will be
     * skipped by the {@link AvailabilityFilteringRule}, which is the default rule for load balancers.
     */
    protected abstract boolean isCircuitBreakerException(Throwable e);
        
    /**
     * Determine if operation can be retried if an exception is thrown. For example, connect 
     * timeout related exceptions
     * are typically retriable.
     * 
     */
    protected abstract boolean isRetriableException(Throwable e);
        
    private boolean isPresentAsCause(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor) {
        return isPresentAsCauseHelper(throwableToSearchIn, throwableToSearchFor) != null;
    }

    private Throwable isPresentAsCauseHelper(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor) {
        int infiniteLoopPreventionCounter = 10;
        while (throwableToSearchIn != null && infiniteLoopPreventionCounter > 0) {
            infiniteLoopPreventionCounter--;
            if (throwableToSearchIn.getClass().isAssignableFrom(
                    throwableToSearchFor)) {
                return throwableToSearchIn;
            } else {
                throwableToSearchIn = throwableToSearchIn.getCause();
            }
        }
        return null;
    }

    protected ClientException generateNIWSException(String uri, Throwable e){
        ClientException niwsClientException;
        if (isPresentAsCause(e, java.net.SocketTimeoutException.class)) {
            niwsClientException = generateTimeoutNIWSException(uri, e);
        }else if (e.getCause() instanceof java.net.UnknownHostException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.UNKNOWN_HOST_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e.getCause() instanceof java.net.ConnectException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.CONNECT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e.getCause() instanceof java.net.NoRouteToHostException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.NO_ROUTE_TO_HOST_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e instanceof ClientException){
            niwsClientException = (ClientException)e;
        }else {
            niwsClientException = new ClientException(
                ClientException.ErrorType.GENERAL,
                "Unable to execute RestClient request for URI:" + uri,
                e);
        }
        return niwsClientException;
    }

    private boolean isPresentAsCause(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor, String messageSubStringToSearchFor) {
        Throwable throwableFound = isPresentAsCauseHelper(throwableToSearchIn, throwableToSearchFor);
        if(throwableFound != null) {
            return throwableFound.getMessage().contains(messageSubStringToSearchFor);
        }
        return false;
    }
    private ClientException generateTimeoutNIWSException(String uri, Throwable e){
        ClientException niwsClientException;
        if (isPresentAsCause(e, java.net.SocketTimeoutException.class,
                "Read timed out")) {
            niwsClientException = new ClientException(
                    ClientException.ErrorType.READ_TIMEOUT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri + ":"
                            + getDeepestCause(e).getMessage(), e);
        } else {
            niwsClientException = new ClientException(
                    ClientException.ErrorType.SOCKET_TIMEOUT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri + ":"
                            + getDeepestCause(e).getMessage(), e);
        }
        return niwsClientException;
    }

    protected int handleRetry(String uri, int retries, int numRetries,
            Exception e) throws ClientException {
        retries++;

        if (retries > numRetries) {
            throw new ClientException(ClientException.ErrorType.NUMBEROF_RETRIES_EXEEDED,
                    "NUMBEROFRETRIESEXEEDED :" + numRetries + " retries, while making a RestClient call for:" + uri,
                    e !=null? e: new RuntimeException());
        }
        logger.error("Exception while executing request which is deemed retry-able, retrying ..., SAME Server Retry Attempt#:" +
                retries +
                ", URI:" +
                uri);
        try {
            Thread.sleep((int) Math.pow(2.0, retries) * 100); 
        } catch (InterruptedException ex) {
        }
        return retries;
    }

    /**
     * This is called after a response is received or an exception is thrown from the {@link #execute(ClientRequest)}
     * to update related stats.  
     */
    protected void noteRequestCompletion(ServerStats stats, ClientRequest request, IResponse response, Throwable e, long responseTime) {        
        try {
            if (stats != null) {
                stats.decrementActiveRequestsCount();
                stats.incrementNumRequests();
                stats.noteResponseTime(responseTime);
                if (response != null) {
                    stats.clearSuccessiveConnectionFailureCount();                    
                }
            }            
        } catch (Throwable ex) {
            logger.error("Unexpected exception", ex);
        }            
    }
       
    /**
     * Called just before {@link #execute(ClientRequest)} call.
     */
    protected void noteOpenConnection(ServerStats serverStats, ClientRequest request) {
        if (serverStats == null) {
            return;
        }
        try {
            serverStats.incrementActiveRequestsCount();
        } catch (Throwable e) {
            logger.info("Unable to note Server Stats:", e);
        }
    }

      
    /**
     * Derive scheme and port from a partial URI. For example, for HTTP based client, the URI with 
     * only path "/" should return "http" and 80, whereas the URI constructed with scheme "https" and
     * path "/" should return
     * "https" and 443. This method is called by {@link #computeFinalUriWithLoadBalancer(ClientRequest)}
     * to get the complete executable URI.
     * 
     */
    protected <T extends ClientRequest> Pair<String, Integer> deriveSchemeAndPortFromPartialUri(T request) {
        URI theUrl = request.getUri();
        boolean isSecure = false;
        String scheme = theUrl.getScheme();
        if (scheme != null) {
            isSecure =  scheme.equalsIgnoreCase("https");
        }
        int port = theUrl.getPort();
        if (port < 0 && !isSecure){
            port = 80;
        } else if (port < 0 && isSecure){
            port = 443;
        }
        if (scheme == null){
            if (isSecure) {
                scheme = "https";
            } else {
                scheme = "http";
            }
        }
        return new Pair<String, Integer>(scheme, port);
    }
    
    /**
     * Get the default port of the target server given the scheme of vip address if it is available. 
     * Subclass should override it to provider protocol specific default port number if any.
     * 
     * @param scheme from the vip address. null if not present.
     * @return 80 if scheme is http, 443 if scheme is https, -1 else.
     */
    protected int getDefaultPortFromScheme(String scheme) {
        if (scheme == null) {
            return -1;
        }
        if (scheme.equals("http")) {
            return 80;
        } else if (scheme.equals("https")) {
            return 443;
        } else {
            return -1;
        }
    }

        
    /**
     * Derive the host and port from virtual address if virtual address is indeed contains the actual host 
     * and port of the server. This is the final resort to compute the final URI in {@link #computeFinalUriWithLoadBalancer(ClientRequest)}
     * if there is no load balancer available and the request URI is incomplete. Sub classes can override this method
     * to be more accurate or throws ClientException if it does not want to support virtual address to be the
     * same as physical server address.
     * <p>
     *  The virtual address is used by certain load balancers to filter the servers of the same function 
     *  to form the server pool. 
     *  
     */
    protected  Pair<String, Integer> deriveHostAndPortFromVipAddress(String vipAddress) 
            throws URISyntaxException, ClientException {
        Pair<String, Integer> hostAndPort = new Pair<String, Integer>(null, -1);
        URI uri = new URI(vipAddress);
        String scheme = uri.getScheme();
        if (scheme == null) {
            uri = new URI("http://" + vipAddress);
        }
        String host = uri.getHost();
        if (host == null) {
            throw new ClientException("Unable to derive host/port from vip address " + vipAddress);
        }
        int port = uri.getPort();
        if (port < 0) {
            port = getDefaultPortFromScheme(scheme);
        }
        if (port < 0) {
            throw new ClientException("Unable to derive host/port from vip address " + vipAddress);
        }
        hostAndPort.setFirst(host);
        hostAndPort.setSecond(port);
        return hostAndPort;
    }
    
    private boolean isVipRecognized(String vipEmbeddedInUri) {
        if (vipEmbeddedInUri == null) {
            return false;
        }
        if (vipAddresses == null) {
            return false;
        }
        String[] addresses = vipAddresses.split(",");
        for (String address: addresses) {
            if (vipEmbeddedInUri.equalsIgnoreCase(address.trim())) {
                return true;
            }
        }
        return false;
    }
    
    /**
     * Compute the final URI from a partial URI in the request. The following steps are performed:
     * 
     * <li> if host is missing and there is a load balancer, get the host/port from server chosen from load balancer
     * <li> if host is missing and there is no load balancer, try to derive host/port from virtual address set with the client
     * <li> if host is present and the authority part of the URI is a virtual address set for the client, 
     * and there is a load balancer, get the host/port from server chosen from load balancer
     * <li> if host is present but none of the above applies, interpret the host as the actual physical address
     * <li> if host is missing but none of the above applies, throws ClientException
     * 
     * @param original Original URI passed from caller
     * @return new request with the final URI  
     */
    @SuppressWarnings("unchecked")
    protected <T extends ClientRequest> T computeFinalUriWithLoadBalancer(T original) throws ClientException{
        URI newURI;
        URI theUrl = original.getUri();

        if (theUrl == null){
            throw new ClientException(ClientException.ErrorType.GENERAL, "NULL URL passed in");
        }

        String host = theUrl.getHost();
        Pair<String, Integer> schemeAndPort = deriveSchemeAndPortFromPartialUri(original);
        String scheme = schemeAndPort.first();
        int port = schemeAndPort.second();
        // Various Supported Cases
        // The loadbalancer to use and the instances it has is based on how it was registered
        // In each of these cases, the client might come in using Full Url or Partial URL
        ILoadBalancer lb = getLoadBalancer();
        Object loadBalancerKey = original.getLoadBalancerKey();
        if (host == null){
            // Partial URL Case
            // well we have to just get the right instances from lb - or we fall back
            if (lb != null){
                Server svc = lb.chooseServer(loadBalancerKey);
                if (svc == null){
                    throw new ClientException(ClientException.ErrorType.GENERAL,
                            "LoadBalancer returned null Server for :"
                            + clientName);
                }
                host = svc.getHost();
                port = svc.getPort();
                if (host == null){
                    throw new ClientException(ClientException.ErrorType.GENERAL,
                            "Invalid Server for :" + svc);
                }
                if (logger.isDebugEnabled()){
                    logger.debug(clientName + " using LB returned Server:" + svc + "for request:" + theUrl);
                }
            } else {
                // No Full URL - and we dont have a LoadBalancer registered to
                // obtain a server
                // if we have a vipAddress that came with the registration, we
                // can use that else we
                // bail out
                if (vipAddresses != null && vipAddresses.contains(",")) {
                    throw new ClientException(
                            ClientException.ErrorType.GENERAL,
                            this.clientName
                                    + "Partial URI of ("
                                    + theUrl
                                    + ") has been sent in to RestClient (with no LB) to be executed."
                                    + " Also, there are multiple vipAddresses and hence RestClient cant pick"
                                    + "one vipAddress to complete this partial uri");
                } else if (vipAddresses != null) {
                    try {
                        Pair<String,Integer> hostAndPort = deriveHostAndPortFromVipAddress(vipAddresses);
                        host = hostAndPort.first();
                        port = hostAndPort.second();
                    } catch (URISyntaxException e) {
                        throw new ClientException(
                                ClientException.ErrorType.GENERAL,
                                this.clientName
                                        + "Partial URI of ("
                                        + theUrl
                                        + ") has been sent in to RestClient (with no LB) to be executed."
                                        + " Also, the configured/registered vipAddress is unparseable (to determine host and port)");
                    }
                }else{
                    throw new ClientException(
                            ClientException.ErrorType.GENERAL,
                            this.clientName
                                    + " has no LoadBalancer registered and passed in a partial URL request (with no host:port)."
                                    + " Also has no vipAddress registered");
                }
            }
        } else {
            // Full URL Case
            // This could either be a vipAddress or a hostAndPort or a real DNS
            // if vipAddress or hostAndPort, we just have to consult the loadbalancer
            // but if it does not return a server, we should just proceed anyways
            // and assume its a DNS
            // For restClients registered using a vipAddress AND executing a request
            // by passing in the full URL (including host and port), we should only
            // consult lb IFF the URL passed is registered as vipAddress in Discovery
            boolean shouldInterpretAsVip = false;

            if (lb != null) {
                shouldInterpretAsVip = isVipRecognized(original.getUri().getAuthority());
            }
            if (shouldInterpretAsVip) {
                Server svc = lb.chooseServer(loadBalancerKey);
                if (svc != null){
                    host = svc.getHost();
                    port = svc.getPort();
                    if (host == null){
                        throw new ClientException(ClientException.ErrorType.GENERAL,
                                "Invalid Server for :" + svc);
                    }
                    if (logger.isDebugEnabled()){
                        logger.debug("using LB returned Server:" + svc + "for request:" + theUrl);
                    }
                }else{
                    // just fall back as real DNS
                    if (logger.isDebugEnabled()){
                        logger.debug(host + ":" + port + " assumed to be a valid VIP address or exists in the DNS");
                    }
                }
            } else {
             // consult LB to obtain vipAddress backed instance given full URL
                //Full URL execute request - where url!=vipAddress
               if (logger.isDebugEnabled()){
                   logger.debug("Using full URL passed in by caller (not using LB/Discovery):" + theUrl);
               }
            }
        }
        // end of creating final URL
        if (host == null){
            throw new ClientException(ClientException.ErrorType.GENERAL,"Request contains no HOST to talk to");
        }
        // just verify that at this point we have a full URL

        try {
            String urlPath = "";
            if (theUrl.getRawPath() != null && theUrl.getRawPath().startsWith("/")) {
                urlPath = theUrl.getRawPath();
            } else {
                urlPath = "/" + theUrl.getRawPath();
            }
            
            newURI = new URI(scheme, theUrl.getUserInfo(), host, port, urlPath, theUrl.getQuery(), theUrl.getFragment());
            return (T) original.replaceUri(newURI);            
        } catch (URISyntaxException e) {
            throw new ClientException(ClientException.ErrorType.GENERAL, e.getMessage());
        }
    }

    protected boolean isRetriable(ClientRequest request) {
        if (request.isRetriable()) {
            return true;            
        } else {
            boolean retryOkayOnOperation = okToRetryOnAllOperations;
            IClientConfig overriddenClientConfig = request.getOverrideConfig();
            if (overriddenClientConfig != null) {
                retryOkayOnOperation = overriddenClientConfig.getPropertyAsBoolean(CommonClientConfigKey.RequestSpecificRetryOn, okToRetryOnAllOperations);
            }
            return retryOkayOnOperation;
        }
    }
    
    protected int getRetriesNextServer(IClientConfig overriddenClientConfig) {
        int numRetries = maxAutoRetriesNextServer;
        if (overriddenClientConfig != null) {
            numRetries = overriddenClientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetriesNextServer, maxAutoRetriesNextServer);
        }
        return numRetries;
    }
    
    public final ServerStats getServerStats(Server server) {
        ServerStats serverStats = null;
        ILoadBalancer lb = this.getLoadBalancer();
        if (lb instanceof AbstractLoadBalancer){
            LoadBalancerStats lbStats = ((AbstractLoadBalancer) lb).getLoadBalancerStats();
            serverStats = lbStats.getSingleServerStat(server);
        }
        return serverStats;

    }

    public final int getNumberRetriesOnSameServer(IClientConfig overriddenClientConfig) {
        int numRetries =  maxAutoRetries;
        if (overriddenClientConfig!=null){
            try {
                numRetries = Integer.parseInt(""+overriddenClientConfig.getProperty(CommonClientConfigKey.MaxAutoRetries,maxAutoRetries));
            } catch (Exception e) {
                logger.warn("Invalid maxRetries requested for RestClient:" + this.clientName);
            }
        }
        return numRetries;
    }

}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.client;

import java.net.URI;
import java.net.URISyntaxException;
import java.net.URLEncoder;
import java.util.Collection;
import java.util.concurrent.TimeUnit;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.base.Strings;
import com.netflix.client.config.CommonClientConfigKey;
import com.netflix.client.config.DefaultClientConfigImpl;
import com.netflix.client.config.IClientConfig;
import com.netflix.loadbalancer.AbstractLoadBalancer;
import com.netflix.loadbalancer.ILoadBalancer;
import com.netflix.loadbalancer.LoadBalancerStats;
import com.netflix.loadbalancer.Server;
import com.netflix.loadbalancer.ServerStats;
import com.netflix.servo.monitor.Monitors;
import com.netflix.servo.monitor.Timer;
import com.netflix.util.Pair;

/**
 * A class contains APIs intended to be used be load balancing client which is subclass of this class.
 * 
 * @author awang
 *
 * @param <T> Type of the request
 * @param <S> Type of the response
 */
public abstract class LoadBalancerContext<T extends ClientRequest, S extends IResponse> implements IClientConfigAware {
    private static final Logger logger = LoggerFactory.getLogger(LoadBalancerContext.class);

    protected String clientName = "default";          

    protected String vipAddresses;
    
    protected int maxAutoRetriesNextServer = DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES_NEXT_SERVER;
    protected int maxAutoRetries = DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES;

    protected LoadBalancerErrorHandler<? super T, ? super S> errorHandler = new DefaultLoadBalancerErrorHandler<ClientRequest, IResponse>();


    boolean okToRetryOnAllOperations = DefaultClientConfigImpl.DEFAULT_OK_TO_RETRY_ON_ALL_OPERATIONS.booleanValue();
        
    private ILoadBalancer lb;
    
    private volatile Timer tracer;

    public LoadBalancerContext() {
    }

    /**
     * Delegate to {@link #initWithNiwsConfig(IClientConfig)}
     * @param clientConfig
     */
    public LoadBalancerContext(IClientConfig clientConfig) {
        initWithNiwsConfig(clientConfig);        
    }

    /**
     * Set necessary parameters from client configuration and register with Servo monitors.
     */
    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
        if (clientConfig == null) {
            return;    
        }
        clientName = clientConfig.getClientName();
        if (clientName == null) {
            clientName = "default";
        }
        vipAddresses = clientConfig.resolveDeploymentContextbasedVipAddresses();
        maxAutoRetries = clientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetries, DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES);
        maxAutoRetriesNextServer = clientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetriesNextServer,maxAutoRetriesNextServer);
        
       okToRetryOnAllOperations = clientConfig.getPropertyAsBoolean(CommonClientConfigKey.OkToRetryOnAllOperations, okToRetryOnAllOperations);
       tracer = getExecuteTracer();

       Monitors.registerObject("Client_" + clientName, this);
    }

    protected Timer getExecuteTracer() {
        if (tracer == null) {
            synchronized(this) {
                if (tracer == null) {
                    tracer = Monitors.newTimer(clientName + "_OperationTimer", TimeUnit.MILLISECONDS);                    
                }
            }
        } 
        return tracer;        
    }
    
    public String getClientName() {
        return clientName;
    }
        
    public ILoadBalancer getLoadBalancer() {
        return lb;    
    }
        
    public void setLoadBalancer(ILoadBalancer lb) {
        this.lb = lb;
    }

    public int getMaxAutoRetriesNextServer() {
        return maxAutoRetriesNextServer;
    }

    public void setMaxAutoRetriesNextServer(int maxAutoRetriesNextServer) {
        this.maxAutoRetriesNextServer = maxAutoRetriesNextServer;
    }

    public int getMaxAutoRetries() {
        return maxAutoRetries;
    }

    public void setMaxAutoRetries(int maxAutoRetries) {
        this.maxAutoRetries = maxAutoRetries;
    }

    protected Throwable getDeepestCause(Throwable e) {
        if(e != null) {
            int infiniteLoopPreventionCounter = 10;
            while (e.getCause() != null && infiniteLoopPreventionCounter > 0) {
                infiniteLoopPreventionCounter--;
                e = e.getCause();
            }
        }
        return e;
    }

    private boolean isPresentAsCause(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor) {
        return isPresentAsCauseHelper(throwableToSearchIn, throwableToSearchFor) != null;
    }

    static Throwable isPresentAsCauseHelper(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor) {
        int infiniteLoopPreventionCounter = 10;
        while (throwableToSearchIn != null && infiniteLoopPreventionCounter > 0) {
            infiniteLoopPreventionCounter--;
            if (throwableToSearchIn.getClass().isAssignableFrom(
                    throwableToSearchFor)) {
                return throwableToSearchIn;
            } else {
                throwableToSearchIn = throwableToSearchIn.getCause();
            }
        }
        return null;
    }
    
    /**
     * Test if certain exception classes exist as a cause in a Throwable 
     */
    public static boolean isPresentAsCause(Throwable throwableToSearchIn,
            Collection<Class<? extends Throwable>> throwableToSearchFor) {
        int infiniteLoopPreventionCounter = 10;
        while (throwableToSearchIn != null && infiniteLoopPreventionCounter > 0) {
            infiniteLoopPreventionCounter--;
            for (Class<? extends Throwable> c: throwableToSearchFor) {
                if (throwableToSearchIn.getClass().isAssignableFrom(c)) {
                    return true;
                }
            }
            throwableToSearchIn = throwableToSearchIn.getCause();
        }
        return false;
    }

    protected ClientException generateNIWSException(String uri, Throwable e){
        ClientException niwsClientException;
        if (isPresentAsCause(e, java.net.SocketTimeoutException.class)) {
            niwsClientException = generateTimeoutNIWSException(uri, e);
        }else if (e.getCause() instanceof java.net.UnknownHostException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.UNKNOWN_HOST_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e.getCause() instanceof java.net.ConnectException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.CONNECT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e.getCause() instanceof java.net.NoRouteToHostException){
            niwsClientException = new ClientException(
                    ClientException.ErrorType.NO_ROUTE_TO_HOST_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri,
                    e);
        }else if (e instanceof ClientException){
            niwsClientException = (ClientException)e;
        }else {
            niwsClientException = new ClientException(
                ClientException.ErrorType.GENERAL,
                "Unable to execute RestClient request for URI:" + uri,
                e);
        }
        return niwsClientException;
    }

    private boolean isPresentAsCause(Throwable throwableToSearchIn,
            Class<? extends Throwable> throwableToSearchFor, String messageSubStringToSearchFor) {
        Throwable throwableFound = isPresentAsCauseHelper(throwableToSearchIn, throwableToSearchFor);
        if(throwableFound != null) {
            return throwableFound.getMessage().contains(messageSubStringToSearchFor);
        }
        return false;
    }
    private ClientException generateTimeoutNIWSException(String uri, Throwable e){
        ClientException niwsClientException;
        if (isPresentAsCause(e, java.net.SocketTimeoutException.class,
                "Read timed out")) {
            niwsClientException = new ClientException(
                    ClientException.ErrorType.READ_TIMEOUT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri + ":"
                            + getDeepestCause(e).getMessage(), e);
        } else {
            niwsClientException = new ClientException(
                    ClientException.ErrorType.SOCKET_TIMEOUT_EXCEPTION,
                    "Unable to execute RestClient request for URI:" + uri + ":"
                            + getDeepestCause(e).getMessage(), e);
        }
        return niwsClientException;
    }

    /**
     * This is called after a response is received or an exception is thrown from the client
     * to update related stats.  
     */
    protected void noteRequestCompletion(ServerStats stats, ClientRequest request, IResponse response, Throwable e, long responseTime) {        
        try {
            if (stats != null) {
                stats.decrementActiveRequestsCount();
                stats.incrementNumRequests();
                stats.noteResponseTime(responseTime);
                if (response != null) {
                    stats.clearSuccessiveConnectionFailureCount();                    
                }
            }            
        } catch (Throwable ex) {
            logger.error("Unexpected exception", ex);
        }            
    }
       
    /**
     * This is usually called just before client execute a request.
     */
    protected void noteOpenConnection(ServerStats serverStats, ClientRequest request) {
        if (serverStats == null) {
            return;
        }
        try {
            serverStats.incrementActiveRequestsCount();
        } catch (Throwable e) {
            logger.info("Unable to note Server Stats:", e);
        }
    }

      
    /**
     * Derive scheme and port from a partial URI. For example, for HTTP based client, the URI with 
     * only path "/" should return "http" and 80, whereas the URI constructed with scheme "https" and
     * path "/" should return
     * "https" and 443. This method is called by {@link #computeFinalUriWithLoadBalancer(ClientRequest)}
     * to get the complete executable URI.
     * 
     */
    protected Pair<String, Integer> deriveSchemeAndPortFromPartialUri(T request) {
        URI theUrl = request.getUri();
        boolean isSecure = false;
        String scheme = theUrl.getScheme();
        if (scheme != null) {
            isSecure =  scheme.equalsIgnoreCase("https");
        }
        int port = theUrl.getPort();
        if (port < 0 && !isSecure){
            port = 80;
        } else if (port < 0 && isSecure){
            port = 443;
        }
        if (scheme == null){
            if (isSecure) {
                scheme = "https";
            } else {
                scheme = "http";
            }
        }
        return new Pair<String, Integer>(scheme, port);
    }
    
    /**
     * Get the default port of the target server given the scheme of vip address if it is available. 
     * Subclass should override it to provider protocol specific default port number if any.
     * 
     * @param scheme from the vip address. null if not present.
     * @return 80 if scheme is http, 443 if scheme is https, -1 else.
     */
    protected int getDefaultPortFromScheme(String scheme) {
        if (scheme == null) {
            return -1;
        }
        if (scheme.equals("http")) {
            return 80;
        } else if (scheme.equals("https")) {
            return 443;
        } else {
            return -1;
        }
    }

        
    /**
     * Derive the host and port from virtual address if virtual address is indeed contains the actual host 
     * and port of the server. This is the final resort to compute the final URI in {@link #computeFinalUriWithLoadBalancer(ClientRequest)}
     * if there is no load balancer available and the request URI is incomplete. Sub classes can override this method
     * to be more accurate or throws ClientException if it does not want to support virtual address to be the
     * same as physical server address.
     * <p>
     *  The virtual address is used by certain load balancers to filter the servers of the same function 
     *  to form the server pool. 
     *  
     */
    protected  Pair<String, Integer> deriveHostAndPortFromVipAddress(String vipAddress) 
            throws URISyntaxException, ClientException {
        Pair<String, Integer> hostAndPort = new Pair<String, Integer>(null, -1);
        URI uri = new URI(vipAddress);
        String scheme = uri.getScheme();
        if (scheme == null) {
            uri = new URI("http://" + vipAddress);
        }
        String host = uri.getHost();
        if (host == null) {
            throw new ClientException("Unable to derive host/port from vip address " + vipAddress);
        }
        int port = uri.getPort();
        if (port < 0) {
            port = getDefaultPortFromScheme(scheme);
        }
        if (port < 0) {
            throw new ClientException("Unable to derive host/port from vip address " + vipAddress);
        }
        hostAndPort.setFirst(host);
        hostAndPort.setSecond(port);
        return hostAndPort;
    }
    
    private boolean isVipRecognized(String vipEmbeddedInUri) {
        if (vipEmbeddedInUri == null) {
            return false;
        }
        if (vipAddresses == null) {
            return false;
        }
        String[] addresses = vipAddresses.split(",");
        for (String address: addresses) {
            if (vipEmbeddedInUri.equalsIgnoreCase(address.trim())) {
                return true;
            }
        }
        return false;
    }
    
    /**
     * Compute the final URI from a partial URI in the request. The following steps are performed:
     * 
     * <li> if host is missing and there is a load balancer, get the host/port from server chosen from load balancer
     * <li> if host is missing and there is no load balancer, try to derive host/port from virtual address set with the client
     * <li> if host is present and the authority part of the URI is a virtual address set for the client, 
     * and there is a load balancer, get the host/port from server chosen from load balancer
     * <li> if host is present but none of the above applies, interpret the host as the actual physical address
     * <li> if host is missing but none of the above applies, throws ClientException
     * 
     * @param original Original URI passed from caller
     * @return new request with the final URI  
     */
    @SuppressWarnings("unchecked")
    protected T computeFinalUriWithLoadBalancer(T original) throws ClientException{
        URI theUrl = original.getUri();

        if (theUrl == null){
            throw new ClientException(ClientException.ErrorType.GENERAL, "NULL URL passed in");
        }

        String host = theUrl.getHost();
        Pair<String, Integer> schemeAndPort = deriveSchemeAndPortFromPartialUri(original);
        String scheme = schemeAndPort.first();
        int port = schemeAndPort.second();
        // Various Supported Cases
        // The loadbalancer to use and the instances it has is based on how it was registered
        // In each of these cases, the client might come in using Full Url or Partial URL
        ILoadBalancer lb = getLoadBalancer();
        Object loadBalancerKey = original.getLoadBalancerKey();
        if (host == null){
            // Partial URL Case
            // well we have to just get the right instances from lb - or we fall back
            if (lb != null){
                Server svc = lb.chooseServer(loadBalancerKey);
                if (svc == null){
                    throw new ClientException(ClientException.ErrorType.GENERAL,
                            "LoadBalancer returned null Server for :"
                            + clientName);
                }
                host = svc.getHost();
                port = svc.getPort();

                if (host == null){
                    throw new ClientException(ClientException.ErrorType.GENERAL,
                            "Invalid Server for :" + svc);
                }
                if (logger.isDebugEnabled()){
                    logger.debug(clientName + " using LB returned Server:" + svc + "for request:" + theUrl);
                }
            } else {
                // No Full URL - and we dont have a LoadBalancer registered to
                // obtain a server
                // if we have a vipAddress that came with the registration, we
                // can use that else we
                // bail out
                if (vipAddresses != null && vipAddresses.contains(",")) {
                    throw new ClientException(
                            ClientException.ErrorType.GENERAL,
                            this.clientName
                                    + "Partial URI of ("
                                    + theUrl
                                    + ") has been sent in to RestClient (with no LB) to be executed."
                                    + " Also, there are multiple vipAddresses and hence RestClient cant pick"
                                    + "one vipAddress to complete this partial uri");
                } else if (vipAddresses != null) {
                    try {
                        Pair<String,Integer> hostAndPort = deriveHostAndPortFromVipAddress(vipAddresses);
                        host = hostAndPort.first();
                        port = hostAndPort.second();
                    } catch (URISyntaxException e) {
                        throw new ClientException(
                                ClientException.ErrorType.GENERAL,
                                this.clientName
                                        + "Partial URI of ("
                                        + theUrl
                                        + ") has been sent in to RestClient (with no LB) to be executed."
                                        + " Also, the configured/registered vipAddress is unparseable (to determine host and port)");
                    }
                }else{
                    throw new ClientException(
                            ClientException.ErrorType.GENERAL,
                            this.clientName
                                    + " has no LoadBalancer registered and passed in a partial URL request (with no host:port)."
                                    + " Also has no vipAddress registered");
                }
            }
        } else {
            // Full URL Case
            // This could either be a vipAddress or a hostAndPort or a real DNS
            // if vipAddress or hostAndPort, we just have to consult the loadbalancer
            // but if it does not return a server, we should just proceed anyways
            // and assume its a DNS
            // For restClients registered using a vipAddress AND executing a request
            // by passing in the full URL (including host and port), we should only
            // consult lb IFF the URL passed is registered as vipAddress in Discovery
            boolean shouldInterpretAsVip = false;

            if (lb != null) {
                shouldInterpretAsVip = isVipRecognized(original.getUri().getAuthority());
            }
            if (shouldInterpretAsVip) {
                Server svc = lb.chooseServer(loadBalancerKey);
                if (svc != null){
                    host = svc.getHost();
                    port = svc.getPort();
                    if (host == null){
                        throw new ClientException(ClientException.ErrorType.GENERAL,
                                "Invalid Server for :" + svc);
                    }
                    if (logger.isDebugEnabled()){
                        logger.debug("using LB returned Server:" + svc + "for request:" + theUrl);
                    }
                }else{
                    // just fall back as real DNS
                    if (logger.isDebugEnabled()){
                        logger.debug(host + ":" + port + " assumed to be a valid VIP address or exists in the DNS");
                    }
                }
            } else {
             // consult LB to obtain vipAddress backed instance given full URL
                //Full URL execute request - where url!=vipAddress
               if (logger.isDebugEnabled()){
                   logger.debug("Using full URL passed in by caller (not using LB/Discovery):" + theUrl);
               }
            }
        }
        // end of creating final URL
        if (host == null){
            throw new ClientException(ClientException.ErrorType.GENERAL,"Request contains no HOST to talk to");
        }
        // just verify that at this point we have a full URL

        try {
            StringBuilder sb = new StringBuilder();
            sb.append(scheme).append("://");
            if (!Strings.isNullOrEmpty(theUrl.getRawUserInfo())) {
                sb.append(theUrl.getRawUserInfo()).append("@");
            }
            sb.append(host);
            if (port >= 0) {
                sb.append(":").append(port);
            }
            sb.append(theUrl.getRawPath());
            if (!Strings.isNullOrEmpty(theUrl.getRawQuery())) {
                sb.append("?").append(theUrl.getRawQuery());
            }
            if (!Strings.isNullOrEmpty(theUrl.getRawFragment())) {
                sb.append("#").append(theUrl.getRawFragment());
            }
            URI newURI = new URI(sb.toString());
            return (T) original.replaceUri(newURI);            
        } catch (URISyntaxException e) {
            throw new ClientException(ClientException.ErrorType.GENERAL, e.getMessage());
        }
    }
    
    protected boolean isRetriable(T request) {
        if (request.isRetriable()) {
            return true;            
        } else {
            boolean retryOkayOnOperation = okToRetryOnAllOperations;
            IClientConfig overriddenClientConfig = request.getOverrideConfig();
            if (overriddenClientConfig != null) {
                retryOkayOnOperation = overriddenClientConfig.getPropertyAsBoolean(CommonClientConfigKey.RequestSpecificRetryOn, okToRetryOnAllOperations);
            }
            return retryOkayOnOperation;
        }
    }
    
    protected int getRetriesNextServer(IClientConfig overriddenClientConfig) {
        int numRetries = maxAutoRetriesNextServer;
        if (overriddenClientConfig != null) {
            numRetries = overriddenClientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetriesNextServer, maxAutoRetriesNextServer);
        }
        return numRetries;
    }
    
    public final ServerStats getServerStats(Server server) {
        ServerStats serverStats = null;
        ILoadBalancer lb = this.getLoadBalancer();
        if (lb instanceof AbstractLoadBalancer){
            LoadBalancerStats lbStats = ((AbstractLoadBalancer) lb).getLoadBalancerStats();
            serverStats = lbStats.getSingleServerStat(server);
        }
        return serverStats;

    }

    protected int getNumberRetriesOnSameServer(IClientConfig overriddenClientConfig) {
        int numRetries =  maxAutoRetries;
        if (overriddenClientConfig!=null){
            try {
                numRetries = overriddenClientConfig.getPropertyAsInteger(CommonClientConfigKey.MaxAutoRetries, maxAutoRetries);
            } catch (Exception e) {
                logger.warn("Invalid maxRetries requested for RestClient:" + this.clientName);
            }
        }
        return numRetries;
    }
    
    protected boolean handleSameServerRetry(URI uri, int currentRetryCount, int maxRetries, Throwable e) {
        if (currentRetryCount > maxRetries) {
            return false;
        }
        logger.debug("Exception while executing request which is deemed retry-able, retrying ..., SAME Server Retry Attempt#: {}, URI: {}",  
                currentRetryCount, uri);
        return true;
    }

    public final LoadBalancerErrorHandler<? super T, ? super S> getErrorHandler() {
        return errorHandler;
    }

    public final void setErrorHandler(
            LoadBalancerErrorHandler<? super T, ? super S> errorHandler) {
        this.errorHandler = errorHandler;
    }

    public final boolean isOkToRetryOnAllOperations() {
        return okToRetryOnAllOperations;
    }

    public final void setOkToRetryOnAllOperations(boolean okToRetryOnAllOperations) {
        this.okToRetryOnAllOperations = okToRetryOnAllOperations;
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/ResponseWithTypedEntity.java;<<<<<<< MINE
package com.netflix.client;

import com.google.common.reflect.TypeToken;

public interface ResponseWithTypedEntity extends IResponse {
    public <T> T get(Class<T> type) throws ClientException;
    
    public <T> T get(TypeToken<T> type) throws ClientException;
}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.client;

import java.io.InputStream;

import com.google.common.reflect.TypeToken;

/**
 * A response type that includes a typed entity in its content.
 * 
 * @author awang
 *
 */
public interface ResponseWithTypedEntity extends IResponse {
    
    public <T> T getEntity(Class<T> type) throws Exception;
    
    public <T> T getEntity(TypeToken<T> type) throws Exception;
    
    public boolean hasEntity();
    
    public InputStream getInputStream() throws ClientException;
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/AsyncLoadBalancingClient.java;<<<<<<< MINE
package com.netflix.client;

import java.net.URI;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.netflix.loadbalancer.Server;
import com.netflix.loadbalancer.ServerStats;
import com.netflix.servo.monitor.Monitors;
import com.netflix.servo.monitor.Stopwatch;
import com.netflix.servo.monitor.Timer;

public class AsyncLoadBalancingClient<Request extends ClientRequest, Response extends ResponseWithTypedEntity>
        extends LoadBalancerContext implements AsyncClient<Request, Response> {
    
    private AsyncClient<Request, Response> asyncClient;
    private static final Logger logger = LoggerFactory.getLogger(AsyncLoadBalancingClient.class);
    private Timer tracer;


    public AsyncLoadBalancingClient(AsyncClient<Request, Response> asyncClient) {
        super();
        this.asyncClient = asyncClient;
    }

    protected AsyncLoadBalancingClient() {
    }

    @Override
    public void execute(final Request request, final ResponseCallback<Response> callback)
            throws ClientException {
        final AtomicInteger retries = new AtomicInteger(0);
        final boolean retryOkayOnOperation = isRetriable(request);

        final int numRetriesNextServer = getRetriesNextServer(request.getOverrideConfig()); 
        Request resolved = computeFinalUriWithLoadBalancer(request);
        asyncExecuteOnSingleServer(resolved, new ResponseCallback<Response>() {

            @Override
            public void onResponseReceived(Response response) {
                callback.onResponseReceived(response);
            }

            @Override
            public void onException(Throwable e) {
                boolean shouldRetry = false;
                if (e instanceof ClientException) {
                    // we dont want to retry for PUT/POST and DELETE, we can for GET
                    shouldRetry = retryOkayOnOperation && numRetriesNextServer > 0;
                }
                if (shouldRetry) {
                    if (retries.incrementAndGet() > numRetriesNextServer) {
                        callback.onException(new ClientException(
                                ClientException.ErrorType.NUMBEROF_RETRIES_NEXTSERVER_EXCEEDED,
                                "NUMBER_OF_RETRIES_NEXTSERVER_EXCEEDED :"
                                + numRetriesNextServer
                                + " retries, while making a RestClient call for:"
                                + request.getUri() + ":" +  getDeepestCause(e).getMessage(), e));
                    }
                    logger.error("Exception while executing request which is deemed retry-able, retrying ..., Next Server Retry Attempt#:"
                            + retries
                            + ", URI tried:"
                            + request.getUri());
                    try {
                        asyncExecuteOnSingleServer(computeFinalUriWithLoadBalancer(request), this);
                    } catch (ClientException e1) {
                        callback.onException(e1);
                    }
                } else {
                    if (e instanceof ClientException) {
                        callback.onException(e);
                    } else {
                        callback.onException(new ClientException(
                                ClientException.ErrorType.GENERAL,
                                "Unable to execute request for URI:" + request.getUri(),
                                e));
                    }
                }
            }
            
        });
    }

    
    
    private Timer getExecuteTracer() {
        if (tracer == null) {
            tracer = Monitors.newTimer(this.getClientName() + "_ExecutionTimer", TimeUnit.MILLISECONDS);
        }
        return tracer;
    }
    
    /**
     * Execute the request on single server after the final URI is calculated. This method takes care of
     * retries and update server stats.
     * @throws ClientException 
     *  
     */
    protected void asyncExecuteOnSingleServer(final Request request, final ResponseCallback<Response> callback) throws ClientException {
        final AtomicInteger retries = new AtomicInteger(0);

        final boolean retryOkayOnOperation = request.isRetriable()? true: okToRetryOnAllOperations;
        final int numRetries = getNumberRetriesOnSameServer(request.getOverrideConfig());
        final URI uri = request.getUri();
        Server server = new Server(uri.getHost(), uri.getPort());
        final ServerStats serverStats = getServerStats(server);
        final Stopwatch tracer = getExecuteTracer().start();
        noteOpenConnection(serverStats, request);
        asyncClient.execute(request, new ResponseCallback<Response>() {
            private Response thisResponse;
            private Throwable thisException;
            @Override
            public void onResponseReceived(Response response) {
                thisResponse = response;
                onComplete();
                callback.onResponseReceived(response);
            }

            @Override
            public void onException(Throwable e) {
                thisException = e;
                onComplete();
                if (serverStats != null) {
                    serverStats.addToFailureCount();
                }
                if (isCircuitBreakerException(e) && serverStats != null) {
                    serverStats.incrementSuccessiveConnectionFailureCount();
                }
                boolean shouldRetry = retryOkayOnOperation && numRetries > 0 && isRetriableException(e);
                if (shouldRetry) {
                    if (retries.incrementAndGet() > numRetries) {
                        callback.onException(new ClientException(ClientException.ErrorType.NUMBEROF_RETRIES_EXEEDED,
                                "NUMBEROFRETRIESEXEEDED :" + numRetries + " retries, while making a RestClient call for: " + uri,
                                e !=null? e: new RuntimeException()));
                    } else {
                        logger.error("Exception while executing request which is deemed retry-able, retrying ..., SAME Server Retry Attempt #:" +
                                retries.get() +
                                ", URI:" +
                                uri);
                        try {
                            Thread.sleep((int) Math.pow(2.0, retries.get()) * 100); 
                        } catch (InterruptedException ex) {
                        }
                        tracer.start();
                        noteOpenConnection(serverStats, request);
                        try {
                            asyncClient.execute(request, this);
                        } catch (ClientException ex) {
                            callback.onException(ex);
                        }
                    } 
                } else {
                    ClientException clientException = generateNIWSException(uri.toString(), e);
                    callback.onException(clientException);
                }
            }
            
            private void onComplete() {
                tracer.stop();
                long duration = tracer.getDuration(TimeUnit.MILLISECONDS);
                noteRequestCompletion(serverStats, request, thisResponse, thisException, duration);
            }            
        });
    }

    
    @Override
    protected boolean isCircuitBreakerException(Throwable e) {
        return true;
    }

    @Override
    protected boolean isRetriableException(Throwable e) {
        return true;
    }
}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.client;

import java.io.IOException;
import java.net.URI;
import java.nio.ByteBuffer;
import java.util.List;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.collect.Lists;
import com.netflix.client.config.IClientConfig;
import com.netflix.loadbalancer.AvailabilityFilteringRule;
import com.netflix.loadbalancer.ILoadBalancer;
import com.netflix.loadbalancer.Server;
import com.netflix.loadbalancer.ServerStats;
import com.netflix.serialization.ContentTypeBasedSerializerKey;
import com.netflix.serialization.Deserializer;
import com.netflix.serialization.SerializationFactory;
import com.netflix.serialization.Serializer;
import com.netflix.servo.monitor.Stopwatch;

/**
 * An asynchronous client that is capable of load balancing with an {@link ILoadBalancer}. It delegates the 
 * asynchronous call to the {@link AsyncClient} passed in from the constructor. As with synchronous I/O client,
 * the URI in the request can be a partial URI without host name or port. The load balancer will be responsible
 * to choose a server and calculate the final URI. If multiple retries are configured, all intermediate failures
 * will be hidden from the caller of the APIs in this class. All call results will be feed back to the load balancer
 * as server statistics to help it choosing the next server, for example, avoiding servers with consecutive connection
 * or read failures or high concurrent requests given the {@link AvailabilityFilteringRule}.
 * 
 * @author awang
 *
 * @param <T> Request type
 * @param <S> Response type
 * @param <U> Type of storage used for delivering partial content, for example, {@link ByteBuffer}
 * @param <V> Type of key to find {@link Serializer} and {@link Deserializer} for the content. For example, for HTTP communication,
 *            the key type is {@link ContentTypeBasedSerializerKey}
 */
public class AsyncLoadBalancingClient<T extends ClientRequest, S extends IResponse, U, V>
        extends LoadBalancerContext<T, S> implements AsyncClient<T, S, U, V> {
    
    private AsyncClient<T, S, U, V> asyncClient;
    private static final Logger logger = LoggerFactory.getLogger(AsyncLoadBalancingClient.class);
    
    public AsyncLoadBalancingClient(AsyncClient<T, S, U, V> asyncClient) {
        super();
        this.asyncClient = asyncClient;
    }
    
    public AsyncLoadBalancingClient(AsyncClient<T, S, U, V> asyncClient, IClientConfig clientConfig) {
        super(clientConfig);
        this.asyncClient = asyncClient;
    }

    protected AsyncLoadBalancingClient() {
    }

    private Future<S> getFuture(final AtomicReference<Future<S>> futurePointer, final CallbackDelegate<S, ?> callbackDelegate) {
        return new Future<S>() {

            @Override
            public boolean cancel(boolean arg0) {
                Future<S> current = futurePointer.get();
                if (current != null) {                    
                    return current.cancel(arg0);
                } else {
                    return false;
                }
            }

            @Override
            public S get() throws InterruptedException, ExecutionException {
                return callbackDelegate.getCompletedResponse();
            }

            @Override
            public S get(long arg0, TimeUnit arg1)
                    throws InterruptedException, ExecutionException,
                    TimeoutException {
                return callbackDelegate.getCompletedResponse(arg0,  arg1);
            }

            @Override
            public boolean isCancelled() {
                Future<S> current = futurePointer.get();
                if (current != null) {                    
                    return current.isCancelled();
                } else {
                    return false;
                }
            }

            @Override
            public boolean isDone() {
                return callbackDelegate.isDone();
            }
            
        };
    }
    
    private static class CallbackDelegate<T extends IResponse, E> implements ResponseCallback<T, E> {

        private ResponseCallback<T, E> callback;

        public CallbackDelegate(ResponseCallback<T, E> callback) {
            this.callback = callback;
        }
        
        private CountDownLatch latch = new CountDownLatch(1);
        private volatile T completeResponse = null; 
        
        private volatile Throwable exception = null;
        
        T getCompletedResponse() throws InterruptedException, ExecutionException {
            latch.await();
            if (completeResponse != null) {
                return completeResponse;
            } else if (exception != null) {
                throw new ExecutionException(exception);
            } else {
                throw new IllegalStateException("No response or exception is received");
            }
        }

        T getCompletedResponse(long time, TimeUnit timeUnit) throws InterruptedException, TimeoutException, ExecutionException {
            if (latch.await(time, timeUnit)) {
                if (completeResponse != null) {
                    return completeResponse;
                } else if (exception != null) {
                    throw new ExecutionException(exception);
                } else {
                    throw new IllegalStateException("No response or exception is received");
                }
            } else {
                throw new TimeoutException();
            }
        }
               
        boolean isDone() {
            return latch.getCount() <= 0;
        }

        @Override
        public void completed(T response) {
            completeResponse = response;
            latch.countDown();
            if (callback != null) {
                callback.completed(response);
            }
        }

        @Override
        public void failed(Throwable e) {
            exception = e;
            latch.countDown();
            if (callback != null) {
                callback.failed(e);
            }
        }

        @Override
        public void cancelled() {
            latch.countDown();
            if (callback != null) {
                callback.cancelled();
            }
        }

        @Override
        public void responseReceived(T response) {
            if (callback != null) {
                callback.responseReceived(response);
            }
        }

        @Override
        public void contentReceived(E content) {
            if (callback != null) {
                callback.contentReceived(content);
            }
        }
    }

    /**
     * Execute a request with callback invoked after the full response is buffered. If multiple retries are configured,
     * all intermediate failures will be hidden from caller and only the last successful response or failure
     * will be used for callback.
     * 
     * @param request Request to execute. It can contain a partial URI without host or port as
     * the load balancer will calculate the final URI after choosing a server.
     */
    @Override
    public Future<S> execute(final T request, final BufferedResponseCallback<S> callback)
            throws ClientException {
        return execute(request, null, callback);
    }
    
    /**
     * Execute a request with callback. If multiple retries are configured,
     * all intermediate failures will be hidden from caller and only the last successful response or failure
     * will be used for callback.
     * 
     * @param request Request to execute. It can contain a partial URI without host or port as
     * the load balancer will calculate the final URI after choosing a server.
     */
    @Override
    public <E> Future<S> execute(final T request, final StreamDecoder<E, U> decoder, final ResponseCallback<S, E> callback)
            throws ClientException {
        final AtomicInteger retries = new AtomicInteger(0);
        final boolean retryOkayOnOperation = isRetriable(request);

        final int numRetriesNextServer = getRetriesNextServer(request.getOverrideConfig()); 
        T resolved = computeFinalUriWithLoadBalancer(request);
        
        final CallbackDelegate<S, E> delegate = new CallbackDelegate<S, E>(callback);
        final AtomicReference<Future<S>> currentRunningTask = new AtomicReference<Future<S>>();
        
        asyncExecuteOnSingleServer(resolved, decoder, new ResponseCallback<S, E>() {

            @Override
            public void completed(S response) {
                delegate.completed(response);
            }

            @Override
            public void failed(Throwable e) {
                boolean shouldRetry = retryOkayOnOperation && numRetriesNextServer > 0 && errorHandler.isRetriableException(request, e, false);
                if (shouldRetry) {
                    if (retries.incrementAndGet() > numRetriesNextServer) {
                        delegate.failed(new ClientException(
                                ClientException.ErrorType.NUMBEROF_RETRIES_NEXTSERVER_EXCEEDED,
                                "NUMBER_OF_RETRIES_NEXTSERVER_EXCEEDED :"
                                + numRetriesNextServer
                                + " retries, while making a RestClient call for:"
                                + request.getUri() + ":" +  getDeepestCause(e).getMessage(), e));
                        return;
                    }
                    try {
                        T newRequest = computeFinalUriWithLoadBalancer(request);
                        logger.debug("Exception while executing request which is deemed retry-able, retrying ..., Next Server Retry Attempt#: {}, URI: {}",
                                retries, newRequest.getUri());
                        asyncExecuteOnSingleServer(newRequest, decoder, this, currentRunningTask);
                    } catch (ClientException e1) {
                        delegate.failed(e1);
                    }
                } else {
                    delegate.failed(e);
                }
            }

            @Override
            public void cancelled() {
                delegate.cancelled();
            }

            @Override
            public void responseReceived(S response) {
                delegate.responseReceived(response);
            }

            @Override
            public void contentReceived(E content) {
                delegate.contentReceived(content);
            }
            
        }, currentRunningTask);
        return getFuture(currentRunningTask, delegate);
    }

    /**
     * Execute the request on single server after the final URI is calculated. This method takes care of
     * retries and update server stats.
     * @throws ClientException 
     *  
     */
    protected <E> void asyncExecuteOnSingleServer(final T request, final StreamDecoder<E, U> decoder, 
            final ResponseCallback<S, E> callback, final AtomicReference<Future<S>> currentRunningTask) throws ClientException {
        final AtomicInteger retries = new AtomicInteger(0);

        final boolean retryOkayOnOperation = request.isRetriable()? true: okToRetryOnAllOperations;
        final int numRetries = getNumberRetriesOnSameServer(request.getOverrideConfig());
        final URI uri = request.getUri();
        Server server = new Server(uri.getHost(), uri.getPort());
        final ServerStats serverStats = getServerStats(server);
        final Stopwatch tracer = getExecuteTracer().start();
        noteOpenConnection(serverStats, request);
        Future<S> future = asyncClient.execute(request, decoder, new ResponseCallback<S, E>() {
            private S thisResponse;
            private Throwable thisException;
            @Override
            public void completed(S response) {
                thisResponse = response;
                onComplete();
                callback.completed(response);
            }

            @Override
            public void failed(Throwable e) {
                thisException = e;
                onComplete();
                if (serverStats != null) {
                    serverStats.addToFailureCount();
                }
                if (errorHandler.isCircuitTrippingException(e) && serverStats != null) {
                    serverStats.incrementSuccessiveConnectionFailureCount();
                }
                boolean shouldRetry = retryOkayOnOperation && numRetries > 0 && errorHandler.isRetriableException(request, e, true);
                if (shouldRetry) {
                    if (!handleSameServerRetry(uri, retries.incrementAndGet(), numRetries, e)) {
                        callback.failed(new ClientException(ClientException.ErrorType.NUMBEROF_RETRIES_EXEEDED,
                                "NUMBEROFRETRIESEXEEDED :" + numRetries + " retries, while making a RestClient call for: " + uri, e));                        
                    } else {
                        tracer.start();
                        noteOpenConnection(serverStats, request);
                        try {
                            Future<S> future = asyncClient.execute(request, decoder, this);
                            currentRunningTask.set(future);
                        } catch (ClientException ex) {
                            callback.failed(ex);
                        }
                    } 
                } else {
                    callback.failed(e);
                }
            }
            
            private void onComplete() {
                tracer.stop();
                long duration = tracer.getDuration(TimeUnit.MILLISECONDS);
                noteRequestCompletion(serverStats, request, thisResponse, thisException, duration);
            }

            @Override
            public void cancelled() {
                onComplete();
                callback.cancelled();
            }

            @Override
            public void responseReceived(S response) {
                if (errorHandler.isCircuitTrippinErrorgResponse(response)) {
                    serverStats.incrementSuccessiveConnectionFailureCount();
                }
                callback.responseReceived(response);
            }

            @Override
            public void contentReceived(E content) {
                callback.contentReceived(content);
            }            
        });
        currentRunningTask.set(future);
    }

    /**
     * Execute the same request that might be sent to multiple servers (as back up requests) if
     * no response is received within the timeout. This method delegates to 
     * {@link AsyncBackupRequestsExecutor#executeWithBackupRequests(AsyncClient, List, long, TimeUnit, StreamDecoder, ResponseCallback)} 
     *
     * @param request Request to execute. It can contain a partial URI without host or port as
     * the load balancer will calculate the final URI after choosing a server.
     * @param numServers the maximal number of servers to try before getting a response
     */
    public <E> AsyncBackupRequestsExecutor.ExecutionResult<S> executeWithBackupRequests(final T request,
            final int numServers, long timeoutIntervalBetweenRequests, TimeUnit unit,
            final StreamDecoder<E, U> decoder,
            
            final ResponseCallback<S, E> callback)
            throws ClientException {
        final List<T> requests = Lists.newArrayList();
        for (int i = 0; i < numServers; i++) {
            requests.add(computeFinalUriWithLoadBalancer(request));
        }
        return AsyncBackupRequestsExecutor.executeWithBackupRequests(this,  requests, timeoutIntervalBetweenRequests, unit, decoder, callback);
    }

    
    @Override
    public void close() throws IOException {
        if (asyncClient != null) {
            asyncClient.close();
        }
    }

    @Override
    public void addSerializationFactory(SerializationFactory<V> factory) {
        asyncClient.addSerializationFactory(factory);
    }

    /**
     * Execute a request where the future will be ready when full response is buffered. If multiple retries are configured,
     * all intermediate failures will be hidden from caller and only the last successful response or failure
     * will be used for creating the future.
     * 
     * @param request Request to execute. It can contain a partial URI without host or port as
     * the load balancer will calculate the final URI after choosing a server.
     */

    @Override
    public Future<S> execute(T request) throws ClientException {
        return execute(request, null);
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/main/java/com/netflix/client/ResponseCallback.java;<<<<<<< MINE
package com.netflix.client;

public interface ResponseCallback<R extends ResponseWithTypedEntity> {
    public void onResponseReceived(R response);

    public void onException(Throwable e);
}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.client;

/**
 * Callback for asynchronous communication.
 * 
 * @author awang
 *
 * @param <T> Type of response, which is protocol specific
 * @param <E> Type of of object that can be formed from partial 
 *             content in the native stream. See {@link StreamDecoder}.
 */
public interface ResponseCallback<T extends IResponse, E> {
    /**
     * Invoked when all communications are successful and content is consumed.
     */
    public void completed(T response);

    /**
     * Invoked when any error happened in the communication or content consumption. 
     */
    public void failed(Throwable e);

    /**
     * Invoked if the I/O operation is cancelled after it is started.
     */
    public void cancelled();
    
    /**
     * Invoked when the initial response is received. For example, the status code and headers
     * of HTTP response is received.
     */
    public void responseReceived(T response);

    /**
     * Invoked when decoded content is delivered from {@link StreamDecoder}.
     */
    public void contentReceived(E content);    
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-core/src/test/java/com/netflix/serialization/JacksonSerializerTest.java;<<<<<<< MINE
package com.netflix.serialization;

import static org.junit.Assert.*;

import java.util.List;

import org.junit.Test;
import com.google.common.reflect.TypeToken;
import com.google.common.collect.Lists;

public class JacksonSerializerTest {    
    @Test
    public void testSerializeList() throws Exception {
        List<Person> people = Lists.newArrayList();
        for (int i = 0; i < 3; i++) {
            people.add(new Person("person " + i, i));
        }
        JacksonSerializationFactory factory = new JacksonSerializationFactory();
        ContentTypeBasedSerializerKey key = new ContentTypeBasedSerializerKey("application/json", new TypeToken<List<Person>>(){});
        Serializer serializer = factory.getSerializer(key).get();
        String content = new String(serializer.serialize(people), "UTF-8");
        Deserializer deserializer = factory.getDeserializer(key).get();
        List<Person> list = deserializer.deserialize(content.getBytes("UTF-8"), new TypeToken<List<Person>>(){});
        assertEquals(people, list);
        Person person = new Person("ribbon", 1);
        byte[] bytes = serializer.serialize(person);
        Person deserialized = deserializer.deserialize(bytes, TypeToken.of(Person.class));
        assertEquals(person, deserialized);
        deserialized = deserializer.deserialize(bytes, Person.class);
        assertEquals(person, deserialized);
    }
}

class Person {
    public String name;
    public int age;
    public Person() {}
    public Person(String name, int age) {
        super();
        this.name = name;
        this.age = age;
    }
    @Override
    public String toString() {
        return "Person [name=" + name + ", age=" + age + "]";
    }
    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + age;
        result = prime * result + ((name == null) ? 0 : name.hashCode());
        return result;
    }
    @Override
    public boolean equals(Object obj) {
        if (this == obj)
            return true;
        if (obj == null)
            return false;
        if (getClass() != obj.getClass())
            return false;
        Person other = (Person) obj;
        if (age != other.age)
            return false;
        if (name == null) {
            if (other.name != null)
                return false;
        } else if (!name.equals(other.name))
            return false;
        return true;
    }
}=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.serialization;

import static org.junit.Assert.*;

import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.util.List;

import org.codehaus.jackson.map.ObjectMapper;
import org.junit.Test;
import com.google.common.reflect.TypeToken;
import com.google.common.collect.Lists;

public class JacksonSerializerTest {    
    @SuppressWarnings("serial")
    @Test
    public void testSerializeList() throws Exception {
        List<Person> people = Lists.newArrayList();
        for (int i = 0; i < 3; i++) {
            people.add(new Person("person " + i, i));
        }
        JacksonSerializationFactory factory = new JacksonSerializationFactory();
        ContentTypeBasedSerializerKey key = new ContentTypeBasedSerializerKey("application/json", new TypeToken<List<Person>>(){});
        Serializer serializer = factory.getSerializer(key).get();
        String content = new String(serializeToBytes(people, serializer), "UTF-8");
        Deserializer deserializer = factory.getDeserializer(key).get();
        List<Person> list = deserializer.deserialize(new ByteArrayInputStream(content.getBytes("UTF-8")), new TypeToken<List<Person>>(){});
        assertEquals(people, list);
        Person person = new Person("ribbon", 1);
        byte[] bytes = serializeToBytes(person, serializer);
        Person deserialized = deserializer.deserialize(new ByteArrayInputStream(bytes), TypeToken.of(Person.class));
        assertEquals(person, deserialized);
        deserialized = deserializer.deserialize(new ByteArrayInputStream(bytes), TypeToken.of(Person.class));
        assertEquals(person, deserialized);
        
        ObjectMapper mapper = new ObjectMapper();
        deserialized = (Person) mapper.readValue(bytes, TypeToken.of(Person.class).getRawType());
        assertEquals(person, deserialized);
    }
    
    
    private byte[] serializeToBytes(Object obj, Serializer serializer) throws Exception {
        ByteArrayOutputStream bout = new ByteArrayOutputStream();
        serializer.serialize(bout, obj);
        return bout.toByteArray();
    }
}

class Person {
    public String name;
    public int age;
    public Person() {}
    public Person(String name, int age) {
        super();
        this.name = name;
        this.age = age;
    }
    @Override
    public String toString() {
        return "Person [name=" + name + ", age=" + age + "]";
    }
    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + age;
        result = prime * result + ((name == null) ? 0 : name.hashCode());
        return result;
    }
    @Override
    public boolean equals(Object obj) {
        if (this == obj)
            return true;
        if (obj == null)
            return false;
        if (getClass() != obj.getClass())
            return false;
        Person other = (Person) obj;
        if (age != other.age)
            return false;
        if (name == null) {
            if (other.name != null)
                return false;
        } else if (!name.equals(other.name))
            return false;
        return true;
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-httpclient/src/main/java/com/netflix/niws/client/http/RestClient.java;<<<<<<< MINE
    protected boolean isRetriableException(Throwable e) {
        boolean shouldRetry = isConnectException(e) || isSocketException(e);
=======
    protected boolean isRetriableException(Throwable e) {
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_b33a5ed_42c3e4c/rev_b33a5ed-42c3e4c/ribbon-httpclient/src/main/java/com/netflix/niws/client/http/RestClient.java;<<<<<<< MINE
    protected boolean isCircuitBreakerException(Throwable e) {
=======
    protected boolean isCircuitBreakerException(Throwable e) {
        if (e instanceof ClientException) {
            ClientException clientException = (ClientException) e;
            if (clientException.getErrorType() == ClientException.ErrorType.SERVER_THROTTLED) {
                return true;
            }
        }
>>>>>>> YOURS
/home/taes/taes/projects/atlas/revisions/rev_799f8e4_9f4a697/rev_799f8e4-9f4a697/atlas-gradle-plugin/dexpatch/src/main/java/com/taobao/android/apatch/ApkPatch.java;<<<<<<< MINE
            prepareClasses = buildPrepareClass(smaliDir2, newFiles, info);
=======

            List finalFilterClasses = filterClasses;
            Collections.sort(classes, new Comparator<String>() {
                @Override
                public int compare(String o1, String o2) {
                    if (dexDiffer.getFilter() == null){
                        return 0;
                    }else {
                        return finalFilterClasses.indexOf(o1) - finalFilterClasses.indexOf(o2);
                    }
                }
            });



//            //æ¯å¦ä¿®æ¹dex
//            if (APatchTool.debug) {
//                PatchMethodTool.modifyMethod(dexFile.getAbsolutePath(), dexFile.getAbsolutePath(), true);
//            }
//
            File smaliDir2 = new File(aptchFolder, "smali2");
            if (!smaliDir2.exists()) {
                smaliDir2.mkdirs();
            }
            try {
                FileUtils.cleanDirectory(smaliDir2);
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
           prepareClasses = buildPrepareClass(smaliDir2, newFiles, info);
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_4be8bde_47e5ff8/rev_4be8bde-47e5ff8/ribbon-core/src/main/java/com/netflix/client/PrimeConnections.java;<<<<<<< MINE
=======
/*
*
* Copyright 2013 Netflix, Inc.
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
* http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*
*/
package com.netflix.client;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.Callable;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.netflix.client.config.CommonClientConfigKey;
import com.netflix.client.config.DefaultClientConfigImpl;
import com.netflix.client.config.IClientConfig;
import com.netflix.loadbalancer.Server;
import com.netflix.servo.monitor.Counter;
import com.netflix.servo.monitor.Monitors;
import com.netflix.servo.monitor.Stopwatch;
import com.netflix.servo.monitor.Timer;

/**
 * Prime the connections for a given Client (For those Client that
 * have a LoadBalancer that knows the set of Servers it will connect to) This is
 * mainly done to address those deployment environments (Read EC2) which benefit
 * from a firewall connection/path warmup prior to actual use for live requests.
 * <p>
 * This class is not protocol specific. Actual priming operation is delegated to 
 * instance of {@link IPrimeConnection}, which is instantiated using reflection
 * according to property {@link CommonClientConfigKey#PrimeConnectionsClassName}.
 * 
 * @author stonse
 * @author awang
 * 
 */
public class PrimeConnections {

    public static interface PrimeConnectionListener {
        public void primeCompleted(Server s, Throwable lastException);
    }
    
    static class PrimeConnectionCounters {
        final AtomicInteger numServersLeft;
        final AtomicInteger numServers;
        final AtomicInteger numServersSuccessful;    
        public PrimeConnectionCounters(int initialSize) {
            numServersLeft = new AtomicInteger(initialSize);
            numServers = new AtomicInteger(initialSize);
            numServersSuccessful = new AtomicInteger(0);
        }
    }
    
    private static final Logger logger = LoggerFactory.getLogger(PrimeConnections.class);

    // affordance to change the URI we connect to while "priming"
    // default of "/" is good for most - but if its heavy operation on
    // the server side, then a more lightweight URI can be chosen
    String primeConnectionsURIPath = "/";

    /**
     * Executor service for executing asynchronous requests.
     */

    private ExecutorService executorService;

    private int maxExecutorThreads = 5;

    private long executorThreadTimeout = 30000;

    private String name = "default";

    private int maxTasksPerExecutorQueue = 100;
    
    private float primeRatio = 1.0f;


    int maxRetries = 9;

    long maxTotalTimeToPrimeConnections = 30 * 1000; // default time

    long totalTimeTaken = 0; // Total time taken

    private boolean aSync = true;
        
    Counter totalCounter;
    Counter successCounter;
    Timer initialPrimeTimer;
    
    private IPrimeConnection connector;

    private PrimeConnections() {
    }

    public PrimeConnections(String name, IClientConfig niwsClientConfig) {
        int maxRetriesPerServerPrimeConnection = Integer.valueOf(DefaultClientConfigImpl.DEFAULT_MAX_RETRIES_PER_SERVER_PRIME_CONNECTION);
        long maxTotalTimeToPrimeConnections = Long.valueOf(DefaultClientConfigImpl.DEFAULT_MAX_TOTAL_TIME_TO_PRIME_CONNECTIONS);
        String primeConnectionsURI = DefaultClientConfigImpl.DEFAULT_PRIME_CONNECTIONS_URI;  
        String className = DefaultClientConfigImpl.DEFAULT_PRIME_CONNECTIONS_CLASS;
        try {
            maxRetriesPerServerPrimeConnection = Integer.parseInt(String.valueOf(niwsClientConfig.getProperty(
                    CommonClientConfigKey.MaxRetriesPerServerPrimeConnection, maxRetriesPerServerPrimeConnection)));
        } catch (Exception e) {
            logger.warn("Invalid maxRetriesPerServerPrimeConnection");
        }
        try {
            maxTotalTimeToPrimeConnections = Long.parseLong(String.valueOf(niwsClientConfig.getProperty(
                    CommonClientConfigKey.MaxTotalTimeToPrimeConnections,maxTotalTimeToPrimeConnections)));
        } catch (Exception e) {
            logger.warn("Invalid maxTotalTimeToPrimeConnections");
        }
        primeConnectionsURI = String.valueOf(niwsClientConfig.getProperty(CommonClientConfigKey.PrimeConnectionsURI, primeConnectionsURI));
        float primeRatio = Float.parseFloat(String.valueOf(niwsClientConfig.getProperty(CommonClientConfigKey.MinPrimeConnectionsRatio)));
        className = (String) niwsClientConfig.getProperty(CommonClientConfigKey.PrimeConnectionsClassName, 
        		DefaultClientConfigImpl.DEFAULT_PRIME_CONNECTIONS_CLASS);
        try {
            connector = (IPrimeConnection) Class.forName(className).newInstance();
            connector.initWithNiwsConfig(niwsClientConfig);
        } catch (Exception e) {
            throw new RuntimeException("Unable to initialize prime connections", e);
        }
        setUp(name, maxRetriesPerServerPrimeConnection, 
                maxTotalTimeToPrimeConnections, primeConnectionsURI, primeRatio);        
    }
        
    public PrimeConnections(String name, int maxRetries, 
            long maxTotalTimeToPrimeConnections, String primeConnectionsURI) {
        setUp(name, maxRetries, maxTotalTimeToPrimeConnections, primeConnectionsURI, DefaultClientConfigImpl.DEFAULT_MIN_PRIME_CONNECTIONS_RATIO);
    }

    public PrimeConnections(String name, int maxRetries, 
            long maxTotalTimeToPrimeConnections, String primeConnectionsURI, float primeRatio) {
        setUp(name, maxRetries, maxTotalTimeToPrimeConnections, primeConnectionsURI, primeRatio);
    }

    private void setUp(String name, int maxRetries, 
            long maxTotalTimeToPrimeConnections, String primeConnectionsURI, float primeRatio) {        
        this.name = name;
        this.maxRetries = maxRetries;
        this.maxTotalTimeToPrimeConnections = maxTotalTimeToPrimeConnections;
        this.primeConnectionsURIPath = primeConnectionsURI;        
        this.primeRatio = primeRatio;
        executorService = new ThreadPoolExecutor(1 /* minimum */,
                maxExecutorThreads /* max threads */,
                executorThreadTimeout /*
                                       * timeout - same property as create
                                       * timeout
                                       */, TimeUnit.MILLISECONDS,
                new LinkedBlockingQueue<Runnable>(maxTasksPerExecutorQueue)
                /* Bounded queue with FIFO- bounded to max tasks */,
                new ASyncPrimeConnectionsThreadFactory(name) /*
                                                              * So we can give
                                                              * our Thread a
                                                              * name
                                                              */
        );        
        totalCounter = Monitors.newCounter(name + "_PrimeConnection_TotalCounter");
        successCounter = Monitors.newCounter(name + "_PrimeConnection_SuccessCounter");
        initialPrimeTimer = Monitors.newTimer(name + "_initialPrimeConnectionsTimer", TimeUnit.MILLISECONDS);
        Monitors.registerObject(name + "_PrimeConnection", this);
    }
    
    /**
     * Prime connections, blocking until configured percentage (default is 100%) of target servers are primed 
     * or max time is reached.
     * 
     * @see CommonClientConfigKey#MinPrimeConnectionsRatio
     * @see CommonClientConfigKey#MaxTotalTimeToPrimeConnections
     * 
     */
    public void primeConnections(List<Server> servers) {
        if (servers == null || servers.size() == 0) {
            logger.debug("No server to prime");
            return;
        }
        for (Server server: servers) {
            server.setReadyToServe(false);
        }
        int totalCount = (int) (servers.size() * primeRatio); 
        final CountDownLatch latch = new CountDownLatch(totalCount);
        final AtomicInteger successCount = new AtomicInteger(0);
        final AtomicInteger failureCount= new AtomicInteger(0);
        primeConnectionsAsync(servers, new PrimeConnectionListener()  {            
            @Override
            public void primeCompleted(Server s, Throwable lastException) {
                if (lastException == null) {
                    successCount.incrementAndGet();
                    s.setReadyToServe(true);
                } else {
                    failureCount.incrementAndGet();
                }
                latch.countDown();
            }
        }); 
                
        Stopwatch stopWatch = initialPrimeTimer.start();
        try {
            latch.await(maxTotalTimeToPrimeConnections, TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
            logger.error("Priming connection interrupted", e);
        } finally {
            stopWatch.stop();
        }
        printStats(totalCount, successCount.get(), failureCount.get(), stopWatch.getDuration(TimeUnit.MILLISECONDS));
    }
    
    private void printStats(int total, int success, int failure, long totalTime) {
        if (total != success) {
            logger.info("Priming Connections not fully successful");
        } else {
            logger.info("Priming connections fully successful");
        }
        logger.debug("numServers left to be 'primed'="
                + (total - success));
        logger.debug("numServers successfully 'primed'=" + success);
        logger
                .debug("numServers whose attempts not complete exclusively due to max time allocated="
                        + (total - (success + failure)));
        logger.debug("Total Time Taken=" + totalTime
                + " msecs, out of an allocated max of (msecs)="
                + maxTotalTimeToPrimeConnections);
    }

    /*
    private void makeConnectionsASync() {
        Callable<Void> ft = new Callable<Void>() {
            public Void call() throws Exception {
                logger.info("primeConnections ...");
                makeConnections();
                return null;
            }
        };
        outerExecutorService.submit(ft);
    }
    */
    
    /**
     * Prime servers asynchronously.
     * 
     * @param servers
     * @param listener
     */
    public List<Future<Boolean>> primeConnectionsAsync(final List<Server> servers, final PrimeConnectionListener listener) {
        if (servers == null) {
            return Collections.emptyList();
        }
        List<Server> allServers = new ArrayList<Server>();
        allServers.addAll(servers);
        if (allServers.size() == 0){
            logger.debug("RestClient:" + name + ". No nodes/servers to prime connections");
            return Collections.emptyList();
        }        

        logger.info("Priming Connections for RestClient:" + name
                + ", numServers:" + allServers.size());
        List<Future<Boolean>> ftList = new ArrayList<Future<Boolean>>();
        for (Server s : allServers) {
            // prevent the server to be used by load balancer
            // will be set to true when priming is done
            s.setReadyToServe(false);
            if (aSync) {
                Future<Boolean> ftC = null;
                try {
                    ftC = makeConnectionASync(s, listener);
                    ftList.add(ftC);

                } catch (Throwable e) { // NOPMD
                    // It does not really matter if there was an exception,
                    // the goal here is to attempt "priming/opening" the route
                    // in ec2 .. actual http results do not matter
                }
            } else {
                connectToServer(s, listener);
            }
        }   
        return ftList;
    }
    
    private Future<Boolean> makeConnectionASync(final Server s, 
            final PrimeConnectionListener listener) throws InterruptedException, ExecutionException {
        Callable<Boolean> ftConn = new Callable<Boolean>() {
            public Boolean call() throws Exception {
                logger.debug("calling primeconnections ...");
                return connectToServer(s, listener);
            }
        };
        return executorService.submit(ftConn);
    }

    public void shutdown() {
        executorService.shutdown();
        Monitors.unregisterObject(name + "_PrimeConnection", this);
    }

    private Boolean connectToServer(final Server s, final PrimeConnectionListener listener) {
        int tryNum = 0;
        Exception lastException = null;
        totalCounter.increment();
        boolean success = false;
        do {
            try {
                logger.debug("Executing PrimeConnections request to server " + s + " with path " + primeConnectionsURIPath
                        + ", tryNum=" + tryNum);
                success = connector.connect(s, primeConnectionsURIPath);
                successCounter.increment();
                break;
            } catch (Exception e) {
                // It does not really matter if there was an exception,
                // the goal here is to attempt "priming/opening" the route
                // in ec2 .. actual http results do not matter
                logger.debug("Error connecting to server: {}", e.getMessage());
                lastException = e;
                sleepBeforeRetry(tryNum);
            } 
            logger.debug("server:" + s + ", result=" + success + ", tryNum="
                    + tryNum + ", maxRetries=" + maxRetries);
            tryNum++;
        } while (!success && (tryNum <= maxRetries));
        // set the alive flag so that it can be used by load balancers
        if (listener != null) {
            try {
                listener.primeCompleted(s, lastException);
            } catch (Throwable e) {
                logger.error("Error calling PrimeComplete listener", e);
            }
        }
        logger.debug("Either done, or quitting server:" + s + ", result="
                + success + ", tryNum=" + tryNum + ", maxRetries=" + maxRetries);        
        return success;
    }

    private void sleepBeforeRetry(int tryNum) {
        try {
            int sleep = (tryNum + 1) * 100;
            logger.debug("Sleeping for " + sleep + "ms ...");
            Thread.sleep(sleep); // making this seconds based is too slow
            // i.e. 200ms, 400 ms, 800ms, 1600ms etc.
        } catch (InterruptedException ex) {
        }
    }
    
    static class ASyncPrimeConnectionsThreadFactory implements ThreadFactory {
        private static final AtomicInteger groupNumber = new AtomicInteger(1);
        private final ThreadGroup group;
        private final AtomicInteger threadNumber = new AtomicInteger(1);
        private final String namePrefix;

        ASyncPrimeConnectionsThreadFactory(String name) {
            SecurityManager s = System.getSecurityManager();
            group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); // NOPMD
            namePrefix = "ASyncPrimeConnectionsThreadFactory-" + name + "-"
                    + groupNumber.getAndIncrement() + "-thread-";
        }

        public Thread newThread(Runnable r) {
            Thread t = new Thread(group, r, namePrefix
                    + threadNumber.getAndIncrement(), 0);
            if (!t.isDaemon())
                t.setDaemon(true);
            if (t.getPriority() != Thread.NORM_PRIORITY)
                t.setPriority(Thread.NORM_PRIORITY);
            return t;
        }
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_4be8bde_47e5ff8/rev_4be8bde-47e5ff8/ribbon-core/src/main/java/com/netflix/loadbalancer/BaseLoadBalancer.java;<<<<<<< MINE
=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.loadbalancer;

import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.Timer;
import java.util.TimerTask;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.collect.ImmutableList;
import com.netflix.client.ClientFactory;
import com.netflix.client.IClientConfigAware;
import com.netflix.client.PrimeConnections;
import com.netflix.client.config.CommonClientConfigKey;
import com.netflix.client.config.IClientConfig;
import com.netflix.servo.annotations.DataSourceType;
import com.netflix.servo.annotations.Monitor;
import com.netflix.servo.monitor.Counter;
import com.netflix.servo.monitor.Monitors;
import com.netflix.util.concurrent.ShutdownEnabledTimer;

/**
 * A basic implementation of the load balancer where an arbitrary list of
 * servers can be set as the server pool. A ping can be set to determine the
 * liveness of a server. Internally, this class maintains an "all" server list
 * and an "up" server list and use them depending on what the caller asks for.
 * 
 * @author stonse
 * 
 */
public class BaseLoadBalancer extends AbstractLoadBalancer implements
        PrimeConnections.PrimeConnectionListener, IClientConfigAware {

    private static Logger logger = LoggerFactory
            .getLogger(BaseLoadBalancer.class);
    private final static IRule DEFAULT_RULE = new RoundRobinRule();
    private static final String DEFAULT_NAME = "default";
    private static final String PREFIX = "LoadBalancer_";

    protected IRule rule = DEFAULT_RULE;

    protected IPing ping = null;

    @Monitor(name = PREFIX + "AllServerList", type = DataSourceType.INFORMATIONAL)
    protected volatile List<Server> allServerList = Collections
            .synchronizedList(new ArrayList<Server>());
    @Monitor(name = PREFIX + "UpServerList", type = DataSourceType.INFORMATIONAL)
    protected volatile List<Server> upServerList = Collections
            .synchronizedList(new ArrayList<Server>());

    protected ReadWriteLock allServerLock = new ReentrantReadWriteLock();
    protected ReadWriteLock upServerLock = new ReentrantReadWriteLock();

    protected String name = DEFAULT_NAME;

    protected Timer lbTimer = null;
    protected int pingIntervalSeconds = 10;
    protected int maxTotalPingTimeSeconds = 5;
    protected Comparator<Server> serverComparator = new ServerComparator();

    protected AtomicBoolean pingInProgress = new AtomicBoolean(false);

    protected LoadBalancerStats lbStats;

    private volatile Counter counter;

    private PrimeConnections primeConnections;

    private volatile boolean enablePrimingConnections = false;
    
    private IClientConfig config;
    
    private List<ServerListChangeListener> changeListeners = new CopyOnWriteArrayList<ServerListChangeListener>();

    /**
     * Default constructor which sets name as "default", sets null ping, and
     * {@link RoundRobinRule} as the rule.
     * <p>
     * This constructor is mainly used by {@link ClientFactory}. Calling this
     * constructor must be followed by calling {@link #init()} or
     * {@link #initWithNiwsConfig(IClientConfig)} to complete initialization.
     * This constructor is provided for reflection. When constructing
     * programatically, it is recommended to use other constructors.
     */
    public BaseLoadBalancer() {
        this.name = DEFAULT_NAME;
        this.ping = null;
        setRule(DEFAULT_RULE);
        setupPingTask();
        lbStats = new LoadBalancerStats(DEFAULT_NAME);
        counter = createCounter();
    }

    public BaseLoadBalancer(String lbName, IRule rule, LoadBalancerStats lbStats) {
        this(lbName, rule, lbStats, null);
    }

    public BaseLoadBalancer(IPing ping, IRule rule) {
        this(DEFAULT_NAME, rule, new LoadBalancerStats(DEFAULT_NAME), ping);
    }

    public BaseLoadBalancer(String name, IRule rule, LoadBalancerStats stats,
            IPing ping) {
        if (logger.isDebugEnabled()) {
            logger.debug("LoadBalancer:  initialized");
        }
        this.name = name;
        this.ping = ping;
        setRule(rule);
        setupPingTask();
        lbStats = stats;
        counter = createCounter();
        init();
    }

    public BaseLoadBalancer(IClientConfig config) {
        initWithNiwsConfig(config);
    }

    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
    	this.config = clientConfig;
        String clientName = clientConfig.getClientName();
        String ruleClassName = (String) clientConfig
                .getProperty(CommonClientConfigKey.NFLoadBalancerRuleClassName);
        String pingClassName = (String) clientConfig
                .getProperty(CommonClientConfigKey.NFLoadBalancerPingClassName);

        IRule rule;
        IPing ping;
        try {
            rule = (IRule) ClientFactory.instantiateInstanceWithClientConfig(
                    ruleClassName, clientConfig);
            ping = (IPing) ClientFactory.instantiateInstanceWithClientConfig(
                    pingClassName, clientConfig);
        } catch (Exception e) {
            throw new RuntimeException("Error initializing load balancer", e);
        }

        this.name = clientName;
        int pingIntervalTime = Integer.parseInt(""
                + clientConfig.getProperty(
                        CommonClientConfigKey.NFLoadBalancerPingInterval,
                        Integer.parseInt("30")));
        int maxTotalPingTime = Integer.parseInt(""
                + clientConfig.getProperty(
                        CommonClientConfigKey.NFLoadBalancerMaxTotalPingTime,
                        Integer.parseInt("2")));

        setPingInterval(pingIntervalTime);
        setMaxTotalPingTime(maxTotalPingTime);

        // cross associate with each other
        // i.e. Rule,Ping meet your container LB
        // LB, these are your Ping and Rule guys ...
        setRule(rule);
        setPing(ping);
        setLoadBalancerStats(new LoadBalancerStats(clientName));
        rule.setLoadBalancer(this);
        if (ping instanceof AbstractLoadBalancerPing) {
            ((AbstractLoadBalancerPing) ping).setLoadBalancer(this);
        }
        logger.info("Client:" + name + " instantiated a LoadBalancer:"
                + toString());
        boolean enablePrimeConnections = false;

        if (clientConfig
                .getProperty(CommonClientConfigKey.EnablePrimeConnections) != null) {
            Boolean bEnablePrimeConnections = Boolean.valueOf(""
                    + clientConfig.getProperty(
                            CommonClientConfigKey.EnablePrimeConnections,
                            "false"));
            enablePrimeConnections = bEnablePrimeConnections.booleanValue();
        }

        if (enablePrimeConnections) {
            this.setEnablePrimingConnections(true);
            PrimeConnections primeConnections = new PrimeConnections(
                    this.getName(), clientConfig);
            this.setPrimeConnections(primeConnections);
        }
        init();
    }

    public void addServerListChangeListener(ServerListChangeListener listener) {
        changeListeners.add(listener);
    }
    
    public void removeServerListChangeListener(ServerListChangeListener listener) {
        changeListeners.remove(listener);
    }

    public IClientConfig getClientConfig() {
    	return config;
    }
    
    private boolean canSkipPing() {
        if (ping == null
                || ping.getClass().getName().equals(DummyPing.class.getName())) {
            // default ping, no need to set up timer
            return true;
        } else {
            return false;
        }
    }

    private void setupPingTask() {
        if (canSkipPing()) {
            return;
        }
        if (lbTimer != null) {
            lbTimer.cancel();
        }
        lbTimer = new ShutdownEnabledTimer("NFLoadBalancer-PingTimer-" + name,
                true);
        lbTimer.schedule(new PingTask(), 0, pingIntervalSeconds * 1000);
        forceQuickPing();
    }

    /**
     * Set the name for the load balancer. This should not be called since name
     * should be immutable after initialization. Calling this method does not
     * guarantee that all other data structures that depend on this name will be
     * changed accordingly.
     */
    void setName(String name) {
        // and register
        this.name = name;
        if (lbStats == null) {
            lbStats = new LoadBalancerStats(name);
        } else {
            lbStats.setName(name);
        }
    }

    public String getName() {
        return name;
    }

    @Override
    public LoadBalancerStats getLoadBalancerStats() {
        return lbStats;
    }

    public void setLoadBalancerStats(LoadBalancerStats lbStats) {
        this.lbStats = lbStats;
    }

    public Lock lockAllServerList(boolean write) {
        Lock aproposLock = write ? allServerLock.writeLock() : allServerLock
                .readLock();
        aproposLock.lock();
        return aproposLock;
    }

    public Lock lockUpServerList(boolean write) {
        Lock aproposLock = write ? upServerLock.writeLock() : upServerLock
                .readLock();
        aproposLock.lock();
        return aproposLock;
    }

    public void setPingInterval(int pingIntervalSeconds) {
        if (pingIntervalSeconds < 1) {
            return;
        }

        this.pingIntervalSeconds = pingIntervalSeconds;
        if (logger.isDebugEnabled()) {
            logger.debug("LoadBalancer:  pingIntervalSeconds set to "
                    + this.pingIntervalSeconds);
        }
        setupPingTask(); // since ping data changed
    }

    public int getPingInterval() {
        return pingIntervalSeconds;
    }

    /*
     * Maximum time allowed for the ping cycle
     */
    public void setMaxTotalPingTime(int maxTotalPingTimeSeconds) {
        if (maxTotalPingTimeSeconds < 1) {
            return;
        }
        this.maxTotalPingTimeSeconds = maxTotalPingTimeSeconds;
        if (logger.isDebugEnabled()) {
            logger.debug("LoadBalancer: maxTotalPingTime set to "
                    + this.maxTotalPingTimeSeconds);
        }

    }

    public int getMaxTotalPingTime() {
        return maxTotalPingTimeSeconds;
    }

    public IPing getPing() {
        return ping;
    }

    public IRule getRule() {
        return rule;
    }

    public boolean isPingInProgress() {
        return pingInProgress.get();
    }

    /* Specify the object which is used to send pings. */

    public void setPing(IPing ping) {
        if (ping != null) {
            if (!ping.equals(this.ping)) {
                this.ping = ping;
                setupPingTask(); // since ping data changed
            }
        } else {
            this.ping = null;
            // cancel the timer task
            lbTimer.cancel();
        }
    }

    /* Ignore null rules */

    public void setRule(IRule rule) {
        if (rule != null) {
            this.rule = rule;
        } else {
            /* default rule */
            this.rule = new RoundRobinRule();
        }
        if (this.rule.getLoadBalancer() != this) {
            this.rule.setLoadBalancer(this);
        }
    }

    /**
     * get the count of servers.
     * 
     * @param onlyAvailable
     *            if true, return only up servers.
     */
    public int getServerCount(boolean onlyAvailable) {
        if (onlyAvailable) {
            return upServerList.size();
        } else {
            return allServerList.size();
        }
    }

    /**
     * Add a server to the 'allServer' list; does not verify uniqueness, so you
     * could give a server a greater share by adding it more than once.
     */
    public void addServer(Server newServer) {
        if (newServer != null) {
            try {
                ArrayList<Server> newList = new ArrayList<Server>();

                newList.addAll(allServerList);
                newList.add(newServer);
                setServersList(newList);
            } catch (Exception e) {
                logger.error("Exception while adding a newServer", e);
            }
        }
    }

    /**
     * Add a list of servers to the 'allServer' list; does not verify
     * uniqueness, so you could give a server a greater share by adding it more
     * than once
     */
    @Override
    public void addServers(List<Server> newServers) {
        if (newServers != null && newServers.size() > 0) {
            try {
                ArrayList<Server> newList = new ArrayList<Server>();
                newList.addAll(allServerList);
                newList.addAll(newServers);
                setServersList(newList);
            } catch (Exception e) {
                logger.error("Exception while adding Servers", e);
            }
        }
    }

    /*
     * Add a list of servers to the 'allServer' list; does not verify
     * uniqueness, so you could give a server a greater share by adding it more
     * than once USED by Test Cases only for legacy reason. DO NOT USE!!
     */
    void addServers(Object[] newServers) {
        if ((newServers != null) && (newServers.length > 0)) {

            try {
                ArrayList<Server> newList = new ArrayList<Server>();
                newList.addAll(allServerList);

                for (Object server : newServers) {
                    if (server != null) {
                        if (server instanceof String) {
                            server = new Server((String) server);
                        }
                        if (server instanceof Server) {
                            newList.add((Server) server);
                        }
                    }
                }
                setServersList(newList);
            } catch (Exception e) {
                logger.error("Exception while adding Servers", e);
            }
        }
    }

    /**
     * Set the list of servers used as the server pool. This overrides existing
     * server list.
     */
    public void setServersList(List lsrv) {
        Lock writeLock = allServerLock.writeLock();
        if (logger.isDebugEnabled()) {
            logger.debug("LoadBalancer:  clearing server list (SET op)");
        }
        ArrayList<Server> newServers = new ArrayList<Server>();
        writeLock.lock();
        try {
            ArrayList<Server> allServers = new ArrayList<Server>();
            for (Object server : lsrv) {
                if (server == null) {
                    continue;
                }

                if (server instanceof String) {
                    server = new Server((String) server);
                }

                if (server instanceof Server) {
                    if (logger.isDebugEnabled()) {
                        logger.debug("LoadBalancer:  addServer ["
                                + ((Server) server).getId() + "]");
                    }
                    allServers.add((Server) server);
                } else {
                    throw new IllegalArgumentException(
                            "Type String or Server expected, instead found:"
                                    + server.getClass());
                }

            }
            boolean listChanged = false;
            if (!allServerList.equals(allServers)) {
                listChanged = true;
                if (changeListeners != null && changeListeners.size() > 0) {
                   List<Server> oldList = ImmutableList.copyOf(allServerList);
                   List<Server> newList = ImmutableList.copyOf(allServers);                   
                   for (ServerListChangeListener l: changeListeners) {
                       try {
                           l.serverListChanged(oldList, newList);
                       } catch (Throwable e) {
                           logger.error("Error invoking server list change listener", e);
                       }
                   }
                }
            }
            if (isEnablePrimingConnections()) {
                for (Server server : allServers) {
                    if (!allServerList.contains(server)) {
                        server.setReadyToServe(false);
                        newServers.add((Server) server);
                    }
                }
                if (primeConnections != null) {
                    primeConnections.primeConnectionsAsync(newServers, this);
                }
            }
            // This will reset readyToServe flag to true on all servers
            // regardless whether
            // previous priming connections are success or not
            allServerList = allServers;
            if (canSkipPing()) {
                for (Server s : allServerList) {
                    s.setAlive(true);
                }
                upServerList = allServerList;
            } else if (listChanged) {
                forceQuickPing();
            }
        } finally {
            writeLock.unlock();
        }
    }

    /* List in string form. SETS, does not add. */
    void setServers(String srvString) {
        if (srvString != null) {

            try {
                String[] serverArr = srvString.split(",");
                ArrayList<Server> newList = new ArrayList<Server>();

                for (String serverString : serverArr) {
                    if (serverString != null) {
                        serverString = serverString.trim();
                        if (serverString.length() > 0) {
                            Server svr = new Server(serverString);
                            newList.add(svr);
                        }
                    }
                }
                setServersList(newList);
            } catch (Exception e) {
                logger.error("Exception while adding Servers", e);
            }
        }
    }

    /**
     * return the server
     * 
     * @param index
     * @param availableOnly
     */
    public Server getServerByIndex(int index, boolean availableOnly) {
        try {
            return (availableOnly ? upServerList.get(index) : allServerList
                    .get(index));
        } catch (Exception e) {
            return null;
        }
    }

    @Override
    public List<Server> getServerList(boolean availableOnly) {
        return (availableOnly ? Collections.unmodifiableList(upServerList) : 
        	Collections.unmodifiableList(allServerList));
    }

    @Override
    public List<Server> getServerList(ServerGroup serverGroup) {
        switch (serverGroup) {
        case ALL:
            return allServerList;
        case STATUS_UP:
            return upServerList;
        case STATUS_NOT_UP:
            ArrayList<Server> notAvailableServers = new ArrayList<Server>(
                    allServerList);
            ArrayList<Server> upServers = new ArrayList<Server>(upServerList);
            notAvailableServers.removeAll(upServers);
            return notAvailableServers;
        }
        return new ArrayList<Server>();
    }

    public void cancelPingTask() {
        if (lbTimer != null) {
            lbTimer.cancel();
        }
    }

    /**
     * TimerTask that keeps runs every X seconds to check the status of each
     * server/node in the Server List
     * 
     * @author stonse
     * 
     */
    class PingTask extends TimerTask {
        public void run() {
            Pinger ping = new Pinger();
            try {
                ping.runPinger();
            } catch (Throwable t) {
                logger.error("Throwable caught while running extends for "
                        + name, t);
            }
        }
    }

    /**
     * Class that contains the mechanism to "ping" all the instances
     * 
     * @author stonse
     *
     */
    class Pinger {

        public void runPinger() {

            if (pingInProgress.get()) {
                return; // Ping in progress - nothing to do
            } else {
                pingInProgress.set(true);
            }

            // we are "in" - we get to Ping

            Object[] allServers = null;
            boolean[] results = null;

            Lock allLock = null;
            Lock upLock = null;

            try {
                /*
                 * The readLock should be free unless an addServer operation is
                 * going on...
                 */
                allLock = allServerLock.readLock();
                allLock.lock();
                allServers = allServerList.toArray();
                allLock.unlock();

                int numCandidates = allServers.length;
                results = new boolean[numCandidates];

                if (logger.isDebugEnabled()) {
                    logger.debug("LoadBalancer:  PingTask executing ["
                            + numCandidates + "] servers configured");
                }

                for (int i = 0; i < numCandidates; i++) {
                    results[i] = false; /* Default answer is DEAD. */
                    try {
                        // NOTE: IFF we were doing a real ping
                        // assuming we had a large set of servers (say 15)
                        // the logic below will run them serially
                        // hence taking 15 times the amount of time it takes
                        // to ping each server
                        // A better method would be to put this in an executor
                        // pool
                        // But, at the time of this writing, we dont REALLY
                        // use a Real Ping (its mostly in memory eureka call)
                        // hence we can afford to simplify this design and run
                        // this
                        // serially
                        if (ping != null) {
                            results[i] = ping.isAlive((Server) allServers[i]);
                        }
                    } catch (Throwable t) {
                        logger.error("Exception while pinging Server:"
                                + allServers[i], t);
                    }
                }

                ArrayList<Server> newUpList = new ArrayList<Server>();

                for (int i = 0; i < numCandidates; i++) {
                    boolean isAlive = results[i];
                    Server svr = (Server) allServers[i];
                    boolean oldIsAlive = svr.isAlive();

                    svr.setAlive(isAlive);

                    if (oldIsAlive != isAlive && logger.isDebugEnabled()) {
                        logger.debug("LoadBalancer:  Server [" + svr.getId()
                                + "] status changed to "
                                + (isAlive ? "ALIVE" : "DEAD"));
                    }

                    if (isAlive) {
                        newUpList.add(svr);
                    }
                }
                // System.out.println(count + " servers alive");
                upLock = upServerLock.writeLock();
                upLock.lock();
                upServerList = newUpList;
                upLock.unlock();
            } catch (Throwable t) {
                logger.error("Throwable caught while running the Pinger-"
                        + name, t);
            } finally {
                pingInProgress.set(false);
            }
        }
    }

    private final Counter createCounter() {
        return Monitors.newCounter("LoadBalancer_ChooseServer");
    }

    /*
     * Get the alive server dedicated to key
     * 
     * @return the dedicated server
     */
    public Server chooseServer(Object key) {
        if (counter == null) {
            counter = createCounter();
        }
        counter.increment();
        if (rule == null) {
            return null;
        } else {
            try {
                return rule.choose(key);
            } catch (Throwable t) {
                return null;
            }
        }
    }

    /* Returns either null, or "server:port/servlet" */
    public String choose(Object key) {
        if (rule == null) {
            return null;
        } else {
            try {
                Server svr = rule.choose(key);
                return ((svr == null) ? null : svr.getId());
            } catch (Throwable t) {
                return null;
            }
        }
    }

    public void markServerDown(Server server) {
        if (server == null) {
            return;
        }

        if (!server.isAlive()) {
            return;
        }

        logger.error("LoadBalancer:  markServerDown called on ["
                + server.getId() + "]");
        server.setAlive(false);
        // forceQuickPing();
    }

    public void markServerDown(String id) {
        boolean triggered = false;

        id = Server.normalizeId(id);

        if (id == null) {
            return;
        }

        Lock writeLock = upServerLock.writeLock();

        try {

            for (Server svr : upServerList) {
                if (svr.isAlive() && (svr.getId().equals(id))) {
                    triggered = true;
                    svr.setAlive(false);
                }
            }

            if (triggered) {
                logger.error("LoadBalancer:  markServerDown called on [" + id
                        + "]");
            }

        } finally {
            try {
                writeLock.unlock();
            } catch (Exception e) { // NOPMD
            }
        }
    }

    /*
     * Force an immediate ping, if we're not currently pinging and don't have a
     * quick-ping already scheduled.
     */
    public void forceQuickPing() {
        if (canSkipPing()) {
            return;
        }
        if (logger.isDebugEnabled()) {
            logger.debug("LoadBalancer:  forceQuickPing invoked");
        }
        Pinger ping = new Pinger();
        try {
            ping.runPinger();
        } catch (Throwable t) {
            logger.error("Throwable caught while running forceQuickPing() for "
                    + name, t);
        }
    }

    public String toString() {
        StringBuilder sb = new StringBuilder();
        sb.append("{NFLoadBalancer:name=").append(this.getName())
                .append(",current list of Servers=").append(this.allServerList)
                .append(",Load balancer stats=")
                .append(this.lbStats.toString()).append("}");
        return sb.toString();
    }

    /**
     * Register with monitors and start priming connections if it is set.
     */
    protected void init() {
        Monitors.registerObject("LoadBalancer_" + name, this);
        // register the rule as it contains metric for available servers count
        Monitors.registerObject("Rule_" + name, this.getRule());
        if (enablePrimingConnections && primeConnections != null) {
            primeConnections.primeConnections(getServerList(true));
        }
    }

    public final PrimeConnections getPrimeConnections() {
        return primeConnections;
    }

    public final void setPrimeConnections(PrimeConnections primeConnections) {
        this.primeConnections = primeConnections;
    }

    @Override
    public void primeCompleted(Server s, Throwable lastException) {
        s.setReadyToServe(true);
    }

    public boolean isEnablePrimingConnections() {
        return enablePrimingConnections;
    }

    public final void setEnablePrimingConnections(
            boolean enablePrimingConnections) {
        this.enablePrimingConnections = enablePrimingConnections;
    }
    
    public void shutdown() {
        cancelPingTask();
        if (primeConnections != null) {
            primeConnections.shutdown();
        }
        Monitors.unregisterObject("LoadBalancer_" + name, this);
        Monitors.unregisterObject("Rule_" + name, this.getRule());
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_4be8bde_47e5ff8/rev_4be8bde-47e5ff8/ribbon-core/src/main/java/com/netflix/loadbalancer/DynamicServerListLoadBalancer.java;<<<<<<< MINE
=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.loadbalancer;

import java.util.Date;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.ScheduledThreadPoolExecutor;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicLong;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.netflix.client.ClientFactory;
import com.netflix.client.config.CommonClientConfigKey;
import com.netflix.client.config.DefaultClientConfigImpl;
import com.netflix.client.config.IClientConfig;
import com.netflix.config.DynamicIntProperty;
import com.netflix.config.DynamicProperty;
import com.netflix.servo.annotations.DataSourceType;
import com.netflix.servo.annotations.Monitor;
import com.google.common.annotations.VisibleForTesting;
import com.google.common.util.concurrent.ThreadFactoryBuilder;

/**
 * A LoadBalancer that has the capabilities to obtain the candidate list of
 * servers using a dynamic source. i.e. The list of servers can potentially be
 * changed at Runtime. It also contains facilities wherein the list of servers
 * can be passed through a Filter criteria to filter out servers that do not
 * meet the desired criteria.
 * 
 * @author stonse
 * 
 */
public class DynamicServerListLoadBalancer<T extends Server> extends
        BaseLoadBalancer {
    private static final Logger LOGGER = LoggerFactory
            .getLogger(DynamicServerListLoadBalancer.class);

    boolean isSecure = false;
    boolean useTunnel = false;
    private static Thread _shutdownThread;

    // to keep track of modification of server lists
    protected AtomicBoolean serverListUpdateInProgress = new AtomicBoolean(
            false);

    private static long LISTOFSERVERS_CACHE_UPDATE_DELAY = 1000; // msecs;
    private static long LISTOFSERVERS_CACHE_REPEAT_INTERVAL = 30 * 1000; // msecs;
                                                                         // //
                                                                         // every
                                                                         // 30
                                                                         // secs

    private static ScheduledThreadPoolExecutor _serverListRefreshExecutor = null;

    private long refeshIntervalMills = LISTOFSERVERS_CACHE_REPEAT_INTERVAL;

    volatile ServerList<T> serverListImpl;

    volatile ServerListFilter<T> filter;
    
    private AtomicLong lastUpdated = new AtomicLong(System.currentTimeMillis());
    
    protected volatile boolean serverRefreshEnabled = false;
    private final static String CORE_THREAD = "DynamicServerListLoadBalancer.ThreadPoolSize";
    private final static DynamicIntProperty poolSizeProp = new DynamicIntProperty(CORE_THREAD, 2);
    
    private volatile ScheduledFuture<?> scheduledFuture;

    static {
        int coreSize = poolSizeProp.get();
        ThreadFactory factory = (new ThreadFactoryBuilder()).setDaemon(true).build();
        _serverListRefreshExecutor = new ScheduledThreadPoolExecutor(coreSize, factory);
        poolSizeProp.addCallback(new Runnable() {
            @Override
            public void run() {
                _serverListRefreshExecutor.setCorePoolSize(poolSizeProp.get());
            }
        
        });
        _shutdownThread = new Thread(new Runnable() {
            public void run() {
                LOGGER.info("Shutting down the Executor Pool for DynamicServerListLoadBalancer");
                shutdownExecutorPool();
            }
        });
        Runtime.getRuntime().addShutdownHook(_shutdownThread);
    }
    
    public DynamicServerListLoadBalancer() {
        super();
    }

    public DynamicServerListLoadBalancer(IClientConfig niwsClientConfig) {
        initWithNiwsConfig(niwsClientConfig);
    }

    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
        try {
            super.initWithNiwsConfig(clientConfig);
            String niwsServerListClassName = clientConfig.getProperty(
                    CommonClientConfigKey.NIWSServerListClassName,
                    DefaultClientConfigImpl.DEFAULT_SEVER_LIST_CLASS)
                    .toString();

            ServerList<T> niwsServerListImpl = (ServerList<T>) ClientFactory
                    .instantiateInstanceWithClientConfig(
                            niwsServerListClassName, clientConfig);
            this.serverListImpl = niwsServerListImpl;

            if (niwsServerListImpl instanceof AbstractServerList) {
                AbstractServerListFilter<T> niwsFilter = ((AbstractServerList) niwsServerListImpl)
                        .getFilterImpl(clientConfig);
                niwsFilter.setLoadBalancerStats(getLoadBalancerStats());
                this.filter = niwsFilter;
            }

            refeshIntervalMills = Integer.valueOf(clientConfig.getProperty(
                    CommonClientConfigKey.ServerListRefreshInterval,
                    LISTOFSERVERS_CACHE_REPEAT_INTERVAL).toString());

            boolean primeConnection = this.isEnablePrimingConnections();
            // turn this off to avoid duplicated asynchronous priming done in BaseLoadBalancer.setServerList()
            this.setEnablePrimingConnections(false);
            enableAndInitLearnNewServersFeature();

            updateListOfServers();
            if (primeConnection && this.getPrimeConnections() != null) {
                this.getPrimeConnections()
                        .primeConnections(getServerList(true));
            }
            this.setEnablePrimingConnections(primeConnection);

        } catch (Exception e) {
            throw new RuntimeException(
                    "Exception while initializing NIWSDiscoveryLoadBalancer:"
                            + clientConfig.getClientName()
                            + ", niwsClientConfig:" + clientConfig, e);
        }
    }

    @Override
    public void setServersList(List lsrv) {
        super.setServersList(lsrv);
        List<T> serverList = (List<T>) lsrv;
        Map<String, List<Server>> serversInZones = new HashMap<String, List<Server>>();
        for (Server server : serverList) {
            // make sure ServerStats is created to avoid creating them on hot
            // path
            getLoadBalancerStats().getSingleServerStat(server);
            String zone = server.getZone();
            if (zone != null) {
                zone = zone.toLowerCase();
                List<Server> servers = serversInZones.get(zone);
                if (servers == null) {
                    servers = new ArrayList<Server>();
                    serversInZones.put(zone, servers);
                }
                servers.add(server);
            }
        }
        setServerListForZones(serversInZones);
    }

    protected void setServerListForZones(
            Map<String, List<Server>> zoneServersMap) {
        LOGGER.debug("Setting server list for zones: {}", zoneServersMap);
        getLoadBalancerStats().updateZoneServerMapping(zoneServersMap);
    }

    public ServerList<T> getServerListImpl() {
        return serverListImpl;
    }

    public void setServerListImpl(ServerList<T> niwsServerList) {
        this.serverListImpl = niwsServerList;
    }

    @Override
    public void setPing(IPing ping) {
        this.ping = ping;
    }

    public ServerListFilter<T> getFilter() {
        return filter;
    }

    public void setFilter(ServerListFilter<T> filter) {
        this.filter = filter;
    }

    @Override
    /**
     * Makes no sense to ping an inmemory disc client
     * 
     */
    public void forceQuickPing() {
        // no-op
    }

    /**
     * Feature that lets us add new instances (from AMIs) to the list of
     * existing servers that the LB will use Call this method if you want this
     * feature enabled
     */
    public void enableAndInitLearnNewServersFeature() {
        keepServerListUpdated();
        serverRefreshEnabled = true;
    }

    private String getIdentifier() {
        return this.getClientConfig().getClientName();
    }

    private void keepServerListUpdated() {
        scheduledFuture = _serverListRefreshExecutor.scheduleAtFixedRate(
                new ServerListRefreshExecutorThread(),
                LISTOFSERVERS_CACHE_UPDATE_DELAY, refeshIntervalMills,
                TimeUnit.MILLISECONDS);
    }

    private static void shutdownExecutorPool() {
        if (_serverListRefreshExecutor != null) {
            _serverListRefreshExecutor.shutdown();

            if (_shutdownThread != null) {
                try {
                    Runtime.getRuntime().removeShutdownHook(_shutdownThread);
                } catch (IllegalStateException ise) { // NOPMD
                    // this can happen if we're in the middle of a real
                    // shutdown,
                    // and that's 'ok'
                }
            }

        }
    }

    public void stopServerListRefreshing() {
        serverRefreshEnabled = false;
        if (scheduledFuture != null) {
            scheduledFuture.cancel(true);
        }
    }
    
    /**
     * Class that updates the list of Servers This is based on the method used
     * by the client * Appropriate Filters are applied before coming up with the
     * right set of servers
     * 
     * @author stonse
     * 
     */
    class ServerListRefreshExecutorThread implements Runnable {

        public void run() {
            if (!serverRefreshEnabled) {
                if (scheduledFuture != null) {
                    scheduledFuture.cancel(true);
                }
                return;
            }
            try {
                updateListOfServers();

            } catch (Throwable e) {
                LOGGER.error(
                        "Exception while updating List of Servers obtained from Discovery client",
                        e);
                // e.printStackTrace();
            }
        }

    }

    @VisibleForTesting
    public void updateListOfServers() {
        List<T> servers = new ArrayList<T>();
        if (serverListImpl != null) {
            servers = serverListImpl.getUpdatedListOfServers();
            LOGGER.debug("List of Servers for {} obtained from Discovery client: {}",
                    getIdentifier(), servers);

            if (filter != null) {
                servers = filter.getFilteredListOfServers(servers);
                LOGGER.debug("Filtered List of Servers for {} obtained from Discovery client: {}",
                        getIdentifier(), servers);
            }
        }
        lastUpdated.set(System.currentTimeMillis());
        updateAllServerList(servers);
    }

    /**
     * Update the AllServer list in the LoadBalancer if necessary and enabled
     * 
     * @param ls
     */
    protected void updateAllServerList(List<T> ls) {
        // other threads might be doing this - in which case, we pass
        if (!serverListUpdateInProgress.get()) {
            serverListUpdateInProgress.set(true);
            for (T s : ls) {
                s.setAlive(true); // set so that clients can start using these
                                  // servers right away instead
                // of having to wait out the ping cycle.
            }
            setServersList(ls);
            super.forceQuickPing();
            serverListUpdateInProgress.set(false);
        }
    }

    @Monitor(name="NumUpdateCyclesMissed", type=DataSourceType.GAUGE)
    public int getNumberMissedCycles() {
        if (!serverRefreshEnabled) {
            return 0;
        }
        return (int) ((int) (System.currentTimeMillis() - lastUpdated.get()) / refeshIntervalMills);
    }
    
    @Monitor(name="LastUpdated", type=DataSourceType.INFORMATIONAL)
    public String getLastUpdate() {
        return new Date(lastUpdated.get()).toString();
    }
    
    @Monitor(name="NumThreads", type=DataSourceType.GAUGE) 
    public int getCoreThreads() {
        if (_serverListRefreshExecutor != null) {
            return _serverListRefreshExecutor.getCorePoolSize();
        } else {
            return 0;
        }
    }
    
    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder("DynamicServerListLoadBalancer:");
        sb.append(super.toString());
        sb.append("ServerList:" + String.valueOf(serverListImpl));
        return sb.toString();
    }
    
    @Override 
    public void shutdown() {
        super.shutdown();
        stopServerListRefreshing();
    }
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_4be8bde_47e5ff8/rev_4be8bde-47e5ff8/ribbon-core/src/test/java/com/netflix/client/LoadBalancerContextTest.java;<<<<<<< MINE
=======
/*
 *
 * Copyright 2013 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.client;

import static org.junit.Assert.*;

import java.net.URLEncoder;

import org.junit.Test;

import com.netflix.client.http.HttpRequest;
import com.netflix.client.http.HttpResponse;
import com.netflix.loadbalancer.BaseLoadBalancer;
import com.netflix.loadbalancer.Server;

public class LoadBalancerContextTest {

    static BaseLoadBalancer lb = new BaseLoadBalancer() {

        @Override
        public Server chooseServer(Object key) {
            return new Server("www.example.com:8080");
        }
    };
    
    
    private MyLoadBalancerContext context;
    
    public LoadBalancerContextTest() {
        context = new MyLoadBalancerContext();
        context.setLoadBalancer(lb);
    }
    
    @Test
    public void testComputeFinalUriWithLoadBalancer() throws ClientException {
        HttpRequest request = HttpRequest.newBuilder().uri("/test?abc=xyz").build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals("http://www.example.com:8080/test?abc=xyz", newRequest.getUri().toString());
    }
    
    @Test
    public void testEncodedPath() throws ClientException {
        String uri = "http://localhost:8080/resources/abc%2Fxyz";
        HttpRequest request = HttpRequest.newBuilder().uri(uri).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals(uri, newRequest.getUri().toString());
    }
    
    @Test
    public void testPreservesUserInfo() throws ClientException {
        // %3A == ":" -- ensure user info is not decoded
        String uri = "http://us%3Aer:pass@localhost:8080?foo=bar";
        HttpRequest request = HttpRequest.newBuilder().uri(uri).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals(uri, newRequest.getUri().toString());
    }
    
    @Test
    public void testQueryWithoutPath() throws ClientException {
        String uri = "?foo=bar";
        HttpRequest request = HttpRequest.newBuilder().uri(uri).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals("http://www.example.com:8080?foo=bar", newRequest.getUri().toString());
    }
    
    @Test
    public void testEncodedPathAndHostChange() throws ClientException {
        String uri = "/abc%2Fxyz";
        HttpRequest request = HttpRequest.newBuilder().uri(uri).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals("http://www.example.com:8080" + uri, newRequest.getUri().toString());
    }

    
    @Test
    public void testEncodedQuery() throws Exception {
        String uri = "http://localhost:8080/resources/abc?";
        String queryString = "name=" + URLEncoder.encode("Ã©Æ&=*%!@#$%^&*()", "UTF-8");   
        HttpRequest request = HttpRequest.newBuilder().uri(uri + queryString).build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals(uri + queryString, newRequest.getUri().toString());        
    }
    
    @Test
    public void testComputeFinalUriWithLoadBalancer_regressionRaw() throws ClientException {
        HttpRequest request = HttpRequest.newBuilder().uri("/test?ampersand=foo%26bar").build();
        HttpRequest newRequest = context.computeFinalUriWithLoadBalancer(request);
        assertEquals("http://www.example.com:8080/test?ampersand=foo%26bar", newRequest.getUri().toString());
    }
}

class MyLoadBalancerContext extends LoadBalancerContext<HttpRequest, HttpResponse> {
}>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_4be8bde_47e5ff8/rev_4be8bde-47e5ff8/ribbon-httpclient/src/main/java/com/netflix/niws/client/http/RestClient.java;<<<<<<< MINE
import java.util.Iterator;
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_4be8bde_47e5ff8/rev_4be8bde-47e5ff8/ribbon-httpclient/src/main/java/com/netflix/niws/client/http/RestClient.java;<<<<<<< MINE
import javax.ws.rs.core.MultivaluedMap;

import com.netflix.client.ClientFactory;
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_4be8bde_47e5ff8/rev_4be8bde-47e5ff8/ribbon-httpclient/src/main/java/com/netflix/niws/client/http/RestClient.java;<<<<<<< MINE
import com.netflix.client.ClientFactory;
import com.netflix.client.RequestSpecificRetryHandler;
=======
import com.netflix.client.ClientFactory;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_4be8bde_47e5ff8/rev_4be8bde-47e5ff8/ribbon-httpclient/src/main/java/com/netflix/niws/client/http/RestClient.java;<<<<<<< MINE
import com.netflix.loadbalancer.ILoadBalancer;
=======
import com.netflix.loadbalancer.BaseLoadBalancer;
import com.netflix.loadbalancer.ILoadBalancer;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_4be8bde_47e5ff8/rev_4be8bde-47e5ff8/ribbon-httpclient/src/main/java/com/netflix/niws/client/http/RestClient.java;<<<<<<< MINE
import com.netflix.serialization.SerializationUtils;
import com.netflix.serialization.Serializer;
import com.netflix.serialization.TypeDef;
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_4be8bde_47e5ff8/rev_4be8bde-47e5ff8/ribbon-httpclient/src/main/java/com/netflix/niws/client/http/RestClient.java;<<<<<<< MINE

    @Override
    public RequestSpecificRetryHandler getRequestSpecificRetryHandler(
            HttpRequest request, IClientConfig requestConfig) {
        if (!request.isRetriable()) {
            return new RequestSpecificRetryHandler(false, false, this.getErrorHandler(), requestConfig);
        }
        if (request.getVerb() != HttpRequest.Verb.GET) {
            return new RequestSpecificRetryHandler(true, false, this.getErrorHandler(), requestConfig);
        } else {
            return new RequestSpecificRetryHandler(true, true, this.getErrorHandler(), requestConfig);
        } 
    }
=======
	
	public void shutdown() {
	    ILoadBalancer lb = this.getLoadBalancer();
	    if (lb instanceof BaseLoadBalancer) {
	        ((BaseLoadBalancer) lb).shutdown();
	    }
	    NFHttpClientFactory.shutdownNFHttpClient(restClientName);
	}
>>>>>>> YOURS
/home/taes/taes/projects/archaius/revisions/rev_450add0_b99c9ae/rev_450add0-b99c9ae/archaius-aws/src/test/java/com/netflix/config/sources/DynamoDbConfigurationSourceTest.java;<<<<<<< MINE

import org.junit.AfterClass;
import org.junit.BeforeClass;
import org.junit.Ignore;
import org.junit.Test;
=======
import static org.mockito.Mockito.*;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d005ea3_539efc9/rev_d005ea3-539efc9/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
   public static List<String> getMessageFieldNames(Class<? extends Message> protoClass, Map<String, String> fieldNameTranslations) {
=======
  public static List<String> getMessageFieldNames(Class<? extends Message> protoClass, Map<String, String> fieldNameTranslations) {
    return getMessageFieldNames(getMessageDescriptor(protoClass), fieldNameTranslations);
  }

   public static List<String> getMessageFieldNames(Descriptor descriptor, Map<String, String> fieldNameTranslations) {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_d005ea3_539efc9/rev_d005ea3-539efc9/src/java/com/twitter/elephantbird/util/Protobufs.java;<<<<<<< MINE
     return ListHelper.filter(Lists.transform(getMessageDescriptor(protoClass).getFields(), fieldTransformer), Predicates.<String>notNull());
=======
     return ListHelper.filter(Lists.transform(descriptor.getFields(), fieldTransformer), Predicates.<String>notNull());
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_f875c0b_8acda1f/rev_f875c0b-8acda1f/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
import com.twitter.elephantbird.thrift.test.TestName;
import com.twitter.elephantbird.thrift.test.TestPerson;
import com.twitter.elephantbird.thrift.test.TestPhoneType;
=======
import com.twitter.elephantbird.thrift.TStructDescriptor.Field;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_aebc2c4_89ee7d8/rev_aebc2c4-89ee7d8/ribbon-client-extensions/src/main/java/com/netflix/ribbonclientextensions/Ribbon.java;<<<<<<< MINE
import com.netflix.ribbonclientextensions.http.HttpRequestTemplate;

import com.netflix.ribbonclientextensions.typedclient.RibbonDynamicProxy;
import io.reactivex.netty.protocol.http.client.HttpClient;
=======
import com.netflix.ribbonclientextensions.http.HttpResourceGroup;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_aebc2c4_89ee7d8/rev_aebc2c4-89ee7d8/ribbon-client-extensions/src/main/java/com/netflix/ribbonclientextensions/Ribbon.java;<<<<<<< MINE
 
    public static <I, O, T> T from(Class<T> contract, HttpClient<I, O> transportClient) {
        return RibbonDynamicProxy.newInstance(contract, transportClient);
=======

    public static <T> T from(Class<T> contract) {
        return null;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_3ef3270_e8d76ea/rev_3ef3270-e8d76ea/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
import com.twitter.elephantbird.thrift.TStructDescriptor.Field;
=======
import com.twitter.elephantbird.thrift.test.TestName;
import com.twitter.elephantbird.thrift.test.TestPerson;
import com.twitter.elephantbird.thrift.test.TestPhoneType;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/PigToThrift.java;<<<<<<< MINE
    @SuppressWarnings("rawtypes")
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
=======
  public TStructDescriptor getTStructDescriptor() {
    return structDesc;
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
    return new LazyTuple(thriftObj);
=======
    return new LazyTuple(structDesc, thriftObj);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
        tuple.set(i, toPigObject(field, value));
=======
        tuple.set(i, toPigObject(field, value, false));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
  private static Object toPigObject(Field field, Object value) {
=======
  static Object toPigObject(Field field, Object value, boolean lazy) {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
      return toTuple(field.gettStructDescriptor(), (TBase<?, ?>)value);
=======
      if (lazy) {
        return new LazyTuple(field.gettStructDescriptor(), (TBase<?, ?>)value);
      } else {
        return toTuple(field.gettStructDescriptor(), (TBase<?, ?>)value);
      }
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
      return toPigMap(field, (Map<Object, Object>)value);
=======
      return toPigMap(field, (Map<Object, Object>)value, lazy);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
      return toPigBag(field.getSetElemField(), (Collection<Object>)value);
=======
      return toPigBag(field.getSetElemField(), (Collection<Object>)value, lazy);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
      return toPigBag(field.getListElemField(), (Collection<Object>)value);
=======
      return toPigBag(field.getListElemField(), (Collection<Object>)value, lazy);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
  private static Map<String, Object> toPigMap(Field field, Map<Object, Object> map) {
=======
  private static Map<String, Object> toPigMap(Field field,
                                              Map<Object, Object> map,
                                              boolean lazy) {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
                            toPigObject(valueField, e.getValue()));
=======
                            toPigObject(valueField, e.getValue(), lazy));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
  private static DataBag toPigBag(Field field, Collection<Object> values) {
=======
  private static DataBag toPigBag(Field field,
                                  Collection<Object> values,
                                  boolean lazy) {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
      Object pValue = toPigObject(field, value);
=======
      Object pValue = toPigObject(field, value, lazy);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
  private class LazyTuple extends AbstractLazyTuple {
=======
  private static class LazyTuple extends AbstractLazyTuple {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
    private M tObject;
=======
    private TBase<?, ?> tObject;
    private TStructDescriptor desc;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
    LazyTuple(M tObject) {
      initRealTuple(structDesc.getFields().size());
=======
    LazyTuple(TStructDescriptor desc, TBase<?, ?> tObject) {
      initRealTuple(desc.getFields().size());
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
=======
      this.desc = desc;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
      Field field = structDesc.getFieldAt(index);
      return toPigObject(field, structDesc.getFieldValue(index, tObject));
=======
      Field field = desc.getFieldAt(index);
      return toPigObject(field, desc.getFieldValue(index, tObject), true);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ProtobufTuple.java;<<<<<<< MINE
    if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
      return protoConv_.messageToTuple(fieldDescriptor, fieldValue);
    } else {
      return protoConv_.singleFieldToTuple(fieldDescriptor, fieldValue);
    }
=======
    return protoConv_.fieldToPig(fieldDescriptor, fieldValue);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/AbstractLazyTuple.java;<<<<<<< MINE
=======
  @Override
  public String toString() {
    convertAll();
    return realTuple.toString();
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/util/ProtobufToPig.java;<<<<<<< MINE
=======
   * Returns either {@link #messageToTuple(FieldDescriptor, Object)}
   * or {@link #singleFieldToTuple(FieldDescriptor, Object)} depending
   * on whether the field is a Message or a simple field.
   */
  protected Object fieldToPig(FieldDescriptor fieldDescriptor, Object fieldValue) {
    if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {
      return messageToTuple(fieldDescriptor, fieldValue);
    } else {
      return singleFieldToTuple(fieldDescriptor, fieldValue);
    }
  }

  /**
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoThriftB64LinePigLoader.java;<<<<<<< MINE
=======
import org.apache.pig.impl.logicalLayer.FrontendException;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoThriftB64LinePigLoader.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.ProjectedThriftTuple;
=======
import com.twitter.elephantbird.pig.util.ProjectedThriftTupleFactory;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoThriftB64LinePigLoader.java;<<<<<<< MINE
  protected final TypeRef<M> typeRef_;
  private ProjectedThriftTuple<M> tupleTemplate;
=======
  protected final TypeRef<M> typeRef_;
  private ProjectedThriftTupleFactory<M> tupleTemplate;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoThriftB64LinePigLoader.java;<<<<<<< MINE
    thriftToPig_ =  ThriftToPig.newInstance(typeRef_);
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoThriftB64LinePigLoader.java;<<<<<<< MINE
      thriftToPig_.getLazyTuple(value) : null;
=======
      tupleTemplate.newTuple(value) : null;
  }

  @Override
  public RequiredFieldResponse pushProjection(RequiredFieldList requiredFieldList)
                                              throws FrontendException {
    return pushProjectionHelper(requiredFieldList);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoThriftBlockPigLoader.java;<<<<<<< MINE
import org.apache.hadoop.mapreduce.Job;
import org.apache.pig.ResourceSchema;
import org.apache.pig.data.Tuple;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoThriftBlockPigLoader.java;<<<<<<< MINE
import com.twitter.elephantbird.mapreduce.input.LzoRecordReader;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoThriftBlockPigLoader.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.pig.util.ThriftToPig;
import com.twitter.elephantbird.util.TypeRef;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoThriftBlockPigLoader.java;<<<<<<< MINE

public class LzoThriftBlockPigLoader<M extends TBase<?, ?>> extends LzoBaseLoadFunc {

  private final TypeRef<M> typeRef_;
  private final ThriftToPig<M> thriftToPig_;
=======
public class LzoThriftBlockPigLoader<M extends TBase<?, ?>> extends LzoThriftB64LinePigLoader<M> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoThriftBlockPigLoader.java;<<<<<<< MINE
    typeRef_ = PigUtil.getThriftTypeRef(thriftClassName);
    thriftToPig_ =  ThriftToPig.newInstance(typeRef_);
  }

  /**
   * Returns next Tuple for the Thrift object read from the input.
   * <p>
   * A small fraction of bad records are tolerated. See {@link LzoRecordReader}
   * for more information on error handling.
   *
   * @see org.apache.pig.LoadFunc#getNext()
   */
  @Override
  public Tuple getNext() throws IOException {
    M value = getNextBinaryValue(typeRef_);

    return value != null ?
      thriftToPig_.getLazyTuple(value) : null;
  }

  @Override
  public ResourceSchema getSchema(String filename, Job job) throws IOException {
    return new ResourceSchema(ThriftToPig.toSchema(typeRef_.getRawClass()));
=======
    super(thriftClassName);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
=======
import java.util.Arrays;
import java.util.List;
import java.util.Properties;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
=======
import org.apache.pig.LoadPushDown;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
=======
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.util.ObjectSerializer;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
=======
import org.apache.pig.impl.util.UDFContext;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
public abstract class LzoBaseLoadFunc extends LoadFunc implements LoadMetadata {
=======
public abstract class LzoBaseLoadFunc extends LoadFunc implements LoadMetadata, LoadPushDown {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
=======
  protected final String LZO_EXTENSION = new LzopCodec().getDefaultExtension();

  @SuppressWarnings("unchecked")
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
  protected String contextSignature;
  protected static final String projectionSuffix = "_LzoBaseLoadFunc_projectedFields";

  protected RequiredFieldList requiredFieldList = null;
=======
  protected String contextSignature;
  protected static final String projectionKey = "LzoBaseLoadFunc_projectedFields";

  protected RequiredFieldList requiredFieldList = null;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
=======
  /** UDF properties for this class based on context signature */
  protected Properties getUDFProperties() {
    return UDFContext.getUDFContext()
        .getUDFProperties(this.getClass(), new String[] {contextSignature});
  }

  @Override
  public void setUDFContextSignature(String signature) {
    this.contextSignature = signature;
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
  // LoadPushDown implementation:

  @Override
  public List<OperatorSet> getFeatures() {
    return Arrays.asList(LoadPushDown.OperatorSet.PROJECTION);
  }

  @Override
  public RequiredFieldResponse pushProjection(
      RequiredFieldList requiredFieldList) throws FrontendException {
    // the default implementation disables the feature.
    // a projection needs to be explicitly supported by sub classes.
    return null;
  }

  /**
   * A helper method for implementing
   * {@link LoadPushDown#pushProjection(RequiredFieldList)}. <p>
   *
   * Stores requiredFieldList in context. The requiredFields are read from
   * context on the backend inside {@link #setLocation(String, Job)}.
   */
  protected RequiredFieldResponse pushProjectionHelper(
                                          RequiredFieldList requiredFieldList)
                                          throws FrontendException {
    try {
      getUDFProperties().setProperty(
                          contextSignature + projectionSuffix,
                          ObjectSerializer.serialize(requiredFieldList));
    } catch (IOException e) { // not expected
      throw new FrontendException(e);
    }

    return new RequiredFieldResponse(true);
  }

=======
  // LoadPushDown implementation:

  @Override
  public List<OperatorSet> getFeatures() {
    return Arrays.asList(LoadPushDown.OperatorSet.PROJECTION);
  }

  @Override
  public RequiredFieldResponse pushProjection(
      RequiredFieldList requiredFieldList) throws FrontendException {
    // the default implementation disables the feature.
    // a projection needs to be explicitly supported by sub classes.
    return null;
  }

  /**
   * A helper method for implementing
   * {@link LoadPushDown#pushProjection(RequiredFieldList)}. <p>
   *
   * Stores requiredFieldList in context. The requiredFields are read from
   * context on the backend (in side {@link #setLocation(String, Job)}).
   */
  protected RequiredFieldResponse pushProjectionHelper(
                                          RequiredFieldList requiredFieldList)
                                          throws FrontendException {
    try {
      getUDFProperties().setProperty(projectionKey,
                                     ObjectSerializer.serialize(requiredFieldList));
    } catch (IOException e) { // not expected
      throw new FrontendException(e);
    }

    return new RequiredFieldResponse(true);
  }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
import org.apache.hadoop.mapreduce.Job;
import org.apache.pig.ResourceSchema;
import org.apache.pig.data.Tuple;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
import com.twitter.elephantbird.mapreduce.input.LzoRecordReader;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.pig.util.ProtobufToPig;
import com.twitter.elephantbird.pig.util.ProtobufTuple;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
public class LzoProtobufBlockPigLoader<M extends Message> extends LzoBaseLoadFunc {

  private TypeRef<M> typeRef_ = null;
  private final ProtobufToPig protoToPig_ = new ProtobufToPig();
=======
public class LzoProtobufBlockPigLoader<M extends Message> extends LzoProtobufB64LinePigLoader<M> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoProtobufBlockPigLoader.java;<<<<<<< MINE
    TypeRef<M> typeRef = PigUtil.getProtobufTypeRef(protoClassName);
    setTypeRef(typeRef);
  }

  /**
   * Set the type parameter so it doesn't get erased by Java.  Must be called before getNext!
   *
   * @param typeRef
   */
  public void setTypeRef(TypeRef<M> typeRef) {
    typeRef_ = typeRef;
  }

  /**
   * Return next Protobuf Tuple from input.
   * <p>
   * A small fraction of bad records in input are tolerated.
   * See  {@link LzoRecordReader} for more information on error handling.
   */
  public Tuple getNext() throws IOException {
    M value = getNextBinaryValue(typeRef_);

    return value != null ?
        new ProtobufTuple(value) : null;
  }

  @Override
  public String[] getPartitionKeys(String location, Job job) throws IOException {
    return null;
  }

  @Override
  public ResourceSchema getSchema(String location, Job job) throws IOException {
    return new ResourceSchema(protoToPig_.toSchema(Protobufs.getMessageDescriptor(typeRef_.getRawClass())));
=======
    super(protoClassName);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
=======
import org.apache.pig.impl.logicalLayer.FrontendException;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.ProjectedProtoTuple;
=======
import com.twitter.elephantbird.pig.util.ProjectedProtobufTupleFactory;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.ProtobufTuple;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
  protected TypeRef<M> typeRef_ = null;
  private final ProtobufToPig protoToPig_ = new ProtobufToPig();
  private ProjectedProtoTuple<M> tupleTemplate = null;
=======
  protected TypeRef<M> typeRef = null;
  private final ProtobufToPig protoToPig = new ProtobufToPig();
  private ProjectedProtobufTupleFactory<M> tupleTemplate = null;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/java/com/twitter/elephantbird/pig/load/LzoProtobufB64LinePigLoader.java;<<<<<<< MINE
        new ProtobufTuple(value) : null;
=======
        tupleTemplate.newTuple(value) : null;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
=======
import java.util.List;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
=======
import org.apache.pig.LoadPushDown.RequiredField;
import org.apache.pig.LoadPushDown.RequiredFieldList;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/test/com/twitter/elephantbird/pig/piggybank/TestThriftToPig.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.ProjectedThriftTuple;
=======
import com.twitter.elephantbird.pig.util.ProjectedThriftTupleFactory;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/test/com/twitter/elephantbird/pig/piggybank/TestProtoToPig.java;<<<<<<< MINE
=======
import org.apache.pig.LoadPushDown.RequiredField;
import org.apache.pig.LoadPushDown.RequiredFieldList;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/test/com/twitter/elephantbird/pig/piggybank/TestProtoToPig.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.pig.util.ProjectedProtoTuple;
=======
import com.twitter.elephantbird.pig.util.PigUtil;
import com.twitter.elephantbird.pig.util.ProjectedProtobufTupleFactory;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/test/com/twitter/elephantbird/pig/piggybank/TestProtoToPig.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.util.TypeRef;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/test/com/twitter/elephantbird/pig/piggybank/TestProtoToPig.java;<<<<<<< MINE
=======
      if (idx%2 == 0) {
        assertEquals(projectedTuple.get(fd.getIndex()/2), normalTuple.get(fd.getIndex()));
      }
      idx++;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_b784885_342f336/rev_b784885-342f336/src/test/com/twitter/elephantbird/pig/piggybank/TestProtoToPig.java;<<<<<<< MINE
=======

  private static RequiredFieldList evenFields(List<FieldDescriptor> protoFields) {
    RequiredFieldList reqList = new RequiredFieldList();

    int i = 0;
    for(FieldDescriptor fd : protoFields) {
      if (i%2 == 0) {
        RequiredField field = new RequiredField();
        field.setAlias(fd.getName());
        field.setIndex(i);
        // field.setType() type is not used
        reqList.add(field);
      }
      i++;
    }
    return reqList;
  }

>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_786e464_200cffe/rev_786e464-200cffe/ribbon-transport/src/main/java/com/netflix/client/netty/http/NettyHttpClient.java;<<<<<<< MINE
=======
import rx.Subscription;
import rx.functions.Func1;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_786e464_200cffe/rev_786e464-200cffe/ribbon-transport/src/test/java/com/netflix/client/netty/http/NettyClientTest.java;<<<<<<< MINE
=======
import org.apache.log4j.Level;
import org.apache.log4j.LogManager;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/cascading2/scheme/LzoTextDelimited.java;<<<<<<< MINE
import com.hadoop.compression.lzo.LzopCodec;

import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.FileOutputFormat;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/cascading2/scheme/LzoTextDelimited.java;<<<<<<< MINE
import org.apache.hadoop.mapred.TextOutputFormat;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/cascading2/scheme/LzoTextDelimited.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapred.output.DeprecatedLzoTextOutputFormat;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/cascading2/scheme/LzoTextDelimited.java;<<<<<<< MINE
    conf.setOutputFormat(TextOutputFormat.class);
    FileOutputFormat.setCompressOutput(conf, true);
    FileOutputFormat.setOutputCompressorClass(conf, LzopCodec.class);
    conf.setOutputKeyClass(Text.class);
    conf.setOutputValueClass(Text.class);
=======
    conf.setOutputFormat(DeprecatedLzoTextOutputFormat.class);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/cascading2/scheme/LzoTextLine.java;<<<<<<< MINE
import com.hadoop.compression.lzo.LzopCodec;

import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.FileOutputFormat;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/cascading2/scheme/LzoTextLine.java;<<<<<<< MINE
import org.apache.hadoop.mapred.TextOutputFormat;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/cascading2/scheme/LzoTextLine.java;<<<<<<< MINE
=======
import com.twitter.elephantbird.mapred.output.DeprecatedLzoTextOutputFormat;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/cascading2/scheme/LzoTextLine.java;<<<<<<< MINE
    conf.setOutputFormat(TextOutputFormat.class);
    FileOutputFormat.setCompressOutput(conf, true);
    FileOutputFormat.setOutputCompressorClass(conf, LzopCodec.class);
    conf.setOutputKeyClass(Text.class);
    conf.setOutputValueClass(Text.class);
=======
    conf.setOutputFormat(DeprecatedLzoTextOutputFormat.class);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/mapred/output/DeprecatedLzoThriftB64LineOutputFormat.java;<<<<<<< MINE
    extends DeprecatedLzoOutputFormat<M, ThriftWritable<M>> {
=======
    extends DeprecatedLzoOutputFormat<NullWritable, ThriftWritable<M>> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/mapred/output/DeprecatedLzoOutputFormat.java;<<<<<<< MINE
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
=======
import com.twitter.elephantbird.util.LzoUtils;

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/mapred/output/DeprecatedLzoOutputFormat.java;<<<<<<< MINE
import org.apache.hadoop.io.NullWritable;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/mapred/output/DeprecatedLzoOutputFormat.java;<<<<<<< MINE
public abstract class DeprecatedLzoOutputFormat <M, W>
    extends FileOutputFormat<NullWritable, W> {
=======
public abstract class DeprecatedLzoOutputFormat <K, V>
    extends FileOutputFormat<K, V> {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/mapred/output/DeprecatedLzoOutputFormat.java;<<<<<<< MINE
    FileSystem fs = file.getFileSystem(job);
    FSDataOutputStream fileOut = fs.create(file, false);
    return new DataOutputStream(codec.createOutputStream(fileOut));
=======

    return LzoUtils.getIndexedLzoOutputStream(job, file);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_13f2963_3a82539/rev_13f2963-3a82539/src/java/com/twitter/elephantbird/mapred/output/DeprecatedLzoTextOutputFormat.java;<<<<<<< MINE
package com.twitter.elephantbird.mapred.output;

import java.io.IOException;

import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.RecordWriter;
import org.apache.hadoop.mapred.TextOutputFormat;
import org.apache.hadoop.util.Progressable;

import com.hadoop.compression.lzo.LzopCodec;
import com.twitter.elephantbird.util.LzoUtils;

@Deprecated
public class DeprecatedLzoTextOutputFormat<K, V> extends TextOutputFormat<K, V> {

  //non-deprecated LzoTextOutputFormat should also extend TextOutputFormat.

  @Override
  public RecordWriter<K, V> getRecordWriter(FileSystem ignored, JobConf job,
      String name, Progressable progress) throws IOException {

    Path file = getPathForCustomFile(job,  "part");
    file = file.suffix(LzopCodec.DEFAULT_LZO_EXTENSION);

    return new LineRecordWriter<K, V>(
                  LzoUtils.getIndexedLzoOutputStream(job, file),
                  job.get("mapred.textoutputformat.separator", "\t"));
  }

}=======
package com.twitter.elephantbird.mapred.output;

import java.io.DataOutputStream;
import java.io.IOException;

import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.RecordWriter;
import org.apache.hadoop.mapred.Reporter;
import org.apache.hadoop.util.Progressable;

public class DeprecatedLzoTextOutputFormat
            extends DeprecatedLzoOutputFormat<NullWritable, Text> {

  @Override
  public RecordWriter<NullWritable, Text> getRecordWriter(FileSystem ignored,
      JobConf job, String name, Progressable progress) throws IOException {

    final DataOutputStream out = getOutputStream(job);

    return new RecordWriter<NullWritable, Text>() {

      public void close(Reporter reporter) throws IOException {
        out.close();
      }

      public void write(NullWritable key, Text value) throws IOException {
        out.write(value.getBytes(), 0, value.getLength());
        out.write('\n');
      }
    };
  }

}>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_74434b8_8cd8347/rev_74434b8-8cd8347/curator-framework/src/main/java/com/netflix/curator/framework/listen/ListenerContainer.java;<<<<<<< MINE
    public void     forEach(Function<T, Void> function)
=======
    public void     forEach(final Function<T, Void> function)
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_74434b8_8cd8347/rev_74434b8-8cd8347/curator-framework/src/main/java/com/netflix/curator/framework/listen/ListenerContainer.java;<<<<<<< MINE
            try
            {
                function.apply(entry.listener);
            }
            catch ( Throwable e )
            {
                log.error(String.format("Listener (%s) threw an exception", entry.listener), e);
            }
=======
            entry.executor.execute
            (
                new Runnable()
                {
                    @Override
                    public void run()
                    {
                        try
                        {
                            function.apply(entry.listener);
                        }
                        catch ( Throwable e )
                        {
                            log.error(String.format("Listener (%s) threw an exception", entry.listener), e);
                        }
                    }
                }
            );
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_d4c0be0_ff4ec29/rev_d4c0be0-ff4ec29/curator-framework/src/main/java/com/netflix/curator/framework/imps/CreateBuilderImpl.java;<<<<<<< MINE
                    boolean     retry = false;
=======
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_d4c0be0_ff4ec29/rev_d4c0be0-ff4ec29/curator-framework/src/main/java/com/netflix/curator/framework/imps/CreateBuilderImpl.java;<<<<<<< MINE
                        try
                        {
                            ZKPaths.mkdirs(client.getZooKeeper(), operationAndData.getData().getPath(), false);
                            retry = true;
                        }
                        catch ( Exception e )
                        {
                            client.logError("Could not create parents for path: " + operationAndData.getData().getPath(), e);
                        }
                    }

                    if ( retry )
                    {
                        try
                        {
                            performBackgroundOperation(operationAndData);
                        }
                        catch ( Exception e )
                        {
                            client.logError("Could not create node after creating parents for path: " + operationAndData.getData().getPath(), e);
                        }
=======
                        backgroundCreateParentsThenNode(operationAndData);
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_d4c0be0_ff4ec29/rev_d4c0be0-ff4ec29/curator-framework/src/main/java/com/netflix/curator/framework/imps/CreateBuilderImpl.java;<<<<<<< MINE
=======
    private void backgroundCreateParentsThenNode(final OperationAndData<PathAndBytes> mainOperationAndData)
    {
        BackgroundOperation<PathAndBytes>     operation = new BackgroundOperation<PathAndBytes>()
        {
            @Override
            public void performBackgroundOperation(OperationAndData<PathAndBytes> dummy) throws Exception
            {
                try
                {
                    ZKPaths.mkdirs(client.getZooKeeper(), mainOperationAndData.getData().getPath(), false);
                }
                catch ( KeeperException e )
                {
                    // ignore
                }
                client.queueOperation(mainOperationAndData);
            }
        };
        OperationAndData<PathAndBytes>        parentOperation = new OperationAndData<PathAndBytes>(operation, mainOperationAndData.getData(), null, null);
        client.queueOperation(parentOperation);
    }

>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_d4c0be0_ff4ec29/rev_d4c0be0-ff4ec29/curator-framework/src/main/java/com/netflix/curator/framework/imps/CuratorFrameworkImpl.java;<<<<<<< MINE
        boolean     queueOperation = false;
=======
        boolean     doQueueOperation = false;
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_d4c0be0_ff4ec29/rev_d4c0be0-ff4ec29/curator-framework/src/main/java/com/netflix/curator/framework/imps/CuratorFrameworkImpl.java;<<<<<<< MINE
                    queueOperation = true;
=======
                    doQueueOperation = true;
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_d4c0be0_ff4ec29/rev_d4c0be0-ff4ec29/curator-framework/src/main/java/com/netflix/curator/framework/imps/CuratorFrameworkImpl.java;<<<<<<< MINE
        if ( queueOperation )
=======
        if ( doQueueOperation )
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_d4c0be0_ff4ec29/rev_d4c0be0-ff4ec29/curator-framework/src/main/java/com/netflix/curator/framework/imps/CuratorFrameworkImpl.java;<<<<<<< MINE
            backgroundOperations.offer(operationAndData);
=======
            queueOperation(operationAndData);
>>>>>>> YOURS
/home/taes/taes/projects/curator/revisions/rev_d4c0be0_ff4ec29/rev_d4c0be0-ff4ec29/curator-framework/src/main/java/com/netflix/curator/framework/imps/CuratorFrameworkImpl.java;<<<<<<< MINE
=======
    <DATA_TYPE> void queueOperation(OperationAndData<DATA_TYPE> operationAndData)
    {
        backgroundOperations.offer(operationAndData);
    }

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_723eb3c_11dfa53/rev_723eb3c-11dfa53/src/java/com/twitter/elephantbird/thrift/TStructDescriptor.java;<<<<<<< MINE
    fields = ImmutableList.of(arr);
=======
    fields = ImmutableList.copyOf(arr);
>>>>>>> YOURS
/home/taes/taes/projects/archaius/revisions/rev_1ad0c78_5296b30/rev_1ad0c78-5296b30/archaius-core/src/main/java/com/netflix/config/DynamicStringSetProperty.java;<<<<<<< MINE
/*
 * Copyright 2014 Netflix, Inc.
=======
/**
 * Copyright 2014 Netflix, Inc.
>>>>>>> YOURS
/home/taes/taes/projects/archaius/revisions/rev_1ad0c78_5296b30/rev_1ad0c78-5296b30/archaius-core/src/main/java/com/netflix/config/DynamicStringSetProperty.java;<<<<<<< MINE
 * http://www.apache.org/licenses/LICENSE-2.0
=======
 *     http://www.apache.org/licenses/LICENSE-2.0
>>>>>>> YOURS
/home/taes/taes/projects/archaius/revisions/rev_1ad0c78_5296b30/rev_1ad0c78-5296b30/archaius-core/src/main/java/com/netflix/config/DynamicStringSetProperty.java;<<<<<<< MINE
 *
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_5c67188_f3e8cdf/rev_5c67188-f3e8cdf/ribbon/src/main/java/com/netflix/ribbon/http/HttpResourceGroup.java;<<<<<<< MINE
    @Override
    protected IClientConfig loadDefaultConfig(String groupName) {
        return IClientConfig.Builder.newBuilder(groupName).build();
    }
    
=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_5c67188_f3e8cdf/rev_5c67188-f3e8cdf/ribbon/src/main/java/com/netflix/ribbon/HttpResourceGroupFactory.java;<<<<<<< MINE
=======
package com.netflix.ribbon;

import com.netflix.client.config.IClientConfig;
import com.netflix.ribbon.http.HttpResourceGroup;

/**
 * Factory for creating an HttpResourceGroup.  For DI either bind DefaultHttpResourceGroupFactory
 * or implement your own to customize or override HttpResourceGroup.
 * 
 * @author elandau
 */
public interface HttpResourceGroupFactory {
    HttpResourceGroup createHttpResourceGroup(String name, ClientOptions options);
    
    HttpResourceGroup createHttpResourceGroup(String name, IClientConfig config);
    
    <T> T from(Class<T> classType);
    
    <T> T from(Class<T> classType, HttpResourceGroup resourceGroup);
}>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestMethodInfo.java;<<<<<<< MINE
=======
import java.util.ArrayList;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestMethodInfo.java;<<<<<<< MINE
=======
import java.util.List;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestMethodInfo.java;<<<<<<< MINE
  // Method-level details
  final boolean isSynchronous;
  Type responseObjectType;
  RequestType requestType = RequestType.SIMPLE;
  String requestMethod;
  boolean requestHasBody;
  String requestUrl;
  Set<String> requestUrlParamNames;
  String requestQuery;

  // Parameter-level details
  String[] requestUrlParam;
  String[] requestQueryName;
  boolean hasQueryParams = false;
  String[] requestFormPair;
  String[] requestMultipartPart;
  int bodyIndex = NO_BODY;
=======
  Type type;
  RestMethod restMethod;
  String path;
  Set<String> pathParams;
  QueryParam[] pathQueryParams;
  List<HeaderPair> headers;
  String[] headerParams;
  String[] namedParams;
  int singleEntityArgumentIndex = NO_SINGLE_ENTITY;
  boolean isMultipart = false;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestMethodInfo.java;<<<<<<< MINE
  /** Loads {@link #requestMethod} and {@link #requestType}. */
=======
  /**
   * Loads {@link #restMethod}, {@link #path}, {@link #pathParams}, {@link #pathQueryParams},
   * {@link headers}, and {@link #isMultipart}.
   */
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestMethodInfo.java;<<<<<<< MINE
  /** Loads {@link #responseObjectType}. Returns {@code true} if method is synchronous. */
=======
  private List<HeaderPair> parseHeaders(String[] headersToParse) {
    List<HeaderPair> headers = new ArrayList<HeaderPair>();
    for (String headerToParse: headersToParse) {
      int colon = headerToParse.indexOf(':');
      headers.add(new HeaderPair(headerToParse.substring(0, colon),
                                 headerToParse.substring(colon + 2)));

    }
    return headers;
  }

  /** Loads {@link #type}. Returns true if the method is synchronous. */
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestMethodInfo.java;<<<<<<< MINE
   * Loads {@link #requestUrlParam}, {@link #requestQueryName}, {@link #requestFormPair}, and
   * {@link #requestMultipartPart}. Must be called after {@link #parseMethodAnnotations()}.
=======
   * Loads {@link #namedParams}, {@link headerParams}, {@link #singleEntityArgumentIndex},
   * Must be called after {@link #parseMethodAnnotations()}}.
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestMethodInfo.java;<<<<<<< MINE
      if (parameterAnnotations != null) {
        for (Annotation parameterAnnotation : parameterAnnotations) {
          Class<? extends Annotation> annotationType = parameterAnnotation.annotationType();

          if (annotationType == Path.class) {
            hasRetrofitAnnotation = true;
            String name = ((Path) parameterAnnotation).value();

            // Verify URL replacement name is actually present in the URL path.
            if (!requestUrlParamNames.contains(name)) {
              throw new IllegalStateException(
                  "Method path \"" + requestUrl + "\" does not contain {" + name + "}.");
            }

            urlParam[i] = name;
          } else if (annotationType == Query.class) {
            hasRetrofitAnnotation = true;
            hasQueryParams = true;
            String name = ((Query) parameterAnnotation).value();

            // TODO verify query name not already used in URL?

            queryName[i] = name;
          } else if (annotationType == Pair.class) {
            if (requestType != RequestType.FORM_ENCODED) {
              throw new IllegalStateException(
                  "@Pair parameters can only be used with form encoding.");
            }

            gotPair = true;
            hasRetrofitAnnotation = true;
            String name = ((Pair) parameterAnnotation).value();

            // TODO verify name not already used?

            formValue[i] = name;
          } else if (annotationType == Part.class) {
            if (requestType != RequestType.MULTIPART) {
              throw new IllegalStateException(
                  "@Part parameters can only be used with multipart encoding.");
            }

            gotPart = true;
            hasRetrofitAnnotation = true;
            String name = ((Part) parameterAnnotation).value();

            // TODO verify name not already used?

            multipartPart[i] = name;
          } else if (annotationType == Body.class) {
            if (requestType != RequestType.SIMPLE) {
              throw new IllegalStateException(
                  "@Body parameters cannot be used with form or multi-part encoding.");
            }
            if (bodyIndex != NO_BODY) {
              throw new IllegalStateException(
                  "Method annotated with multiple Body method annotations: " + method);
            }

            hasRetrofitAnnotation = true;
            bodyIndex = i;
=======
      if (parameterAnnotations == null || parameterAnnotations.length == 0) {
        throw new IllegalStateException("Argument " + i + " lacks annotation.");
      }
      for (Annotation parameterAnnotation : parameterAnnotations) {
        Class<? extends Annotation> annotationType = parameterAnnotation.annotationType();
        if (annotationType == Name.class) {
          String name = ((Name) parameterAnnotation).value();
          namedParams[i] = name;
          boolean isPathParam = pathParams.contains(name);
          if (parameterType == TypedOutput.class && (isPathParam || !restMethod.hasBody())) {
            throw new IllegalStateException("TypedOutput cannot be used as URL parameter.");
          }
          if (!isPathParam && !isMultipart && restMethod.hasBody()) {
            throw new IllegalStateException(
                "Non-path params can only be used in multipart request.");
          }
        } else if (annotationType == Header.class) {
          String header = ((Header) parameterAnnotation).value();
          headerParams[i] = header;
          if (parameterType != String.class) {
            throw new IllegalStateException(
                "Expected @Header parameter type to be String: " + header);
          }
        } else if (annotationType == SingleEntity.class) {
          if (isMultipart) {
            throw new IllegalStateException("SingleEntity cannot be used with multipart request.");
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/client/UrlConnectionClient.java;<<<<<<< MINE
=======
import retrofit.http.HeaderPair;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/client/ApacheClient.java;<<<<<<< MINE
=======
import retrofit.http.HeaderPair;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/client/Request.java;<<<<<<< MINE
=======
import retrofit.http.HeaderPair;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/client/Response.java;<<<<<<< MINE
=======
import retrofit.http.HeaderPair;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/Headers.java;<<<<<<< MINE
=======
// Copyright 2013 Square, Inc.
package retrofit.http;

import static java.lang.annotation.ElementType.METHOD;
import static java.lang.annotation.RetentionPolicy.RUNTIME;

import java.lang.annotation.Retention;
import java.lang.annotation.Target;

/**
 * Adds headers literally supplied in the {@code value}.
 *
 * <p/>
 * ex.
 *
 * <pre>
 * @Headers("Cache-Control: max-age=640000")
 * @GET("/")
 * ...
 *
 * @Headers({
 *   "X-Foo: Bar",
 *   "X-Ping: Pong"
 * })
 * @GET("/")
 * ...
 * </pre>
 *
 * @author Adrian Cole (adrianc@netflix.com)
 */
@Target(METHOD) @Retention(RUNTIME)
public @interface Headers {
  String[] value();
}>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RequestBuilder.java;<<<<<<< MINE
=======
import java.util.ArrayList;
import java.util.Iterator;
import java.util.LinkedHashSet;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RequestBuilder.java;<<<<<<< MINE
  /** A list of custom headers. */
  RequestBuilder headers(List<Header> headers) {
=======
  RequestBuilder setHeaders(List<HeaderPair> headers) {
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RequestBuilder.java;<<<<<<< MINE
  /**
   * Construct a {@link Request} from the supplied information. You <strong>must</strong> call
   * {@link #methodInfo}, {@link #apiUrl}, {@link #args}, and {@link #headers} before invoking this
   * method.
   */
  Request build() throws UnsupportedEncodingException {
    String apiUrl = this.apiUrl;

    StringBuilder url = new StringBuilder(apiUrl);
    if (apiUrl.endsWith("/")) {
      // We enforce relative paths to start with '/'. Prevent a double-slash.
      url.deleteCharAt(url.length() - 1);
    }

    // Append the method relative URL.
    url.append(buildRelativeUrl());

    // Append query parameters, if needed.
    if (methodInfo.hasQueryParams) {
      boolean first = true;
      String requestQuery = methodInfo.requestQuery;
      if (requestQuery != null) {
        url.append(requestQuery);
        first = false;
      }
      String[] requestQueryName = methodInfo.requestQueryName;
      for (int i = 0; i < requestQueryName.length; i++) {
        String query = requestQueryName[i];
        if (query != null) {
          String value = URLEncoder.encode(String.valueOf(args[i]), "UTF-8");
          url.append(first ? '?' : '&').append(query).append('=').append(value);
          first = false;
        }
=======
  /** List of all URL parameters. Return value will be mutated. */
  private List<Parameter> createParamList() {
    List<Parameter> params = new ArrayList<Parameter>();

    // Add arguments as parameters.
    String[] pathNamedParams = methodInfo.namedParams;
    int singleEntityArgumentIndex = methodInfo.singleEntityArgumentIndex;
    for (int i = 0; i < pathNamedParams.length; i++) {
      Object arg = args[i];
      if (arg == null || pathNamedParams[i] == null) continue;
      if (i != singleEntityArgumentIndex) {
        params.add(new Parameter(pathNamedParams[i], arg, arg.getClass()));
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RequestBuilder.java;<<<<<<< MINE
=======
    }

    List<HeaderPair> headers = new ArrayList<HeaderPair>();
    if (this.headers != null) {
      headers.addAll(this.headers);
    }
    if (methodInfo.headers != null) {
      headers.addAll(methodInfo.headers);
    }
    // RFC 2616: Field names are case-insensitive
    List<String> lcHeadersToRemove = new ArrayList<String>();
    if (methodInfo.headerParams != null) {
      for (int i = 0; i < methodInfo.headerParams.length; i++) {
        String name = methodInfo.headerParams[i];
        if (name == null) continue;
        Object arg = args[i];
        if (arg != null) {
          headers.add(new HeaderPair(name, arg.toString()));
        } else {
          lcHeadersToRemove.add(name.toLowerCase());
        }
      }
    }
    for (Iterator<HeaderPair> header = headers.iterator(); header.hasNext();) {
      // RFC 2616: Field names are case-insensitive
      if (lcHeadersToRemove.contains(header.next().getName().toLowerCase()))
        header.remove();
    }
    return new Request(methodInfo.restMethod.value(), url.toString(), headers, body);
  }
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/Header.java;<<<<<<< MINE
=======
// Copyright 2013 Square, Inc.
package retrofit.http;

import java.lang.annotation.Retention;
import java.lang.annotation.Target;

import static java.lang.annotation.ElementType.PARAMETER;
import static java.lang.annotation.RetentionPolicy.RUNTIME;

/**
 * Replaces the header with the the value of its target. If the target is null,
 * the header is removed.
 *
 * <p/>
 * ex.
 *
 * <pre>
 * @GET("/")
 * void foo(@Header("Auth-Token") String token, ..);
 * </pre>
 *
 * @author Adrian Cole (adrianc@netflix.com)
 */
@Retention(RUNTIME) @Target(PARAMETER)
public @interface Header {
  String value();
}>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
  private final RequestHeaders requestHeaders;
=======
  private final HeaderPairs headers;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
      Executor callbackExecutor, RequestHeaders requestHeaders, Converter converter,
      Profiler profiler, Log log, boolean debug) {
=======
      Executor callbackExecutor, HeaderPairs headers, Converter converter, Profiler profiler,
      Log log, boolean debug) {
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
    private RequestHeaders requestHeaders;
=======
    private HeaderPairs headers;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/main/java/retrofit/http/RestAdapter.java;<<<<<<< MINE
    public Builder setRequestHeaders(RequestHeaders requestHeaders) {
      if (requestHeaders == null) throw new NullPointerException("requestHeaders");
      this.requestHeaders = requestHeaders;
=======
    public Builder setHeaders(HeaderPairs headers) {
      if (headers == null) throw new NullPointerException("headers");
      this.headers = headers;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/test/java/retrofit/http/client/UrlConnectionClientTest.java;<<<<<<< MINE
=======
import retrofit.http.HeaderPair;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/test/java/retrofit/http/client/ApacheClientTest.java;<<<<<<< MINE
=======
import retrofit.http.HeaderPair;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/test/java/retrofit/http/RequestBuilderTest.java;<<<<<<< MINE
=======
import java.util.Set;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/test/java/retrofit/http/RequestBuilderTest.java;<<<<<<< MINE
    private String query;
    private final List<String> pathParams = new ArrayList<String>();
    private final List<String> queryParams = new ArrayList<String>();
    private final List<String> pairParams = new ArrayList<String>();
    private final List<String> partParams = new ArrayList<String>();
=======
    private Set<String> pathParams;
    private final List<QueryParam> queryParams = new ArrayList<QueryParam>();
    private final List<String> headerParams = new ArrayList<String>();
    private final List<String> namedParams = new ArrayList<String>();
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/test/java/retrofit/http/RequestBuilderTest.java;<<<<<<< MINE
    private final List<Header> headers = new ArrayList<Header>();
    private int bodyIndex = NO_BODY;
=======
    private final List<HeaderPair> headers = new ArrayList<HeaderPair>();
    private final List<HeaderPair> methodHeaders = new ArrayList<HeaderPair>();
    private int singleEntityArgumentIndex = NO_SINGLE_ENTITY;
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_2ef7ca0_941ae85/rev_2ef7ca0-941ae85/retrofit/src/test/java/retrofit/http/RequestBuilderTest.java;<<<<<<< MINE
    Helper setBody(Object value) {
      addParam(null, null, null, null, value);
      bodyIndex = args.size() - 1;
=======
    Helper addHeaderParam(String name, Object value) {
      if (name == null) {
        throw new IllegalArgumentException("Name can not be null.");
      }
      headerParams.add(name);
      args.add(value);
      return this;
    }

    Helper addSingleEntityParam(Object value) {
      if (singleEntityArgumentIndex != NO_SINGLE_ENTITY) {
        throw new IllegalStateException("Single entity param already added.");
      }
      // Relying on the fact that this is already less one.
      singleEntityArgumentIndex = namedParams.size();
      namedParams.add(null);
      args.add(value);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_2e05eec_21dbeee/rev_2e05eec-21dbeee/src/java/com/twitter/elephantbird/util/ThriftUtils.java;<<<<<<< MINE
import java.nio.ByteBuffer;
import java.util.Collection;
import java.util.Map;
import java.util.Map.Entry;
=======
import java.lang.reflect.Field;
import java.lang.reflect.Method;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_2e05eec_21dbeee/rev_2e05eec-21dbeee/src/java/com/twitter/elephantbird/util/ThriftUtils.java;<<<<<<< MINE
      java.lang.reflect.Field field = containingClass.getDeclaredField(fieldName);
      return field.getType();
    } catch (NoSuchFieldException e) {
      throw new RuntimeException("while trying to find " + fieldName + " in "
                                 + containingClass, e);
=======
      // checking the return type of get method works for union as well.
      String getMethodName = "get"
                             + fieldName.substring(0, 1).toUpperCase()
                             + fieldName.substring(1);
      Method method = containingClass.getDeclaredMethod(getMethodName);
      return method.getReturnType();
    } catch (NoSuchMethodException e) {
      throw new RuntimeException("while trying to find type for " + fieldName +
                                 " in " + containingClass, e);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_2e05eec_21dbeee/rev_2e05eec-21dbeee/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
import com.hadoop.compression.lzo.LzopCodec;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_2e05eec_21dbeee/rev_2e05eec-21dbeee/src/java/com/twitter/elephantbird/pig/load/LzoBaseLoadFunc.java;<<<<<<< MINE
  protected final String LZO_EXTENSION = new LzopCodec().getDefaultExtension();

=======
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_d665e56_bf94f53/rev_d665e56-bf94f53/retrofit/src/main/java/retrofit/http/mime/FormUrlEncodedTypedOutput.java;<<<<<<< MINE
/*
 * Copyright (C) 2013 Square, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package retrofit.http.mime;

import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.io.OutputStream;
import java.net.URLEncoder;

public final class FormUrlEncodedTypedOutput implements TypedOutput {
  final ByteArrayOutputStream content = new ByteArrayOutputStream();

  public void addField(String name, String value) {
    if (name == null) {
      throw new NullPointerException("name");
    }
    if (value == null) {
      throw new NullPointerException("value");
    }
    if (content.size() > 0) {
      content.write('&');
    }
    try {
      name = URLEncoder.encode(name, "UTF-8");
      value = URLEncoder.encode(value, "UTF-8");

      content.write(name.getBytes("UTF-8"));
      content.write('=');
      content.write(value.getBytes("UTF-8"));
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }

  @Override public String fileName() {
    return null;
  }

  @Override public String mimeType() {
    return "application/x-www-form-urlencoded; charset=UTF-8";
  }

  @Override public long length() {
    return content.size();
  }

  @Override public void writeTo(OutputStream out) throws IOException {
    out.write(content.toByteArray());
  }
}=======
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_d665e56_bf94f53/rev_d665e56-bf94f53/retrofit/src/main/java/retrofit/http/RequestBuilder.java;<<<<<<< MINE
/*
 * Copyright (C) 2012 Square, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package retrofit.http;

import java.io.UnsupportedEncodingException;
import java.net.URLEncoder;
import java.util.ArrayList;
import java.util.List;
import retrofit.http.client.Header;
import retrofit.http.client.Request;
import retrofit.http.mime.FormUrlEncodedTypedOutput;
import retrofit.http.mime.MultipartTypedOutput;
import retrofit.http.mime.TypedOutput;

import static retrofit.http.RestMethodInfo.NO_BODY;

/** Builds HTTP requests from Java method invocations. */
final class RequestBuilder {
  private final Converter converter;

  private RestMethodInfo methodInfo;
  private Object[] args;
  private String apiUrl;
  private List<retrofit.http.client.Header> headers;

  RequestBuilder(Converter converter) {
    this.converter = converter;
  }

  /** Supply cached method metadata info. */
  RequestBuilder methodInfo(RestMethodInfo methodDetails) {
    this.methodInfo = methodDetails;
    return this;
  }

  /** Base API url. */
  RequestBuilder apiUrl(String apiUrl) {
    this.apiUrl = apiUrl;
    return this;
  }

  /** Arguments from method invocation. */
  RequestBuilder args(Object[] args) {
    this.args = args;
    return this;
  }

  /** A list of custom headers. */
  RequestBuilder headers(List<retrofit.http.client.Header> headers) {
    this.headers = headers;
    return this;
  }

  /**
   * Construct a {@link Request} from the supplied information. You <strong>must</strong> call
   * {@link #methodInfo}, {@link #apiUrl}, {@link #args}, and {@link #headers} before invoking this
   * method.
   */
  Request build() throws UnsupportedEncodingException {
    String apiUrl = this.apiUrl;

    StringBuilder url = new StringBuilder(apiUrl);
    if (apiUrl.endsWith("/")) {
      // We require relative paths to start with '/'. Prevent a double-slash.
      url.deleteCharAt(url.length() - 1);
    }

    // Append the method relative URL.
    url.append(buildRelativeUrl());

    // Append query parameters, if needed.
    if (methodInfo.hasQueryParams) {
      boolean first = true;
      String requestQuery = methodInfo.requestQuery;
      if (requestQuery != null) {
        url.append(requestQuery);
        first = false;
      }
      String[] requestQueryName = methodInfo.requestQueryName;
      for (int i = 0; i < requestQueryName.length; i++) {
        String query = requestQueryName[i];
        if (query != null) {
          String value = URLEncoder.encode(String.valueOf(args[i]), "UTF-8");
          url.append(first ? '?' : '&').append(query).append('=').append(value);
          first = false;
        }
      }
    }

    List<retrofit.http.client.Header> headers = new ArrayList<retrofit.http.client.Header>();
    if (this.headers != null) {
      headers.addAll(this.headers);
    }
    List<Header> methodHeaders = methodInfo.headers;
    if (methodHeaders != null) {
      headers.addAll(methodHeaders);
    }
    // RFC 2616: Header names are case-insensitive.
    String[] requestParamHeader = methodInfo.requestParamHeader;
    if (requestParamHeader != null) {
      for (int i = 0; i < requestParamHeader.length; i++) {
        String name = requestParamHeader[i];
        if (name == null) continue;
        Object arg = args[i];
        if (arg != null) {
          headers.add(new retrofit.http.client.Header(name, String.valueOf(arg)));
        }
      }
    }

    return new Request(methodInfo.requestMethod, url.toString(), headers, buildBody());
  }

  /** Create the final relative URL by performing parameter replacement. */
  private String buildRelativeUrl() throws UnsupportedEncodingException {
    String replacedPath = methodInfo.requestUrl;
    String[] requestUrlParam = methodInfo.requestUrlParam;
    for (int i = 0; i < requestUrlParam.length; i++) {
      String param = requestUrlParam[i];
      if (param != null) {
        String value = URLEncoder.encode(String.valueOf(args[i]), "UTF-8");
        replacedPath = replacedPath.replace("{" + param + "}", value);
      }
    }
    return replacedPath;
  }

  /** Create the request body using the method info and invocation arguments. */
  private TypedOutput buildBody() {
    switch (methodInfo.requestType) {
      case SIMPLE: {
        int bodyIndex = methodInfo.bodyIndex;
        if (bodyIndex == NO_BODY) {
          return null;
        }
        Object body = args[bodyIndex];
        if (body instanceof TypedOutput) {
          return (TypedOutput) body;
        } else {
          return converter.toBody(body);
        }
      }

      case FORM_URL_ENCODED: {
        FormUrlEncodedTypedOutput body = new FormUrlEncodedTypedOutput();
        String[] requestFormPair = methodInfo.requestFormPair;
        for (int i = 0; i < requestFormPair.length; i++) {
          String name = requestFormPair[i];
          if (name != null) {
            body.addField(name, String.valueOf(args[i]));
          }
        }
        return body;
      }

      case MULTIPART: {
        MultipartTypedOutput body = new MultipartTypedOutput();
        String[] requestMultipartPart = methodInfo.requestMultipartPart;
        for (int i = 0; i < requestMultipartPart.length; i++) {
          String name = requestMultipartPart[i];
          if (name != null) {
            Object value = args[i];
            if (value instanceof TypedOutput) {
              body.addPart(name, (TypedOutput) value);
            } else {
              body.addPart(name, converter.toBody(value));
            }
          }
        }
        return body;
      }

      default:
        throw new IllegalArgumentException("Unknown request type " + methodInfo.requestType);
    }
  }
}=======
>>>>>>> YOURS
/home/taes/taes/projects/retrofit/revisions/rev_d665e56_bf94f53/rev_d665e56-bf94f53/retrofit/src/test/java/retrofit/http/mime/FormUrlEncodingTypedOutputTest.java;<<<<<<< MINE
// Copyright 2013 Square, Inc.
package retrofit.http.mime;

import java.io.ByteArrayOutputStream;
import org.junit.Test;

import static org.fest.assertions.api.Assertions.assertThat;

public class FormUrlEncodingTypedOutputTest {
  @Test public void urlEncoding() throws Exception {
    FormUrlEncodedTypedOutput fe = new FormUrlEncodedTypedOutput();
    fe.addField("a&b", "c=d");
    fe.addField("space, the", "final frontier");

    ByteArrayOutputStream out = new ByteArrayOutputStream();
    fe.writeTo(out);
    String actual = new String(out.toByteArray(), "UTF-8");
    assertThat(actual).isEqualTo("a%26b=c%3Dd&space%2C+the=final+frontier");
  }

  @Test public void utf8encoding() throws Exception {
    FormUrlEncodedTypedOutput fe = new FormUrlEncodedTypedOutput();
    fe.addField("ooÉ", "É¹Éq");

    ByteArrayOutputStream out = new ByteArrayOutputStream();
    fe.writeTo(out);
    String actual = new String(out.toByteArray(), "UTF-8");
    assertThat(actual).isEqualTo("oo%C9%9F=%C9%B9%C9%90q");
  }

  @Test public void encodedPairs() throws Exception {
    FormUrlEncodedTypedOutput fe = new FormUrlEncodedTypedOutput();
    fe.addField("sim", "ple");

    ByteArrayOutputStream out1 = new ByteArrayOutputStream();
    fe.writeTo(out1);
    String actual1 = new String(out1.toByteArray(), "UTF-8");
    assertThat(actual1).isEqualTo("sim=ple");

    fe.addField("hey", "there");
    fe.addField("help", "me");

    ByteArrayOutputStream out2 = new ByteArrayOutputStream();
    fe.writeTo(out2);
    String actual2 = new String(out2.toByteArray(), "UTF-8");
    assertThat(actual2).isEqualTo("sim=ple&hey=there&help=me");
  }
}=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_a7db88d_d84d866/rev_a7db88d-d84d866/src/java/com/twitter/elephantbird/mapreduce/input/MultiInputFormat.java;<<<<<<< MINE
  protected static void setClassConf(Class<?> clazz, Configuration conf) {
=======
  public static void setClassConf(Class<?> clazz, Configuration conf) {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_a7db88d_d84d866/rev_a7db88d-d84d866/src/java/com/twitter/elephantbird/mapred/input/DeprecatedInputFormatWrapper.java;<<<<<<< MINE
  public static void setInputFormat(Class<?> realInputFormatClass,
                                    JobConf jobConf) {
=======
  public static void setInputFormat(Class<?> realInputFormatClass, JobConf jobConf) {
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_879cae7_4bd4aa3/rev_879cae7-4bd4aa3/ribbon/src/main/java/com/netflix/ribbon/http/HttpResourceGroup.java;<<<<<<< MINE
    public static class Builder {
        public Builder(ClientConfigFactory configFactory, RibbonTransportFactory transportFactory) {
        }

        public void withClientOptions(ClientOptions options) {

        }

        public void withHeader() {

        }

        public void withClientConfig(IClientConfig config) {

        }

    }

    public HttpResourceGroup(String groupName) {
        this(groupName, null);
=======
    public static class Builder {
        private ClientOptions clientOptions;
        private HttpHeaders httpHeaders = new DefaultHttpHeaders();
        private ClientConfigFactory clientConfigFactory;
        private RibbonTransportFactory transportFactory;
        private String name;

        private Builder(String name, ClientConfigFactory configFactory, RibbonTransportFactory transportFactory) {
            this.name = name;
            this.clientConfigFactory = configFactory;
            this.transportFactory = transportFactory;
        }

        public static Builder newBuilder(String groupName, ClientConfigFactory configFactory, RibbonTransportFactory transportFactory) {
            return new Builder(groupName, configFactory, transportFactory);
        }

        public Builder withClientOptions(ClientOptions options) {
            this.clientOptions = options;
            return this;
        }

        public Builder withHeader(String name, String value) {
            httpHeaders.add(name, value);
            return this;
        }

        public HttpResourceGroup build() {
            return new HttpResourceGroup(name, clientOptions, clientConfigFactory, transportFactory, httpHeaders);
        }
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_879cae7_4bd4aa3/rev_879cae7-4bd4aa3/ribbon/src/main/java/com/netflix/ribbon/proxy/MethodTemplateExecutor.java;<<<<<<< MINE
=======
import rx.Observable;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_879cae7_4bd4aa3/rev_879cae7-4bd4aa3/ribbon/src/main/java/com/netflix/ribbon/proxy/MethodTemplateExecutor.java;<<<<<<< MINE
import rx.Observable;

=======
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_879cae7_4bd4aa3/rev_879cae7-4bd4aa3/ribbon/src/main/java/com/netflix/ribbon/proxy/MethodTemplateExecutor.java;<<<<<<< MINE
=======
    private final Builder<?> httpRequestTemplateBuilder;
    private final EvCacheProviderPool evCacheProviderPool;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_879cae7_4bd4aa3/rev_879cae7-4bd4aa3/ribbon/src/main/java/com/netflix/ribbon/proxy/MethodTemplateExecutor.java;<<<<<<< MINE
        httpRequestTemplate = createHttpRequestTemplate();
=======
        this.evCacheProviderPool = evCacheProviderPool;
        httpRequestTemplateBuilder = createHttpRequestTemplateBuilder();
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_879cae7_4bd4aa3/rev_879cae7-4bd4aa3/ribbon/src/main/java/com/netflix/ribbon/proxy/MethodTemplateExecutor.java;<<<<<<< MINE
    private HttpRequestTemplate<?> createHttpRequestTemplate() {
        HttpRequestTemplate<?> httpRequestTemplate = createBaseHttpRequestTemplate(httpResourceGroup);
        for (AnnotationProcessor processor: proxyAnnotations.getProcessors()) {
            processor.process(httpRequestTemplate, methodTemplate.getMethod());
        }
        return httpRequestTemplate;
=======
    private Builder<?> createHttpRequestTemplateBuilder() {
        Builder<?> httpRequestTemplateBuilder = createBaseHttpRequestTemplate(httpResourceGroup);
        withRequestUriBase(httpRequestTemplateBuilder);
        withHttpHeaders(httpRequestTemplateBuilder);
        withHystrixHandlers(httpRequestTemplateBuilder);
        withCacheProviders(httpRequestTemplateBuilder);
        return httpRequestTemplateBuilder;
>>>>>>> YOURS
/home/taes/taes/projects/ribbon/revisions/rev_352cb58_00824ee/rev_352cb58-00824ee/ribbon-transport/src/test/java/com/netflix/client/netty/udp/UdpClientTest.java;<<<<<<< MINE
/*
 *
 * Copyright 2014 Netflix, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */
package com.netflix.client.netty.udp;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import io.netty.channel.socket.DatagramPacket;
import io.reactivex.netty.channel.ObservableConnection;
import io.reactivex.netty.client.RxClient;

import java.nio.charset.Charset;
import java.util.concurrent.TimeoutException;

import org.junit.Rule;
import org.junit.Test;

import rx.Observable;
import rx.functions.Func1;

import com.google.common.collect.Lists;
import com.netflix.client.config.DefaultClientConfigImpl;
import com.netflix.client.netty.MyUDPClient;
import com.netflix.client.netty.RibbonTransport;
import com.netflix.loadbalancer.BaseLoadBalancer;
import com.netflix.loadbalancer.Server;

/**
 * Created by awang on 8/5/14.
 */
public class UdpClientTest {

    @Rule
    public HelloUdpServerExternalResource server = new HelloUdpServerExternalResource();
    
    @Test
    public void testUdpClientWithoutTimeout() throws Exception {
        server.start();
        
        BaseLoadBalancer lb = new BaseLoadBalancer();
        lb.setServersList(Lists.newArrayList(new Server("localhost", server.getServerPort())));
        RxClient<DatagramPacket, DatagramPacket> client = RibbonTransport.newUdpClient(lb,
                DefaultClientConfigImpl.getClientConfigWithDefaultValues());
        
        String response = client.connect().flatMap(new Func1<ObservableConnection<DatagramPacket, DatagramPacket>,
                Observable<DatagramPacket>>() {
            @Override
            public Observable<DatagramPacket> call(ObservableConnection<DatagramPacket, DatagramPacket> connection) {
                connection.writeStringAndFlush("Is there anybody out there?");
                return connection.getInput();
            }
        }).take(1)
                .map(new Func1<DatagramPacket, String>() {
                    @Override
                    public String call(DatagramPacket datagramPacket) {
                        return datagramPacket.content().toString(Charset.defaultCharset());
                    }
                })
                .toBlocking()
                .first();
        assertEquals(HelloUdpServerExternalResource.WELCOME_MSG, response);
    }

    @Test
    public void testUdpClientTimeout() throws Exception {
        server.setTimeout(5000);
        server.start();
        
        BaseLoadBalancer lb = new BaseLoadBalancer();
        Server myServer = new Server("localhost", server.getServerPort());
        lb.setServersList(Lists.newArrayList(myServer));
        MyUDPClient client = new MyUDPClient(lb, DefaultClientConfigImpl.getClientConfigWithDefaultValues());
        try {
            String response = client.submit("Is there anybody out there?")
                    .map(new Func1<DatagramPacket, String>() {
                        @Override
                        public String call(DatagramPacket datagramPacket) {
                            return datagramPacket.content().toString(Charset.defaultCharset());
                        }
                    })
                    .toBlocking()
                    .first();
            fail("Exception expected");
        } catch (Exception e) {
            assertTrue(e.getCause() instanceof TimeoutException);
            assertEquals(1, client.getLoadBalancerContext().getServerStats(myServer).getSuccessiveConnectionFailureCount());
        }
    }

}=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_9a3bd70_20697f0/rev_9a3bd70-20697f0/src/java/com/twitter/elephantbird/pig/store/SequenceFileStorage.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.store;

import java.io.IOException;

import org.apache.commons.cli.Option;
import org.apache.commons.cli.OptionBuilder;
import org.apache.commons.cli.Options;
import org.apache.commons.cli.ParseException;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.SequenceFile;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.io.compress.CompressionCodecFactory;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.OutputFormat;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
import org.apache.pig.LoadFunc;
import org.apache.pig.ResourceSchema;
import org.apache.pig.ResourceSchema.ResourceFieldSchema;
import org.apache.pig.StoreFunc;
import org.apache.pig.StoreFuncInterface;
import org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil;
import org.apache.pig.data.Tuple;
import org.apache.pig.impl.PigContext;
import org.apache.pig.impl.util.UDFContext;

import com.google.common.base.Preconditions;
import com.twitter.elephantbird.pig.load.SequenceFileLoader;
import com.twitter.elephantbird.pig.util.GenericWritableConverter;
import com.twitter.elephantbird.pig.util.PigCounterHelper;
import com.twitter.elephantbird.pig.util.WritableConverter;

/**
 * Pig StoreFunc supporting conversion between Pig tuples and arbitrary key-value pairs stored
 * within {@link SequenceFile}s. Example usage:
 *
 * <pre>
 * pairs = LOAD '$INPUT' AS (key: int, value: chararray);
 *
 * STORE pairs INTO '$OUTPUT' USING com.twitter.elephantbird.pig.store.SequenceFileStorage (
 *   '-c com.twitter.elephantbird.pig.util.IntWritableConverter',
 *   '-c com.twitter.elephantbird.pig.util.TextConverter'
 * );
 * </pre>
 *
 * @author Andy Schlaikjer
 */
public class SequenceFileStorage<K extends Writable, V extends Writable> extends
    SequenceFileLoader<K, V> implements StoreFuncInterface {
  /**
   * Failure modes for use with {@link PigCounterHelper} to keep track of runtime error counts.
   *
   * @author Andy Schlaikjer
   */
  public static enum Error {
    /**
     * Null tuple was supplied to {@link SequenceFileStorage#putNext(Tuple)}.
     */
    NULL_TUPLE,
    /**
     * Tuple supplied to {@link SequenceFileStorage#putNext(Tuple)} whose length is not 2.
     */
    TUPLE_SIZE,
    /**
     * Null key was supplied to {@link SequenceFileStorage#putNext(Tuple)} and key type is not
     * {@link NullWritable}.
     */
    NULL_KEY,
    /**
     * Null value was supplied to {@link SequenceFileStorage#putNext(Tuple)} and value type is not
     * {@link NullWritable}.
     */
    NULL_VALUE;
  }

  public static final String TYPE_PARAM = "type";
  private final PigCounterHelper counterHelper = new PigCounterHelper();
  private Class<K> keyClass;
  private Class<V> valueClass;
  private RecordWriter<K, V> writer;

  /**
   * Parses key and value options from argument strings. Available options for both key and value
   * argument strings match those supported by
   * {@link SequenceFileLoader#SequenceFileLoader(String, String)}, as well as:
   * <dl>
   * <dt>-t|--type cls</dt>
   * <dd>{@link Writable} implementation class of data. If Writable class reported by
   * {@link WritableConverter#getWritableClass()} is null (e.g. when using
   * {@link GenericWritableConverter}), this option must be specified.</dd>
   * </dl>
   *
   * @param keyArgs
   * @param valueArgs
   * @throws ParseException
   * @throws IOException
   * @throws ClassNotFoundException
   */
  public SequenceFileStorage(String keyArgs, String valueArgs) throws ParseException, IOException,
      ClassNotFoundException {
    super(keyArgs, valueArgs);
  }

  /**
   * Default constructor which uses default options for key and value.
   *
   * @throws ClassNotFoundException
   * @throws IOException
   * @throws ParseException
   * @see #SequenceFileStorage(String, String)
   */
  public SequenceFileStorage() throws ParseException, IOException, ClassNotFoundException {
    this("", "");
  }

  @Override
  protected Options getKeyValueOptions() {
    @SuppressWarnings("static-access")
    Option typeOption =
        OptionBuilder
            .withLongOpt(TYPE_PARAM)
            .hasArg()
            .withArgName("cls")
            .withDescription(
                "Writable type of data. Defaults to type returned by getWritableClass()"
                    + " method of configured WritableConverter.").create("t");
    return super.getKeyValueOptions().addOption(typeOption);
  }

  @Override
  protected void initialize() throws IOException {
    /*
     * Attempt to initialize key, value classes using arguments. If user doesn't specify '--type'
     * arg, then class will be null.
     */
    keyClass = getWritableClass(keyArguments.getOptionValue(TYPE_PARAM));
    valueClass = getWritableClass(valueArguments.getOptionValue(TYPE_PARAM));

    // initialize key, value converters
    keyConverter.initialize(keyClass);
    valueConverter.initialize(valueClass);

    // allow converters to define writable classes if not already defined
    if (keyClass == null) {
      keyClass = keyConverter.getWritableClass();
    }
    if (valueClass == null) {
      valueClass = valueConverter.getWritableClass();
    }
  }

  /**
   * @param writableClassName
   * @return {@code null} if writableClassName is {@code null}, otherwise the Class instance named
   * by writableClassName.
   * @throws IOException
   */
  @SuppressWarnings("unchecked")
  private static <W extends Writable> Class<W> getWritableClass(String writableClassName)
      throws IOException {
    if (writableClassName == null) {
      return null;
    }
    try {
      return PigContext.resolveClassName(writableClassName);
    } catch (Exception e) {
      throw new IOException(String.format("Failed to load Writable class '%s'", writableClassName),
          e);
    }
  }

  @Override
  public void setStoreFuncUDFContextSignature(String signature) {
    this.signature = signature;
  }

  @Override
  public void checkSchema(ResourceSchema schema) throws IOException {
    Preconditions.checkNotNull(schema, "Schema is null");
    ResourceFieldSchema[] fields = schema.getFields();
    Preconditions.checkNotNull(fields, "Schema fields are undefined");
    Preconditions.checkArgument(2 == fields.length,
        "Expecting 2 schema fields but found %s", fields.length);
    keyConverter.checkStoreSchema(fields[0]);
    valueConverter.checkStoreSchema(fields[1]);
  }

  @Override
  public String relToAbsPathForStoreLocation(String location, Path cwd) throws IOException {
    return LoadFunc.getAbsolutePath(location, cwd);
  }

  @SuppressWarnings("unchecked")
  @Override
  public void setStoreLocation(String location, Job job) throws IOException {
    ensureUDFContext(job.getConfiguration());
    verifyWritableClass(keyClass, true, keyConverter);
    verifyWritableClass(valueClass, false, valueConverter);
    job.setOutputKeyClass(keyClass);
    job.setOutputValueClass(valueClass);
    FileOutputFormat.setOutputPath(job, new Path(location));
    if ("true".equals(job.getConfiguration().get("output.compression.enabled"))) {
      FileOutputFormat.setCompressOutput(job, true);
      String codec = job.getConfiguration().get("output.compression.codec");
      FileOutputFormat.setOutputCompressorClass(job,
          PigContext.resolveClassName(codec).asSubclass(CompressionCodec.class));
    } else {
      // This makes it so that storing to a directory ending with ".gz" or ".bz2" works.
      setCompression(new Path(location), job);
    }
  }

  private void ensureUDFContext(Configuration conf) throws IOException {
    if (UDFContext.getUDFContext().isUDFConfEmpty()
        && conf.get("pig.udf.context") != null) {
      MapRedUtil.setupUDFContext(conf);
    }
  }

  /**
   * Tests validity of Writable class, ensures consistent error message for both key and value
   * tests.
   *
   * @param writableClass class being tested.
   * @param isKeyClass {@code true} if testing keyClass, {@code false} otherwise.
   * @param writableConverter associated WritableConverter instance.
   */
  private static <W extends Writable> void verifyWritableClass(Class<W> writableClass,
      boolean isKeyClass, WritableConverter<W> writableConverter) {
    Preconditions.checkNotNull(writableClass, "%s Writable class is undefined;"
        + " WritableConverter of type '%s' does not define default Writable type,"
        + " and no type was specified by user", isKeyClass ? "Key" : "Value", writableConverter
        .getClass().getName());
  }

  /**
   * @param path
   * @param job
   */
  private void setCompression(Path path, Job job) {
    CompressionCodecFactory codecFactory = new CompressionCodecFactory(job.getConfiguration());
    CompressionCodec codec = codecFactory.getCodec(path);
    if (codec != null) {
      FileOutputFormat.setCompressOutput(job, true);
      FileOutputFormat.setOutputCompressorClass(job, codec.getClass());
    } else {
      FileOutputFormat.setCompressOutput(job, false);
    }
  }

  @Override
  public OutputFormat<K, V> getOutputFormat() throws IOException {
    return new SequenceFileOutputFormat<K, V>();
  }

  @Override
  @SuppressWarnings({ "rawtypes", "unchecked" })
  public void prepareToWrite(RecordWriter writer) throws IOException {
    this.writer = writer;
  }

  @Override
  public void putNext(Tuple t) throws IOException {
    // validate input tuple
    if (t == null) {
      counterHelper.incrCounter(Error.NULL_TUPLE, 1);
      return;
    }
    if (t.size() != 2) {
      counterHelper.incrCounter(Error.TUPLE_SIZE, 1);
      return;
    }

    // convert key from pig to writable
    K key = keyConverter.toWritable(t.get(0));
    if (key == null) {
      counterHelper.incrCounter(Error.NULL_KEY, 1);
      return;
    }

    // convert value from pig to writable
    V value = valueConverter.toWritable(t.get(1));
    if (value == null) {
      counterHelper.incrCounter(Error.NULL_VALUE, 1);
      return;
    }

    // write key-value pair
    try {
      writer.write(key, value);
    } catch (InterruptedException e) {
      throw new IOException(e);
    }
  }

  @Override
  public void cleanupOnFailure(String location, Job job) throws IOException {
    StoreFunc.cleanupOnFailureImpl(location, job);
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_9a3bd70_20697f0/rev_9a3bd70-20697f0/src/java/com/twitter/elephantbird/pig/load/SequenceFileLoader.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.load;

import java.io.EOFException;
import java.io.IOException;
import java.lang.reflect.Constructor;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.Properties;

import org.apache.commons.cli.CommandLine;
import org.apache.commons.cli.GnuParser;
import org.apache.commons.cli.HelpFormatter;
import org.apache.commons.cli.Option;
import org.apache.commons.cli.OptionBuilder;
import org.apache.commons.cli.Options;
import org.apache.commons.cli.ParseException;
import org.apache.commons.cli.UnrecognizedOptionException;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.DataInputBuffer;
import org.apache.hadoop.io.SequenceFile;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.mapreduce.InputFormat;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.RecordReader;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.pig.Expression;
import org.apache.pig.FileInputLoadFunc;
import org.apache.pig.LoadCaster;
import org.apache.pig.LoadMetadata;
import org.apache.pig.LoadPushDown;
import org.apache.pig.PigException;
import org.apache.pig.ResourceSchema;
import org.apache.pig.ResourceSchema.ResourceFieldSchema;
import org.apache.pig.ResourceStatistics;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigSplit;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.apache.pig.impl.PigContext;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.util.UDFContext;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.base.Preconditions;
import com.google.common.collect.ImmutableList;
import com.google.common.collect.Lists;
import com.twitter.elephantbird.mapreduce.input.RawSequenceFileInputFormat;
import com.twitter.elephantbird.pig.store.SequenceFileStorage;
import com.twitter.elephantbird.pig.util.PigCounterHelper;
import com.twitter.elephantbird.pig.util.TextConverter;
import com.twitter.elephantbird.pig.util.WritableConverter;

/**
 * Pig LoadFunc supporting conversion from key, value objects stored within {@link SequenceFile}s to
 * Pig objects. Example usage:
 *
 * <pre>
 * pairs = LOAD '$INPUT' USING com.twitter.elephantbird.pig.load.SequenceFileLoader (
 *   '-c com.twitter.elephantbird.pig.util.IntWritableConverter',
 *   '-c com.twitter.elephantbird.pig.util.TextConverter'
 * ) as (
 *   key: int,
 *   value: chararray
 * );
 *
 * -- or, making use of defaults
 * pairs = LOAD '$INPUT' USING com.twitter.elephantbird.pig.load.SequenceFileLoader ();
 * </pre>
 *
 * @author Andy Schlaikjer
 * @see WritableConverter
 */
public class SequenceFileLoader<K extends Writable, V extends Writable> extends FileInputLoadFunc
    implements LoadPushDown, LoadMetadata {
  /**
   * Counter enum for error conditions.
   */
  public static enum Counter {
    /**
     * {@link EOFException}s encountered while reading input.
     */
    EOFException
  };

  private static final Logger LOG = LoggerFactory.getLogger(SequenceFileLoader.class);
  public static final String CONVERTER_PARAM = "converter";
  public static final String SKIP_EOF_ERRORS_PARAM = "skipEOFErrors";
  private static final String READ_KEY_PARAM = "_readKey";
  private static final String READ_VALUE_PARAM = "_readValue";
  protected final CommandLine keyArguments;
  protected final CommandLine valueArguments;
  protected final CommandLine otherArguments;
  protected final WritableConverter<K> keyConverter;
  protected final WritableConverter<V> valueConverter;
  private final DataByteArray keyDataByteArray = new DataByteArray();
  private final DataByteArray valueDataByteArray = new DataByteArray();
  private final List<Object> tuple2 = Arrays.asList(new Object(), new Object()), tuple1 = Arrays
      .asList(new Object()), tuple0 = Collections.emptyList();
  private final TupleFactory tupleFactory = TupleFactory.getInstance();
  protected String signature;
  private RecordReader<DataInputBuffer, DataInputBuffer> reader;
  private boolean readKey = true;
  private boolean readValue = true;
  private final PigCounterHelper counterHelper = new PigCounterHelper();

  /**
   * Parses key and value options from argument strings. Available options for key and value
   * argument strings include:
   *
   * <dl>
   * <dt>-c|--converter cls</dt>
   * <dd>{@link WritableConverter} implementation class to use for conversion of data. Defaults to
   * {@link TextConverter} for both key and value.</dd>
   * </dl>
   *
   * Any extra arguments found will be treated as String arguments for the WritableConverter
   * constructor. For instance, the argument string {@code "-c MyConverter 123 abc"} specifies
   * WritableConverter class {@code MyConverter} along with two constructor arguments {@code "123"}
   * and {@code "abc"}. This will cause SequenceFileLoader to attempt to invoke the following
   * constructors, in order, to create a new instance of MyConverter:
   *
   * <ol>
   * <li><code>MyConverter(String arg1, String arg2)</code> -- constructor arguments are passed as
   * explicit arguments.</li>
   * <li><code>MyConverter(String[] args)</code> -- constructor arguments are passed within a String
   * array.</li>
   * <li><code>MyConverter(String... args)</code> -- same as above, with var args syntax.</li>
   * <li><code>MyConverter(String argString)</code> -- constructor arguments are joined with space
   * char to create {@code argString}.</li>
   * </ol>
   *
   * If none of these constructors exist, a RuntimeException will be thrown.
   *
   * <p>
   * Note that WritableConverter constructor arguments prefixed by one or more hyphens will be
   * interpreted as options for SequenceFileLoader itself, resulting in an
   * {@link UnrecognizedOptionException}. To avoid this, place these values after a {@code --}
   * (double-hyphen) token:
   *
   * <pre>
   * A = LOAD '$data' USING com.twitter.elephantbird.pig.load.SequenceFileLoader (
   *   '-c ...IntWritableConverter',
   *   '-c ...MyComplexWritableConverter basic options here -- --complex -options here'
   * );
   * </pre>
   *
   * @param keyArgs argument string containing key options.
   * @param valueArgs argument string containing value options.
   * @param otherArgs argument string containing other options.
   * @throws ParseException
   * @throws IOException
   */
  public SequenceFileLoader(String keyArgs, String valueArgs, String otherArgs)
      throws ParseException, IOException {
    // parse key, value arguments
    Options keyValueOptions = getKeyValueOptions();
    Options otherOptions = getOtherOptions();
    keyArguments = parseArguments(keyValueOptions, keyArgs);
    valueArguments = parseArguments(keyValueOptions, valueArgs);
    otherArguments = parseArguments(otherOptions, otherArgs);

    // construct key, value converters
    keyConverter = getWritableConverter(keyArguments);
    valueConverter = getWritableConverter(valueArguments);

    // initialize key, value converters
    initialize();
  }

  /**
   * Default constructor. Defaults used for all options.
   *
   * @throws ParseException
   * @throws IOException
   */
  public SequenceFileLoader() throws ParseException, IOException {
    this("", "");
  }

  /**
   * Constructor without other arguments (backwards compatible).
   *
   * @throws ParseException
   * @throws IOException
   */
  public SequenceFileLoader(String keyArgs, String valueArgs) throws ParseException, IOException {
    this(keyArgs, valueArgs, "");
  }

  /**
   * @return Options instance containing valid key/value options.
   */
  protected Options getKeyValueOptions() {
    @SuppressWarnings("static-access")
    Option converterOption =
        OptionBuilder
            .withLongOpt(CONVERTER_PARAM)
            .hasArg()
            .withArgName("cls")
            .withDescription(
                String.format("Converter type to use for conversion of data. Defaults to '%s'.",
                    TextConverter.class.getName())).create("c");
    return new Options().addOption(converterOption);
  }

  /**
   * @return Options instance containing valid global options.
   */
  protected Options getOtherOptions() {
    @SuppressWarnings("static-access")
    Option skipEOFOption =
        OptionBuilder
            .withLongOpt(SKIP_EOF_ERRORS_PARAM)
            .withDescription(
                "Skip EOFExceptions if they occur while reading data." +
                    " Useful for reading sequence files while they are being created."
            ).create();
    return new Options().addOption(skipEOFOption);
  }

  /**
   * @param args
   * @return CommandLine instance containing options parsed from argument string.
   * @throws ParseException
   */
  private static CommandLine parseArguments(Options options, String args) throws ParseException {
    CommandLine cmdline = null;
    try {
      cmdline = new GnuParser().parse(options, args.split(" "));
    } catch (ParseException e) {
      new HelpFormatter().printHelp(SequenceFileStorage.class.getName() + "(keyArgs, valueArgs)",
          options);
      throw e;
    }
    return cmdline;
  }

  /**
   * @param arguments
   * @return new WritableConverter instance constructed using given arguments.
   */
  @SuppressWarnings("unchecked")
  private static <T extends Writable> WritableConverter<T> getWritableConverter(
      CommandLine arguments) {
    // get remaining non-empty argument strings from commandline
    String[] converterArgs = removeEmptyArgs(arguments.getArgs());
    try {

      // get converter classname
      String converterClassName =
          arguments.getOptionValue(CONVERTER_PARAM, TextConverter.class.getName());

      // get converter class
      Class<WritableConverter<T>> converterClass =
          PigContext.resolveClassName(converterClassName);

      // construct converter instance
      if (converterArgs == null || converterArgs.length == 0) {

        // use default ctor
        return converterClass.newInstance();

      } else {
        try {

          // look up ctor having explicit number of String arguments
          Class<?>[] parameterTypes = new Class<?>[converterArgs.length];
          Arrays.fill(parameterTypes, String.class);
          Constructor<WritableConverter<T>> ctor = converterClass.getConstructor(parameterTypes);
          return ctor.newInstance((Object[]) converterArgs);

        } catch (NoSuchMethodException e) {
          try {

            // look up ctor having single String[] (or String... varargs) argument
            Constructor<WritableConverter<T>> ctor =
                converterClass.getConstructor(new Class<?>[] { String[].class });
            return ctor.newInstance((Object) converterArgs);

          } catch (NoSuchMethodException e2) {

            // look up ctor having single String argument and join args together
            Constructor<WritableConverter<T>> ctor =
                converterClass.getConstructor(new Class<?>[] { String.class });
            StringBuilder sb = new StringBuilder(converterArgs[0]);
            for (int i = 1; i < converterArgs.length; ++i) {
              sb.append(" ").append(converterArgs[i]);
            }
            return ctor.newInstance(sb.toString());

          }
        }
      }
    } catch (Exception e) {
      throw new RuntimeException("Failed to create WritableConverter instance", e);
    }
  }

  /**
   * @param args
   * @return new String[] containing non-empty values from args.
   */
  private static String[] removeEmptyArgs(String[] args) {
    List<String> converterArgsFiltered = Lists.newArrayList();
    for (String arg : args) {
      if (arg == null || arg.isEmpty())
        continue;
      converterArgsFiltered.add(arg);
    }
    return converterArgsFiltered.toArray(new String[0]);
  }

  /**
   * Initializes key, value WritableConverters.
   *
   * @throws IOException
   */
  protected void initialize() throws IOException {
    keyConverter.initialize(null);
    valueConverter.initialize(null);
  }

  @Override
  public InputFormat<DataInputBuffer, DataInputBuffer> getInputFormat() throws IOException {
    return new RawSequenceFileInputFormat();
  }

  @Override
  public LoadCaster getLoadCaster() throws IOException {
    /*
     * We have two LoadCasters--one for the key type, another for the value type. Unfortunately,
     * LoadCaster doesn't allow clients to specify which field it's casting (nor schema of field),
     * so we're out of luck here. No casting supported.
     */
    return null;
  }

  @Override
  public void setUDFContextSignature(String signature) {
    this.signature = signature;
  }

  protected Properties getContextProperties() {
    return UDFContext.getUDFContext().getUDFProperties(getClass(), new String[] { signature });
  }

  protected String getContextProperty(String name, String defaultValue) {
    return getContextProperties().getProperty(signature + name, defaultValue);
  }

  protected void setContextProperty(String name, String value) {
    Preconditions.checkNotNull(name, "Context property name is null");
    getContextProperties().setProperty(signature + name, value);
  }

  @Override
  public List<OperatorSet> getFeatures() {
    return ImmutableList.of(OperatorSet.PROJECTION);
  }

  @Override
  public RequiredFieldResponse pushProjection(RequiredFieldList requiredFieldList)
      throws FrontendException {
    readKey = readValue = false;
    for (RequiredField field : requiredFieldList.getFields()) {
      // TODO fix Pig's handling of RequiredField type initialization
      int i = field.getIndex();
      switch (i) {
        case 0:
          readKey = true;
          // TODO(Andy Schlaikjer) enable schema checking here?
          // try {
          // keyConverter.checkLoadSchema(ResourceSchemaUtil.createResourceFieldSchema(field));
          // } catch (IOException e) {
          // throw new FrontendException("Key schema check failed", e);
          // }
          break;
        case 1:
          readValue = true;
          // TODO(Andy Schlaikjer) enable schema checking here?
          // try {
          // valueConverter.checkLoadSchema(ResourceSchemaUtil.createResourceFieldSchema(field));
          // } catch (IOException e) {
          // throw new FrontendException("Value schema check failed", e);
          // }
          break;
        default:
          // TODO fix Pig's silent ignorance of FrontendExceptions thrown from here
          throw new FrontendException("Expected field indices in [0, 1] but found index " + i);
      }
    }
    setContextProperty(READ_KEY_PARAM, Boolean.toString(readKey));
    setContextProperty(READ_VALUE_PARAM, Boolean.toString(readValue));
    return new RequiredFieldResponse(true);
  }

  @Override
  public ResourceSchema getSchema(String location, Job job) throws IOException {
    // determine key field schema
    ResourceFieldSchema keySchema = keyConverter.getLoadSchema();
    if (keySchema == null) {
      return null;
    }
    keySchema.setName("key");

    // determine value field schema
    ResourceFieldSchema valueSchema = valueConverter.getLoadSchema();
    if (valueSchema == null) {
      return null;
    }
    valueSchema.setName("value");

    // return tuple schema
    ResourceSchema resourceSchema = new ResourceSchema();
    resourceSchema.setFields(new ResourceFieldSchema[] { keySchema, valueSchema });
    return resourceSchema;
  }

  /**
   * This implementation returns {@code null}.
   *
   * @see org.apache.pig.LoadMetadata#getStatistics(java.lang.String,
   * org.apache.hadoop.mapreduce.Job)
   */
  @Override
  public ResourceStatistics getStatistics(String location, Job job) throws IOException {
    return null;
  }

  /**
   * This implementation returns {@code null}.
   *
   * @see org.apache.pig.LoadMetadata#getPartitionKeys(java.lang.String,
   * org.apache.hadoop.mapreduce.Job)
   */
  @Override
  public String[] getPartitionKeys(String location, Job job) throws IOException {
    return null;
  }

  /**
   * This implementation throws {@link UnsupportedOperationException}.
   *
   * @see org.apache.pig.LoadMetadata#setPartitionFilter(org.apache.pig.Expression)
   * @throws UnsupportedOperationException
   */
  @Override
  public void setPartitionFilter(Expression expression) throws IOException {
    throw new UnsupportedOperationException();
  }

  @Override
  public void setLocation(String location, Job job) throws IOException {
    Preconditions.checkNotNull(location, "Location is null");
    Preconditions.checkNotNull(job, "Job is null");
    Path inputPath = new Path(location);
    FileInputFormat.setInputPaths(job, inputPath);
    readKey = Boolean.parseBoolean(getContextProperty(READ_KEY_PARAM, "true"));
    readValue = Boolean.parseBoolean(getContextProperty(READ_VALUE_PARAM, "true"));
  }

  @Override
  @SuppressWarnings({ "rawtypes", "unchecked" })
  public void prepareToRead(RecordReader reader, PigSplit split) throws IOException {
    this.reader = reader;
  }

  @Override
  public Tuple getNext() throws IOException {
    try {
      if (!reader.nextKeyValue())
        return null;
      List<Object> tuple = tuple0;
      if (readKey) {
        if (readValue) {
          tuple = tuple2;
          tuple.set(0, getCurrentKeyObject());
          tuple.set(1, getCurrentValueObject());
        } else {
          tuple = tuple1;
          tuple.set(0, getCurrentKeyObject());
        }
      } else if (readValue) {
        tuple = tuple1;
        tuple.set(0, getCurrentValueObject());
      }
      return tupleFactory.newTupleNoCopy(tuple);
    } catch (EOFException e) {
      if (!otherArguments.hasOption(SKIP_EOF_ERRORS_PARAM)) {
        throw e;
      }

      /*
       * Prefer to keep reading rather than causing the job to fail when it hits a file still being
       * written.
       */
      LOG.warn("EOFException encountered while reading input", e);
      counterHelper.incrCounter(Counter.EOFException, 1L);
    } catch (InterruptedException e) {
      throw new ExecException("Error while reading input", 6018, PigException.REMOTE_ENVIRONMENT, e);
    }

    return null;
  }

  private Object getCurrentKeyObject() throws IOException, InterruptedException {
    DataInputBuffer ibuf = reader.getCurrentKey();
    keyDataByteArray.set(Arrays.copyOf(ibuf.getData(), ibuf.getLength()));
    return keyConverter.bytesToObject(keyDataByteArray);
  }

  private Object getCurrentValueObject() throws IOException, InterruptedException {
    DataInputBuffer ibuf = reader.getCurrentValue();
    valueDataByteArray.set(Arrays.copyOf(ibuf.getData(), ibuf.getLength()));
    return valueConverter.bytesToObject(valueDataByteArray);
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_2ad1a24_abcabcd/rev_2ad1a24-abcabcd/src/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
=======
package com.twitter.elephantbird.pig.util;

import java.nio.ByteBuffer;
import java.util.Arrays;
import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
import org.apache.pig.LoadFunc;
import org.apache.pig.backend.executionengine.ExecException;
import org.apache.pig.data.BagFactory;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.DataByteArray;
import org.apache.pig.data.DataType;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
import org.apache.thrift.TBase;
import org.apache.thrift.protocol.TType;

import com.google.common.collect.Lists;
import com.twitter.elephantbird.pig.load.ThriftPigLoader;
import com.twitter.elephantbird.thrift.TStructDescriptor;
import com.twitter.elephantbird.thrift.TStructDescriptor.Field;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

/**
 * <li> converts a Thrift struct to a Pig tuple
 * <li> utilities to provide schema for Pig loaders and Pig scripts
 */
public class ThriftToPig<M extends TBase<?, ?>> {

  public static final Logger LOG = LogManager.getLogger(ThriftToPig.class);

  private static BagFactory bagFactory = BagFactory.getInstance();
  private static TupleFactory tupleFactory  = TupleFactory.getInstance();

  private TStructDescriptor structDesc;

  public static <M extends TBase<?, ?>> ThriftToPig<M> newInstance(Class<M> tClass) {
    return new ThriftToPig<M>(tClass);
  }

  public static <M extends TBase<?, ?>> ThriftToPig<M> newInstance(TypeRef<M> typeRef) {
    return new ThriftToPig<M>(typeRef.getRawClass());
  }

  public ThriftToPig(Class<M> tClass) {
    structDesc = TStructDescriptor.getInstance(tClass);
  }

  public TStructDescriptor getTStructDescriptor() {
    return structDesc;
  }

  /**
   * Converts a thrift object to Pig tuple.
   * All the fields are deserialized.
   * It might be better to use getLazyTuple() if not all fields
   * are required.
   */
  public Tuple getPigTuple(M thriftObj) {
    return toTuple(structDesc, thriftObj);
  }

  /**
   * Similar to {@link #getPigTuple(TBase)}. This delays
   * serialization of tuple contents until they are requested.
   * @param thriftObj
   * @return
   */
  public Tuple getLazyTuple(M thriftObj) {
    return new LazyTuple(structDesc, thriftObj);
  }

  @SuppressWarnings("rawtypes")
  private static <T extends TBase>Tuple toTuple(TStructDescriptor tDesc, T tObj) {
    int size = tDesc.getFields().size();
    Tuple tuple = tupleFactory.newTuple(size);
    for (int i=0; i<size; i++) {
      Field field = tDesc.getFieldAt(i);
      Object value = tDesc.getFieldValue(i, tObj);
      try {
        tuple.set(i, toPigObject(field, value, false));
      } catch (ExecException e) { // not expected
        throw new RuntimeException(e);
      }
    }
    return tuple;
  }

  @SuppressWarnings("unchecked")
  public static Object toPigObject(Field field, Object value, boolean lazy) {
    if (value == null) {
      return null;
    }

    switch (field.getType()) {
    case TType.BOOL:
      return Integer.valueOf((Boolean)value ? 1 : 0);
    case TType.BYTE :
      return Integer.valueOf((Byte)value);
    case TType.I16 :
      return Integer.valueOf((Short)value);
    case TType.STRING:
      return stringTypeToPig(value);
    case TType.STRUCT:
      if (lazy) {
        return new LazyTuple(field.gettStructDescriptor(), (TBase<?, ?>)value);
      } else {
        return toTuple(field.gettStructDescriptor(), (TBase<?, ?>)value);
      }
    case TType.MAP:
      return toPigMap(field, (Map<Object, Object>)value, lazy);
    case TType.SET:
      return toPigBag(field.getSetElemField(), (Collection<Object>)value, lazy);
    case TType.LIST:
      return toPigBag(field.getListElemField(), (Collection<Object>)value, lazy);
    case TType.ENUM:
      return value.toString();
    default:
      // standard types : I32, I64, DOUBLE, etc.
      return value;
    }
  }

  /**
   * TType.STRING is a mess in Thrift. It could be byte[], ByteBuffer,
   * or even a String!.
   */
  private static Object stringTypeToPig(Object value) {
    if (value instanceof String) {
      return value;
    }
    if (value instanceof byte[]) {
      byte[] buf = (byte[])value;
      return new DataByteArray(Arrays.copyOf(buf, buf.length));
    }
    if (value instanceof ByteBuffer) {
      ByteBuffer bin = (ByteBuffer)value;
      byte[] buf = new byte[bin.remaining()];
      bin.mark();
      bin.get(buf);
      bin.reset();
      return new DataByteArray(buf);
    }
    return null;
  }

  private static Map<String, Object> toPigMap(Field field,
                                              Map<Object, Object> map,
                                              boolean lazy) {
    // PIG map's key always a String. just use toString() and hope
    // things would work out ok.
    HashMap<String, Object> out = new HashMap<String, Object>(map.size());
    Field valueField = field.getMapValueField();
    for(Entry<Object, Object> e : map.entrySet()) {
      Object prev = out.put(e.getKey().toString(),
                            toPigObject(valueField, e.getValue(), lazy));
      if (prev != null) {
        String msg = "Duplicate keys while converting to String while "
          + " processing map " + field.getName() + " (key type : "
          + field.getMapKeyField().getType() + " value type : "
          + field.getMapValueField().getType() + ")";
        LOG.warn(msg);
        throw new RuntimeException(msg);
      }
    }
    return out;
  }

  private static DataBag toPigBag(Field field,
                                  Collection<Object> values,
                                  boolean lazy) {
    List<Tuple> tuples = Lists.newArrayListWithExpectedSize(values.size());
    for(Object value : values) {
      Object pValue = toPigObject(field, value, lazy);
      if (pValue instanceof Tuple) { // DataBag should contain Tuples
        tuples.add((Tuple)pValue);
      } else {
        tuples.add(tupleFactory.newTuple(pValue));
      }
    }
    return bagFactory.newDefaultBag(tuples);
  }

  @SuppressWarnings("serial")
  /**
   * Delays serialization of Thrift fields until they are requested.
   */
  private static class LazyTuple extends AbstractLazyTuple {
    /* NOTE : This is only a partial optimization. The other part
     * is to avoid deserialization of the Thrift fields from the
     * binary buffer.
     *
     * Currently TDeserializer allows deserializing just one field,
     * psuedo-skipping over the fields before it.
     * But if we are going deserialize 5 fields out of 20, we will be
     * skipping over same set of fields multiple times. OTOH this might
     * still be better than a full deserialization.
     *
     * We need to write our own version of TBinaryProtocol that truly skips.
     * Even TDeserializer 'skips'/ignores only after deserializing fields.
     * (e.g. Strings, Integers, buffers etc).
     */
    private TBase<?, ?> tObject;
    private TStructDescriptor desc;

    LazyTuple(TStructDescriptor desc, TBase<?, ?> tObject) {
      initRealTuple(desc.getFields().size());
      this.tObject = tObject;
      this.desc = desc;
    }

    @Override
    protected Object getObjectAt(int index) {
      Field field = desc.getFieldAt(index);
      return toPigObject(field, desc.getFieldValue(index, tObject), true);
    }
  }

  /**
   * Returns Pig schema for the Thrift struct.
   */
  public static Schema toSchema(Class<? extends TBase<?, ?>> tClass) {
    return toSchema(TStructDescriptor.getInstance(tClass));
  }

  public Schema toSchema() {
    return toSchema(structDesc);
  }

  public static Schema toSchema(TStructDescriptor tDesc ) {
    Schema schema = new Schema();

    try {
      for(Field field : tDesc.getFields()) {
        schema.add(singleFieldToFieldSchema(field.getName(), field));
      }
    } catch (FrontendException t) {
      throw new RuntimeException(t);
    }

    return schema;
  }

  /**
   * return {@link FieldSchema} for a given field.
   */
  private static FieldSchema singleFieldToFieldSchema(String fieldName, Field field) throws FrontendException {
    //TODO we should probably implement better naming, the current system is pretty nonsensical now
    switch (field.getType()) {
      case TType.STRUCT:
        return new FieldSchema(fieldName, toSchema(field.gettStructDescriptor()), DataType.TUPLE);
      case TType.LIST:
        return new FieldSchema(fieldName, singleFieldToTupleSchema(fieldName + "_tuple", field.getListElemField()), DataType.BAG);
      case TType.SET:
        return new FieldSchema(fieldName, singleFieldToTupleSchema(fieldName + "_tuple", field.getSetElemField()), DataType.BAG);
      case TType.MAP:
        if (field.getMapKeyField().getType() != TType.STRING
            && field.getMapKeyField().getType() != TType.ENUM) {
          LOG.warn("Using a map with non-string key for field " + field.getName()
              + ". while converting to PIG Tuple, toString() is used for the key."
              + " It could result in incorrect maps.");
        }
        return new FieldSchema(fieldName, new Schema(singleFieldToFieldSchema(null, field.getMapValueField())), DataType.MAP);
      default:
        return new FieldSchema(fieldName, null, getPigDataType(field));
    }
  }

  /**
   * A helper function which wraps a Schema in a tuple (for Pig bags) if our version of pig makes it necessary
   */
  private static Schema wrapInTupleIfPig9(Schema schema) throws FrontendException {
      if (PigUtil.Pig9orNewer) {
          return new Schema(new FieldSchema("t",schema,DataType.TUPLE));
      } else {
          return schema;
      }
  }

  /**
   * Returns a schema with single tuple (for Pig bags).
   */
  private static Schema singleFieldToTupleSchema(String fieldName, Field field) throws FrontendException {
    switch (field.getType()) {
      case TType.STRUCT:
        return wrapInTupleIfPig9(toSchema(field.gettStructDescriptor()));
      case TType.LIST:
      case TType.SET:
      case TType.MAP:
        return wrapInTupleIfPig9(new Schema(singleFieldToFieldSchema(fieldName, field)));
      default:
        return wrapInTupleIfPig9(new Schema(new FieldSchema(fieldName, null, getPigDataType(field))));
    }
  }

  private static byte getPigDataType(Field field) {
    switch (field.getType()) {
      case TType.BOOL:
      case TType.BYTE:
      case TType.I16:
      case TType.I32:
        return DataType.INTEGER;
      case TType.ENUM:
        return DataType.CHARARRAY;
      case TType.I64:
        return DataType.LONG;
      case TType.DOUBLE:
        return DataType.DOUBLE;
      case TType.STRING:
        return field.isBuffer() ? DataType.BYTEARRAY : DataType.CHARARRAY;
      default:
        throw new IllegalArgumentException("Unexpected type where a simple type is expected : " + field.getType());
    }
  }

  /**
   * Turn a Thrift Struct into a loading schema for a pig script.
   */
  public static String toPigScript(Class<? extends TBase<?, ?>> thriftClass,
                                   Class<? extends LoadFunc> pigLoader) {
    StringBuilder sb = new StringBuilder();
    /* we are commenting out explicit schema specification. The schema is
     * included mainly to help the readers of the pig script. Pig learns the
     * schema directly from the loader.
     * If explicit schema is not commented, we might have surprising results
     * when a Thrift class (possibly in control of another team) changes,
     * but the Pig script is not updated. Commenting it out avoids this.
     */
    StringBuilder prefix = new StringBuilder("       --  ");
    sb.append("raw_data = load '$INPUT_FILES' using ")
      .append(pigLoader.getName())
      .append("('")
      .append(thriftClass.getName())
      .append("');\n")
      .append(prefix)
      .append("as ");
    prefix.append("   ");

    try {
      stringifySchema(sb, toSchema(thriftClass), DataType.TUPLE, prefix);
    } catch (FrontendException e) {
      throw new RuntimeException(e);
    }

    sb.append("\n");
    return sb.toString();
  }

  /**
   * Print formatted schema. This is a modified version of
   * {@link Schema#stringifySchema(StringBuilder, Schema, byte)}
   * with support for (indented) pretty printing.
   */
  // This is used for building up output string
  // type can only be BAG or TUPLE
  public static void stringifySchema(StringBuilder sb,
                                     Schema schema,
                                     byte type,
                                     StringBuilder prefix)
                                          throws FrontendException{
      // this is a modified version of {@link Schema#stringifySchema(StringBuilder, Schema, byte)}
      if (type == DataType.TUPLE) {
          sb.append("(") ;
      }
      else if (type == DataType.BAG) {
          sb.append("{") ;
      }

      prefix.append("  ");
      sb.append("\n").append(prefix);

      if (schema == null) {
          sb.append("null") ;
      }
      else {
          boolean isFirst = true ;
          for (int i=0; i< schema.size() ;i++) {

              if (!isFirst) {
                  sb.append(",\n").append(prefix);
              }
              else {
                  isFirst = false ;
              }

              FieldSchema fs = schema.getField(i) ;

              if(fs == null) {
                  sb.append("null");
                  continue;
              }

              if (fs.alias != null) {
                  sb.append(fs.alias);
                  sb.append(": ");
              }

              if (DataType.isAtomic(fs.type)) {
                  sb.append(DataType.findTypeName(fs.type)) ;
              }
              else if ( (fs.type == DataType.TUPLE) ||
                        (fs.type == DataType.BAG) ) {
                  // safety net
                  if (schema != fs.schema) {
                      stringifySchema(sb, fs.schema, fs.type, prefix) ;
                  }
                  else {
                      throw new AssertionError("Schema refers to itself "
                                               + "as inner schema") ;
                  }
              } else if (fs.type == DataType.MAP) {
                sb.append(DataType.findTypeName(fs.type) + "[");
                if (fs.schema!=null)
                    stringifySchema(sb, fs.schema, fs.type, prefix);
                sb.append("]");
              } else {
                  sb.append(DataType.findTypeName(fs.type)) ;
              }
          }
      }

      prefix.setLength(prefix.length()-2);
      sb.append("\n").append(prefix);

      if (type == DataType.TUPLE) {
          sb.append(")") ;
      }
      else if (type == DataType.BAG) {
          sb.append("}") ;
      }
  }

  public static void main(String[] args) throws Exception {
    if (args.length > 0) {
      Class<? extends TBase<?, ?>> tClass = ThriftUtils.getTypeRef(args[0]).getRawClass();
      System.out.println(args[0] + " : " + toSchema(tClass).toString());
      System.out.println(toPigScript(tClass, ThriftPigLoader.class));
    }
  }
}>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/util/ThriftToDynamicProto.java;<<<<<<< MINE
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/util/ThriftToDynamicProto.java;<<<<<<< MINE
  private static final Logger LOG = LogManager.getLogger(ThriftToDynamicProto.class);
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/util/LzoUtils.java;<<<<<<< MINE
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
=======
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/util/LzoUtils.java;<<<<<<< MINE
  public static final Logger LOG = LogManager.getLogger(LzoUtils.class);
=======
  public static final Logger LOG = LoggerFactory.getLogger(LzoUtils.class);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/util/ThriftToProto.java;<<<<<<< MINE
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/util/ThriftToProto.java;<<<<<<< MINE
=======
@SuppressWarnings("rawtypes")
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/util/ThriftToProto.java;<<<<<<< MINE
  private static final Logger LOG = LogManager.getLogger(ThriftToProto.class);
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/mapreduce/output/LzoOutputFormat.java;<<<<<<< MINE
=======
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/mapreduce/output/LzoOutputFormat.java;<<<<<<< MINE
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;

=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/mapreduce/output/LzoOutputFormat.java;<<<<<<< MINE
  public static final Logger LOG = LogManager.getLogger(LzoOutputFormat.class);
=======
  public static final Logger LOG = LoggerFactory.getLogger(LzoOutputFormat.class);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/mapreduce/input/LzoGenericProtobufBlockInputFormat.java;<<<<<<< MINE
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/mapreduce/io/ThriftConverter.java;<<<<<<< MINE
import com.twitter.elephantbird.thrift.ThriftBinaryDeserializer;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/mapreduce/io/ThriftConverter.java;<<<<<<< MINE
=======
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/core/src/main/java/com/twitter/elephantbird/mapreduce/io/ThriftConverter.java;<<<<<<< MINE
  public static final Logger LOG = LogManager.getLogger(ThriftConverter.class);
=======
  public static final Logger LOG = LoggerFactory.getLogger(ThriftConverter.class);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/rcfile/src/main/java/com/twitter/elephantbird/mapreduce/output/RCFileThriftOutputFormat.java;<<<<<<< MINE
          if (tObj.isSet(fd.getFieldIdEnum())) {
            ThriftUtils.writeFieldNoTag(tProto, fd, tDesc.getFieldValue(i, tObj));
          }
=======
          ThriftUtils.writeFieldNoTag(tProto, fd, tDesc.getFieldValue(i, tObj));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/rcfile/src/main/java/com/twitter/elephantbird/mapreduce/output/RCFileProtobufOutputFormat.java;<<<<<<< MINE
=======
            // match protobuf's serialization (write only if hasField() is true)
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/rcfile/src/main/java/com/twitter/elephantbird/mapreduce/input/RCFileThriftInputFormat.java;<<<<<<< MINE
=======
        // else no need to set default value since any default value
        // would have been serialized when this record was written.
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/rcfile/src/main/java/com/twitter/elephantbird/mapreduce/input/RCFileProtobufInputFormat.java;<<<<<<< MINE
=======
        FieldDescriptor fd = knownRequiredFields.get(i);
        Object value = null;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/rcfile/src/main/java/com/twitter/elephantbird/mapreduce/input/RCFileProtobufInputFormat.java;<<<<<<< MINE
          Object value = Protobufs.readFieldNoTag(
=======
          value = Protobufs.readFieldNoTag(
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/rcfile/src/main/java/com/twitter/elephantbird/mapreduce/input/RCFileProtobufInputFormat.java;<<<<<<< MINE
          tuple.set(i, protoToPig.fieldToPig(knownRequiredFields.get(i), value));
=======
        } else if (fd.getType() != FieldDescriptor.Type.MESSAGE) {
          value = fd.getDefaultValue();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/rcfile/src/main/java/com/twitter/elephantbird/mapreduce/input/RCFileProtobufInputFormat.java;<<<<<<< MINE
=======
        tuple.set(i, protoToPig.fieldToPig(fd, value));
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/pig/src/main/java/com/twitter/elephantbird/pig/store/LzoThriftBlockPigStorage.java;<<<<<<< MINE
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/pig/src/main/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/pig/src/main/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
=======
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/pig/src/main/java/com/twitter/elephantbird/pig/util/ThriftToPig.java;<<<<<<< MINE
  public static final Logger LOG = LogManager.getLogger(ThriftToPig.class);
=======
  public static final Logger LOG = LoggerFactory.getLogger(ThriftToPig.class);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/pig/src/main/java/com/twitter/elephantbird/pig/piggybank/JsonStringToMap.java;<<<<<<< MINE
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/pig/src/main/java/com/twitter/elephantbird/pig/piggybank/JsonStringToMap.java;<<<<<<< MINE
=======
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_56e97f9_c1ca987/rev_56e97f9-c1ca987/pig/src/main/java/com/twitter/elephantbird/pig/piggybank/JsonStringToMap.java;<<<<<<< MINE
  private static final Logger LOG = LogManager.getLogger(JsonStringToMap.class);
=======
  private static final Logger LOG = LoggerFactory.getLogger(JsonStringToMap.class);
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_643ff62_8dd1811/rev_643ff62-8dd1811/src/java/com/twitter/elephantbird/mapreduce/output/RCFileThriftOutputFormat.java;<<<<<<< MINE
package com.twitter.elephantbird.mapreduce.output;

import java.io.IOException;
import java.util.List;
import java.util.Map;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hive.serde2.ByteStream;
import org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable;
import org.apache.hadoop.hive.serde2.columnar.BytesRefWritable;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.thrift.TBase;
import org.apache.thrift.TException;
import org.apache.thrift.protocol.TBinaryProtocol;
import org.apache.thrift.protocol.TField;
import org.apache.thrift.protocol.TProtocolUtil;
import org.apache.thrift.protocol.TType;
import org.apache.thrift.transport.TIOStreamTransport;
import org.apache.thrift.transport.TMemoryInputTransport;

import com.google.common.collect.ImmutableMap;
import com.google.common.collect.Maps;
import com.twitter.data.proto.Misc.ColumnarMetadata;
import com.twitter.elephantbird.mapreduce.io.ThriftWritable;
import com.twitter.elephantbird.thrift.TStructDescriptor;
import com.twitter.elephantbird.thrift.TStructDescriptor.Field;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.ThriftUtils;
import com.twitter.elephantbird.util.TypeRef;

/**
 * OutputFormat for storing Thrift objects in RCFile.<p>
 *
 * Each of the top level fields is stored in a separate column.
 * Thrift field ids are stored in RCFile metadata.<p>
 *
 * The user can write either a {@link ThriftWritable} with the Thrift object
 * or a {@link BytesWritable} with serialized Thrift bytes. The latter
 * ensures that all the fields are preserved even if the current Thrift
 * definition does not match the definition represented in the serialized bytes.
 * Any fields not recognized by current Thrift class are stored in the last
 * column.
 */
public class RCFileThriftOutputFormat extends RCFileOutputFormat {

  // typeRef is only required for setting metadata for the RCFile
  private TypeRef<? extends TBase<?, ?>> typeRef;
  private TStructDescriptor tDesc;
  private List<Field> tFields;
  private int numColumns;

  private BytesRefArrayWritable rowWritable = new BytesRefArrayWritable();
  private BytesRefWritable[] colValRefs;

  /** internal, for MR use only. */
  public RCFileThriftOutputFormat() {
  }

  public RCFileThriftOutputFormat(TypeRef<? extends TBase<?, ?>> typeRef) { // for PigLoader etc.
    this.typeRef = typeRef;
    init();
  }

  private void init() {
    tDesc = TStructDescriptor.getInstance(typeRef.getRawClass());
    tFields = tDesc.getFields();
    numColumns = tFields.size() + 1; // known fields + 1 for unknown fields
    colValRefs = new BytesRefWritable[numColumns];

    for (int i = 0; i < numColumns; i++) {
      colValRefs[i] = new BytesRefWritable();
      rowWritable.set(i, colValRefs[i]);
    }
  }

  protected ColumnarMetadata makeColumnarMetadata() {
    ColumnarMetadata.Builder metadata = ColumnarMetadata.newBuilder();

    metadata.setClassname(typeRef.getRawClass().getName());
    for(Field fd : tDesc.getFields()) {
      metadata.addFieldId(fd.getFieldId());
    }
    metadata.addFieldId(-1); // -1 for unknown fields

    return metadata.build();
  }

  private class ProtobufWriter extends RCFileOutputFormat.Writer {

    private ByteStream.Output byteStream = new ByteStream.Output();
    private TBinaryProtocol tProto = new TBinaryProtocol(
                                        new TIOStreamTransport(byteStream));

    // used when deserializing thrift bytes
    private Map<Short, Integer> idMap;
    private TMemoryInputTransport mTransport;
    private TBinaryProtocol skipProto;

    ProtobufWriter(TaskAttemptContext job) throws IOException {
      super(RCFileThriftOutputFormat.this, job, Protobufs.toText(makeColumnarMetadata()));
    }

    @Override @SuppressWarnings("unchecked")
    public void write(NullWritable key, Writable value) throws IOException, InterruptedException {
      try {
        if (value instanceof BytesWritable) {
          // TODO: handled errors
          fromBytes((BytesWritable)value);
        } else {
          fromObject((TBase<?, ?>)((ThriftWritable)value).get());
        }
      } catch (TException e) {
        // might need to tolerate a few errors.
        throw new IOException(e);
      }

      super.write(null, rowWritable);
    }

    @SuppressWarnings("unchecked")
    private void fromObject(TBase tObj)
                    throws IOException, InterruptedException, TException {

      byteStream.reset(); // reinitialize the byteStream if buffer is too large?
      int startPos = 0;

      // top level fields are split across the columns.
      for (int i=0; i < numColumns; i++) {

        if (i < (numColumns - 1)) {

          Field fd = tFields.get(i);
          if (tObj.isSet(fd.getFieldIdEnum())) {
            ThriftUtils.writeFieldNoTag(tProto, fd, tDesc.getFieldValue(i, tObj));
          }

        } // else { }  : no 'unknown fields' in thrift object

        colValRefs[i].set(byteStream.getData(),
                          startPos,
                          byteStream.getCount() - startPos);
        startPos = byteStream.getCount();
      }
    }

    /**
     * extract serialized bytes for each field, including unknown fields and
     * store those byes in columns.
     */
    private void fromBytes(BytesWritable bytesWritable)
                       throws IOException, InterruptedException, TException {

      if (mTransport == null) {
        initIdMap();
        mTransport = new TMemoryInputTransport();
        skipProto = new TBinaryProtocol(mTransport);
      }

      byte[] bytes = bytesWritable.getBytes();
      mTransport.reset(bytes, 0, bytesWritable.getLength());
      byteStream.reset();

      // set all the fields to null
      for(BytesRefWritable ref : colValRefs) {
        ref.set(bytes, 0, 0);
      }

      skipProto.readStructBegin();

      while (true) {
        int start = mTransport.getBufferPosition();

        TField field = skipProto.readFieldBegin();
        if (field.type == TType.STOP) {
          break;
        }

        int fieldStart = mTransport.getBufferPosition();

        // skip still creates and copies primitive objects (String, buffer, etc)
        // skipProto could override readString() and readBuffer() to avoid that.
        TProtocolUtil.skip(skipProto, field.type);

        int end = mTransport.getBufferPosition();

        Integer idx = idMap.get(field.id);

        if (idx != null && field.type == tFields.get(idx).getType()) {
          // known field
          colValRefs[idx].set(bytes, fieldStart, end-fieldStart);
        } else {
          // unknown field, copy the bytes to last column (with field id)
          byteStream.write(bytes, start, end-start);
        }
      }

      if (byteStream.getCount() > 0) {
        byteStream.write(TType.STOP);
        colValRefs[colValRefs.length-1].set(byteStream.getData(),
                                            0,
                                            byteStream.getCount());
      }
    }

    private void initIdMap() {
      idMap = Maps.newHashMap();
      for(int i=0; i<tFields.size(); i++) {
        idMap.put(tFields.get(i).getFieldId(), i);
      }
      idMap = ImmutableMap.copyOf(idMap);
    }
  }

  /**
   * Stores supplied class name in configuration. This configuration is
   * read on the remote tasks to initialize the output format correctly.
   */
  public static void setClassConf(Class<? extends TBase<?, ?> > thriftClass, Configuration conf) {
    ThriftUtils.setClassConf(conf, RCFileThriftOutputFormat.class, thriftClass);
  }

  @Override
  public RecordWriter<NullWritable, Writable>
    getRecordWriter(TaskAttemptContext job) throws IOException, InterruptedException {

    if (typeRef == null) {
      typeRef = ThriftUtils.getTypeRef(job.getConfiguration(), RCFileProtobufOutputFormat.class);
      init();
    }

    RCFileOutputFormat.setColumnNumber(job.getConfiguration(), numColumns);
    return new ProtobufWriter(job);
  }
}=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_643ff62_8dd1811/rev_643ff62-8dd1811/src/java/com/twitter/elephantbird/mapreduce/output/RCFileOutputFormat.java;<<<<<<< MINE
package com.twitter.elephantbird.mapreduce.output;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.hive.ql.io.RCFile;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.io.SequenceFile.Metadata;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.io.compress.GzipCodec;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.ReflectionUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.twitter.elephantbird.pig.util.RCFileUtil;

/**
 * Hive's {@link org.apache.hadoop.hive.ql.io.RCFileOutputFormat} is written for
 * deprecated OutputFormat. Pig requires newer OutputFormat.
 * In addition RCFileOutputFormat's functionality this class adds RCFile
 * metadata support.
 *
 * TODO: contribute this to PIG.
 */

public class RCFileOutputFormat extends FileOutputFormat<NullWritable, Writable> {

  private static final Logger LOG = LoggerFactory.getLogger(RCFileOutputFormat.class);

  // in case we need different compression from global default compression
  public static String COMPRESSION_CODEC_CONF = "elephantbird.rcfile.output.compression.codec";

  public static String DEFAULT_EXTENSION = ".rc";
  public static String EXTENSION_OVERRIDE_CONF = "elephantbird.refile.output.filename.extension"; // "none" disables it.

  /**
   * set number of columns into the given configuration.
   *
   * @param conf
   *          configuration instance which need to set the column number
   * @param columnNum
   *          column number for RCFile's Writer
   *
   */
  public static void setColumnNumber(Configuration conf, int columnNum) {
    assert columnNum > 0;
    conf.setInt(RCFile.COLUMN_NUMBER_CONF_STR, columnNum);
  }

  /**
   * Returns the number of columns set in the conf for writers.
   *
   * @param conf
   * @return number of columns for RCFile's writer
   */
  public static int getColumnNumber(Configuration conf) {
    return conf.getInt(RCFile.COLUMN_NUMBER_CONF_STR, 0);
  }

  protected RCFile.Writer createRCFileWriter(TaskAttemptContext job,
                                             Text columnMetadata)
                                             throws IOException {
    Configuration conf = job.getConfiguration();

    // override compression codec if set.
    String codecOverride = conf.get(COMPRESSION_CODEC_CONF);
    if (codecOverride != null) {
      conf.setBoolean("mapred.output.compress", true);
      conf.set("mapred.output.compression.codec", codecOverride);
    }

    CompressionCodec codec = null;
    if (getCompressOutput(job)) {
      Class<? extends CompressionCodec> codecClass = getOutputCompressorClass(job, GzipCodec.class);
      codec = (CompressionCodec) ReflectionUtils.newInstance(codecClass, conf);
    }

    Metadata metadata = null;
    if (columnMetadata != null) {
      metadata = new Metadata();
      metadata.set(new Text(RCFileUtil.COLUMN_METADATA_PROTOBUF_KEY), columnMetadata);
    }

    String ext = conf.get(EXTENSION_OVERRIDE_CONF, DEFAULT_EXTENSION);
    Path file = getDefaultWorkFile(job, ext.equalsIgnoreCase("none") ? null : ext);

    LOG.info("writing to rcfile " + file.toString());

    return new RCFile.Writer(file.getFileSystem(conf), conf, file, job, metadata, codec);
  }

  /**
   * RecordWriter wrapper around an RCFile.Writer
   */
  static protected class Writer extends RecordWriter<NullWritable, Writable> {

    private RCFile.Writer rcfile;

    protected Writer(RCFileOutputFormat outputFormat,
                     TaskAttemptContext job,
                     Text columnMetadata) throws IOException {
      rcfile = outputFormat.createRCFileWriter(job, columnMetadata);
    }

    @Override
    public void close(TaskAttemptContext context) throws IOException, InterruptedException {
      rcfile.close();
    }

    @Override
    public void write(NullWritable key, Writable value) throws IOException, InterruptedException {
      rcfile.append(value);
      // add counters
    }
  }

  @Override
  public RecordWriter<NullWritable, Writable> getRecordWriter(
      TaskAttemptContext job) throws IOException, InterruptedException {
    return new Writer(this, job, null);
  }
}=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_643ff62_8dd1811/rev_643ff62-8dd1811/src/java/com/twitter/elephantbird/mapreduce/output/RCFileProtobufOutputFormat.java;<<<<<<< MINE
package com.twitter.elephantbird.mapreduce.output;

import java.io.IOException;
import java.util.List;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hive.serde2.ByteStream;
import org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable;
import org.apache.hadoop.hive.serde2.columnar.BytesRefWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;

import com.google.protobuf.CodedOutputStream;
import com.google.protobuf.Message;
import com.google.protobuf.Descriptors.FieldDescriptor;
import com.google.protobuf.Message.Builder;
import com.twitter.data.proto.Misc.ColumnarMetadata;
import com.twitter.elephantbird.mapreduce.io.ProtobufWritable;
import com.twitter.elephantbird.util.Protobufs;
import com.twitter.elephantbird.util.TypeRef;

/**
 * OutputFormat for storing protobufs in RCFile.<p>
 *
 * Each of the top level fields is stored in a separate column.
 * The protobuf field numbers are stored in RCFile metadata.<p>
 *
 * A protobuf message can contain <a href="https://developers.google.com/protocol-buffers/docs/proto#updating">
 * "unknown fields"</a>. These fields are preserved and stored
 * in the last column. e.g. if protobuf A with 4 fields (a, b, c, d) is
 * serialized and when it is deserialized A has only 3 fields (a, c, d),
 * then 'b' is carried over as an unknown field.
 */
public class RCFileProtobufOutputFormat extends RCFileOutputFormat {

  /* typeRef is only required for setting metadata for the RCFile
   * if we delay file creation until the first row is written,
   * this info could be derived from protobuf being written.
   */
  private TypeRef<? extends Message> typeRef;
  private List<FieldDescriptor> msgFields;
  private int numColumns;

  private BytesRefArrayWritable rowWritable = new BytesRefArrayWritable();
  private BytesRefWritable[] colValRefs;
  private ByteStream.Output byteStream = new ByteStream.Output();
  private CodedOutputStream protoStream = CodedOutputStream.newInstance(byteStream);

  /** internal, for MR use only. */
  public RCFileProtobufOutputFormat() {
  }

  public RCFileProtobufOutputFormat(TypeRef<? extends Message> typeRef) { // for PigLoader etc.
    this.typeRef = typeRef;
    init();
  }

  private void init() {
    Builder msgBuilder = Protobufs.getMessageBuilder(typeRef.getRawClass());
    msgFields = msgBuilder.getDescriptorForType().getFields();
    numColumns = msgFields.size() + 1; // known fields + 1 for unknown fields
    colValRefs = new BytesRefWritable[numColumns];

    for (int i = 0; i < numColumns; i++) {
      colValRefs[i] = new BytesRefWritable();
      rowWritable.set(i, colValRefs[i]);
    }
  }

  protected ColumnarMetadata makeColumnarMetadata() {
    ColumnarMetadata.Builder metadata = ColumnarMetadata.newBuilder();

    metadata.setClassname(typeRef.getRawClass().getName());
    for(FieldDescriptor fd : msgFields) {
      metadata.addFieldId(fd.getNumber());
    }
    metadata.addFieldId(-1); // -1 for unknown fields

    return metadata.build();
  }

  private class ProtobufWriter extends RCFileOutputFormat.Writer {

    ProtobufWriter(TaskAttemptContext job) throws IOException {
      super(RCFileProtobufOutputFormat.this, job, Protobufs.toText(makeColumnarMetadata()));
    }

    @Override
    public void write(NullWritable key, Writable value) throws IOException, InterruptedException {
      @SuppressWarnings("unchecked")
      Message msg = ((ProtobufWritable<Message>)value).get();

      protoStream.flush();
      byteStream.reset(); // reinitialize the byteStream if buffer is too large?
      int startPos = 0;

      // top level fields are split across the columns.
      for (int i=0; i < numColumns; i++) {

        if (i < (numColumns - 1)) {

          FieldDescriptor fd = msgFields.get(i);
          if (fd.isRepeated() || msg.hasField(fd)) {
            Protobufs.writeFieldNoTag(protoStream, fd, msg.getField(fd));
          }

        } else { // last column : write unknown fields
          msg.getUnknownFields().writeTo(protoStream); // could be empty
        }

        protoStream.flush();
        colValRefs[i].set(byteStream.getData(),
                          startPos,
                          byteStream.getCount() - startPos);
        startPos = byteStream.getCount();
      }

      super.write(null, rowWritable);
    }
  }

  /**
   * Stores supplied class name in configuration. This configuration is
   * read on the remote tasks to initialize the output format correctly.
   */
  public static void setClassConf(Class<? extends Message> protoClass, Configuration conf) {
    Protobufs.setClassConf(conf, RCFileProtobufOutputFormat.class, protoClass);
  }

  @Override
  public RecordWriter<NullWritable, Writable>
    getRecordWriter(TaskAttemptContext job) throws IOException, InterruptedException {

    if (typeRef == null) {
      typeRef = Protobufs.getTypeRef(job.getConfiguration(), RCFileProtobufOutputFormat.class);
      init();
    }

    RCFileOutputFormat.setColumnNumber(job.getConfiguration(), numColumns);
    return new ProtobufWriter(job);
  }

}=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_34cf049_2c0f0fe/rev_34cf049-2c0f0fe/rcfile/src/main/java/com/twitter/elephantbird/mapreduce/output/RCFileOutputFormat.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.RCFileUtil;
=======
import com.twitter.data.proto.Misc.ColumnarMetadata;
import com.twitter.elephantbird.util.RCFileUtil;
import com.twitter.elephantbird.util.Protobufs;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_6d28c12_2c0f0fe/rev_6d28c12-2c0f0fe/rcfile/src/main/java/com/twitter/elephantbird/mapreduce/input/RCFileProtobufInputFormat.java;<<<<<<< MINE
    private Message               msgInstance;
    private Builder               msgBuilder;
    private boolean               readUnknownsColumn = false;
    private List<FieldDescriptor> knownRequiredFields = Lists.newArrayList();
    private ArrayList<Integer>    columnsBeingRead = Lists.newArrayList();
=======
    protected Builder               msgBuilder;
    protected boolean               readUnknownsColumn = false;
    protected List<FieldDescriptor> knownRequiredFields = Lists.newArrayList();
    protected ArrayList<Integer>    columnsBeingRead = Lists.newArrayList();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_6d28c12_2c0f0fe/rev_6d28c12-2c0f0fe/rcfile/src/main/java/com/twitter/elephantbird/mapreduce/input/RCFileProtobufInputFormat.java;<<<<<<< MINE
      currentValue = builder.build();
      return currentValue;
    }

    /**
     * Returns a Tuple consisting of required fields with out creating
     * a Protobuf message at the top level.
     */
    public Tuple getCurrentTupleValue() throws IOException, InterruptedException {

      BytesRefArrayWritable byteRefs = getCurrentValue();
      if (byteRefs == null) {
        return null;
      }

      Tuple tuple = tf.newTuple(knownRequiredFields.size());

      for (int i=0; i < knownRequiredFields.size(); i++) {
        BytesRefWritable buf = byteRefs.get(columnsBeingRead.get(i));
        FieldDescriptor fd = knownRequiredFields.get(i);
        Object value = null;
        if (buf.getLength() > 0) {
          value = Protobufs.readFieldNoTag(
              CodedInputStream.newInstance(buf.getData(), buf.getStart(), buf.getLength()),
              knownRequiredFields.get(i),
              msgBuilder);
        } else { // use the value from default instance
          value = msgInstance.getField(fd);
        }
        tuple.set(i, protoToPig.fieldToPig(fd, value));
      }

      if (readUnknownsColumn) {
        // we can handle this if needed.
        throw new IOException("getCurrentTupleValue() is not supported when 'readUnknownColumns' is set");
      }

      return tuple;
=======
      return builder.build();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_923d61a_468dd30/rev_923d61a-468dd30/src/java/com/twitter/elephantbird/thrift/TStructDescriptor.java;<<<<<<< MINE
package com.twitter.elephantbird.thrift;

import java.nio.ByteBuffer;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import org.apache.thrift.TBase;
import org.apache.thrift.TEnum;
import org.apache.thrift.TException;
import org.apache.thrift.TFieldIdEnum;
import org.apache.thrift.TUnion;
import org.apache.thrift.meta_data.EnumMetaData;
import org.apache.thrift.meta_data.FieldMetaData;
import org.apache.thrift.meta_data.FieldValueMetaData;
import org.apache.thrift.meta_data.ListMetaData;
import org.apache.thrift.meta_data.MapMetaData;
import org.apache.thrift.meta_data.SetMetaData;
import org.apache.thrift.meta_data.StructMetaData;
import org.apache.thrift.protocol.TType;

import com.google.common.collect.ImmutableList;
import com.google.common.collect.ImmutableMap;
import com.google.common.collect.Maps;
import com.twitter.elephantbird.util.ThriftUtils;


/**
 * Expanded metadata of a Thrift class. The main purpose is
 * help recursive traversals of Thrift structs or objects
 * with the following :
 * <ul>
 *  <li> build much more detailed information about fields so that
 *       other iterators don't need to.
 *  <li> avoids runtime type checking while processing many objects of the
 *       same class (common case).
 *  <li> Handles different Thrift quirks.
 *
 */
public class TStructDescriptor {

  private static Map<Class<?>, TStructDescriptor> structMap = Maps.newHashMap();

  private List<Field> fields;
  private Class<? extends TBase<?, ?>> tClass;
  private boolean isUnion;

  public Class<? extends TBase<?, ?>> getThriftClass() {
    return tClass;
  }

  public TBase<?, ?> newThriftObject() throws TException {
    try {
      return tClass.newInstance();
    } catch (Exception e) { //not excpected
      throw new TException(e);
    }
  }
  /**
   * The list of fields returned is immutable.
   */
  public List<Field> getFields() {
    return fields;
  }

  public Field getFieldAt(int idx) {
    return fields.get(idx);
  }

  @SuppressWarnings("unchecked")
  public Object getFieldValue(int fieldIdx, TBase tObject) {
    /* Thrift 0.5 throws an NPE when the field is binary and
     * happens to be null. Otherwise user could just
     * invoke tObject.getFieldValue(field.getFieldIdEnum()).
     * Should revisit this once we move to a newer version.
     *
     * here, the assumption is the field is not null most of the
     * time. otherwise, rather than catching the exception, we
     * could cache 'BufferForFieldName()' method and invoke it.
     *
     * this also helps with unions.
     */
    Field field = fields.get(fieldIdx);
    try {
      if (isUnion && field.getFieldIdEnum() != ((TUnion<?, ?>)tObject).getSetField()) {
        return null;
      }
      return tObject.getFieldValue(field.getFieldIdEnum());
    } catch (NullPointerException e) {
      return null;
    }
  }

  /**
   * Creates a descriptor for a Thrift class
   */
  public static TStructDescriptor getInstance(Class<? extends TBase<?, ?>> tClass) {
    synchronized (structMap) {
      TStructDescriptor desc = structMap.get(tClass);
      if (desc == null) {
        desc = new TStructDescriptor();
        desc.tClass = tClass;
        structMap.put(tClass, desc);
        desc.build(tClass);
      }
      return desc;
    }
  }

  private TStructDescriptor() {
    // all the initialization is done in build().
  }

  private void build(Class<? extends TBase<?, ?>> tClass) {
    Map<? extends TFieldIdEnum, FieldMetaData> fieldMap = FieldMetaData.getStructMetaDataMap(tClass);
    Field[] arr = new Field[fieldMap.size()];

    isUnion = TUnion.class.isAssignableFrom(tClass);

    int idx = 0;
    for (Entry<? extends TFieldIdEnum, FieldMetaData> e : fieldMap.entrySet()) {
      arr[idx++] = new Field(e.getKey(),
                             e.getValue(),
                             e.getKey().getFieldName(),
                             tClass,
                             e.getValue().valueMetaData);
    }
    // make it immutable since users have access.
    fields = ImmutableList.copyOf(arr);
  }

  /**
   * returns 'enum name -> enum object' mapping.
   * Currently used for converting Tuple to a Thrift object.
   */
  static private Map<String, TEnum> extractEnumMap(Class<? extends TEnum> enumClass) {
    ImmutableMap.Builder<String, TEnum> builder = ImmutableMap.builder();
    for(TEnum e : enumClass.getEnumConstants()) {
      builder.put(e.toString(), e);
    }
    return builder.build();
  }

  /**
   * Maintains all the relevant info for a field
   */
  public static class Field {

    private final TFieldIdEnum fieldIdEnum;
    private final FieldMetaData fieldMetaData;
    private final short fieldId;
    private final String fieldName;
    private final FieldValueMetaData field;

    // following fields are set when they are relevant.
    private final Field listElemField;    // lists
    private final Field setElemField;     // sets
    private final Field mapKeyField;      // maps
    private final Field mapValueField;    // maps
    private final Map<String, TEnum> enumMap; // enums
    private final Map<Integer, TEnum> enumIdMap; // enums
    private final TStructDescriptor tStructDescriptor; // Structs
    private final boolean isBuffer_;  // strings


    @SuppressWarnings("unchecked") // for casting 'structClass' below
    private Field(TFieldIdEnum fieldIdEnum, FieldMetaData fieldMetaData, String fieldName, Class<?> enclosingClass,
                  FieldValueMetaData field) {
      // enclosingClass is only to check a TType.STRING is actually a buffer.
      this.fieldIdEnum = fieldIdEnum;
      this.fieldMetaData = fieldMetaData;
      this.fieldId = fieldIdEnum == null ? 1 : fieldIdEnum.getThriftFieldId();
      this.fieldName = fieldName;
      this.field = field;

      // common case, avoids type checks below.
      boolean simpleField = field.getClass() == FieldValueMetaData.class;

      if (!simpleField && field instanceof ListMetaData) {
        listElemField = new Field(null, null, fieldName + "_list_elem", null,
                                  ((ListMetaData)field).elemMetaData);
      } else {
        listElemField = null;
      }

      if (!simpleField && field instanceof MapMetaData) {
        mapKeyField = new Field(null, null, fieldName + "_map_key", null,
                                ((MapMetaData)field).keyMetaData);
        mapValueField = new Field(null, null, fieldName + "_map_value", null,
                            ((MapMetaData)field).valueMetaData);

      } else {
        mapKeyField = null;
        mapValueField = null;
      }

      if (!simpleField && field instanceof SetMetaData) {
        setElemField = new Field(null, null, fieldName + "_set_elem", null,
                                ((SetMetaData)field).elemMetaData);
      } else {
        setElemField = null;
      }

      if (!simpleField && field instanceof EnumMetaData) {
        enumMap = extractEnumMap(((EnumMetaData)field).enumClass);

        ImmutableMap.Builder<Integer, TEnum> builder = ImmutableMap.builder();
        for(TEnum e : enumMap.values()) {
          builder.put(e.getValue(), e);
        }
        enumIdMap = builder.build();
      } else {
        enumMap = null;
        enumIdMap = null;
      }

      if (field.isStruct()) {
        tStructDescriptor =
          getInstance((Class<? extends TBase<?, ?>>)
                      ((StructMetaData)field).structClass);

      } else {
        tStructDescriptor = null;
      }

      if (field.type == TType.STRING && enclosingClass != null) {
        // only Thrift 0.6 and above have explicit isBuffer() method.
        // until then a partial work around that works only if
        // the field is not inside a container.
        isBuffer_ =
          ThriftUtils.getFieldType(enclosingClass, fieldName) != String.class;
      } else {
        isBuffer_= false;
      }
    }

    public short getFieldId() {
      return fieldId;
    }

    public byte getType() {
      return field.type;
    }

    /**
     * This valid only for fields of a Struct. It is null for other fields
     * in containers like List.
     */
    public TFieldIdEnum getFieldIdEnum() {
      return fieldIdEnum;
    }

    public FieldValueMetaData getField() {
      return field;
    }

    public boolean isBuffer() {
      return isBuffer_;
    }

    public boolean isList() {
      return listElemField != null;
    }

    public Field getListElemField() {
      return listElemField;
    }

    public boolean isSet() {
      return setElemField != null;
    }

    public Field getSetElemField() {
      return setElemField;
    }

    public boolean isMap() {
      return mapKeyField != null;
    }

    public Field getMapKeyField() {
      return mapKeyField;
    }

    public Field getMapValueField() {
      return mapValueField;
    }

    public boolean isStruct() {
      return tStructDescriptor != null;
    }

    public TStructDescriptor gettStructDescriptor() {
      return tStructDescriptor;
    }

    public boolean isEnum() {
      return enumMap != null;
    }

    public TEnum getEnumValueOf(String name) {
      return enumMap.get(name);
    }

    public TEnum getEnumValueOf(int id) {
      return enumIdMap.get(id);
    }

    public String getName() {
      return fieldName;
    }

    public short getId() {
     return fieldId;
    }

    public FieldMetaData getFieldMetaData() {
      return fieldMetaData;
    }
  }
}=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_460cf9d_df176b3/rev_460cf9d-df176b3/core/src/test/java/com/twitter/elephantbird/mapreduce/input/TestLzoTextInputFormat.java;<<<<<<< MINE
=======

import com.twitter.elephantbird.util.CoreTestUtil;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_460cf9d_df176b3/rev_460cf9d-df176b3/rcfile/src/test/java/com/twitter/elephantbird/pig/load/TestRCFileProtobufStorage.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.UnitTestUtil;
import com.twitter.elephantbird.util.ContextUtil;
=======
import com.twitter.elephantbird.pig.util.PigTestUtil;
import com.twitter.elephantbird.util.CoreTestUtil;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_460cf9d_df176b3/rev_460cf9d-df176b3/rcfile/src/test/java/com/twitter/elephantbird/pig/load/TestRCFileProtobufStorage.java;<<<<<<< MINE
import org.apache.pig.ExecType;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_460cf9d_df176b3/rev_460cf9d-df176b3/rcfile/src/test/java/com/twitter/elephantbird/pig/load/TestRCFileThriftStorage.java;<<<<<<< MINE
import com.twitter.elephantbird.pig.util.UnitTestUtil;
import com.twitter.elephantbird.util.ContextUtil;
=======
import com.twitter.elephantbird.pig.util.PigTestUtil;
import com.twitter.elephantbird.util.CoreTestUtil;
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_460cf9d_df176b3/rev_460cf9d-df176b3/rcfile/src/test/java/com/twitter/elephantbird/pig/load/TestRCFileThriftStorage.java;<<<<<<< MINE
import org.apache.pig.ExecType;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_460cf9d_df176b3/rev_460cf9d-df176b3/pig/src/test/java/com/twitter/elephantbird/pig/util/AbstractTestWritableConverter.java;<<<<<<< MINE
import com.twitter.elephantbird.util.ContextUtil;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_460cf9d_df176b3/rev_460cf9d-df176b3/pig/src/test/java/com/twitter/elephantbird/pig/util/AbstractTestWritableConverter.java;<<<<<<< MINE
import org.apache.pig.ExecType;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_dec9394_814e05e/rev_dec9394-814e05e/core/src/main/java/com/twitter/elephantbird/thrift/TStructDescriptor.java;<<<<<<< MINE
import org.apache.thrift.meta_data.FieldValueMetaData;
import org.apache.thrift.meta_data.ListMetaData;
import org.apache.thrift.meta_data.MapMetaData;
import org.apache.thrift.meta_data.SetMetaData;
=======
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_c8c3348_ea96846/rev_c8c3348-ea96846/hadoop-compat/src/main/java/com/twitter/elephantbird/util/HadoopCompat.java;<<<<<<< MINE

      GET_CONFIGURATION_METHOD  = JobContext.class        .getMethod("getConfiguration");
      SET_STATUS_METHOD         = TaskAttemptContext.class.getMethod("setStatus", String.class);
      GET_TASK_ATTEMPT_ID       = TaskAttemptContext.class.getMethod("getTaskAttemptID");
      INCREMENT_COUNTER_METHOD  = Counter.class           .getMethod("increment", Long.TYPE);
      GET_COUNTER_VALUE_METHOD  = Counter.class           .getMethod("getValue");
      GET_JOB_ID_METHOD         = JobContext.class        .getMethod("getJobID");
      GET_JOB_NAME_METHOD       = JobContext.class        .getMethod("getJobName");
      GET_INPUT_SPLIT_METHOD    = MapContext.class        .getMethod("getInputSplit");

=======
      GET_CONFIGURATION_METHOD = Class.forName(PACKAGE+".JobContext")
                                    .getMethod("getConfiguration");
      SET_STATUS_METHOD = Class.forName(PACKAGE+".TaskAttemptContext")
                                    .getMethod("setStatus", String.class);
      GET_TASK_ATTEMPT_ID = Class.forName(PACKAGE+".TaskAttemptContext")
                                    .getMethod("getTaskAttemptID");
      INCREMENT_COUNTER_METHOD = Class.forName(PACKAGE+".Counter")
                                    .getMethod("increment", Long.TYPE);
      PROGRESS_METHOD = Class.forName(PACKAGE+".TaskAttemptContext")
                                    .getMethod("progress");

>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_9f1257c_88aca05/rev_9f1257c-88aca05/core/src/main/java/com/twitter/elephantbird/mapreduce/input/LzoBinaryBlockRecordReader.java;<<<<<<< MINE
    deserializer_ = reader.getProtoConverter();
=======
    deserializer_ = reader.getConverter();
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_9f1257c_88aca05/rev_9f1257c-88aca05/core/src/main/java/com/twitter/elephantbird/mapreduce/input/LzoBinaryBlockRecordReader.java;<<<<<<< MINE
      } catch (Throwable e) {
=======
      } catch (Exception e) {
>>>>>>> YOURS
/home/taes/taes/projects/elephant-bird/revisions/rev_9f1257c_88aca05/rev_9f1257c-88aca05/core/src/main/java/com/twitter/elephantbird/mapreduce/io/BinaryBlockReader.java;<<<<<<< MINE
  public BinaryConverter<M> getProtoConverter() {
=======
  public BinaryConverter<M> getConverter() {
>>>>>>> YOURS
